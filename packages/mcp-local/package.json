{
  "name": "nodebench-mcp",
  "version": "2.9.0",
  "description": "Make AI agents catch the bugs they normally ship. 129 MCP tools: progressive discovery with hybrid search, project boilerplate scaffolding, autonomous capability benchmarks (C-compiler pattern), structured research, 3-layer testing, quality gates, persistent knowledge, LLM calling, security analysis, platform bridge, model benchmarking, visual regression, report generation, academic paper writing, deterministic local file parsing (CSV/XLSX/PDF/DOCX/PPTX/ZIP/JSON/JSONL/TXT), Android flicker detection, and Figma flow analysis. v2.8: +3 progressive disclosure tools (discover_tools, get_tool_quick_ref, get_workflow_chain) +2 boilerplate tools (scaffold_nodebench_project, get_boilerplate_status) +3 benchmark tools (start_autonomy_benchmark, log_benchmark_milestone, complete_autonomy_benchmark) +9 local file tools (ZIP/DOCX/PPTX/JSON primitives). Every tool response auto-appends quickRef (what to do next). --preset lite (39), core (87), or full (129). Benchmarked: 13 issues caught, 26 blind spots prevented.",
  "type": "module",
  "bin": {
    "nodebench-mcp": "./dist/index.js"
  },
  "main": "./dist/index.js",
  "files": [
    "dist",
    "README.md",
    "NODEBENCH_AGENTS.md",
    "STYLE_GUIDE.md"
  ],
  "scripts": {
    "build": "tsc",
    "dev": "tsx src/index.ts",
    "test": "vitest run",
    "test:open-dataset": "vitest run src/__tests__/openDatasetParallelEval.test.ts",
    "test:open-dataset:toolbench": "vitest run src/__tests__/openDatasetParallelEvalToolbench.test.ts",
    "test:open-dataset:swebench": "vitest run src/__tests__/openDatasetParallelEvalSwebench.test.ts",
    "test:open-dataset:gaia": "vitest run src/__tests__/openDatasetParallelEvalGaia.test.ts",
    "test:open-dataset:all": "vitest run src/__tests__/openDatasetParallelEval.test.ts src/__tests__/openDatasetParallelEvalToolbench.test.ts src/__tests__/openDatasetParallelEvalSwebench.test.ts",
    "test:open-dataset:full": "vitest run src/__tests__/openDatasetParallelEval.test.ts src/__tests__/openDatasetParallelEvalToolbench.test.ts src/__tests__/openDatasetParallelEvalSwebench.test.ts src/__tests__/openDatasetParallelEvalGaia.test.ts",
    "bench:perf:compare": "cross-env NODEBENCH_RUN_PERF_COMPARE=1 vitest run src/__tests__/openDatasetPerfComparison.test.ts --reporter=verbose",
    "test:watch": "vitest",
    "dataset:bfcl:refresh": "tsx src/__tests__/fixtures/generateBfclLongContextFixture.ts",
    "dataset:toolbench:refresh": "tsx src/__tests__/fixtures/generateToolbenchInstructionFixture.ts",
    "dataset:swebench:refresh": "tsx src/__tests__/fixtures/generateSwebenchVerifiedFixture.ts",
    "dataset:gaia:refresh": "python src/__tests__/fixtures/generateGaiaLevel3Fixture.py",
    "dataset:gaia:capability:refresh": "python src/__tests__/fixtures/generateGaiaCapabilityFixture.py",
    "dataset:gaia:capability:files:refresh": "python src/__tests__/fixtures/generateGaiaCapabilityFilesFixture.py",
    "dataset:gaia:capability:media:refresh": "python src/__tests__/fixtures/generateGaiaCapabilityMediaFixture.py",
    "dataset:gaia:capability:audio:refresh": "python src/__tests__/fixtures/generateGaiaCapabilityAudioFixture.py",
    "verify": "node test-setup.mjs",
    "test:gaia:capability": "cross-env NODEBENCH_RUN_GAIA_CAPABILITY=1 vitest run src/__tests__/gaiaCapabilityEval.test.ts --reporter=verbose",
    "test:gaia:capability:files": "cross-env NODEBENCH_RUN_GAIA_CAPABILITY=1 vitest run src/__tests__/gaiaCapabilityFilesEval.test.ts --reporter=verbose",
    "test:gaia:capability:media": "cross-env NODEBENCH_RUN_GAIA_CAPABILITY=1 vitest run src/__tests__/gaiaCapabilityMediaEval.test.ts --reporter=verbose",
    "test:gaia:capability:audio": "cross-env NODEBENCH_RUN_GAIA_CAPABILITY=1 vitest run src/__tests__/gaiaCapabilityAudioEval.test.ts --reporter=verbose",
    "prepublishOnly": "npm run build && npm run test"
  },
  "keywords": [
    "mcp",
    "model-context-protocol",
    "claude",
    "ai-agents",
    "web-search",
    "github",
    "vision",
    "verification",
    "sqlite",
    "quality-gates",
    "parallel-agents",
    "toolset-gating",
    "eval",
    "qa-automation",
    "agentic",
    "academic-writing",
    "research-paper"
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/HomenShum/nodebench-ai.git",
    "directory": "packages/mcp-local"
  },
  "homepage": "https://github.com/HomenShum/nodebench-ai/tree/main/packages/mcp-local#readme",
  "bugs": {
    "url": "https://github.com/HomenShum/nodebench-ai/issues"
  },
  "license": "MIT",
  "author": "HomenShum",
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.4",
    "better-sqlite3": "^11.0.0",
    "nodebench-ai": "file:../.."
  },
  "optionalDependencies": {
    "@anthropic-ai/sdk": "^0.71.2",
    "@google/genai": "^1.10.0",
    "cheerio": "^1.0.0",
    "openai": "^5.8.2",
    "papaparse": "^5.5.3",
    "pdf-parse": "^2.4.5",
    "playwright": "^1.57.0",
    "sharp": "^0.34.5",
    "tesseract.js": "^7.0.0",
    "xlsx": "^0.18.5",
    "yauzl": "^2.10.0"
  },
  "devDependencies": {
    "@types/better-sqlite3": "^7.6.0",
    "@types/node": "^20.11.0",
    "tsx": "^4.7.0",
    "typescript": "^5.3.3",
    "vitest": "^3.2.4"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
