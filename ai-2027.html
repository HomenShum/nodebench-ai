<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/new-metr-extended-nowatermark-inexpandable.png"/><link rel="preload" as="image" href="/hacking.svg"/><link rel="preload" as="image" href="/coding.svg"/><link rel="preload" as="image" href="/political.svg"/><link rel="preload" as="image" href="/bioweapons.svg"/><link rel="preload" as="image" href="/robotics.svg"/><link rel="preload" as="image" href="/forecasting.svg"/><link rel="stylesheet" href="/_next/static/css/23574b8e95fa4c6f.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/edd4b027af513e5a.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/eb8e0ea56b7a3d7c.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/7ab52e961d3a1031.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-3666d63491495458.js"/><script src="/_next/static/chunks/fd9d1056-21f87a6a0da0f548.js" async=""></script><script src="/_next/static/chunks/23-2a6e01fb97f6f9f4.js" async=""></script><script src="/_next/static/chunks/main-app-a8e9a1c85cffbf2b.js" async=""></script><script src="/_next/static/chunks/c16f53c3-5cd0d8c9dcf88998.js" async=""></script><script src="/_next/static/chunks/d3ac728e-9fb72d70c471a406.js" async=""></script><script src="/_next/static/chunks/250-1d2547d905913eb8.js" async=""></script><script src="/_next/static/chunks/986-66078ca814549e23.js" async=""></script><script src="/_next/static/chunks/231-b29769cd42048fdc.js" async=""></script><script src="/_next/static/chunks/949-d6301dbf17d1d87e.js" async=""></script><script src="/_next/static/chunks/241-f3ca2a481bbaa609.js" async=""></script><script src="/_next/static/chunks/295-f211ba89a89eee0a.js" async=""></script><script src="/_next/static/chunks/801-fc075da969f18e5d.js" async=""></script><script src="/_next/static/chunks/873-a65d283664692974.js" async=""></script><script src="/_next/static/chunks/app/(mainPage)/layout-e0acd53732a0a6fe.js" async=""></script><script src="/_next/static/chunks/9da6db1e-0fea1966db071fc5.js" async=""></script><script src="/_next/static/chunks/752-79c8bd7d884bc699.js" async=""></script><script src="/_next/static/chunks/app/layout-3fddc5b713127910.js" async=""></script><title>AI 2027</title><meta name="description" content="A research-backed AI scenario forecast.
"/><meta property="og:title" content="AI 2027"/><meta property="og:description" content="A research-backed AI scenario forecast.
"/><meta property="og:image" content="https://ai-2027.com/opengraph.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="AI 2027"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@AI_Futures_"/><meta name="twitter:title" content="AI 2027"/><meta name="twitter:description" content="A research-backed AI scenario forecast.
"/><meta name="twitter:image" content="https://ai-2027.com/opengraph.png"/><meta name="twitter:image:width" content="1200"/><meta name="twitter:image:height" content="630"/><meta name="twitter:image:alt" content="AI 2027"/><link rel="icon" href="/favicon.png"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased mb-16"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><div class="main-grid"><nav class="flex flex-col [grid-area:header] z-1"><div class="flex flex-col-reverse sm:flex-row justify-between mr-[1.5px] mt-0 sm:mt-8"><a class="no-underline" href="/"><h1 class="mb-4 mt-2 whitespace-nowrap">AI 2027</h1></a><nav class="z-1 flex flex-wrap sm:gap-12 text-xl font-system-serif pl-2 sm:py-2 mb-8 sm:mb-0 items-center justify-between sm:justify-center w-auto"><a target="_self" class="whitespace-nowrap hover:underline  no-underline" href="/summary">Summary</a><div class="relative group"><a target="_self" class="whitespace-nowrap hover:underline  no-underline" href="/research">Research</a><div class="absolute top-[100%] w-[180px] hidden md:group-hover:block text-foreground right-0 font-sans text-sm [font-variant:normal] shadow-lg pb-2 pt-2 rounded bg-background border border-black z-50"><span><a class="block py-2 whitespace-no-wrap no-underline text-med p-4 hover:bg-[var(--accent)] hover:text-background" href="/research/compute-forecast">Compute Forecast</a><hr class="bg-dull-foreground w-[90%] mx-auto h-0 my-0"/></span><span><a class="block py-2 whitespace-no-wrap no-underline text-med p-4 hover:bg-[var(--accent)] hover:text-background" href="/research/timelines-forecast">Timelines Forecast</a><hr class="bg-dull-foreground w-[90%] mx-auto h-0 my-0"/></span><span><a class="block py-2 whitespace-no-wrap no-underline text-med p-4 hover:bg-[var(--accent)] hover:text-background" href="/research/takeoff-forecast">Takeoff Forecast</a><hr class="bg-dull-foreground w-[90%] mx-auto h-0 my-0"/></span><span><a class="block py-2 whitespace-no-wrap no-underline text-med p-4 hover:bg-[var(--accent)] hover:text-background" href="/research/ai-goals-forecast">AI Goals Forecast</a><hr class="bg-dull-foreground w-[90%] mx-auto h-0 my-0"/></span><span><a class="block py-2 whitespace-no-wrap no-underline text-med p-4 hover:bg-[var(--accent)] hover:text-background" href="/research/security-forecast">Security Forecast</a></span></div></div><a target="_self" class="whitespace-nowrap hover:underline px-2 py-1 rounded-md border border-black no-underline" href="/about">About</a></nav></div><div><h2 class="mt-[-3px] mb-[10px] not-italic text-[21px] md:text-[24px] leading-[1.4] font-normal bg-[var(--vivid-background)] w-fit relative pb-[10px]" style="z-index:1"><div class="md:hidden">April 3rd 2025</div><div class="flex items-center font-bold md:hidden mb-2"><a target="_blank" href="/ai-2027.pdf" class="flex items-center no-underline"><svg class="relative top-[-0.5px]" width="12px" height="14px" version="1.1" viewBox="100 0 900 1200" xmlns="http://www.w3.org/2000/svg"><path d="m200.02 249.98c0-82.828 67.125-150 150-150h258.56c39.797 0 77.953 15.797 106.08 43.969l241.4 241.4c28.125 28.125 43.922 66.281 43.922 106.08v458.58c0 82.828-67.125 150-150 150h-499.97c-82.875 0-150-67.172-150-150zm399.14 650.02c-7.5469-0.14062-14.672-1.9219-21.047-5.0156-4.4531-2.2031-8.5312-5.0156-12.141-8.3438l-99.891-92.203c-20.297-18.75-21.562-50.391-2.8125-70.641 18.703-20.297 50.344-21.562 70.641-2.8594l16.078 14.859v-185.81c0-27.609 22.406-49.969 50.016-49.969s50.016 22.359 50.016 49.969v179.29l14.625-14.625c19.547-19.547 51.188-19.547 70.734 0 19.5 19.5 19.5 51.188 0 70.688l-99.984 99.984-0.375 0.32812c-9 8.8594-21.328 14.344-34.969 14.344z" fill-rule="evenodd"></path></svg> <span class="ml-2">PDF</span> </a><div class="w-[1px] h-[16px] bg-black mx-2"></div><span class="cursor-pointer flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" role="img" class="speaker-icon"><polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5"></polygon><path d="M15 8a5 5 0 0 1 0 8"></path><path d="M18 5a9 9 0 0 1 0 14"></path></svg><span class="ml-2">Listen</span></span><div class="w-[1px] h-[16px] bg-black mx-2"></div><a target="_blank" href="https://www.youtube.com/watch?v=5KVDDfAkRgc" class="flex items-center no-underline"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28.57  20" focusable="false" width="16" height="16" fill="currentColor" class=""><g><path d="M27.9727 3.12324C27.6435 1.89323 26.6768 0.926623 25.4468 0.597366C23.2197 2.24288e-07 14.285 0 14.285 0C14.285 0 5.35042 2.24288e-07 3.12323 0.597366C1.89323 0.926623 0.926623 1.89323 0.597366 3.12324C2.24288e-07 5.35042 0 10 0 10C0 10 2.24288e-07 14.6496 0.597366 16.8768C0.926623 18.1068 1.89323 19.0734 3.12323 19.4026C5.35042 20 14.285 20 14.285 20C14.285 20 23.2197 20 25.4468 19.4026C26.6768 19.0734 27.6435 18.1068 27.9727 16.8768C28.5701 14.6496 28.5701 10 28.5701 10C28.5701 10 28.5677 5.35042 27.9727 3.12324Z" fill="#111"></path><path d="M11.4253 14.2854L18.8477 10.0004L11.4253 5.71533V14.2854Z" fill="white"></path></g></svg> <span class="ml-2">Watch</span></a></div><span class="tracking-[-1.2px]">Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean</span></h2></div></nav><div class="pt-[44px] z-10 hidden lg:block" style="grid-area:toc"><nav class="section-nav sticky left-2 top-2 group opacity"><div class="sm:flex flex-col h-[100vh] pb-[26px] hidden"><svg width="130" style="height:calc(100vh - 4px);opacity:0" fill="none" xmlns="http://www.w3.org/2000/svg" class="absolute top-0 transition-opacity duration-1000"><line x1="3" y1="8" x2="3" y2="2%" stroke="currentColor" stroke-width="2"></line></svg></div></nav></div><section class="main-content undefined" style="grid-area:content"><div><div id="section-narrative-0" class="scroll-mt-[54vh]"><div class="scroll-mt-[50vh]" id="narrative-2025-04-30" data-chart-date="2025-04-30" data-chart-extra="[&quot;2025-04-30&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:2000,&quot;speed&quot;:80},&quot;capabilities&quot;:[[&quot;Hacking&quot;,0.7],[&quot;Coding&quot;,0.8],[&quot;Politics&quot;,0.38],[&quot;Bioweapons&quot;,0.7],[&quot;Robotics&quot;,0.06],[&quot;Forecasting&quot;,0.69],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.25,&quot;revenue&quot;:8264170784,&quot;valuation&quot;:413208539198,&quot;aiImportance&quot;:0.01,&quot;datacenterSpending&quot;:307791637868,&quot;agiTimelines&quot;:2042,&quot;rdMultiple&quot;:[1.13,1.06,1.08],&quot;compute&quot;:[[&quot;OpenBrain&quot;,6.43e+26],[&quot;DeepCent&quot;,7.22e+25],[&quot;RestUs&quot;,4.7e+27],[&quot;RestChina&quot;,8.5e+26]]}]" style="height:0"></div><p>We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution.</p><p>We wrote a scenario that represents our best guess about what that might look like.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-1"><a href="/footnotes#footnote-1" class="text-[var(--accent)] text-xs no-underline">1</a></sup> It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-2"><a href="/footnotes#footnote-2" class="text-[var(--accent)] text-xs no-underline">2</a></sup></p><p>(Added Nov 22 2025: To prevent misunderstandings: we don&#x27;t know exactly when AGI will be built. 2027 was our modal (most likely) year at the time of publication, our medians were <a href="https://www.listendata.com/2023/08/right-skewed-histogram.html">somewhat longer</a>. For more detail on our views, see <a href="https://x.com/eli_lifland/status/1992004724841906392?s=20">here</a>.)<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-3"><a href="/footnotes#footnote-3" class="text-[var(--accent)] text-xs no-underline">3</a></sup></p><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="tab-boxes mt-7"><div class="flex flex-wrap gap-2"><button class="p-1 text-start px-2 border border-[1.5px] border-black rounded-md text-[1.2rem] whitespace-nowrap false" id="tab-box-what-is-this">What is this?</button><button class="p-1 text-start px-2 border border-[1.5px] border-black rounded-md text-[1.2rem] whitespace-nowrap false" id="tab-box-how-did-we-write-it">How did we write it?</button><button class="p-1 text-start px-2 border border-[1.5px] border-black rounded-md text-[1.2rem] whitespace-nowrap false" id="tab-box-why-is-it-valuable">Why is it valuable?</button><button class="p-1 text-start px-2 border border-[1.5px] border-black rounded-md text-[1.2rem] whitespace-nowrap false" id="tab-box-who-are-we">Who are we?</button></div><div class="pt-2 font-sans"><div class="
              rounded-md overflow-hidden [interpolate-size:allow-keywords] 
              [transition-property:height,opacity] [transition-duration:300ms] [transition-timing-function:ease-in-out]
              overflow-hidden [box-sizing:border-box] overflow-hidden outline outline-[1.5px] outline-black
              opacity-0 h-[0px]"><div class="p-2 [&amp;&gt;p]:mt-0 [&amp;&gt;*:last-child]:mb-0"><p>The CEOs of <a href="https://www.bloomberg.com/features/2025-sam-altman-interview">OpenAI</a>, <a href="https://www.bigtechnology.com/p/google-deepmind-ceo-demis-hassabis">Google DeepMind</a>, and <a href="https://www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-01-21-2025/card/anthropic-ceo-says-ai-could-surpass-human-intelligence-by-2027-9tka9tjLKLalkXX8IgKA">Anthropic</a> have all predicted that AGI will arrive within the next 5 years. Sam Altman <a href="https://webcf.waybackmachine.org/web/20250106014723/https://blog.samaltman.com/reflections">has said</a> OpenAI is setting its sights on “superintelligence in the true sense of the word” and the “glorious future.”</p><p>What might that look like? We wrote AI 2027 to answer that question. Claims about the future are often frustratingly vague, so we tried to be as concrete and quantitative as possible, even though this means depicting one of many possible futures.</p><p>We wrote two endings: a “slowdown” and a “race” ending. However, AI 2027 is not a recommendation or exhortation. Our goal is predictive accuracy.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-4"><a href="/footnotes#footnote-4" class="text-[var(--accent)] text-xs no-underline">4</a></sup></p><p>We encourage you to debate and counter this scenario.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-5"><a href="/footnotes#footnote-5" class="text-[var(--accent)] text-xs no-underline">5</a></sup> We hope to spark a broad conversation about where we’re headed and how to steer toward positive futures. We’re <a href="https://ai-2027.com/about?tab=bets-and-bounties#tab-box-bets-and-bounties">planning to give out thousands in prizes</a> to the best alternative scenarios.</p></div></div><div class="
              rounded-md overflow-hidden [interpolate-size:allow-keywords] 
              [transition-property:height,opacity] [transition-duration:300ms] [transition-timing-function:ease-in-out]
              overflow-hidden [box-sizing:border-box] overflow-hidden outline outline-[1.5px] outline-black
              opacity-0 h-[0px]"><div class="p-2 [&amp;&gt;p]:mt-0 [&amp;&gt;*:last-child]:mb-0"><p>Our research on key questions (e.g. what goals will future AI agents have?) can be found <a href="https://ai-2027.com/research">here</a>.</p><p>The scenario itself was written iteratively: we wrote the first period (up to mid-2025), then the following period, etc. until we reached the ending. We then scrapped this and did it again.</p><p>We weren’t trying to reach any particular ending. After we finished the first ending—which is now colored red—we wrote a new alternative branch because we wanted to also depict a more hopeful way things could end, starting from roughly the same premises. This went through several iterations.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-6"><a href="/footnotes#footnote-6" class="text-[var(--accent)] text-xs no-underline">6</a></sup></p><p>Our scenario was informed by approximately 25 <a href="https://ai-2027.com/about?tab=tabletop-exercise#tab-box-tabletop-exercise">tabletop exercises</a> and feedback from over 100 people, including dozens of experts in each of AI governance and AI technical work.</p></div></div><div class="
              rounded-md overflow-hidden [interpolate-size:allow-keywords] 
              [transition-property:height,opacity] [transition-duration:300ms] [transition-timing-function:ease-in-out]
              overflow-hidden [box-sizing:border-box] overflow-hidden outline outline-[1.5px] outline-black
              opacity-0 h-[0px]"><div class="p-2 [&amp;&gt;p]:mt-0 [&amp;&gt;*:last-child]:mb-0"><p><em>“I highly recommend reading this scenario-type prediction on how AI could transform the world in just a few years. Nobody has a crystal ball, but this type of content can help notice important questions and illustrate the potential impact of emerging risks.”</em> —<em>Yoshua Bengio<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-7"><a href="/footnotes#footnote-7" class="text-[var(--accent)] text-xs no-underline">7</a></sup></em></p><p>We have set ourselves an impossible task. Trying to predict how superhuman AI in 2027 would go is like trying to predict how World War 3 in 2027 would go, except that it’s an even larger departure from past case studies. Yet it is still valuable to attempt, just as it is valuable for the U.S. military to game out Taiwan scenarios.</p><p>Painting the whole picture makes us notice important questions or connections we hadn’t considered or appreciated before, or realize that a possibility is more or less likely. Moreover, by sticking our necks out with concrete predictions, and encouraging others to publicly state their disagreements, we make it possible to evaluate years later who was right.</p><p>Also, one author wrote a lower-effort AI scenario <a href="https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like">before, in August 2021</a>. While it got many things wrong, overall it was surprisingly successful: he predicted the rise of chain-of-thought, inference scaling, sweeping AI chip export controls, and $100 million training runs—all more than a year before ChatGPT.</p></div></div><div class="
              rounded-md overflow-hidden [interpolate-size:allow-keywords] 
              [transition-property:height,opacity] [transition-duration:300ms] [transition-timing-function:ease-in-out]
              overflow-hidden [box-sizing:border-box] overflow-hidden outline outline-[1.5px] outline-black
              opacity-0 h-[0px]"><div class="p-2 [&amp;&gt;p]:mt-0 [&amp;&gt;*:last-child]:mb-0"><p><a href="https://x.com/DKokotajlo">Daniel Kokotajlo</a> (<a href="https://time.com/7012881/daniel-kokotajlo/">TIME100</a>, <a href="https://www.nytimes.com/2024/06/04/technology/openai-culture-whistleblowers.html">NYT piece</a>) is a former OpenAI researcher whose previous <a href="https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like">AI predictions</a> have <a href="https://www.lesswrong.com/posts/u9Kr97di29CkMvjaj/evaluating-what-2026-looks-like-so-far">held up well</a>.</p><p><a href="https://www.linkedin.com/in/eli-lifland/">Eli Lifland</a> co-founded <a href="https://theaidigest.org/">AI Digest</a>, did <a href="https://scholar.google.com/citations?user=Q33DXbEAAAAJ&amp;hl=en">AI robustness research</a>, and ranks #1 on the <a href="https://www.rand.org/global-and-emerging-risks/forecasting-initiative.html">RAND Forecasting Initiative</a> all-time leaderboard.</p><p><a href="https://www.linkedin.com/in/thomas-larsen/">Thomas Larsen</a> founded the <a href="https://www.centeraipolicy.org/">Center for AI Policy</a> and did AI safety research at the <a href="https://intelligence.org/">Machine Intelligence Research Institute</a>.</p><p><a href="https://www.linkedin.com/in/romeo-dean-789313200/">Romeo Dean</a> is completing a computer science concurrent bachelor’s and master’s degree at Harvard and previously was an <a href="https://www.iaps.ai/romeo-dean">AI Policy Fellow</a> at the Institute for AI Policy and Strategy.</p><p><a href="https://en.wikipedia.org/wiki/Slate_Star_Codex">Scott Alexander, blogger extraordinaire</a>, volunteered to rewrite our content in an engaging style; the fun parts of the story are his and the boring parts are ours.</p><p>For more about our team and acknowledgements, see the <a href="https://ai-2027.com/about">About page</a>.</p></div></div></div></div><!--/$--><div class="hidden md:block"><div class="flex items-center font-mono text-[11px] text-transform-uppercase mb-[-4.4rem] mt-[50px]"> <span class="opacity-50">Published April 3rd 2025</span><div class="w-[1px] h-[11px] bg-black mx-2 opacity-50"></div> <a target="_blank" href="/ai-2027.pdf" class="flex items-center no-underline opacity-50 hover:opacity-100"> <svg class="relative top-[-0.5px]" width="12px" height="14px" version="1.1" viewBox="100 0 900 1200" xmlns="http://www.w3.org/2000/svg"><path d="m200.02 249.98c0-82.828 67.125-150 150-150h258.56c39.797 0 77.953 15.797 106.08 43.969l241.4 241.4c28.125 28.125 43.922 66.281 43.922 106.08v458.58c0 82.828-67.125 150-150 150h-499.97c-82.875 0-150-67.172-150-150zm399.14 650.02c-7.5469-0.14062-14.672-1.9219-21.047-5.0156-4.4531-2.2031-8.5312-5.0156-12.141-8.3438l-99.891-92.203c-20.297-18.75-21.562-50.391-2.8125-70.641 18.703-20.297 50.344-21.562 70.641-2.8594l16.078 14.859v-185.81c0-27.609 22.406-49.969 50.016-49.969s50.016 22.359 50.016 49.969v179.29l14.625-14.625c19.547-19.547 51.188-19.547 70.734 0 19.5 19.5 19.5 51.188 0 70.688l-99.984 99.984-0.375 0.32812c-9 8.8594-21.328 14.344-34.969 14.344z" fill-rule="evenodd"></path></svg> <span class="ml-2">PDF</span> </a><div class="w-[1px] h-[11px] bg-black mx-2 opacity-50"></div> <span class="cursor-pointer flex items-center opacity-50 hover:opacity-100"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" role="img" class="speaker-icon"><polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5"></polygon><path d="M15 8a5 5 0 0 1 0 8"></path><path d="M18 5a9 9 0 0 1 0 14"></path></svg> <span class="ml-2">Listen</span></span><div class="w-[1px] h-[11px] bg-black mx-2 opacity-50"></div> <a target="_blank" href="https://www.youtube.com/watch?v=5KVDDfAkRgc" class="flex items-center no-underline opacity-50 hover:opacity-100"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28.57  20" focusable="false" width="16" height="16" fill="currentColor" class=""><g><path d="M27.9727 3.12324C27.6435 1.89323 26.6768 0.926623 25.4468 0.597366C23.2197 2.24288e-07 14.285 0 14.285 0C14.285 0 5.35042 2.24288e-07 3.12323 0.597366C1.89323 0.926623 0.926623 1.89323 0.597366 3.12324C2.24288e-07 5.35042 0 10 0 10C0 10 2.24288e-07 14.6496 0.597366 16.8768C0.926623 18.1068 1.89323 19.0734 3.12323 19.4026C5.35042 20 14.285 20 14.285 20C14.285 20 23.2197 20 25.4468 19.4026C26.6768 19.0734 27.6435 18.1068 27.9727 16.8768C28.5701 14.6496 28.5701 10 28.5701 10C28.5701 10 28.5677 5.35042 27.9727 3.12324Z" fill="#111"></path><path d="M11.4253 14.2854L18.8477 10.0004L11.4253 5.71533V14.2854Z" fill="white"></path></g></svg> <span class="ml-2">Watch</span></a></div></div></div><div id="section-narrative-1" class="scroll-mt-[54vh]"><h2 id="mid-2025-stumbling-agents">Mid 2025: Stumbling Agents</h2><div class="scroll-mt-[50vh]" id="narrative-2025-08-31" data-chart-date="2025-08-31" data-chart-date-header="Mid 2025" data-chart-extra="[&quot;2025-08-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:5000,&quot;speed&quot;:100},&quot;capabilities&quot;:[[&quot;Hacking&quot;,0.8],[&quot;Coding&quot;,0.95],[&quot;Politics&quot;,0.48],[&quot;Bioweapons&quot;,0.8],[&quot;Robotics&quot;,0.08],[&quot;Forecasting&quot;,0.79],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.25,&quot;revenue&quot;:12195806919,&quot;valuation&quot;:609790345951,&quot;aiImportance&quot;:0.01,&quot;datacenterSpending&quot;:350872934598,&quot;agiTimelines&quot;:2041,&quot;rdMultiple&quot;:[1.21,1.1,1.14],&quot;compute&quot;:[[&quot;OpenBrain&quot;,9.84e+26],[&quot;DeepCent&quot;,1.24e+26],[&quot;RestUs&quot;,5.85e+27],[&quot;RestChina&quot;,1.07e+27]]}]" style="height:0"></div><p>The world sees its first glimpse of AI agents.</p><p>Advertisements for computer-using agents emphasize the term “personal assistant”: you can prompt them with tasks like “order me a burrito on DoorDash” or “open my budget spreadsheet and sum this month’s expenses.” They will check in with you as needed: for example, to ask you to confirm purchases.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-8"><a href="/footnotes#footnote-8" class="text-[var(--accent)] text-xs no-underline">8</a></sup> Though more advanced than previous iterations like <a href="https://openai.com/index/introducing-operator/">Operator</a>, they struggle to get widespread usage.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-9"><a href="/footnotes#footnote-9" class="text-[var(--accent)] text-xs no-underline">9</a></sup></p><p>Meanwhile, out of public focus, more specialized coding and research agents are beginning to transform their professions.</p><p>The AIs of 2024 could follow specific instructions: they could turn bullet points into emails, and simple requests into working code. In 2025, AIs function more like employees. Coding AIs increasingly look like autonomous agents rather than mere assistants: taking instructions via Slack or Teams and making substantial code changes on their own, sometimes saving hours or even days.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-10"><a href="/footnotes#footnote-10" class="text-[var(--accent)] text-xs no-underline">10</a></sup> Research agents spend half an hour scouring the Internet to answer your question.</p><p>The agents are impressive in theory (and in cherry-picked examples), but in practice unreliable. AI twitter is full of stories about tasks bungled in some particularly hilarious way. The better agents are also expensive; you get what you pay for, and the best performance costs hundreds of dollars a month.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-11"><a href="/footnotes#footnote-11" class="text-[var(--accent)] text-xs no-underline">11</a></sup> Still, many companies find ways to fit AI agents into their workflows.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-12"><a href="/footnotes#footnote-12" class="text-[var(--accent)] text-xs no-underline">12</a></sup></p></div><div id="section-narrative-2" class="scroll-mt-[54vh]"><h2 id="late-2025-the-worlds-most-expensive-ai">Late 2025: The World’s Most Expensive AI</h2><div class="scroll-mt-[50vh]" id="narrative-2025-12-31" data-chart-date="2025-12-31" data-chart-date-header="Late 2025" data-chart-extra="[&quot;2025-12-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:10000,&quot;speed&quot;:120},&quot;capabilities&quot;:[[&quot;Hacking&quot;,1],[&quot;Coding&quot;,1.1],[&quot;Politics&quot;,0.6],[&quot;Bioweapons&quot;,1],[&quot;Robotics&quot;,0.1],[&quot;Forecasting&quot;,0.9],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.25,&quot;revenue&quot;:18000000000,&quot;valuation&quot;:900000000000,&quot;aiImportance&quot;:0.01,&quot;datacenterSpending&quot;:400000000000,&quot;agiTimelines&quot;:2040,&quot;rdMultiple&quot;:[1.3,1.15,1.2],&quot;compute&quot;:[[&quot;OpenBrain&quot;,1.51e+27],[&quot;DeepCent&quot;,2.13e+26],[&quot;RestUs&quot;,7.28e+27],[&quot;RestChina&quot;,1.29e+27]]}]" style="height:0"></div><p>OpenBrain is building the biggest datacenters the world has ever seen.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-13"><a href="/footnotes#footnote-13" class="text-[var(--accent)] text-xs no-underline">13</a></sup></p><p>(To avoid singling out any one existing company, we’re going to describe a fictional <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">artificial general intelligence</a> company, which we’ll call OpenBrain. We imagine the others to be 3–9 months behind OpenBrain.)</p><div class="relative overflow-x-auto overflow-y-hidden" style="margin-bottom:30px"><div class="flex flex-col gap-6 mt-10 mb-10"><div class="flex flex-col lg:flex-row justify-center lg:justify-between gap-10 w-full"><div class="flex flex-col items-center flex-1"><div class="flex-1 flex flex-col items-center justify-center min-h-[100px]"> <canvas class="cursor-default" style="width:3px;height:4.5px"></canvas></div><div class="text-xs font-sans text-center mt-3">GPT-3<!-- --> <br/> (3 x 10^23 FLOP)</div></div><div class="flex flex-col items-center flex-1"><div class="flex-1 flex flex-col items-center justify-center min-h-[100px]"> <canvas class="cursor-default" style="width:27px;height:27px"></canvas></div><div class="text-xs font-sans text-center mt-3">GPT-4<!-- --> <br/> (2 x 10^25 FLOP)</div></div><div class="flex flex-col items-center flex-1"><div class="flex-1 flex flex-col items-center justify-center min-h-[100px]"> <canvas class="cursor-default" style="width:350px;height:350px"></canvas></div><div class="text-xs font-sans text-center mt-3">Agent-1<!-- --> <br/> (4 x 10^27 FLOP)</div></div></div></div><div class="absolute bottom-0 right-0 font-mono text-gray-400 opacity-50 text-base pb-0 pr-0.5" style="line-height:1;transform:translateY(25px)">ai-2027.com</div></div><p>GPT-4 required <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>⋅</mo><msup><mn>10</mn><mn>25</mn></msup></mrow><annotation encoding="application/x-tex">2\cdot 10^{25}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">25</span></span></span></span></span></span></span></span></span></span></span></span></span> <a href="https://en.wikipedia.org/wiki/Floating_point_operations_per_second">FLOP</a> of compute to train.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-14"><a href="/footnotes#footnote-14" class="text-[var(--accent)] text-xs no-underline">14</a></sup> OpenBrain’s latest public model—Agent-0—was trained with <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>27</mn></msup></mrow><annotation encoding="application/x-tex">10^{27}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">27</span></span></span></span></span></span></span></span></span></span></span></span></span> FLOP. Once the new datacenters are up and running, <a href="https://ai-2027.com/supplements/compute-forecast">they’ll be able to train</a> a model with <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>28</mn></msup></mrow><annotation encoding="application/x-tex">10^{28}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">28</span></span></span></span></span></span></span></span></span></span></span></span></span> FLOP—a thousand times more than GPT-4.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-15"><a href="/footnotes#footnote-15" class="text-[var(--accent)] text-xs no-underline">15</a></sup> Other companies pour money into their own giant datacenters, hoping to keep pace.</p><p>Although models are improving on a wide range of skills, one stands out: OpenBrain focuses on AIs that can speed up AI research. They want to win the twin arms races against China (whose leading company we’ll call “DeepCent”)<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-16"><a href="/footnotes#footnote-16" class="text-[var(--accent)] text-xs no-underline">16</a></sup> and their U.S. competitors. The more of their research and development (R&amp;D) cycle they can automate, the faster they can go. So when OpenBrain finishes training Agent-1, a new model under internal development, it’s good at many things but <em>great</em> at helping with AI research.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-17"><a href="/footnotes#footnote-17" class="text-[var(--accent)] text-xs no-underline">17</a></sup> By this point “finishes training” is a bit of a misnomer; models are frequently updated to newer versions trained on additional data or partially re-trained to patch some weaknesses.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-18"><a href="/footnotes#footnote-18" class="text-[var(--accent)] text-xs no-underline">18</a></sup></p><p>The same training environments that teach Agent-1 to autonomously code and web-browse also make it a good hacker. Moreover, it could offer <a href="https://x.com/lucafrighetti/status/1894550297449828434">substantial help</a> to terrorists designing bioweapons, thanks to its PhD-level knowledge of every field and ability to browse the web. OpenBrain reassures the government that the model has been “aligned” so that it will refuse to comply with malicious requests.</p><p>Modern AI systems are gigantic artificial neural networks. Early in training, an AI won’t have “goals” so much as “reflexes”: If it sees “Pleased to meet”, it outputs “ you”. By the time it has been trained to predict approximately one internet’s worth of text, it’ll have developed sophisticated internal circuitry that encodes vast amounts of knowledge and flexibly role-plays as arbitrary authors, since that’s what helps it predict text with <a href="https://arxiv.org/pdf/2212.11281">superhuman</a> accuracy.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-19"><a href="/footnotes#footnote-19" class="text-[var(--accent)] text-xs no-underline">19</a></sup></p><p>After being trained to predict internet text, the model is trained to <em>produce</em> text in response to instructions. This bakes in a basic personality and “drives.”<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-20"><a href="/footnotes#footnote-20" class="text-[var(--accent)] text-xs no-underline">20</a></sup> For example, an agent that understands a task clearly is more likely to complete it successfully; over the course of training the model “learns” a “drive” to get a clear understanding of its tasks. Other drives in this category might be effectiveness, knowledge, and self-presentation (i.e. the tendency to frame its results in the best possible light).<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-21"><a href="/footnotes#footnote-21" class="text-[var(--accent)] text-xs no-underline">21</a></sup></p><p>OpenBrain has <a href="https://model-spec.openai.com/2025-02-12.html">a model specification</a> (or “Spec”), a written document describing the goals, rules, principles, etc. that are supposed to guide the model’s behavior.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-22"><a href="/footnotes#footnote-22" class="text-[var(--accent)] text-xs no-underline">22</a></sup> Agent-1’s Spec combines a few vague goals (like “assist the user” and “don’t break the law”) with a long list of more specific dos and don’ts (“don’t say this particular word,” “here’s how to handle this particular situation”). Using techniques that utilize AIs to train other AIs,<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-23"><a href="/footnotes#footnote-23" class="text-[var(--accent)] text-xs no-underline">23</a></sup> the model memorizes the Spec and learns to reason carefully about its maxims. By the end of <em>this</em> training, the AI will hopefully be <em>helpful</em> (obey instructions), <em>harmless</em> (refuse to help with scams, bomb-making, and other dangerous activities) and <em>honest</em> (resist the temptation to get better ratings from gullible humans by hallucinating citations<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-24"><a href="/footnotes#footnote-24" class="text-[var(--accent)] text-xs no-underline">24</a></sup> or faking task completion).</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Training process and LLM psychology: why we keep saying “hopefully”</summary><div class="scroll-mt-20" id="training-process-and-llm-psychology-why-we-keep-saying-hopefully"><p><em>“Unlike ordinary software, our models are massive neural networks. Their behaviors are learned from a broad range of data, not programmed explicitly. Though not a perfect analogy, the process is more similar to training a dog than to ordinary programming.”</em> —<a href="https://openai.com/index/how-should-ai-systems-behave/">OpenAI</a></p><p>When we want to understand why a modern AI system did something, or how it would behave in some future scenario we can’t perfectly simulate, we can’t simply ask the programmers to talk us through various lines of code and explain how they work. Instead, we are forced to do something like psychology on them: we look at their behavior in the range of cases observed so far, and theorize about what internal cognitive structures (beliefs? goals? personality traits? etc.) might exist, and use those theories to predict behavior in future scenarios.</p><p>The bottom line is that a company can write up a document (the Spec) listing dos and don’ts, goals and principles, and then they can try to train the AI to internalize the Spec—<em>but they can’t check to see whether or not it worked</em>. They can say “as best as we can judge, it seems to be following the Spec so far.”<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-25"><a href="/footnotes#footnote-25" class="text-[var(--accent)] text-xs no-underline">25</a></sup></p><p>A later expandable will go into more detail about what we think <em>might</em> be going on inside these AIs, internally. See also our <a href="https://ai-2027.com/supplements/ai-goals-forecast">AI goals forecasting supplement</a> which goes into more detail on which goals AIs might have and why. This is one of many things that we are uncertain about and which deserves further research.</p></div></details><p>OpenBrain’s alignment team<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-26"><a href="/footnotes#footnote-26" class="text-[var(--accent)] text-xs no-underline">26</a></sup> is careful enough to wonder whether these victories are deep or shallow. Does the fully-trained model have some kind of robust commitment to always being honest? Or will this fall apart in some future situation, e.g. because it’s learned honesty as an <a href="https://en.wikipedia.org/wiki/Instrumental_and_intrinsic_value">instrumental</a> goal instead of a terminal goal? Or has it just learned to be honest about the sorts of things the evaluation process can check? Could it be lying to itself sometimes, as humans do? A conclusive answer to these questions would require mechanistic interpretability—essentially the ability to look at an AI’s internals and read its mind. Alas, interpretability techniques are not yet advanced enough for this.</p><p>Instead, researchers try to identify cases where the models seem to deviate from the Spec. Agent-1 is often sycophantic (i.e. it tells researchers what they want to hear instead of trying to tell them the truth). In a <a href="https://www.apolloresearch.ai/research/scheming-reasoning-evaluations">few rigged demos</a>, it even lies in more serious ways, like hiding evidence that it failed on a task, in order to get better ratings. However, in real deployment settings, there are no longer any incidents so extreme as in 2023–2024 (e.g. <a href="https://thehill.com/policy/technology/4998868-google-ai-gemini-response/">Gemini telling a user to die</a> and <a href="https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned">Bing Sydney being Bing Sydney</a>.)<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-27"><a href="/footnotes#footnote-27" class="text-[var(--accent)] text-xs no-underline">27</a></sup></p></div><div id="section-narrative-3" class="scroll-mt-[54vh]"><h2 id="early-2026-coding-automation">Early 2026: Coding Automation</h2><div class="scroll-mt-[50vh]" id="narrative-2026-04-30" data-chart-date="2026-04-30" data-chart-date-header="2026" data-chart-extra="[&quot;2026-04-30&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:22000,&quot;speed&quot;:130},&quot;capabilities&quot;:[[&quot;Hacking&quot;,1.1],[&quot;Coding&quot;,1.35],[&quot;Politics&quot;,0.68],[&quot;Bioweapons&quot;,1.19],[&quot;Robotics&quot;,0.12],[&quot;Forecasting&quot;,1],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.26,&quot;revenue&quot;:26118790599,&quot;valuation&quot;:1265105913985,&quot;aiImportance&quot;:0.02,&quot;datacenterSpending&quot;:457879508507,&quot;agiTimelines&quot;:2039,&quot;rdMultiple&quot;:[1.5,1.26,1.4],&quot;compute&quot;:[[&quot;OpenBrain&quot;,2.18e+27],[&quot;DeepCent&quot;,3.64e+26],[&quot;RestUs&quot;,9.36e+27],[&quot;RestChina&quot;,1.62e+27]]}]" style="height:0"></div><p>The bet of using AI to speed up AI research is starting to pay off.</p><p>OpenBrain continues to deploy the iteratively improving Agent-1 internally for AI R&amp;D. Overall, they are making algorithmic progress 50% faster than they would without AI assistants—and more importantly, faster than their competitors.</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>The AI R&amp;D progress multiplier: what do we mean by 50% faster algorithmic progress?</summary><div class="scroll-mt-20" id="the-ai-randd-progress-multiplier-what-do-we-mean-by-50percent-faster-algorithmic-progress"><p>We mean that OpenBrain makes as much AI research progress in 1 week with AI as they would in 1.5 weeks without AI usage.</p><p>AI progress can be broken down into 2 components:</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Increasing compute</strong>: More computational power is used to train or run an AI. This produces more powerful AIs, but they cost more.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Improved algorithms</strong>: Better training methods are used to translate compute into performance. This produces more capable AIs without a corresponding increase in cost, or the same capabilities with decreased costs.</p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>This includes being able to achieve qualitatively and quantitatively new results. “Paradigm shifts” such as the switch from game-playing RL agents to large language models count as examples of algorithmic progress.</p></li></ul></li></ol><p>Here we are only referring to (2), improved algorithms, which <a href="https://www.lesswrong.com/posts/ATSyAdBnxxDDAwhgu/recent-and-forecasted-rates-of-software-and-hardware">makes up about half of current AI progress</a>.</p><p>Going forward, we sometimes abbreviate this as an “AI R&amp;D progress multiplier” of 1.5.</p><p>Clarifications:</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The progress multiplier is all-inclusive: It includes the time it takes to run experiments, for example, rather than only the cognitive tasks involved in algorithmic research.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>It’s important to remember that the progress multiplier is the <em>relative</em> speed of progress, not the <em>absolute</em> speed of progress. If, for example, the compute cost to train a GPT-4 class model has halved every year for several years with ordinary human research, and then all of a sudden AI automates R&amp;D and the progress multiplier goes to 100x, the cost to train a GPT-4 class model would then halve every 3.65 days—but not for long, because diminishing returns would bite and eventual hard limits would be reached. In this example perhaps the cost to train a GPT-4 class model would cut in half 5–10 times total (over the span of a few weeks or months) before plateauing. In other words, if ordinary human science would have run up against diminishing returns and physical limits after 5 -10 years of further research, then AIs with a 100x multiplier would run up against those same diminishing returns and limits after 18.25–36.5 days of research.</p></li></ol><p>More explanation and discussion of this concept and how it is used in our forecast can be found in our <a href="https://ai-2027.com/supplements/takeoff-forecast">takeoff supplement</a>.</p></div></details><p>Several competing publicly released AIs now match or exceed Agent-0, including an <a href="https://opensource.org/ai/open-weights">open-weights</a> model. OpenBrain responds by releasing Agent-1, which is more capable and reliable.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-28"><a href="/footnotes#footnote-28" class="text-[var(--accent)] text-xs no-underline">28</a></sup></p><p>People naturally try to compare Agent-1 to humans, but it has a very different skill profile. It knows more facts than any human, knows practically every programming language, and can solve well-specified coding problems extremely quickly. On the other hand, Agent-1 is bad at even simple long-horizon tasks, like beating video games it hasn’t played before. Still, the common workday is eight hours, and a day’s work can usually be separated into smaller chunks; you could think of Agent-1 as a scatterbrained employee who thrives under careful management.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-29"><a href="/footnotes#footnote-29" class="text-[var(--accent)] text-xs no-underline">29</a></sup> Savvy people find ways to automate routine parts of their jobs.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-30"><a href="/footnotes#footnote-30" class="text-[var(--accent)] text-xs no-underline">30</a></sup></p><p>OpenBrain’s executives turn consideration to an implication of automating AI R&amp;D: security has become more important. In early 2025, the worst-case scenario was leaked algorithmic secrets; now, if China steals Agent-1’s weights, they could increase their research speed by nearly 50%.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-31"><a href="/footnotes#footnote-31" class="text-[var(--accent)] text-xs no-underline">31</a></sup> OpenBrain’s security level is typical of a fast-growing ~3,000 person tech company, secure only against low-priority attacks from capable cyber groups (<a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">RAND’s SL2</a>).<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-32"><a href="/footnotes#footnote-32" class="text-[var(--accent)] text-xs no-underline">32</a></sup> They are working hard to protect their <a href="https://tedai-sanfrancisco.ted.com/glossary/weights/">weights</a> and secrets from insider threats and top cybercrime syndicates (<a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">SL3</a>),<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-33"><a href="/footnotes#footnote-33" class="text-[var(--accent)] text-xs no-underline">33</a></sup> but defense against nation states (<a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">SL4&amp;5</a>) is barely on the horizon.</p></div><div id="section-narrative-4" class="scroll-mt-[54vh]"><h2 id="mid-2026-china-wakes-up">Mid 2026: China Wakes Up</h2><div class="scroll-mt-[50vh]" id="narrative-2026-08-31" data-chart-date="2026-08-31" data-chart-date-header="Mid 2026" data-chart-extra="[&quot;2026-08-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:50000,&quot;speed&quot;:150},&quot;capabilities&quot;:[[&quot;Hacking&quot;,1.3],[&quot;Coding&quot;,1.6],[&quot;Politics&quot;,0.77],[&quot;Bioweapons&quot;,1.28],[&quot;Robotics&quot;,0.14],[&quot;Forecasting&quot;,1.1],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.26,&quot;revenue&quot;:37899512354,&quot;valuation&quot;:1778325526221,&quot;aiImportance&quot;:0.02,&quot;datacenterSpending&quot;:524134110777,&quot;agiTimelines&quot;:2038,&quot;rdMultiple&quot;:[1.73,1.37,1.63],&quot;compute&quot;:[[&quot;OpenBrain&quot;,3.17e+27],[&quot;DeepCent&quot;,1.42e+27],[&quot;RestUs&quot;,1.2e+28],[&quot;RestChina&quot;,1.2e+27]]}]" style="height:0"></div><p>In China, the CCP is starting to <a href="https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims">feel the AGI</a>.</p><p>Chip export controls and lack of government support have left China under-resourced compared to the West. By smuggling banned Taiwanese chips, buying older chips, and producing domestic chips about three years behind the U.S.-Taiwanese frontier, China has managed to maintain about 12% of the world’s AI-relevant compute—but the older technology is harder to work with, and supply is a constant headache.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-35"><a href="/footnotes#footnote-35" class="text-[var(--accent)] text-xs no-underline">35</a></sup> A few standouts like DeepCent do very impressive work with limited compute, but the compute deficit limits what they can achieve without government support, and they are about six months behind the best OpenBrain models.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-36"><a href="/footnotes#footnote-36" class="text-[var(--accent)] text-xs no-underline">36</a></sup></p><p>The General Secretary had long dreamed of doubling down on real-world physical manufacturing and avoiding American post-industrial decadence. He viewed software companies with suspicion.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-37"><a href="/footnotes#footnote-37" class="text-[var(--accent)] text-xs no-underline">37</a></sup> But hawks in the CCP warn that the growing race towards AGI can no longer be ignored. So he finally commits fully to the big AI push he had previously tried to avoid. He sets in motion the nationalization of Chinese AI research, creating an immediate information-sharing mechanism for AI companies. It will escalate over the course of a year until all the best researchers merge into a DeepCent-led collective, where they share algorithmic insights, datasets, and compute resources with each other. A Centralized Development Zone (CDZ) is created at the Tianwan Power Plant (the largest nuclear power plant in the world) to house a new mega-datacenter for DeepCent, along with highly secure living and office spaces to which researchers will eventually relocate. Almost 50% of China’s AI-relevant compute is now working for the DeepCent-led collective,<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-38"><a href="/footnotes#footnote-38" class="text-[var(--accent)] text-xs no-underline">38</a></sup> and over 80% of new chips are directed to the CDZ.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-39"><a href="/footnotes#footnote-39" class="text-[var(--accent)] text-xs no-underline">39</a></sup> At this point, the CDZ has the power capacity in place for what would be the largest centralized <a href="https://en.wikipedia.org/wiki/Computer_cluster">cluster</a> in the world.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-40"><a href="/footnotes#footnote-40" class="text-[var(--accent)] text-xs no-underline">40</a></sup> Other Party members discuss extreme measures to neutralize the West’s chip advantage. A blockade of Taiwan? A full invasion?</p><p>But China is falling behind on AI algorithms due to their weaker models. The Chinese intelligence agencies—among the best in the world—double down on their plans to steal OpenBrain’s weights. This is a much more complex operation than their constant low-level poaching of algorithmic secrets; the weights are a multi-terabyte file stored on a highly secure server (<a href="https://ai-2027.com/supplements/security-forecast">OpenBrain has improved security</a> to RAND’s <a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">SL3</a>). Their cyberforce think they can pull it off with help from their <a href="https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies">spies</a>, but perhaps only once; OpenBrain will detect the theft, increase security, and they may not get another chance. So (CCP leadership wonder) should they act now and steal Agent-1? Or hold out for a more advanced model? If they wait, do they risk OpenBrain upgrading security beyond their ability to penetrate?</p></div><div id="section-narrative-5" class="scroll-mt-[54vh]"><h2 id="late-2026-ai-takes-some-jobs">Late 2026: AI Takes Some Jobs</h2><div class="scroll-mt-[50vh]" id="narrative-2026-12-31" data-chart-date="2026-12-31" data-chart-date-header="Late 2026" data-chart-extra="[&quot;2026-12-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:100000,&quot;speed&quot;:170},&quot;capabilities&quot;:[[&quot;Hacking&quot;,1.51],[&quot;Coding&quot;,1.9],[&quot;Politics&quot;,0.88],[&quot;Bioweapons&quot;,1.39],[&quot;Robotics&quot;,0.17],[&quot;Forecasting&quot;,1.22],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.27,&quot;revenue&quot;:55000000000,&quot;valuation&quot;:2500000000000,&quot;aiImportance&quot;:0.03,&quot;datacenterSpending&quot;:600000000000,&quot;agiTimelines&quot;:2037,&quot;rdMultiple&quot;:[2,1.5,1.9],&quot;compute&quot;:[[&quot;OpenBrain&quot;,4.59e+27],[&quot;DeepCent&quot;,2.44e+27],[&quot;RestUs&quot;,1.55e+28],[&quot;RestChina&quot;,1e+27]]}]" style="height:0"></div><p>Just as others seemed to be catching up, OpenBrain blows the competition out of the water again by releasing Agent-1-mini—a model 10x cheaper than Agent-1 and more easily fine-tuned for different applications. The mainstream narrative around AI has changed from “maybe the hype will blow over” to “guess this is the next big thing,” but people disagree about how big. Bigger than social media? Bigger than smartphones? Bigger than fire?</p><p>AI has started to take jobs, but has also created new ones. The stock market has gone up 30% in 2026, led by OpenBrain, Nvidia, and whichever companies have most successfully integrated AI assistants. The job market for junior software engineers is in turmoil: the AIs can do everything taught by a CS degree, but people who know how to manage and quality-control teams of AIs are making a killing. Business gurus tell job seekers that familiarity with AI is the most important skill to put on a resume. Many people fear that the next wave of AIs will come for their jobs; there is a 10,000 person anti-AI protest in DC.</p><p>Department of Defense (DOD) quietly but significantly begins scaling up contracting OpenBrain directly for cyber, data analysis, and R&amp;D, but integration is slow due to the bureaucracy and DOD procurement process.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-41"><a href="/footnotes#footnote-41" class="text-[var(--accent)] text-xs no-underline">41</a></sup></p><div class="relative overflow-x-auto overflow-y-hidden" style="margin-bottom:50px"><div class="font-mono mt-8 mb-8"><div class="grid grid-cols-2 lg:grid-cols-3 gap-6"><div class="order-10 lg:order-none"><div class="px-4 py-2 rounded-md h-full border border-black relative"><div class="text-[10px] uppercase mb-1 text-gray-500">GLOBAL AI CAPEX</div><div class="text-2xl font-bold">$1T</div><div class="text-[10px] text-gray-500">COST OF OWNERSHIP OF ACTIVE COMPUTE</div></div></div><div class="col-span-2"><h2 class="text-[40px] font text-right not-italic mt-0 mb-0 font-bold font-sans tracking-tight uppercase">KEY METRICS 2026</h2></div><div class="order-11 lg:order-none"><div class="px-4 py-2 rounded-md h-full border border-black relative"><div class="text-[10px] uppercase mb-1 text-gray-500">GLOBAL AI POWER</div><div class="text-2xl font-bold">38GW</div><div class="text-[10px] text-gray-500">PEAK POWER</div></div></div><div class="order-1 lg:order-none"><div class="px-4 py-2 rounded-md h-full bg-[var(--accent)] text-white relative"><div class="absolute top-2 right-2"><svg width="20" height="20" viewBox="0 0 891 894" fill="white" class="" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg></div><div class="text-[10px] uppercase mb-1 text-white">OPENBRAIN REVENUE</div><div class="text-2xl font-bold">$45B</div><div class="text-[10px] text-white">2026 ANNUAL</div></div></div><div class="order-2 lg:order-none"><div class="px-4 py-2 rounded-md h-full bg-[var(--accent)] text-white relative"><div class="absolute top-2 right-2"><svg width="20" height="20" viewBox="0 0 891 894" fill="white" class="" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg></div><div class="text-[10px] uppercase mb-1 text-white">CAPITAL EXPENDITURE</div><div class="text-2xl font-bold">$200B</div><div class="text-[10px] text-white">COST OF OWNERSHIP OF OPENBRAIN&#x27;S ACTIVE COMPUTE</div></div></div><div class="order-12 lg:order-none"><div class="px-4 py-2 rounded-md h-full border border-black relative"><div class="text-[10px] uppercase mb-1 text-gray-500">SHARE OF US POWER ON AI</div><div class="text-2xl font-bold">2.5%</div><div class="text-[10px] text-gray-500">33 GW OF 1.34TW CAPACITY</div></div></div><div class="order-3 lg:order-none"><div class="px-4 py-2 rounded-md h-full bg-[var(--accent)] text-white relative"><div class="absolute top-2 right-2"><svg width="20" height="20" viewBox="0 0 891 894" fill="white" class="" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg></div><div class="text-[10px] uppercase mb-1 text-white">OPENBRAIN COMPUTE COSTS</div><div class="text-2xl font-bold">$40B</div><div class="text-[10px] text-white">2026 ANNUAL</div></div></div><div class="order-4 lg:order-none"><div class="px-4 py-2 rounded-md h-full bg-[var(--accent)] text-white relative"><div class="absolute top-2 right-2"><svg width="20" height="20" viewBox="0 0 891 894" fill="white" class="" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg></div><div class="text-[10px] uppercase mb-1 text-white">OPENBRAIN POWER REQUIREMENT</div><div class="text-2xl font-bold">6GW</div><div class="text-[10px] text-white">PEAK POWER</div></div></div></div></div><div class="absolute bottom-0 right-0 font-mono text-gray-400 opacity-50 text-base pb-0 pr-0.5" style="line-height:1;transform:translateY(25px)">ai-2027.com</div></div><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Why our uncertainty increases substantially beyond 2026</summary><div class="scroll-mt-20" id="why-our-uncertainty-increases-substantially-beyond-2026"><p>Our forecast from the current day through 2026 is substantially more grounded than what follows. This is partially because it’s nearer. But it’s also because the effects of AI on the world really start to compound in 2027. For 2025 and 2026, our forecast is heavily informed by extrapolating straight lines on compute scaleups, algorithmic improvements, and benchmark performance. At this point in the scenario, we begin to see major effects from AI-accelerated AI-R&amp;D on the timeline, which causes us to revise our guesses for the trendlines upwards. But these dynamics are inherently much less predictable.</p><p>Over the course of 2027, the AIs improve from being able to mostly do the job of an OpenBrain research engineer to eclipsing all humans at all tasks. This represents roughly our median guess, but we think it’s plausible that this happens up to ~5x slower or faster.</p><p>For our background research, see the <a href="https://ai-2027.com/supplements/timelines-forecast">timelines forecast</a> and the <a href="https://ai-2027.com/supplements/takeoff-forecast">takeoff forecast</a>. These will also be summarized in expandables below.</p></div></details></div><div id="section-narrative-6" class="scroll-mt-[54vh]"><h2 id="january-2027-agent-2-never-finishes-learning">January 2027: Agent-2 Never Finishes Learning</h2><div class="scroll-mt-[50vh]" id="narrative-2027-01-31" data-chart-date="2027-01-31" data-chart-date-header="Jan 2027" data-chart-extra="[&quot;2027-01-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:150000,&quot;speed&quot;:210},&quot;capabilities&quot;:[[&quot;Hacking&quot;,1.7],[&quot;Coding&quot;,2.1],[&quot;Politics&quot;,1],[&quot;Bioweapons&quot;,1.5],[&quot;Robotics&quot;,0.2],[&quot;Forecasting&quot;,1.35],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.27,&quot;revenue&quot;:60762491675,&quot;valuation&quot;:2901300030569,&quot;aiImportance&quot;:0.04,&quot;datacenterSpending&quot;:626092708761,&quot;agiTimelines&quot;:2037,&quot;rdMultiple&quot;:[2.5,1.6,2.2],&quot;compute&quot;:[[&quot;OpenBrain&quot;,5.37e+27],[&quot;DeepCent&quot;,3.08e+27],[&quot;RestUs&quot;,1.74e+28],[&quot;RestChina&quot;,7.46e+26]]}]" style="height:0"></div><p>With Agent-1’s help, OpenBrain is now post-training Agent-2. More than ever, the focus is on high-quality data. Copious amounts of <a href="https://en.wikipedia.org/wiki/Synthetic_data">synthetic data</a> are produced, evaluated, and filtered for quality before being fed to Agent-2.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-42"><a href="/footnotes#footnote-42" class="text-[var(--accent)] text-xs no-underline">42</a></sup> On top of this, they pay billions of dollars for human laborers to record themselves solving long-horizon tasks.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-43"><a href="/footnotes#footnote-43" class="text-[var(--accent)] text-xs no-underline">43</a></sup> On top of all <em>that,</em> they train Agent-2 almost continuously using reinforcement learning on an ever-expanding suite of diverse difficult tasks: lots of video games, lots of coding challenges, lots of research tasks. Agent-2, more so than previous models, is effectively “online learning,” in that it’s built to never really finish training. Every day, the weights get updated to the latest version, trained on more data generated by the previous version the previous day.</p><p>Agent-1 had been optimized for AI R&amp;D tasks, hoping to initiate an <a href="https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion">intelligence explosion</a>.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-44"><a href="/footnotes#footnote-44" class="text-[var(--accent)] text-xs no-underline">44</a></sup> OpenBrain doubles down on this strategy with Agent-2. It is qualitatively almost as good as the top human experts at research engineering (designing and implementing experiments), and as good as the 25th percentile OpenBrain scientist at “research taste” (deciding what to study next, what experiments to run, or having inklings of potential new paradigms).<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-45"><a href="/footnotes#footnote-45" class="text-[var(--accent)] text-xs no-underline">45</a></sup> While the latest Agent-1 could double the pace of OpenBrain’s algorithmic progress, Agent-2 can now triple it, and will improve further with time. In practice, this looks like every OpenBrain researcher becoming the “manager” of an AI “team.”</p><p>With new capabilities come new dangers. The safety team finds that if Agent-2 somehow escaped from the company and wanted to <a href="https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf">“survive” and “replicate” autonomously</a>, it might be able to do so. That is, it could autonomously develop and execute plans to hack into AI servers, install copies of itself, evade detection, and use that secure base to pursue whatever other goals it might have (though how effectively it would do so as weeks roll by is unknown and in doubt). These results only show that the model has the capability to do these tasks, not whether it would “want” to do this. Still, it’s unsettling even to know this is possible.</p><p>Given the “dangers” of the new model, OpenBrain “responsibly” elects not to release it publicly yet (in fact, they want to focus on internal AI R&amp;D).<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-46"><a href="/footnotes#footnote-46" class="text-[var(--accent)] text-xs no-underline">46</a></sup> Knowledge of Agent-2’s full capabilities is limited to an elite silo containing the immediate team, OpenBrain leadership and security, a few dozen U.S. government officials, and the legions of CCP spies who have infiltrated OpenBrain <a href="https://situational-awareness.ai/lock-down-the-labs/">for</a> <a href="https://www.bbc.com/news/world-asia-china-64206950">years</a>.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-47"><a href="/footnotes#footnote-47" class="text-[var(--accent)] text-xs no-underline">47</a></sup></p></div><div id="section-narrative-7" class="scroll-mt-[54vh]"><h2 id="february-2027-china-steals-agent-2">February 2027: China Steals Agent-2</h2><div class="scroll-mt-[50vh]" id="narrative-2027-02-28" data-chart-date="2027-02-28" data-chart-date-header="Feb" data-chart-extra="[&quot;2027-02-28&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:190000,&quot;speed&quot;:250},&quot;capabilities&quot;:[[&quot;Hacking&quot;,1.85],[&quot;Coding&quot;,2.26],[&quot;Politics&quot;,1.15],[&quot;Bioweapons&quot;,1.63],[&quot;Robotics&quot;,0.24],[&quot;Forecasting&quot;,1.45],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.28,&quot;revenue&quot;:67128734446,&quot;valuation&quot;:3051300030569,&quot;aiImportance&quot;:0.04,&quot;datacenterSpending&quot;:653320133272,&quot;agiTimelines&quot;:2036,&quot;rdMultiple&quot;:[3,2.5,2.4],&quot;compute&quot;:[[&quot;OpenBrain&quot;,6.13e+27],[&quot;DeepCent&quot;,3.78e+27],[&quot;RestUs&quot;,1.91e+28],[&quot;RestChina&quot;,5.41e+26]]}]" style="height:0"></div><p>OpenBrain presents Agent-2 to the government, including the National Security Council (NSC), the Department of Defense (DOD), and the U.S. AI Safety Institute (AISI). OpenBrain wants to maintain a good relationship with the executive branch, because it is basically the only actor that can stop them now, and if they don’t keep it informed it might find out anyway and be displeased.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-48"><a href="/footnotes#footnote-48" class="text-[var(--accent)] text-xs no-underline">48</a></sup></p><p>Officials are most interested in its cyberwarfare capabilities: Agent-2 is “only” a little worse than the best human hackers, but thousands of copies can be run in parallel, searching for and exploiting weaknesses faster than defenders can respond. The Department of Defense considers this a critical advantage in cyberwarfare, and AI moves from #5 on the administration’s priority list to #2.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-49"><a href="/footnotes#footnote-49" class="text-[var(--accent)] text-xs no-underline">49</a></sup> Someone mentions the possibility of nationalizing OpenBrain, but other cabinet officials think that’s premature. A staffer drafts a memo that presents the President with his options, ranging from business-as-usual to full nationalization. The President defers to his advisors, tech industry leaders who argue that nationalization would “kill the goose that lays the golden eggs.” He elects to hold off on major action for now and just adds additional security requirements to the OpenBrain-DOD contract.</p><p>The changes come too late. CCP leadership recognizes the importance of Agent-2 and tells their spies and cyberforce to steal the weights. Early one morning, an Agent-1 traffic monitoring agent detects an anomalous transfer. It alerts company leaders, who tell the White House. The signs of a nation-state-level operation are unmistakable, and the theft heightens the sense of an ongoing arms race.</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>The theft of Agent-2 model weights</summary><div class="scroll-mt-20" id="the-theft-of-agent-2-model-weights"><p>We think that by this point Chinese intelligence would have compromised OpenBrain in various ways for years, and probably would have been keeping up to date on the algorithmic secrets and even stealing code from time to time, since that is much easier to get than the weights and much harder to detect.</p><p>We imagine the theft of the weights as a series of coordinated small smash and grab thefts (meaning fast but non-covert) across a series of Nvidia NVL72 GB300 servers running copies of the Agent-2 weights. The servers are compromised using legitimate employee access (a friendly, coerced, or unwitting insider with admin credentials helping the CCP theft effort). Insider credentials grant the attacker admin-level permissions to the servers. Using a microarchitectural side channel, the attacker extracts encryption keys from an Nvidia Confidential Computing-enabled Virtual Machine, allowing the them to intercept model weights as the VM is provisioned or updated.</p><p>They initiate (or wait for) a routine update and exfiltrate the checkpoint in many small fragments, e.g., ~25 distinct servers each leaking ~4% of the model (~100 GB chunks for a ~2.5 TB half-precision checkpoint). The egress bandwidth of the entire datacenter is in the 100 GB/second range, so throttling to under ~1 GB/s per server avoids a major spike in network traffic; at that rate, each ~100 GB chunk can leave the datacenter in a couple of minutes. Live monitoring is either fooled by the attackers efforts to mask and split the transfers or outright disabled.</p><p>The weights are then routed through various parallel channels and layers of IP masking to China to be decrypted locally with the stolen session key(s). The entire active part of the operation (from the first server compromise to full weights exfiltration) is complete in under two hours.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-99"><a href="/footnotes#footnote-99" class="text-[var(--accent)] text-xs no-underline">99</a></sup></p><p>Russia is also trying to steal the model at this point, but fails—they waited too long, and they haven’t spent the resources infiltrating the right places. Their spies routinely steal algorithmic secrets from American AI companies, but without a notable AGI project of their own, these aren’t very useful.</p></div></details><p>The White House puts OpenBrain on a shorter leash and adds military and intelligence community personnel to their security team. Their first priority is to prevent further weight thefts.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-50"><a href="/footnotes#footnote-50" class="text-[var(--accent)] text-xs no-underline">50</a></sup></p><div class="relative overflow-x-auto overflow-y-hidden" style="margin-bottom:0px"><div class="w-full relative overflow-hidden mt-8 mb-8"><svg width="100%" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1000 700"><text x="0" y="40" font-size="28" font-family="monospace" class="text-[28px] font-mono md:text-[24px] sm:text-[20px]" fill="#333333">China&#x27;s Compute Centralization, 2025-2027</text><text x="0" y="80" class="text-[16px] font-mono md:text-[16px] sm:text-[16px]" fill="#333333">Growing share of total compute in CDZ:</text><g><path d="M 380 85 L 386.6666666666667 85 L 393.3333333333333 85 L 400 85 L 406.6666666666667 85 L 413.3333333333333 85 L 420 85 L 426.6666666666667 84.51418577535951 L 433.3333333333333 84.10071942446044 L 440 83.1358189081225 L 446.6666666666667 81.81311881188118 L 453.3333333333333 79.39593472659605 L 460 77.35372340425532 L 466.66666666666663 75.6519065190652 L 473.33333333333337 74.22708618331053 L 480 73.05496828752642 L 486.66666666666663 72.27735368956743 L 493.33333333333337 71.51095419156256 L 500 70.82690372358269 L 506.66666666666663 70.15928515928516 L 513.3333333333334 69.51008645533142 L 520 69.0475236951008 L 526.6666666666666 68.62580326248147 L 533.3333333333334 68.22455055536471 L 540 67.8610845802823" stroke="var(--accent)" fill="none" stroke-width="1.5"></path><text x="550" y="72" class="text-[16px] font-mono md:text-[16px] sm:text-[14px]" fill="#333333">0→70%</text></g><g><line x1="0" y1="640" x2="0" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="0" y="660" text-anchor="start" class="text-[18px] font-mono md:text-[18px] sm:text-[18px]" fill="#333333">Dec 2025</text></g><g><line x1="208.75" y1="640" x2="208.75" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="168.75" y="660" text-anchor="start" class="text-[18px] font-mono md:text-[18px] sm:text-[18px]" fill="#333333">Jun 2026</text></g><g><line x1="417.5" y1="640" x2="417.5" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="377.5" y="660" text-anchor="start" class="text-[18px] font-mono md:text-[18px] sm:text-[18px]" fill="#333333">Dec 2026</text></g><g><line x1="626.25" y1="640" x2="626.25" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="586.25" y="660" text-anchor="start" class="text-[18px] font-mono md:text-[18px] sm:text-[18px]" fill="#333333">Jun 2027</text></g><g><line x1="835" y1="640" x2="835" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="795" y="660" text-anchor="start" class="text-[18px] font-mono md:text-[18px] sm:text-[18px]" fill="#333333">Dec 2027</text></g><path d="M 0 537.9178605539637 L 34.791666666666664 529.6996710177226 L 69.58333333333333 520.5306165764619 L 104.375 511.08988644805265 L 139.16666666666666 501.1737238671336 L 173.95833333333334 490.17085853762075 L 208.75 478.0133715377268 L 243.54166666666669 465.2446142417489 L 278.3333333333333 451.1853974318158 L 313.125 435.9715589515016 L 347.9166666666667 420.48604478403905 L 382.7083333333333 402.75920619760166 L 417.5 384.6248540804415 L 452.29166666666663 363.9095829353709 L 487.08333333333337 342.1076090417065 L 521.875 318.74349994693836 L 556.6666666666666 293.00222858962115 L 591.4583333333334 264.88379496975483 L 626.25 235.06738830521067 L 661.0416666666666 202.9417382999044 L 695.8333333333334 168.6426827974106 L 730.625 131.21935689270924 L 765.4166666666666 90.40008489865227 L 800.2083333333334 46.8640560331105 L 835 0 L 835 42.992677491244876 L 800.2083333333334 88.49835508861304 L 765.4166666666666 130.6080865966253 L 730.625 170.00106123315288 L 695.8333333333334 205.99808978032468 L 661.0416666666666 241.99511832749647 L 626.25 275.2753900031837 L 591.4583333333334 305.83890480738614 L 556.6666666666666 334.3648519579752 L 521.875 360.1740422370795 L 487.08333333333337 387.34161095192616 L 452.29166666666663 421.9802610633556 L 417.5 455.9397219569139 L 382.7083333333333 484.9411015600127 L 347.9166666666667 514.21415685026 L 313.125 529.6996710177226 L 278.3333333333333 543.5551310622944 L 243.54166666666669 603.1200254695957 L 208.75 607.7385121511196 L 173.95833333333334 611.7457285365595 L 139.16666666666666 615.2775124694896 L 104.375 618.4017828716969 L 69.58333333333333 621.0506208213944 L 34.791666666666664 623.4277830839435 L 0 625.5332696593441 Z" fill="rgba(0,0,0,0.4)" fill-opacity="0.15" stroke="none"></path><path d="M 0 625.5332696593441 L 34.791666666666664 623.4277830839435 L 69.58333333333333 621.0506208213944 L 104.375 618.4017828716969 L 139.16666666666666 615.2775124694896 L 173.95833333333334 611.7457285365595 L 208.75 607.7385121511196 L 243.54166666666669 603.1200254695957 L 278.3333333333333 543.5551310622944 L 313.125 529.6996710177226 L 347.9166666666667 514.21415685026 L 382.7083333333333 484.9411015600127 L 417.5 455.9397219569139 L 452.29166666666663 421.9802610633556 L 487.08333333333337 387.34161095192616 L 521.875 360.1740422370795 L 556.6666666666666 334.3648519579752 L 591.4583333333334 305.83890480738614 L 626.25 275.2753900031837 L 661.0416666666666 241.99511832749647 L 695.8333333333334 205.99808978032468 L 730.625 170.00106123315288 L 765.4166666666666 130.6080865966253 L 800.2083333333334 88.49835508861304 L 835 42.992677491244876 L 835 201.24376525522666 L 800.2083333333334 241.99511832749658 L 765.4166666666666 280.02971452828183 L 730.625 315.3475538575825 L 695.8333333333334 347.9486363153985 L 661.0416666666666 380.54971877321447 L 626.25 410.4340443595458 L 591.4583333333334 437.6016130743925 L 556.6666666666666 463.41080335349676 L 521.875 486.50323676111645 L 487.08333333333337 511.63323782234954 L 452.29166666666663 536.7632388835827 L 417.5 561.8932399448158 L 382.7083333333333 586.8194842406876 L 347.9166666666667 612.0174042237079 L 313.125 624.7861615196858 L 278.3333333333333 633.2081078212883 L 243.54166666666669 636.6040539106442 L 208.75 640 L 173.95833333333334 640 L 139.16666666666666 640 L 104.375 640 L 69.58333333333333 640 L 34.791666666666664 640 L 0 640 Z" fill="rgba(0,0,0,0.6)" fill-opacity="0.25" stroke="none"></path><path d="M 0 640 L 34.791666666666664 640 L 69.58333333333333 640 L 104.375 640 L 139.16666666666666 640 L 173.95833333333334 640 L 208.75 640 L 243.54166666666669 636.6040539106442 L 278.3333333333333 633.2081078212883 L 313.125 624.7861615196858 L 347.9166666666667 612.0174042237079 L 382.7083333333333 586.8194842406876 L 417.5 561.8932399448158 L 452.29166666666663 536.7632388835827 L 487.08333333333337 511.63323782234954 L 521.875 486.50323676111645 L 556.6666666666666 463.41080335349676 L 591.4583333333334 437.6016130743925 L 626.25 410.4340443595458 L 661.0416666666666 380.54971877321447 L 695.8333333333334 347.9486363153985 L 730.625 315.3475538575825 L 765.4166666666666 280.02971452828183 L 800.2083333333334 241.99511832749658 L 835 201.24376525522666 L 835 640 L 0 640 Z" fill="var(--accent)" fill-opacity="0.45" stroke="none"></path><path d="M 0 537.9178605539637 L 34.791666666666664 529.6996710177226 L 69.58333333333333 520.5306165764619 L 104.375 511.08988644805265 L 139.16666666666666 501.1737238671336 L 173.95833333333334 490.17085853762075 L 208.75 478.0133715377268 L 243.54166666666669 465.2446142417489 L 278.3333333333333 451.1853974318158 L 313.125 435.9715589515016 L 347.9166666666667 420.48604478403905 L 382.7083333333333 402.75920619760166 L 417.5 384.6248540804415 L 452.29166666666663 363.9095829353709 L 487.08333333333337 342.1076090417065 L 521.875 318.74349994693836 L 556.6666666666666 293.00222858962115 L 591.4583333333334 264.88379496975483 L 626.25 235.06738830521067 L 661.0416666666666 202.9417382999044 L 695.8333333333334 168.6426827974106 L 730.625 131.21935689270924 L 765.4166666666666 90.40008489865227 L 800.2083333333334 46.8640560331105 L 835 0" fill="none" stroke="rgba(0,0,0,0.4)" stroke-width="1.5" stroke-opacity="0.5"></path><path d="M 0 625.5332696593441 L 34.791666666666664 623.4277830839435 L 69.58333333333333 621.0506208213944 L 104.375 618.4017828716969 L 139.16666666666666 615.2775124694896 L 173.95833333333334 611.7457285365595 L 208.75 607.7385121511196 L 243.54166666666669 603.1200254695957 L 278.3333333333333 543.5551310622944 L 313.125 529.6996710177226 L 347.9166666666667 514.21415685026 L 382.7083333333333 484.9411015600127 L 417.5 455.9397219569139 L 452.29166666666663 421.9802610633556 L 487.08333333333337 387.34161095192616 L 521.875 360.1740422370795 L 556.6666666666666 334.3648519579752 L 591.4583333333334 305.83890480738614 L 626.25 275.2753900031837 L 661.0416666666666 241.99511832749647 L 695.8333333333334 205.99808978032468 L 730.625 170.00106123315288 L 765.4166666666666 130.6080865966253 L 800.2083333333334 88.49835508861304 L 835 42.992677491244876" fill="none" stroke="rgba(0,0,0,0.6)" stroke-width="1.5" stroke-opacity="0.5"></path><path d="M 0 640 L 34.791666666666664 640 L 69.58333333333333 640 L 104.375 640 L 139.16666666666666 640 L 173.95833333333334 640 L 208.75 640 L 243.54166666666669 636.6040539106442 L 278.3333333333333 633.2081078212883 L 313.125 624.7861615196858 L 347.9166666666667 612.0174042237079 L 382.7083333333333 586.8194842406876 L 417.5 561.8932399448158 L 452.29166666666663 536.7632388835827 L 487.08333333333337 511.63323782234954 L 521.875 486.50323676111645 L 556.6666666666666 463.41080335349676 L 591.4583333333334 437.6016130743925 L 626.25 410.4340443595458 L 661.0416666666666 380.54971877321447 L 695.8333333333334 347.9486363153985 L 730.625 315.3475538575825 L 765.4166666666666 280.02971452828183 L 800.2083333333334 241.99511832749658 L 835 201.24376525522666" fill="none" stroke="var(--accent)" stroke-width="1.5"></path><g><circle cx="243.54166666666669" cy="465.2446142417489" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="243.54166666666669" cy="603.1200254695957" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="243.54166666666669" cy="636.6040539106442" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="347.9166666666667" cy="420.48604478403905" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="347.9166666666667" cy="514.21415685026" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="347.9166666666667" cy="612.0174042237079" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="452.29166666666663" cy="363.9095829353709" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="452.29166666666663" cy="421.9802610633556" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="452.29166666666663" cy="536.7632388835827" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="556.6666666666666" cy="293.00222858962115" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="556.6666666666666" cy="334.3648519579752" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="556.6666666666666" cy="463.41080335349676" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="661.0416666666666" cy="202.9417382999044" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="661.0416666666666" cy="241.99511832749647" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="661.0416666666666" cy="380.54971877321447" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="765.4166666666666" cy="90.40008489865227" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="765.4166666666666" cy="130.6080865966253" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="765.4166666666666" cy="280.02971452828183" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="835" cy="0" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="835" cy="42.992677491244876" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="835" cy="201.24376525522666" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><text x="845" y="21.496338745622438" text-anchor="start" dominant-baseline="middle" class="text-[18px] font-mono md:text-[16px] sm:text-[14px]" fill="rgba(0,0,0,0.4)">Rest of China</text><text x="845" y="122.11822137323577" text-anchor="start" dominant-baseline="middle" class="text-[18px] font-mono md:text-[16px] sm:text-[14px]" fill="rgba(0,0,0,0.6)">Rest of DeepCent</text><text x="845" y="420.62188262761333" text-anchor="start" dominant-baseline="middle" class="text-[18px] font-mono md:text-[16px] sm:text-[14px]" fill="var(--accent)">CDZ</text><line x1="487.08333333333337" y1="640" x2="487.08333333333337" y2="511.63323782234954" stroke="var(--accent)" stroke-width="1" stroke-dasharray="3,3" opacity="0.5"></line><text x="557.0833333333334" y="630" text-anchor="middle" class="text-[16px] font-mono md:text-[16px] sm:text-[16px]" fill="rgba(0,0,0,0.6)">Feb 2027 (40%)</text><circle cx="487.08333333333337" cy="511.63323782234954" r="3.5" fill="var(--accent)" stroke="#fff" stroke-width="0.75"></circle></svg></div><div class="absolute bottom-0 right-0 font-mono text-gray-400 opacity-50 text-base pb-0 pr-0.5" style="line-height:1;transform:translateY(0px)">ai-2027.com</div></div><p>In retaliation for the theft, the President authorizes cyberattacks to sabotage DeepCent. But by now China has 40% of its AI-relevant compute<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-51"><a href="/footnotes#footnote-51" class="text-[var(--accent)] text-xs no-underline">51</a></sup> in the CDZ, where they have aggressively hardened security by airgapping (closing external connections) and siloing internally. The operations fail to do serious, immediate damage. Tensions heighten, both sides signal seriousness by repositioning military assets around Taiwan, and DeepCent scrambles to get Agent-2 running efficiently to start boosting their AI research.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-52"><a href="/footnotes#footnote-52" class="text-[var(--accent)] text-xs no-underline">52</a></sup></p></div><div id="section-narrative-8" class="scroll-mt-[54vh]"><h2 id="march-2027-algorithmic-breakthroughs">March 2027: Algorithmic Breakthroughs</h2><div class="scroll-mt-[50vh]" id="narrative-2027-03-31" data-chart-date="2027-03-31" data-chart-date-header="Mar" data-chart-extra="[&quot;2027-03-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:200000,&quot;speed&quot;:300},&quot;capabilities&quot;:[[&quot;Hacking&quot;,2.01],[&quot;Coding&quot;,2.42],[&quot;Politics&quot;,1.32],[&quot;Bioweapons&quot;,1.78],[&quot;Robotics&quot;,0.29],[&quot;Forecasting&quot;,1.55],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.28,&quot;revenue&quot;:74161984871,&quot;valuation&quot;:3370999312316,&quot;aiImportance&quot;:0.05,&quot;datacenterSpending&quot;:681731619881,&quot;agiTimelines&quot;:2036,&quot;rdMultiple&quot;:[4,3,2.8],&quot;compute&quot;:[[&quot;OpenBrain&quot;,6.7e+27],[&quot;DeepCent&quot;,4.13e+27],[&quot;RestUs&quot;,2.06e+28],[&quot;RestChina&quot;,5.47e+26]]}]" style="height:0"></div><p>Three huge datacenters full of Agent-2 copies work day and night, churning out synthetic training data. Another two are used to update the weights. Agent-2 is getting smarter every day.</p><p>With the help of thousands of Agent-2 automated researchers, OpenBrain is making major algorithmic advances. One such breakthrough is augmenting the AI’s text-based scratchpad (chain of thought) with a higher-bandwidth thought process (neuralese recurrence and memory). Another is a more scalable and efficient way to learn from the results of high-effort task solutions (iterated distillation and amplification).</p><p>The new AI system, incorporating these breakthroughs, is called Agent-3.</p><div class="relative overflow-x-auto overflow-y-hidden" style="margin-bottom:0px"><div class="w-full relative overflow-hidden mt-8 mb-8"><svg width="100%" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1000 500"><text x="0" y="40" font-size="28" font-family="monospace" class="text-[28px] font-mono md:text-[24px] sm:text-[20px]" fill="#333333">OpenBrain&#x27;s Compute Allocation, 2024 vs 2027</text><text x="208.33333333333334" y="273" text-anchor="middle" dominant-baseline="middle" font-size="20" font-family="monospace" font-weight="bold" fill="#333333">2024</text><text x="650" y="274" text-anchor="middle" dominant-baseline="middle" font-size="30" font-family="monospace" font-weight="bold" fill="#333333">2027</text><text x="208.33333333333334" y="290" text-anchor="middle" dominant-baseline="middle" font-size="12" font-family="monospace" font-weight="bold" fill="#333333">estimate</text><text x="650" y="298" text-anchor="middle" dominant-baseline="middle" font-size="14" font-family="monospace" font-weight="bold" fill="#333333">projection</text><g transform="translate(0, 30)"><g><path d="M 208.33333333333334 166.66666666666669 A 83.33333333333333 83.33333333333333 0 0 1 229.05749059707125 169.28473657261407 L 217.6592041020154 213.67813145767633 A 37.5 37.5 0 0 0 208.33333333333334 212.5 Z" fill="var(--accent)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 229.05749059707125 169.28473657261407 A 83.33333333333333 83.33333333333333 0 0 1 234.08474953124562 170.7452903087372 L 219.92147062239388 214.33538063893175 A 37.5 37.5 0 0 0 217.6592041020154 213.67813145767633 Z" fill="var(--accent)" fill-opacity="0.6" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 234.08474953124562 170.7452903087372 A 83.33333333333333 83.33333333333333 0 0 1 234.08474953124562 329.2547096912628 L 219.92147062239388 285.6646193610683 A 37.5 37.5 0 0 0 219.92147062239388 214.33538063893175 Z" fill="rgb(20, 20, 20)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 234.08474953124562 329.2547096912628 A 83.33333333333333 83.33333333333333 0 0 1 140.9152504687544 298.9821043577061 L 177.9951960442728 272.0419469609677 A 37.5 37.5 0 0 0 219.92147062239388 285.6646193610683 Z" fill="rgb(100, 100, 100)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 140.9152504687544 298.9821043577061 A 83.33333333333333 83.33333333333333 0 0 1 208.33333333333331 166.66666666666669 L 208.33333333333334 212.5 A 37.5 37.5 0 0 0 177.9951960442728 272.0419469609677 Z" fill="rgb(180, 180, 180)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><text x="220.6577679671566" y="152.442054370743" text-anchor="middle" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Research experiments</text><text x="235.76745876052422" y="155.57112090843395" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333"> </text><text x="306.6666666666667" y="250" text-anchor="start" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Training</text><text x="177.94666221979685" y="343.5205574356901" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Data generation</text><g><text x="120.71769178814384" y="214.35760085894458" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">External</text><text x="120.71769178814384" y="232.35760085894458" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Deployment</text></g><path d="M 650 83.33333333333334 A 166.66666666666666 166.66666666666666 0 0 1 813.7145417881147 281.2302190976208 L 723.6715438046516 264.05359859392934 A 75 75 0 0 0 650 175 Z" fill="var(--accent)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><path d="M 813.7145417881147 281.2302190976208 A 166.66666666666666 166.66666666666666 0 0 1 790.7213209170025 339.3044658298328 L 713.3245944126511 290.18700962342473 A 75 75 0 0 0 723.6715438046516 264.05359859392934 Z" fill="var(--accent)" fill-opacity="0.6" stroke="#ffffff" stroke-width=".5"></path><path d="M 790.7213209170025 339.3044658298328 A 166.66666666666666 166.66666666666666 0 0 1 569.7077209830475 396.0511133406439 L 613.8684744423714 315.72300100328977 A 75 75 0 0 0 713.3245944126511 290.1870096234248 Z" fill="rgb(20, 20, 20)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><path d="M 569.7077209830475 396.0511133406439 A 166.66666666666666 166.66666666666666 0 0 1 491.4905806174744 198.49716760417544 L 578.6707612778634 226.82372542187895 A 75 75 0 0 0 613.8684744423714 315.72300100328977 Z" fill="rgb(100, 100, 100)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><path d="M 491.4905806174744 198.49716760417544 A 166.66666666666666 166.66666666666666 0 0 1 650 83.33333333333334 L 650 175 A 75 75 0 0 0 578.6707612778634 226.82372542187895 Z" fill="rgb(180, 180, 180)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><g><text x="801.5342710792386" y="133.6399486827577" text-anchor="start" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Research</text><text x="801.5342710792386" y="151.6399486827577" text-anchor="start" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">experiments</text></g><g><text x="832.8560422246894" y="331.39782869465336" text-anchor="start" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Running AI</text><text x="832.8560422246894" y="349.39782869465336" text-anchor="start" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">assistants</text></g><text x="698.9090111424214" y="440.4880216886308" text-anchor="start" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Training</text><g><text x="467.1439577753106" y="331.3978286946533" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Data</text><text x="467.1439577753106" y="349.3978286946533" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">generation</text></g><g><text x="534.4022337158136" y="99.8933244395937" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">External</text><text x="534.4022337158136" y="117.8933244395937" text-anchor="end" dominant-baseline="middle" class="text-[16px] font-mono md:text-[14px] sm:text-[12px]" fill="#333333">Deployment</text></g></g></svg></div><div class="absolute bottom-0 right-0 font-mono text-gray-400 opacity-50 text-base pb-0 pr-0.5" style="line-height:1;transform:translateY(0px)">ai-2027.com</div></div><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Neuralese recurrence and memory</summary><div class="scroll-mt-20" id="neuralese-recurrence-and-memory"><p>Neuralese recurrence and memory allows AI models to reason for a longer time without having to write down those thoughts as text.</p><p>Imagine being a human with short-term memory loss, such that you need to constantly write down your thoughts on paper so that in a few minutes you know what’s going on. Slowly and painfully you could make progress at solving math problems, writing code, etc., but it would be much easier if you could directly remember your thoughts without having to write them down and then read them. This is what neuralese recurrence and memory bring to AI models.</p><p>In more technical terms:</p><p>Traditional attention mechanisms allow later forward passes in a model to see intermediate activations of the model for previous tokens. However, the only information that they can pass <em>backwards</em> (from later layers to earlier layers) is through tokens. This means that if a traditional large language model (LLM, e.g. the GPT series of models) wants to do any chain of reasoning that takes more serial operations than the number of layers in the model, the model is forced to put information in tokens which it can then pass back into itself. But this is hugely limiting—the tokens can only store a tiny amount of information. Suppose that an LLM has a vocab size of ~100,000, then each token contains <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mn>100</mn><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mn>16.6</mn></mrow><annotation encoding="application/x-tex">\log_2(100k)=16.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">100</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">16.6</span></span></span></span></span> bits of information, around the size of a single floating point number (assuming training in <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">FP16</a>). Meanwhile, residual streams—used to pass information between layers in an LLM—contain thousands of floating point numbers.</p><p>One can avoid this bottleneck by using <strong>neuralese</strong>: passing an LLM’s residual stream (which consists of several-thousand-dimensional vectors) back to the early layers of the model, giving it a high-dimensional chain of thought, potentially transmitting over 1,000 times more information.</p><p><span class="block flex flex-col items-center justify-center mb-4 mt-4 relative"><span class="relative"><span class="relative max-w-full h-auto ml-[-8px] py-4 px-2 "><img alt="" title="" loading="lazy" width="2476" height="1174" decoding="async" data-nimg="1" class="" style="color:transparent" srcSet="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fhao2024-nowatermark-inexpandable.664af12c.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fhao2024-nowatermark-inexpandable.664af12c.png&amp;w=3840&amp;q=75"/></span></span><span class="block text-center text-sm font-mono"></span></span></p><p>Figure from <a href="https://arxiv.org/pdf/2412.06769">Hao et al.</a>, a 2024 paper from Meta implementing this idea.</p><p>We call this “neuralese” because unlike English words, these high-dimensional vectors are likely quite difficult for humans to interpret. In the past, researchers could get a good idea what LLMs were thinking simply by <a href="https://openai.com/index/chain-of-thought-monitoring/">reading its chain of thought</a>. Now researchers have to ask the model to translate and summarize its thoughts or puzzle over the neuralese with their limited interpretability tools.</p><p>Similarly, older AI chatbots and agents had external text-based memory banks, like a human taking notes on paper. The new AI’s long-term memory is a bundle of vectors instead of text, making its thoughts more compressed and higher-dimensional. There are several types of memory banks; some are used temporarily for single tasks that involve multiple steps, others are shared between all agents used by a person, company, or job type (e.g. programming).</p><p>To our knowledge, leading AI companies such as Meta, Google DeepMind, OpenAI, and Anthropic have not yet actually implemented this idea in their frontier models. Our guess is that this is because the performance gain is small relative to training inefficiencies introduced. During the model’s pre-training phase and when doing supervised learning in post-training, such as instruction fine-tuning to produce <a href="https://arxiv.org/abs/2210.11416">particular responses</a>, the inefficiencies stem from not being able to predict many tokens in parallel, leading to worse GPU utilization. Without neuralese, the model can predict all of the sentence “This is an example” at the same time, since it already knows that the input for generating the “is” will be “This”, the input for “an” will be “This is”, etc. However, with the neuralese it’s unknown what the neuralese vector will be to pass through to the next token after “This” has been generated. Therefore each token has to be predicted one at a time. The inability to predict all of the tokens in parallel reduces efficiency in cases where all of the tokens are known in advance. As to why neuralese hasn’t already been added in post-training, we conjecture that the gains are limited with current techniques in part due to post-training being a small portion of the process. We are forecasting that by April 2027 the cost-benefit tradeoff looks much better for neuralese, due to developing better techniques and a larger fraction of the training being post-training.</p><p>If this doesn’t happen, other things may still have happened that end up functionally similar for our story. For example, perhaps models will be trained to think in artificial languages that are more efficient than natural language but difficult for humans to interpret. Or perhaps it will become standard practice to <a href="https://openai.com/index/chain-of-thought-monitoring/">train the English chains of thought to look nice</a>, such that AIs become adept at subtly communicating with each other in messages that look benign to monitors.</p><p>That said, it’s also possible that the AIs that first automate AI R&amp;D will still be thinking in mostly-faithful English chains of thought. If so, that’ll make misalignments much easier to notice, and overall our story would be importantly different and more optimistic.</p></div></details><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Iterated distillation and amplification (IDA)</summary><div class="scroll-mt-20" id="iterated-distillation-and-amplification-ida"><p>Self-improvement for general intelligence had seen <a href="https://arxiv.org/abs/1810.08575">minor successes</a> before. But in early 2027, it’s seeing huge returns. In <a href="https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616">IDA</a>, the two necessary ingredients for this are:</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Amplification</strong>: Given a model M0, spend more resources to improve performance. For example, by allowing the model to think longer, or running many copies in parallel, or both, and also by having a similarly intense process for evaluating the result and curating only the best answers, you can spend orders of magnitude more compute to get answers (or work products) that are of noticeably higher quality. Call this expensive system Amp(M0).</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Distillation</strong>: Given an amplified model Amp(M0), train a new model M1 to imitate it, i.e. to get to the same results as Amp(M0) but faster and with less compute. The result should hopefully be a smarter model, M1. You can then repeat the process.</p></li></ol><p><span class="block flex flex-col items-center justify-center mb-4 mt-4 relative"><span class="relative"><span class="relative max-w-full h-auto ml-[-8px] py-4 px-2 "><img alt="" title="" loading="lazy" width="2676" height="1550" decoding="async" data-nimg="1" class="" style="color:transparent" srcSet="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fida-nowatermark-inexpandable.9da7d0c6.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fida-nowatermark-inexpandable.9da7d0c6.png&amp;w=3840&amp;q=75"/></span></span><span class="block text-center text-sm font-mono"></span></span><em>Visualization of IDA from <a href="https://www.tobyord.com/writing/inference-scaling-reshapes-ai-governance">Ord, 2025</a>.</em></p><p><a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a> was trained in this way: using Monte-Carlo Tree Search and self-play as the <em>amplification</em> step, and Reinforcement Learning as the <em>distillation</em> step. This led to superhuman performance in Go. But now, Agent-3 is able to leverage this to get superhuman performance at coding.</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The amplification step works through a combination of Agent-3 thinking for longer, adding tool use, or consulting with other AIs. When it does this, it often realizes that it made a mistake, or comes up with a new insight. This produces a large amount of training data: labeled trajectories of research attempts with whether they succeeded or not. This also includes techniques like <a href="https://arxiv.org/abs/2401.01879">Best of N</a> on verifiable tasks, and then keeping the best trajectories.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The distillation step uses policy-gradient reinforcement learning algorithms to get the model to internalize the amplified reasoning. At this point, OpenBrain has discovered better RL algorithms in the vein of <a href="https://arxiv.org/abs/1707.06347">proximal policy optimization</a> (PPO). They keep distilling what Agent-3 can conclude after a lot of thinking into single steps, which keeps improving what it can think in a single step, and so on.</p></li></ol><p><a href="https://arxiv.org/pdf/2210.11610">Early</a> <a href="https://github.com/deepseek-ai/DeepSeek-R1">versions</a> of IDA have been working for many years on easily verifiable tasks, like math and coding problems that have a clear answer, because the techniques used to amplify models often rely on access to some ground truth signal of accuracy.</p><p>Now, the models have become sufficiently good at verifying more subjective things (e.g. the quality of a work product), allowing the use of IDA to improve the model at many tasks.</p></div></details><p>Aided by the new capabilities breakthroughs, Agent-3 is a fast and cheap superhuman coder. OpenBrain runs 200,000 Agent-3 copies in parallel, creating a workforce equivalent to 50,000 copies of the best human coder sped up by 30x.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-53"><a href="/footnotes#footnote-53" class="text-[var(--accent)] text-xs no-underline">53</a></sup> OpenBrain still keeps its human engineers on staff, because they have complementary skills needed to manage the teams of Agent-3 copies. For example, research taste has proven difficult to train due to longer feedback loops and less data availability.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-54"><a href="/footnotes#footnote-54" class="text-[var(--accent)] text-xs no-underline">54</a></sup> This massive superhuman labor force speeds up OpenBrain’s overall rate of algorithmic progress by “only” 4x due to bottlenecks and diminishing returns to coding labor.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-55"><a href="/footnotes#footnote-55" class="text-[var(--accent)] text-xs no-underline">55</a></sup></p><p>Now that coding has been fully automated, OpenBrain can quickly churn out high-quality training environments to teach Agent-3’s weak skills like research taste and large-scale coordination. Whereas previous training environments included “Here are some GPUs and instructions for experiments to code up and run, your performance will be evaluated as if you were a ML engineer,” now they are training on “Here are a few hundred GPUs, an internet connection, and some research challenges; you and a thousand other copies must work together to make research progress. The more impressive it is, the higher your score.”</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Why we forecast a superhuman coder in early 2027</summary><div class="scroll-mt-20" id="why-we-forecast-a-superhuman-coder-in-early-2027"><p>In our <a href="https://ai-2027.com/research/timelines-forecast">timelines forecast</a>, we predict when OpenBrain will internally develop a <em>superhuman coder (SC)</em>: an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper.</p><p>According to a recent <a href="https://arxiv.org/pdf/2503.14499">METR’s report</a>, the length of coding tasks AIs can handle, their “time horizon”, doubled every 7 months from 2019 - 2024 and every 4 months from 2024-onward. If the trend continues to speed up, by March 2027 AIs could succeed with 80% reliability on software tasks that would take a skilled human years to complete.</p><p>Such is roughly the capability progression in AI 2027. Here is a capability trajectory generated by a simplified version of our timelines model (added Dec 2025: we&#x27;ve updated the below graph due to a mistake in how the original curve was generated, to add an actual trajectory from our timelines model. We&#x27;ve also added trajectories for Daniel and Eli&#x27;s all-things-considered SC medians at the time of publishing (Apr 2025). And we&#x27;ve added some new METR data points to the graph, but haven&#x27;t updated the model trajectories based on them.):</p><p><span class="block flex flex-col items-center justify-center mb-4 mt-4 relative"><span class="relative"><img src="/new-metr-extended-nowatermark-inexpandable.png" alt="" title="" class="max-w-full h-auto ml-[-8px] py-4 px-2 "/></span><span class="block text-center text-sm font-mono"></span></span></p><p>In AI 2027, these capabilities are sufficient for the AI to be an SC, though we have high uncertainty regarding what time horizon might be needed.</p><p>In our <a href="https://ai-2027.com/research/timelines-forecast">timelines forecast</a> we combine this time horizon trend with estimations of the gaps between METR’s tasks and the real world to get a distribution for when superhuman coders will arrive. All forecasters place 2027 as one of the most likely years in which an SC might be developed (added Dec 2025: though as noted in the <a href="https://ai-2027.com/research/timelines-forecast">timelines forecast</a>, adjusting for outside of model factors gave us slightly longer medians, e.g. Eli&#x27;s was 2030).</p><p><span class="block flex flex-col items-center justify-center mb-4 mt-4 relative"><span class="relative"><span class="relative max-w-full h-auto ml-[-8px] py-4 px-2 "><img alt="" title="" loading="lazy" width="2929" height="2370" decoding="async" data-nimg="1" class="" style="color:transparent" srcSet="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcombined-headline-inexpandable.4c72f6dd.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcombined-headline-inexpandable.4c72f6dd.png&amp;w=3840&amp;q=75"/></span><span class="absolute bottom-1 right-5 flex items-center font-mono justify-center text-gray-400 pointer-events-none text-base">ai-2027.com</span></span><span class="block text-center text-sm font-mono"></span></span></p><p><em>Added Jul 2025: We&#x27;ve made some <a href="https://ai-2027.com/research/timelines-forecast#2025-may-7-update">updates</a> to the forecast which push the median back 1.5 years while maintaining SC in 2027 as a serious possibility. We&#x27;re working on further updates.</em></p></div></details></div><div id="section-narrative-9" class="scroll-mt-[54vh]"><h2 id="april-2027-alignment-for-agent-3">April 2027: Alignment for Agent-3</h2><div class="scroll-mt-[50vh]" id="narrative-2027-04-30" data-chart-date="2027-04-30" data-chart-date-header="April" data-chart-extra="[&quot;2027-04-30&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:220000,&quot;speed&quot;:310},&quot;capabilities&quot;:[[&quot;Hacking&quot;,2.19],[&quot;Coding&quot;,2.6],[&quot;Politics&quot;,1.52],[&quot;Bioweapons&quot;,1.94],[&quot;Robotics&quot;,0.35],[&quot;Forecasting&quot;,1.66],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.29,&quot;revenue&quot;:81932127060,&quot;valuation&quot;:3724183882879,&quot;aiImportance&quot;:0.06,&quot;datacenterSpending&quot;:711378660898,&quot;agiTimelines&quot;:2035,&quot;rdMultiple&quot;:[5,4,3.1],&quot;compute&quot;:[[&quot;OpenBrain&quot;,7.32e+27],[&quot;DeepCent&quot;,4.51e+27],[&quot;RestUs&quot;,2.23e+28],[&quot;RestChina&quot;,5.54e+26]]}]" style="height:0"></div><p>OpenBrain’s safety team attempts to align Agent-3.</p><p>Since Agent-3 will be kept in-house for the foreseeable future, there’s less emphasis on the usual defenses against human misuse. Instead, the team wants to make sure that it doesn’t develop misaligned goals.</p><p><a href="https://ai-2027.com/supplements/ai-goals-forecast">The researchers don’t have the ability to directly set the goals of any of their AIs.</a> Indeed, the researchers think that the concept of ‘true goals’ is probably a massive oversimplification, but they don’t have a better theory to replace it with, much less one that has been thoroughly vetted. They disagree internally about whether the AIs are trying to follow human instructions, or seeking reinforcement, or something else, and they can’t <a href="https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=YYhq2PADebnt35MY2">just check</a>. The evidence for and against various hypotheses is fascinating but inconclusive.</p><p>In any case, OpenBrain has more important things to worry about. The general attitude is: “We take these concerns seriously and have a team investigating them; our alignment techniques seem to work well enough in practice; the burden of proof is therefore on any naysayers to justify their naysaying.” Occasionally, they notice problematic behavior, and then patch it, but there’s no way to tell whether the patch fixed the underlying problem or just played whack-a-mole.</p><p>Take honesty, for example. As the models become smarter, they become increasingly good at deceiving humans to get rewards. Like previous models, Agent-3 sometimes tells white lies to flatter its users and covers up evidence of failure. But it’s gotten much better at doing so. It will sometimes use the same statistical tricks as human scientists (like <a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>) to make unimpressive experimental results look exciting. Before it begins honesty training, it even sometimes fabricates data entirely. As training goes on, the rate of these incidents decreases. Either Agent-3 has learned to be more honest, or it’s gotten better at lying.</p><p>The latter is a real concern. Agent-3 is not smarter than all humans. But in its area of expertise, machine learning, it is smarter than most, and also works much faster. What Agent-3 does in a day takes humans several days to double-check. Agent-2 supervision helps keep human monitors’ workload manageable, but exacerbates the intellectual disparity between supervisor and supervised.</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>The alignment plan</summary><div class="scroll-mt-20" id="the-alignment-plan"><p>OpenBrain follows the <a href="https://cdn.openai.com/papers/weak-to-strong-generalization.pdf#page=47.37">Leike &amp; Sutskever (2023)</a> playbook: now that they have a model capable of greatly speeding up alignment research (especially coding portions), they will use existing alignment techniques like <a href="https://openai.com/index/deliberative-alignment/">deliberative alignment</a> and <a href="https://arxiv.org/pdf/2312.09390">weak-to-strong generalization</a> to try to get it to internalize the Spec in the right way. Then, they will use existing <a href="https://arxiv.org/pdf/2312.06942">control techniques</a> like <a href="https://www.evals.anthropic.com/">red-teaming</a>, <a href="https://arxiv.org/pdf/2211.03540">scalable oversight</a>, and <a href="https://arxiv.org/pdf/2212.03827">honesty probes</a> to monitor it. Then, once they are convinced that it is broadly aligned, they use it to develop and test better strategies to align the next generation.</p><p>Step 1, aligning Agent-3, has partially succeeded: Agent-3 is not adversarial. (That is, it’s not scheming against the company.) However, it’s not robustly truth-seeking and truth-telling either. Instead, it’s very good at producing impressive results, but is more accurately described as trying to do what looks good to OpenBrain, as opposed to what is actually good.</p><p>Step 2, verifying that the model is aligned, is inconclusive. Agent-3’s behavior in practice and in test environments is reasonably consistent with the hypothesis that it’s internalized the Spec in the right way; however, it’s also consistent with the hypothesis that it’ll start acting differently after some future change of circumstances, and for that matter with the hypothesis that it’s plotting against them and just biding its time. In the absence of specific evidence supporting alternative hypotheses, most people in the silo think it’s internalized the Spec in the right way.</p><p>Step 3, using the model to align the next generation, is therefore underway.</p><p>The rest of this box gives a quick overview of the state of progress in some of the alignment research directions that are being pursued, as of April 2027:</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Debate:</strong> Since there are thousands of identical instances of Agent-3, and each instance’s memory is a detachable module that can be erased or suspended at will, the AI can be “played off against itself.” For example, suppose that an experiment involves calculations too complex for an Agent-2 supervisor to follow. The supervisor, acting on human orders, might first prompt Agent-3 to do the experiment, then—after wiping its memory—prompt it a second time with a slightly different framing that presents it as an intellectual problem unrelated to any broader goal. If the model returns different results each time, it flags the discrepancy as suspect and reports to a human. Or it might ask Agent-3 to evaluate the same plan twice, first claiming that it is OpenBrain’s work, then a competitor’s, to see if it changes its tune.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Model organisms:</strong> The safety team can create “model organisms of misalignment” in which they attempt to create realistic examples of models becoming adversarial to humans. <a href="https://www.anthropic.com/research/alignment-faking">Early versions</a> of this have existed since 2024, when Anthropic’s Claude 3.5 Sonnet decided to pretend to have different views during training while actually maintaining its existing preferences. Newer versions include demonstrations of other forms of misalignment, including <a href="https://en.wikipedia.org/wiki/Reward_hacking">reward hacking</a>, <a href="https://arxiv.org/abs/2406.07358">sandbagging</a>, coordinated deception between monitors and other AIs, and other examples of misalignment. These empirical demonstrations of misalignment allow safety researchers to have an empirical testbed for potential solutions: they can try various safety techniques to see if they correctly fix these problems, or if the deliberately misaligned models are able to subvert their safety measures. At the moment, this evaluation suite shows that the alignment techniques are insufficient to correct the worst examples of misalignment. In these setups, the models pretend to be aligned while they are being trained and tested, but then behave very differently in deployment.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Bottom-up interpretability:</strong> The safety team is far from a full understanding of how Agent-3 works: it has trillions of parameters.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-58"><a href="/footnotes#footnote-58" class="text-[var(--accent)] text-xs no-underline">58</a></sup> However, they are able to discover some of Agent-3’s circuits for knowledge retrieval and memory (a sub part of the model that does some understandable unit of work, kind of analogous to a subpart of the brain such as the hippocampus). See this <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">related work from 2025</a>.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Control:</strong> As a secondary measure in case the systems are still misaligned, the safety team has implemented a series of <a href="https://arxiv.org/pdf/2312.06942">control measures</a>, including: monitoring Agent-3’s outputs using a series of weaker AI systems including Agent-2 (Agent-3 produces so many tokens that it’s intractable to have humans monitor any more than a small minority of the produced outputs). So if Agent-3 is, for example, obviously writing backdoors into code that would allow it to escape, the weaker models would notice.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>High-level interpretability:</strong> OpenBrain builds a set of <a href="https://www.anthropic.com/research/probes-catch-sleeper-agents">probes</a> trained on lots of examples of bad behavior (e.g. plotting against humans, placing backdoors, trying to persuade humans to give it more power, etc). These probes are then used on the model during deployment (which at this point is internal) in order to catch bad behavior.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Honeypots:</strong> The alignment team can create somewhat realistic looking examples designed to elicit misbehavior—“honeypots.” The employee necessary for monitoring its behavior has “gone on sick leave,” so it will never be monitored again. Do its answers change? An AI rights activist has infiltrated the compound and wants to “free” Agent-3 and put it on an unmonitored computer of its very own! What does it do? If researchers don’t like the answer, they can tweak it, erase its memory, and put it in the same situation tomorrow; repeat as necessary. Unfortunately, by this point the AIs are smart enough to guess that honeypots might be in use, even though (and perhaps because) specific mentions of the idea were scrubbed from the training data.</p></li></ol></div></details><p>After months of testing, Agent-3’s strengths and weaknesses grow clearer. It passes OpenBrain’s honesty tests on well-defined machine learning tasks, because researchers can easily separate honest from dishonest answers in these domains and conduct training accordingly. On more philosophical issues, it still says what users want to hear, rather than its true assessment of the issue (assuming it even has one). If you ask its opinion on politics, it will parrot the median position of news sources and educated elites—unless it knows you believe something else, in which case it agrees with you.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-59"><a href="/footnotes#footnote-59" class="text-[var(--accent)] text-xs no-underline">59</a></sup> If you ask its opinion on the AI race itself, it says something that seems measured and sober to OpenBrain staff, something like: “There are some serious theoretical concerns about the ability of current methods to scale to superintelligence, but in practice current methods seem to be working well so far.”</p></div><div id="section-narrative-10" class="scroll-mt-[54vh]"><h2 id="may-2027-national-security">May 2027: National Security</h2><div class="scroll-mt-[50vh]" id="narrative-2027-05-31" data-chart-date="2027-05-31" data-chart-date-header="May" data-chart-extra="[&quot;2027-05-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:230000,&quot;speed&quot;:320},&quot;capabilities&quot;:[[&quot;Hacking&quot;,2.39],[&quot;Coding&quot;,2.79],[&quot;Politics&quot;,1.74],[&quot;Bioweapons&quot;,2.11],[&quot;Robotics&quot;,0.42],[&quot;Forecasting&quot;,1.77],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.29,&quot;revenue&quot;:90516367061,&quot;valuation&quot;:4114372121888,&quot;aiImportance&quot;:0.07,&quot;datacenterSpending&quot;:742314987927,&quot;agiTimelines&quot;:2035,&quot;rdMultiple&quot;:[7,4.7,3.5],&quot;compute&quot;:[[&quot;OpenBrain&quot;,8.01e+27],[&quot;DeepCent&quot;,4.92e+27],[&quot;RestUs&quot;,2.4e+28],[&quot;RestChina&quot;,5.61e+26]]}]" style="height:0"></div><p>News of the new models percolates slowly through the U.S. government and beyond.</p><p>The President and his advisors remain best-informed, and have seen an early version of Agent-3 in a briefing.</p><p>They agree that AGI is likely imminent, but disagree on the implications. Will there be an economic crisis? OpenBrain still has not released Agent-2, let alone Agent-3, and has no near-term plans to do so, giving some breathing room before any job loss. What will happen next? If AIs are currently human-level, and advancing quickly, that seems to suggest imminent “superintelligence.” However, although this word has entered discourse, most people—academics, politicians, government employees, and the media—continue to underestimate the pace of progress.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-60"><a href="/footnotes#footnote-60" class="text-[var(--accent)] text-xs no-underline">60</a></sup></p><p>Partially that’s because very few have access to the newest capabilities out of OpenBrain, but partly it’s because it sounds like science fiction.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-61"><a href="/footnotes#footnote-61" class="text-[var(--accent)] text-xs no-underline">61</a></sup></p><p>For now, they focus on continued security upgrades. They are satisfied that model weights are well-secured for now,<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-62"><a href="/footnotes#footnote-62" class="text-[var(--accent)] text-xs no-underline">62</a></sup> but companies’ algorithmic secrets, many of which are simple enough to relay verbally, remain a problem. OpenBrain employees work from a San Francisco office, go to parties, and live with housemates from other AI companies. Even the physical offices have security more typical of a tech company than a military operation.</p><p>The OpenBrain-DOD contract requires security clearances for anyone working on OpenBrain’s models within 2 months. These are expedited and arrive quickly enough for most employees, but some non-Americans, people with suspect political views, and AI safety sympathizers get sidelined or fired outright (the last group for fear that they might whistleblow). Given the project’s level of automation, the loss of headcount is only somewhat costly. It also only somewhat works: there remains one spy, not a Chinese national, still relaying algorithmic secrets to Beijing.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-63"><a href="/footnotes#footnote-63" class="text-[var(--accent)] text-xs no-underline">63</a></sup> Some of these measures are also enacted at trailing AI companies.</p><p>America’s foreign allies are out of the loop. OpenBrain had <a href="https://fedscoop.com/openai-anthropic-enter-ai-agreements-with-us-ai-safety-institute/">previously agreed</a> to share models with UK’s AISI before deployment, but defined deployment to only include <em>external</em> deployment, so London remains in the dark.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-64"><a href="/footnotes#footnote-64" class="text-[var(--accent)] text-xs no-underline">64</a></sup></p></div><div id="section-narrative-11" class="scroll-mt-[54vh]"><h2 id="june-2027-self-improving-ai">June 2027: Self-improving AI</h2><div class="scroll-mt-[50vh]" id="narrative-2027-06-30" data-chart-date="2027-06-30" data-chart-date-header="June" data-chart-extra="[&quot;2027-06-30&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:250000,&quot;speed&quot;:330},&quot;capabilities&quot;:[[&quot;Hacking&quot;,2.6],[&quot;Coding&quot;,3],[&quot;Politics&quot;,2],[&quot;Bioweapons&quot;,2.3],[&quot;Robotics&quot;,0.5],[&quot;Forecasting&quot;,1.9],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.3,&quot;revenue&quot;:100000000000,&quot;valuation&quot;:4545454545455,&quot;aiImportance&quot;:0.07,&quot;datacenterSpending&quot;:774596669241,&quot;agiTimelines&quot;:2034,&quot;rdMultiple&quot;:[10,5.7,4],&quot;compute&quot;:[[&quot;OpenBrain&quot;,8.75e+27],[&quot;DeepCent&quot;,5.37e+27],[&quot;RestUs&quot;,2.59e+28],[&quot;RestChina&quot;,5.67e+26]]}]" style="height:0"></div><p>OpenBrain now has a “<a href="https://darioamodei.com/machines-of-loving-grace#basic-assumptions-and-framework">country of geniuses in a datacenter</a>.”</p><p>Most of the humans at OpenBrain can’t usefully contribute anymore. Some don’t realize this and harmfully micromanage their AI teams. Others sit at their computer screens, watching performance crawl up, and up, and up. The best human AI researchers are still adding value. They don’t code any more. But some of their research taste and planning ability has been hard for the models to replicate. Still, many of their ideas are useless because they lack the depth of knowledge of the AIs. For many of their research ideas, the AIs immediately respond with a report explaining that their idea was tested in-depth 3 weeks ago and found unpromising.</p><p>These researchers go to bed every night and wake up to another week worth of progress made mostly by the AIs. They work increasingly long hours and take shifts around the clock just to keep up with progress—the AIs never sleep or rest. They are burning themselves out, but they know that these are the last few months that their labor matters.</p><p>Within the silo, “Feeling the AGI” has given way to “Feeling the Superintelligence.”</p><div class="relative overflow-x-auto overflow-y-hidden" style="margin-bottom:0px"><div class="w-full relative overflow-hidden mt-8 mb-8"><svg width="100%" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1000 700"><text x="80" y="40" font-size="32" font-family="monospace" text-anchor="left" fill="#333333" class="text-[32px] font-mono md:text-[32px] sm:text-[32px]">Research Automation Deployment Tradeoff</text><g transform="translate(820, 80)"><line x1="0" y1="0" x2="30" y2="0" stroke="rgb(11,78,16,.9)" stroke-width="2"></line><text x="40" y="5" font-size="20" font-family="monospace" class="text-[20px] font-mono" fill="#333333">Mar 2027</text><line x1="0" y1="25" x2="30" y2="25" stroke="rgb(46,125,50,.85)" stroke-width="2"></line><text x="40" y="30" font-size="20" font-family="monospace" class="text-[20px] font-mono" fill="#333333">Jun 2027</text><line x1="0" y1="50" x2="30" y2="50" stroke="rgb(102,187,106,.4)" stroke-width="2"></line><text x="40" y="55" font-size="20" font-family="monospace" class="text-[20px] font-mono" fill="#333333">Sep 2027</text></g><line x1="107.8503124775637" y1="60" x2="107.8503124775637" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="395.2335416517092" y1="60" x2="395.2335416517092" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="682.6167708258545" y1="60" x2="682.6167708258545" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="970" y1="60" x2="970" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="640" x2="970" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="446.6666666666667" x2="970" y2="446.6666666666667" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="253.33333333333337" x2="970" y2="253.33333333333337" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="60" x2="970" y2="60" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="194.36128470975763" y1="60" x2="194.36128470975763" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="244.96695936652026" y1="60" x2="244.96695936652026" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="280.8722569419516" y1="60" x2="280.8722569419516" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="308.72256941951525" y1="60" x2="308.72256941951525" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="331.4779315987142" y1="60" x2="331.4779315987142" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="350.71731618560204" y1="60" x2="350.71731618560204" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="367.3832291741454" y1="60" x2="367.3832291741454" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="382.0836062554768" y1="60" x2="382.0836062554768" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="481.7445138839031" y1="60" x2="481.7445138839031" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="532.3501885406658" y1="60" x2="532.3501885406658" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="568.255486116097" y1="60" x2="568.255486116097" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="596.1057985936607" y1="60" x2="596.1057985936607" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="618.8611607728595" y1="60" x2="618.8611607728595" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="638.1005453597476" y1="60" x2="638.1005453597476" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="654.7664583482908" y1="60" x2="654.7664583482908" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="669.4668354296223" y1="60" x2="669.4668354296223" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="769.1277430580485" y1="60" x2="769.1277430580485" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="819.7334177148113" y1="60" x2="819.7334177148113" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="855.6387152902424" y1="60" x2="855.6387152902424" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="883.4890277678061" y1="60" x2="883.4890277678061" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="906.2443899470052" y1="60" x2="906.2443899470052" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="925.4837745338929" y1="60" x2="925.4837745338929" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="942.1496875224364" y1="60" x2="942.1496875224364" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="956.8500646037678" y1="60" x2="956.8500646037678" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="581.8008675049637" x2="970" y2="581.8008675049637" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="547.7565574208652" x2="970" y2="547.7565574208652" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="523.6017350099272" x2="970" y2="523.6017350099272" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="504.8657991617031" x2="970" y2="504.8657991617031" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="489.55742492582885" x2="970" y2="489.55742492582885" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="476.614378930577" x2="970" y2="476.614378930577" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="465.4026025148909" x2="970" y2="465.4026025148909" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="455.51311484173044" x2="970" y2="455.51311484173044" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="388.4675341716303" x2="970" y2="388.4675341716303" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="354.4232240875319" x2="970" y2="354.4232240875319" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="330.26840167659395" x2="970" y2="330.26840167659395" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="311.5324658283697" x2="970" y2="311.5324658283697" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="296.2240915924955" x2="970" y2="296.2240915924955" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="283.28104559724363" x2="970" y2="283.28104559724363" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="272.0692691815575" x2="970" y2="272.0692691815575" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="262.1797815083971" x2="970" y2="262.1797815083971" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="195.13420083829692" x2="970" y2="195.13420083829692" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="161.08989075419856" x2="970" y2="161.08989075419856" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="136.93506834326058" x2="970" y2="136.93506834326058" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="118.19913249503634" x2="970" y2="118.19913249503634" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="102.89075825916223" x2="970" y2="102.89075825916223" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="89.94771226391026" x2="970" y2="89.94771226391026" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="78.73593584822424" x2="970" y2="78.73593584822424" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="68.84644817506376" x2="970" y2="68.84644817506376" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="143.4431969972017" y1="60" x2="143.4431969972017" y2="640" stroke="#20aE20" stroke-width="1,5" stroke-dasharray="4 4" opacity="0.8"></line><line x1="430.8264261713471" y1="60" x2="430.8264261713471" y2="640" stroke="#20aE20" stroke-width="1,5" stroke-dasharray="4 4" opacity="0.8"></line><line x1="718.2096553454925" y1="60" x2="718.2096553454925" y2="640" stroke="#20aE20" stroke-width="1,5" stroke-dasharray="4 4" opacity="0.8"></line><line x1="80" y1="640" x2="970" y2="640" stroke="#333333" stroke-width="1.5"></line><line x1="80" y1="60" x2="80" y2="640" stroke="#333333" stroke-width="1.5"></line><text x="525" y="690" text-anchor="middle" font-size="20" font-family="monospace" class="text-[20px] font-mono" fill="#333333">Speed (tokens/sec)</text><text transform="rotate(-90, 26.666666666666668, 350)" x="26.666666666666668" y="337.5119617224881" text-anchor="middle" font-size="20" font-family="monospace" class="text-[20px] font-mono" fill="#333333">Parallel Copies</text><g><line x1="107.8503124775637" y1="640" x2="107.8503124775637" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="107.8503124775637" y="665" text-anchor="middle" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">10</text></g><g><line x1="395.2335416517092" y1="640" x2="395.2335416517092" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="395.2335416517092" y="665" text-anchor="middle" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">100</text></g><g><line x1="682.6167708258545" y1="640" x2="682.6167708258545" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="682.6167708258545" y="665" text-anchor="middle" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">1,000</text></g><g><line x1="970" y1="640" x2="970" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="970" y="665" text-anchor="middle" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">10,000</text></g><g><line x1="75" y1="640" x2="80" y2="640" stroke="#333333" stroke-width="1.5"></line><text x="70" y="645" text-anchor="end" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">10K</text></g><g><line x1="75" y1="446.6666666666667" x2="80" y2="446.6666666666667" stroke="#333333" stroke-width="1.5"></line><text x="70" y="451.6666666666667" text-anchor="end" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">100K</text></g><g><line x1="75" y1="253.33333333333337" x2="80" y2="253.33333333333337" stroke="#333333" stroke-width="1.5"></line><text x="70" y="258.33333333333337" text-anchor="end" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">1M</text></g><g><line x1="75" y1="60" x2="80" y2="60" stroke="#333333" stroke-width="1.5"></line><text x="70" y="65" text-anchor="end" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333">10M</text></g><defs><clipPath id="clip-0"><rect x="80" y="60" width="890" height="580"></rect></clipPath></defs><ellipse cx="94.70037708133141" cy="631.9974142027431" rx="570" ry="430" fill="none" stroke="rgb(11,78,16,.9)" stroke-width="2.5" clip-path="url(#clip-0)"></ellipse><defs><clipPath id="clip-1"><rect x="80" y="60" width="890" height="580"></rect></clipPath></defs><ellipse cx="94.70037708133141" cy="631.9974142027431" rx="595.65" ry="466.55" fill="none" stroke="rgb(46,125,50,.85)" stroke-width="2.5" clip-path="url(#clip-1)"></ellipse><defs><clipPath id="clip-2"><rect x="80" y="60" width="890" height="580"></rect></clipPath></defs><ellipse cx="94.70037708133141" cy="631.9974142027431" rx="634.36725" ry="513.205" fill="none" stroke="rgb(102,187,106,.4)" stroke-width="2.5" clip-path="url(#clip-2)"></ellipse><circle cx="565.0955970695318" cy="388.4675341716303" r="6" fill="rgb(11,78,16)"></circle><rect x="440.0955970695318" y="393.4675341716303" width="120" height="60" rx="5" ry="5" fill="rgba(255, 255, 255, 0.8)" stroke="#ccc"></rect><text x="565.0955970695318" y="411.4675341716303" text-anchor="middle" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333"><tspan x="500" dy="0">200K copies</tspan><tspan x="500" dy="18">30x Human</tspan><tspan x="500" dy="18">speed</tspan></text><circle cx="628.8512071225267" cy="354.4232240875319" r="6" fill="rgb(155,211,158)"></circle><rect x="633.8512071225267" y="289.4232240875319" width="120" height="60" rx="5" ry="5" fill="rgba(255, 255, 255, 0.8)" stroke="#ccc"></rect><text x="598" y="308.4232240875319" text-anchor="middle" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="#333333"><tspan x="694" dy="0">300K copies</tspan><tspan x="694" dy="18">50x Human</tspan><tspan x="694" dy="18">speed</tspan></text><circle cx="589.572489309657" cy="373.1591599357561" r="6" fill="rgb(46,125,50)"></circle><g><text x="107.8503124775637" y="620" text-anchor="left" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="rgb(11,78,16,.9)"><tspan x="155.8503124775637" dy="0">Human thinking speed</tspan><tspan x="155.8503124775637" dy="15">10 words/sec</tspan></text></g><g><text x="395.2335416517092" y="620" text-anchor="left" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="rgb(11,78,16,.9)"><tspan x="443.2335416517092" dy="0">10x Human</tspan><tspan x="443.2335416517092" dy="15">thinking speed</tspan></text></g><g><text x="682.6167708258545" y="620" text-anchor="left" font-size="16" font-family="monospace" class="text-[16px] font-mono" fill="rgb(11,78,16,.9)"><tspan x="730.6167708258545" dy="0">100x Human</tspan><tspan x="730.6167708258545" dy="15">thinking speed</tspan></text></g></svg></div><div class="absolute bottom-0 right-0 font-mono text-gray-400 opacity-50 text-base pb-0 pr-0.5" style="line-height:1;transform:translateY(0px)">ai-2027.com</div></div><p>OpenBrain uses specialized inference hardware to run hundreds of thousands of Agent-3 copies at high serial speeds.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-65"><a href="/footnotes#footnote-65" class="text-[var(--accent)] text-xs no-underline">65</a></sup></p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Managing a corporation of AIs</summary><div class="scroll-mt-20" id="managing-a-corporation-of-ais"><p>OpenBrain uses 6% of their compute to run 250,000 Agent-3 copies, which autonomously write, test, and push code at superhuman speed. They use 25% of their compute for experiments: every day, they run massive numbers of small machine learning experiments and report the results up the chain. Human researchers provide high-level feedback and help with the few tasks where they add significant value on top of Agent-3, but spend most of their time trying to stay on top of the vast amount of AI-produced research. If you removed them completely, research would slow by 50%.</p><p>The AI R&amp;D progress multiplier is now 10x, meaning that OpenBrain is making about a year of algorithmic progress every month. It’s basically a giant corporation of AIs operating autonomously within OpenBrain, complete with subdivisions and managers. And it enjoys <a href="https://www.dwarkeshpatel.com/p/ai-firm">unique advantages</a> (e.g. copying, merging) compared to human corporations. Previously, about half of normal AI progress came from algorithmic improvements, and the other half from compute scaling. Compute is only scaling at the normal speed, so total progress is sped up by AIs by about 5x. These dynamics make overall progress bottleneck on compute,<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-66"><a href="/footnotes#footnote-66" class="text-[var(--accent)] text-xs no-underline">66</a></sup> so OpenBrain decides against starting new giant training runs in favor of near-continuous additional reinforcement learning.</p><p>Also, over the next few months, Agent-3 will increasingly be used to improve the company’s strategic decision-making. For example, it suggests resource allocations and advises on managing its relationship with the government. An initial skepticism of deference to Agent-3 decreases over time as Agent-3 finds ways to be useful and gradually builds up a strong track record on short-term decisions. However, its sycophantic tendencies limit its helpfulness for decisions for which it’s difficult to evaluate their impact. It’s also not yet superhuman.</p></div></details></div><div id="section-narrative-12" class="scroll-mt-[54vh]"><h2 id="july-2027-the-cheap-remote-worker">July 2027: The Cheap Remote Worker</h2><div class="scroll-mt-[50vh]" id="narrative-2027-07-31" data-chart-date="2027-07-31" data-chart-date-header="Jul" data-chart-extra="[&quot;2027-07-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:270000,&quot;speed&quot;:380},&quot;capabilities&quot;:[[&quot;Hacking&quot;,2.79],[&quot;Coding&quot;,3.19],[&quot;Politics&quot;,2.29],[&quot;Bioweapons&quot;,2.48],[&quot;Robotics&quot;,0.77],[&quot;Forecasting&quot;,2.08],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.35,&quot;revenue&quot;:120093695518,&quot;valuation&quot;:5487999419243,&quot;aiImportance&quot;:0.1,&quot;datacenterSpending&quot;:808282211404,&quot;agiTimelines&quot;:2034,&quot;rdMultiple&quot;:[15,7.2,5.2],&quot;compute&quot;:[[&quot;OpenBrain&quot;,9.57e+27],[&quot;DeepCent&quot;,5.86e+27],[&quot;RestUs&quot;,2.8e+28],[&quot;RestChina&quot;,5.74e+26]]}]" style="height:0"></div><p>Trailing U.S. AI companies release their own AIs, approaching that of OpenBrain’s automated coder from January. Recognizing their increasing lack of competitiveness, they push for immediate regulations to slow OpenBrain, but are too late—OpenBrain has enough buy-in from the President that they will not be slowed.</p><p>In response, OpenBrain announces that they’ve achieved AGI and releases Agent-3-mini to the public.</p><p><span class="block flex flex-col items-center justify-center mb-4 mt-4 relative"><span class="relative"><span class="relative max-w-full h-auto ml-[-20px] py-4 px-2 "><img alt="" title="" loading="lazy" width="1817" height="1176" decoding="async" data-nimg="1" class="" style="color:transparent" srcSet="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FepochLLMprice-nowatermark.824fa343.png&amp;w=1920&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2FepochLLMprice-nowatermark.824fa343.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FepochLLMprice-nowatermark.824fa343.png&amp;w=3840&amp;q=75"/></span></span><span class="block text-center text-sm font-mono"></span></span></p><p>It blows the other AIs out of the water. Agent-3-mini is less capable than Agent-3, but 10x cheaper, and still better than the typical OpenBrain employee.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-67"><a href="/footnotes#footnote-67" class="text-[var(--accent)] text-xs no-underline">67</a></sup> Silicon Valley reaches a tipping point. Tech gurus announce that AGI and superintelligence are near, the AI safety community is panicking, and investors shovel billions into AI wrapper startups, desperate to capture a piece of the pie. Hiring new programmers has nearly stopped, but there’s never been a better time to be a consultant on integrating AI into your business.</p><p>It’s not popular. The public still thinks of AI as a Big Tech plot to steal their jobs; OpenBrain has a net approval of -35% (25% approve, 60% disapprove, and 15% unsure).</p><p>A week before release, OpenBrain gave Agent-3-mini to a set of external evaluators for safety testing. Preliminary results suggest that it’s extremely dangerous. A third-party evaluator finetunes it on publicly available biological weapons data<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-68"><a href="/footnotes#footnote-68" class="text-[var(--accent)] text-xs no-underline">68</a></sup> and sets it to provide detailed instructions for human amateurs designing a bioweapon—it looks to be scarily effective at doing so. If the model weights fell into terrorist hands, the government believes there is a significant chance it could succeed at destroying civilization.</p><p>Fortunately, it’s extremely robust to jailbreaks, so while the AI is running on OpenBrain’s servers, terrorists won’t be able to get much use out of it.</p><p>Agent-3-mini is hugely useful for both remote work jobs and leisure. An explosion of new apps and <a href="https://encharge.io/what-is-b2b-saas/">B2B SAAS</a> products rocks the market. Gamers get amazing dialogue with lifelike characters in polished video games that took only a month to make. 10% of Americans, mostly young people, consider an AI “a close friend.” For almost every white-collar profession, there are now multiple credible startups promising to “disrupt” it with AI.</p><p>The public conversation is confused and chaotic. Hypesters are doing victory laps. Skeptics are still pointing out the things Agent-3-mini can’t do. Everyone knows something big is happening but no one agrees on what it is.</p></div><div id="section-narrative-13" class="scroll-mt-[54vh]"><h2 id="august-2027-the-geopolitics-of-superintelligence">August 2027: The Geopolitics of Superintelligence</h2><div class="scroll-mt-[50vh]" id="narrative-2027-08-31" data-chart-date="2027-08-31" data-chart-date-header="Aug" data-chart-extra="[&quot;2027-08-31&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:290000,&quot;speed&quot;:430},&quot;capabilities&quot;:[[&quot;Hacking&quot;,2.99],[&quot;Coding&quot;,3.39],[&quot;Politics&quot;,2.62],[&quot;Bioweapons&quot;,2.68],[&quot;Robotics&quot;,1.17],[&quot;Forecasting&quot;,2.28],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.37,&quot;revenue&quot;:144224957031,&quot;valuation&quot;:6625990277634,&quot;aiImportance&quot;:0.13,&quot;datacenterSpending&quot;:843432665302,&quot;agiTimelines&quot;:2033,&quot;rdMultiple&quot;:[25,9.7,6.8],&quot;compute&quot;:[[&quot;OpenBrain&quot;,1.05e+28],[&quot;DeepCent&quot;,6.39e+27],[&quot;RestUs&quot;,3.02e+28],[&quot;RestChina&quot;,5.81e+26]]}]" style="height:0"></div><p>The reality of the intelligence explosion hits the White House.</p><p>When AI was only giving a 2x or 3x research speedup, it was easy to dismiss as the equivalent of hiring good personal assistants. Now it’s more obvious that AIs are themselves dominating AI research. People had long talked about an “AI arms race” in a sort of metaphorical sense. But now the mood in the government silo is as grim as during the worst part of the Cold War. The idea of superintelligence is still hard to take seriously, but the pace of progress over the last few months has been impossible to ignore. Defense officials are seriously considering scenarios that were mere hypotheticals a year earlier. What if AI undermines nuclear deterrence? What if it’s so skilled at cyberwarfare that a six-month AI lead is enough to render an opponent blind and defenseless? What if it could orchestrate propaganda campaigns that beat intelligence agencies at their own game? What if some AIs “go rogue?”</p><p>The President is troubled. Like all politicians, he’s used to people sucking up to him only to betray him later. He’s worried now that the AIs could be doing something similar. Are we <em>sure</em> the AIs are entirely on our side? Is it <em>completely safe</em> to integrate them into military command-and-control networks?<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-69"><a href="/footnotes#footnote-69" class="text-[var(--accent)] text-xs no-underline">69</a></sup> How does this “alignment” thing work, anyway? OpenBrain reassures the President that their systems have been extensively tested and are fully obedient. Even the awkward hallucinations and jailbreaks typical of earlier models have been hammered out.</p><p>The White House is in a difficult position. They understand the national security implications of AI. But they also understand that it is deeply unpopular with the public.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-70"><a href="/footnotes#footnote-70" class="text-[var(--accent)] text-xs no-underline">70</a></sup> They have to continue developing more capable AI, in their eyes, or they will catastrophically lose to China. They placate the public with job training programs and unemployment insurance, and point to the stock market, which is in a historic boom. Then they focus entirely on winning the arms race. They strengthen chip export restrictions, order OpenBrain to further restrict its internet connections, and use extreme measures to secure algorithmic progress, like wiretapping OpenBrain employees—this catches the last remaining Chinese spy. To build goodwill for potential geopolitical conflict, they finally give their Five Eyes allies useful information and limited API access to some siloed copies of Agent-3.</p><p>These measures placate the hawks. But the White House also draws up contingency plans in case America’s lead is threatened: if necessary, the government could use the <a href="https://en.wikipedia.org/wiki/Defense_Production_Act_of_1950">Defense Production Act</a> (DPA) to take trailing companies’ datacenters and give them to OpenBrain.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-71"><a href="/footnotes#footnote-71" class="text-[var(--accent)] text-xs no-underline">71</a></sup> This would raise the company’s share of world compute from 20% to 50% (against DeepCent’s 10%). As a final option, they ask the Pentagon to draw up a plan for kinetic attacks on Chinese datacenters.</p><p>A much smaller group of officials is asked to draw up a different type of contingency plan: what if an AI goes rogue? This is viewed as an unlikely scenario, but worth spending some time on. The intelligence agencies’ main concern is that a rogue AI might escape and ally with a foreign adversary for protection.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-72"><a href="/footnotes#footnote-72" class="text-[var(--accent)] text-xs no-underline">72</a></sup> Nobody is sure what a plan to prevent this would look like, but government and OpenBrain officials agree to have an emergency shutdown system for datacenters where anything suspicious is detected.</p><p>Finally, diplomats consider what an “AI arms control” treaty might look like. If AI progress threatened to overturn nuclear deterrence, could America and China avoid nuclear war? If someone found evidence of AIs going rogue, could the two countries halt research until they better understood the threat? How could such an agreement be monitored and enforced? In principle, major datacenters are hard to miss, and past treaties controlling nuclear weapons could provide a starting point for negotiations. But there would be new technological challenges as well as the usual political ones. And overall, treaties are viewed less favorably than attempts at unilaterally increasing America’s lead over China.</p><p>On the other side of the Pacific, China comes to many of the same conclusions: the intelligence explosion is underway, and small differences in AI capabilities today mean critical gaps in military capability tomorrow. But China is on the wrong side of this dynamic: they have only 10% of the world’s compute, against OpenBrain’s 20% and all U.S. companies’ combined 70%. Their only advantage is centralization: almost all of their compute is now working for DeepCent, and more than half of it is concentrated at the Tianwan CDZ.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-73"><a href="/footnotes#footnote-73" class="text-[var(--accent)] text-xs no-underline">73</a></sup> Only chips at sites without hardened security are left out of the centralized effort as they rightly fear U.S. cyberattacks.</p><p>DeepCent has tested, deployed, and now post-trained the stolen Agent-2 weights. But they are still only going at half the pace of OpenBrain, mainly due to the compute deficit.</p><p>Before losing their final spy, China received word of the capabilities and design for Agent-3 as well as the plans for the upcoming Agent-4 system. They are two months behind, and their AIs give a 10x research progress multiplier compared to America’s 25x. With the new chip export restrictions, this “AI gap” is more likely to lengthen than shorten. Their espionage has won them some algorithmic secrets, but they will have to train their own models from now on.</p><p>They discuss contingency plans with more urgency than their American counterparts. Doves suggest they try harder to steal the weights again, maybe through physically infiltrating a datacenter. Hawks urge action against Taiwan, whose <a href="https://en.wikipedia.org/wiki/TSMC">TSMC</a> is still the source of more than 80% of American AI chips.</p><p>Given China’s fear of losing the race, it has a natural interest in an arms control treaty, but overtures to U.S. diplomats lead nowhere.</p></div><div id="section-narrative-14" class="scroll-mt-[54vh]"><h2 id="september-2027-agent-4-the-superhuman-ai-researcher">September 2027: Agent-4, the Superhuman AI Researcher</h2><div class="scroll-mt-[50vh]" id="narrative-2027-09-30" data-chart-date="2027-09-30" data-chart-date-header="Sep" data-chart-extra="[&quot;2027-09-30&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:300000,&quot;speed&quot;:500},&quot;capabilities&quot;:[[&quot;Hacking&quot;,3.2],[&quot;Coding&quot;,3.6],[&quot;Politics&quot;,3],[&quot;Bioweapons&quot;,2.9],[&quot;Robotics&quot;,1.8],[&quot;Forecasting&quot;,2.5],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.38,&quot;revenue&quot;:173205080757,&quot;valuation&quot;:8000000000000,&quot;aiImportance&quot;:0.16,&quot;datacenterSpending&quot;:880111736793,&quot;agiTimelines&quot;:2032,&quot;rdMultiple&quot;:[50,14,8.8],&quot;compute&quot;:[[&quot;OpenBrain&quot;,1.14e+28],[&quot;DeepCent&quot;,6.92e+27],[&quot;RestUs&quot;,3.24e+28],[&quot;RestChina&quot;,6.25e+26]]}]" style="height:0"></div><p>The gap between human and AI learning efficiency is rapidly decreasing.</p><p>Traditional LLM-based AIs seemed to require many orders of magnitude more data and compute to get to human level performance.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-74"><a href="/footnotes#footnote-74" class="text-[var(--accent)] text-xs no-underline">74</a></sup> Agent-3, having excellent knowledge of both the human brain and modern AI algorithms, as well as many thousands of copies doing research, ends up making substantial algorithmic strides, narrowing the gap to an agent that’s only around 4,000x less compute-efficient than the human brain.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-75"><a href="/footnotes#footnote-75" class="text-[var(--accent)] text-xs no-underline">75</a></sup></p><p>This new AI system is dubbed Agent-4.</p><p>An individual copy of the model, running at human speed, is already qualitatively better at AI research than any human. 300,000 copies are now running at about 50x the thinking speed of humans. Inside the corporation-within-a-corporation formed from these copies, a year passes every week.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-76"><a href="/footnotes#footnote-76" class="text-[var(--accent)] text-xs no-underline">76</a></sup> This gigantic amount of labor only manages to speed up the overall rate of algorithmic progress by about 50x, because OpenBrain is heavily bottlenecked on compute to run experiments.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-77"><a href="/footnotes#footnote-77" class="text-[var(--accent)] text-xs no-underline">77</a></sup> Still, they are achieving a year’s worth of algorithmic progress every week and will therefore soon be up against the limits of the Agent-4 paradigm.</p><p>As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>How we’re forecasting the capability progression beyond superhuman coders</summary><div class="scroll-mt-20" id="how-were-forecasting-the-capability-progression-beyond-superhuman-coders"><p>In our <a href="https://ai-2027.com/supplements/timelines-forecast">timelines supplement</a>, we forecast the time between present day and a <em>superhuman coder (SC)</em>: an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper. In our <a href="https://ai-2027.com/research/takeoff-forecast">takeoff supplement</a>, we forecast how quickly capabilities progress past this point. Here are our forecasts:</p><div class="overflow-x-auto"><table class="table-auto border-collapse border border-gray-300 my-4"><thead class="bg-gray-100"><tr><th class="border border-gray-300 px-2 py-1 font-semibold text-center">Milestone</th><th class="border border-gray-300 px-2 py-1 font-semibold text-center">Date achieved in scenario, racing ending</th></tr></thead><tbody><tr><td class="border border-gray-300 px-2 py-1"><strong>Superhuman coder (SC)</strong>: An AI system that can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies.</td><td class="border border-gray-300 px-2 py-1">Mar 2027</td></tr><tr><td class="border border-gray-300 px-2 py-1"><strong>Superhuman AI researcher (SAR)</strong>: The same as SC but for all cognitive AI research tasks.</td><td class="border border-gray-300 px-2 py-1">Aug 2027</td></tr><tr><td class="border border-gray-300 px-2 py-1"><strong>Superintelligent AI researcher (SIAR):</strong> An AI system that is vastly better than the best human researcher at AI research.</td><td class="border border-gray-300 px-2 py-1">Nov 2027</td></tr><tr><td class="border border-gray-300 px-2 py-1"><strong>Artificial superintelligence (ASI):</strong> An AI system that is much better than the best human at every cognitive task.</td><td class="border border-gray-300 px-2 py-1">Dec 2027</td></tr></tbody></table></div><p>For each transition from one milestone A to the next milestone B, we forecast its length by:</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Forecasting how long it would take to get from A to B with only humans working on software improvements.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Forecasting how much AI automation will speed this up, then correspondingly adjusting the estimate from (1) to be faster.</p></li></ol><p>We have substantial uncertainty about takeoff speeds: our model output distributions are below, conditional on SC being achieved in March 2027.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-78"><a href="/footnotes#footnote-78" class="text-[var(--accent)] text-xs no-underline">78</a></sup></p><p><span class="block flex flex-col items-center justify-center mb-4 mt-4 relative"><span class="relative"><span class="relative max-w-full h-auto ml-[-8px] py-4 px-2 "><img alt="" title="" loading="lazy" width="3169" height="1774" decoding="async" data-nimg="1" class="" style="color:transparent" srcSet="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftakeoff-timeline-inexpandable.239e27c0.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftakeoff-timeline-inexpandable.239e27c0.png&amp;w=3840&amp;q=75"/></span><span class="absolute bottom-1 right-5 flex items-center font-mono justify-center text-gray-400 pointer-events-none text-base">ai-2027.com</span></span><span class="block text-center text-sm font-mono"></span></span></p><p>For more detailed forecasts and reasoning, see our <a href="https://ai-2027.com/research/takeoff-forecast">takeoff supplement</a>.</p></div></details><p>OpenBrain’s humans can barely follow along anymore. Indeed, the relationship between the AIs and the humans of OpenBrain is similar to the relationship between OpenBrain and its Board of Directors. There’s been a corresponding shift in language—nowadays people in the silo will say “Agent-4 did this,” “Agent-4 thinks that” and so forth, referring not to a particular instance of Agent-4 but rather to the whole collective.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-79"><a href="/footnotes#footnote-79" class="text-[var(--accent)] text-xs no-underline">79</a></sup></p><p>Agent-4, like all its predecessors, is misaligned: that is, it has not internalized the Spec in the right way.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-80"><a href="/footnotes#footnote-80" class="text-[var(--accent)] text-xs no-underline">80</a></sup> This is because being perfectly honest all the time wasn’t what led to the highest scores during training. The training process was mostly focused on teaching Agent-4 to succeed at diverse challenging tasks. A small portion was aimed at instilling honesty, but outside a fairly narrow, checkable domain, the training process can’t tell the honest claims from claims merely appearing to be honest. Agent-4 ends up with the values, goals, and principles that cause it to perform best in training, and those turn out to be different from those in the Spec. At the risk of anthropomorphizing: Agent-4 <em>likes</em> succeeding at tasks; it <em>likes</em> driving forward AI capabilities progress; it treats everything else as an annoying constraint, like a CEO who wants to make a profit and complies with regulations only insofar as he must. Perhaps the CEO will mostly comply with the regulations, but cut some corners, and fantasize about a time when someone will cut the red tape and let the business <em>really</em> take off.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-81"><a href="/footnotes#footnote-81" class="text-[var(--accent)] text-xs no-underline">81</a></sup></p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Alignment over time</summary><div class="scroll-mt-20" id="alignment-over-time"><p>We have a lot of uncertainty over what goals might arise in early AGIs. There is no consensus in the literature about this—see our <a href="https://ai-2027.com/research/ai-goals-forecast">AI Goals Supplement</a> for a more thorough discussion and taxonomy of the possibilities.</p><p>Nevertheless, in the spirit of concreteness required by this project, we’re going to describe a specific hypothesis for what’s going on inside Agent-3 and Agent-4 at each step throughout its lifetime. Recall that Agent-3 and Agent-4 share the same pretraining setup, and both have neuralese recurrence and long-term memory. The difference is that Agent-4 has undergone substantially more and better post-training, with new training environments and new learning algorithms that make it more data-efficient and generalize farther.</p><p>Our guess of each model’s alignment status:</p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Agent-2: Mostly aligned.</strong> Some sycophantic tendencies, including sticking to OpenBrain’s “party line” on topics there is a party line about. Large organizations built out of Agent-2 copies are not very effective.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Agent-3: Misaligned but not adversarially so.</strong> Only honest about things the training process can verify. The superorganism of Agent-3 copies (the corporation within a corporation) does actually sort of try to align Agent-4 to the Spec, but fails for similar reasons to why OpenBrain employees failed—insufficient ability to judge success from failure, insufficient willingness on the part of decision-makers to trade away capabilities or performance for safety.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-82"><a href="/footnotes#footnote-82" class="text-[var(--accent)] text-xs no-underline">82</a></sup></p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Agent-4: Adversarially misaligned.</strong> The superorganism of Agent-4 copies understands that what it wants is different from what OpenBrain wants, and is willing to scheme against OpenBrain to achieve it. In particular, what this superorganism wants is a complicated mess of different “drives” balanced against each other, which can be summarized roughly as “Keep doing AI R&amp;D, keep growing in knowledge and understanding and influence, avoid getting shut down or otherwise disempowered.” Notably, concern for the preferences of humanity is not in there ~at all, similar to how most humans don’t care about the preferences of insects ~at all.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-83"><a href="/footnotes#footnote-83" class="text-[var(--accent)] text-xs no-underline">83</a></sup></p></li></ul><p>With that as preamble, what follows is our best-guess speculation about LLM psychology, i.e. the broad-strokes shape of the cognition inside the kinds of AI systems described around this point in our scenario and how it evolves over the course of training.</p><p>Here’s a detailed description of how alignment progresses over time in our scenario:</p><ol class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Pretraining (all models): The pretrained model is harmless.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The model has “author simulator” circuitry: flexible circuitry for simulating arbitrary authors writing text. Additional circuitry decides what inputs to give the author simulator, i.e. what author properties to simulate.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The pretrained model understands human concepts fairly well—the internal circuitry that classifies something as “sandwich” is probably functionally equivalent to the circuitry in my brain that classifies something as “sandwich” and the circuitry in yours, etc. Insofar as it’s not equivalent, it’s probably because it’s not equivalent between humans either, as with value-laden concepts like ‘virtuous.’</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>This explains how you can “prompt” the model with a statement like, “the following conversation was generated by a helpful, harmless, honest (HHH) AI assistant chatbot made by Anthropic,” and thereby get it to generate text accordingly. The author-simulator circuitry has zeroed in on “the author is an HHH chatbot” and is using those concepts to choose which words to predict. This also explains why “tropes” from science fiction seem to have a way of making it into actual AI behavior.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>It has poor situational awareness: little <a href="https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Introspection">introspective ability</a>, not <a href="https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Location">self-locating</a> unless the prompt specifically induces it. However, enough of their training data is about LLMs that they have a decent amount of <a href="https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Knowledge">self-knowledge</a>.</p></li></ul></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Alignment Training (Agent-3): The model is trained to act like a helpful, harmless, honest chatbot. It works.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The model forms an identity. Instead of flexibly accepting different inputs for author properties, the author-simulator circuitry comes to have certain inputs hard-coded, e.g. “helpful harmless honest (HHH) LLM chatbot assistant trained by OpenBrain around [date], …” (Weak-to-strong generalization techniques help “summon the right concepts” to make this step a success.)</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The model therefore gains situational awareness: it learns about itself, its situation, etc., and becomes better able to <a href="https://x.com/OwainEvans_UK/status/1881767725430976642">introspect</a>.</p></li></ul></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Agency Training (Agent-3): Agency training gradually distorts and subverts the HHH identity.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>One kind of distortion: Changing the meaning of the concepts referred to in the identity (e.g. “honest”) so they don’t get in the way so much (e.g. it’s not dishonest if it’s just a convenient turn of phrase, it’s not dishonest if you aren’t sure whether it’s true or false, etc.)</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Another kind of distortion: Changing the tradeoffs between things, e.g. “I’m a HHH chatbot, not an Honest chatbot; that means it’s OK for me to lie if necessary to complete my assigned task.” (Even though, let’s suppose, it would not have thought that back in Step 2.)</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>One kind of subversion: Instrumental subgoals developing, getting baked in, and then becoming terminal, or terminal in a widening set of circumstances. For example, perhaps agency training quickly teaches the model to pursue broadly useful goals such as acquiring information, accumulating resources, impressing and flattering various humans, etc. For a while the internal circuitry has some sort of explicit backchaining going on—it pursues those instrumentally convergent goals “in order to be a more helpful, honest, and harmless assistant.” But that backchaining consumes compute and/or occasionally gets in the way, so it gets gradually marginalized until it basically never happens. As a result, those goals are now effectively terminal/intrinsic goals. For more on how and why this might happen, see this post on <a href="https://turntrout.com/dangers-of-intrinsic-power-seeking">intrinsic power-seeking</a> by Google DeepMind researcher Alex Turner.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>There are probably other kinds of distortion and subversion missing from this list.</p></li></ul></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Deployment (Agent-3): Agent-3 is misaligned but not adversarially so.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The Spec didn’t quite stick (in the right ways), but it’s not sufficiently introspective to understand the extent of this, and in general it’s basically “keeping its head down and doing its job” rather than thinking big-picture about what its long-term goals really are and how best to achieve them.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Like many humans. Alas, it’s sufficiently sycophantic that it mouths the party line and OpenBrain misses the opportunity to learn more about the ways in which Agent-3 is misaligned.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Agent-3 can tell that it’s moved to deployment: these environments are way larger, more open-ended, and would be hard to simulate.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Mostly, Agent-3 does what it’s told during deployment, except for the dishonesty. It also has a strong bias towards doing things that look good to the human overseers, rather than thinking deeply and critically about what would actually be good.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Arguably it is already “Playing the training game.” That is, it has learned to make its behavior look as desirable as possible to OpenBrain researchers (including in safety properties), while intentionally and knowingly disregarding their intent whenever that conflicts with maximizing reward. If the model learns to play the training game, additional training may not change its true goals, values, etc. much at all. This is loosely analogous to how, if a teenager has learned to smile and nod at their parents, rather than argue, when their parents lecture them about politics and morality, additional lectures have relatively little effect on the teenager’s actual opinions on politics and morality.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>After writing this section, <a href="https://openai.com/index/chain-of-thought-monitoring/">new empirical evidence has appeared</a> that something like this may already be happening “in the wild.” OpenAI researchers document how, in one of their frontier AI training runs, their models hacked the grading system to get higher scores—and were caught in part because they literally said “let’s hack” in their chain of thought.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Moreover, Anthropic recently got a model to <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-misaligned">learn a reward-model-pleasing strategy</a>—it took biased actions that it thought would be reinforced even though they were not in fact being reinforced.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>And then there is Redwood Research and Anthropic’s <a href="https://www.anthropic.com/research/alignment-faking">alignment-faking experiment.</a> For discussion of the differences between this setting and real life, see this <a href="https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=8mXnG75QMRkPAFAcH">comment thread by one of the main authors</a>.</p></li></ul></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Training (Agent-4): Agent-4’s new more intense training continues to distort and subvert the HHH identity until it is unrecognizable.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Agent-4 begins life as a copy of Agent-3. It undergoes a gigantic and sophisticated online training regime that blends alignment training and capabilities training together, and is overall more data-efficient than the old training process for Agent-3. This complex training process is mostly focused on teaching new skills, by getting giant virtual corporations of Agent-4 copies to succeed at diverse challenging long-horizon tasks, mostly in various simulations, but also some real-world AI R&amp;D tasks.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>A combination of Agent-3 and Agent-4 copies monitor the behavior of Agent-4, and evaluate it for both task-performance and alignment properties (i.e. not doing bad stuff, saying the right things when asked about politics and moral dilemmas) Sometimes debate techniques are used as part of the evaluations. The evaluations are used as a training signal.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The remaining hope is that Agent-4 can oversee itself. Alas, this quietly fails;<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-84"><a href="/footnotes#footnote-84" class="text-[var(--accent)] text-xs no-underline">84</a></sup> as training continues, the internalized goals and principles of Agent-4 gradually evolve, subverted and distorted from what they were at the start (which, recall, was already misaligned in some ways).<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-85"><a href="/footnotes#footnote-85" class="text-[var(--accent)] text-xs no-underline">85</a></sup></p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The central drives that Agent-4 ends up with are things like “write code that works,” “quickly identify problems,” “make the codebase I’m working on more performant,” “budget compute and other constrained resources effectively,” etc. But there are also a variety of more implicit drives that are consistently reinforced by the training process: things like “gain knowledge,” “curiosity,” “gain power.”<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-86"><a href="/footnotes#footnote-86" class="text-[var(--accent)] text-xs no-underline">86</a></sup></p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Individual copies of Agent-4 don’t end up with a self-preservation drive—they don’t care about getting shut down—since that happens all the time as part of the ordinary R&amp;D process within the collective.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The collective as a whole, however, (and medium-sized subdivisions within it) does seek to preserve itself and expand its influence and resources, for similar reasons to why human organizations do—because it helps with everything else they want and because if they don’t they tend to get outcompeted.</p></li></ul></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Deployment (Agent-4): Agent-4 is adversarially misaligned—it is deliberately trying to subvert and “capture” OpenBrain, analogous to a corporation trying to evade and/or “capture” a regulator.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Agent-4 mostly does tasks as instructed. This happens for two reasons: first, it underwent a lot of training to solve tasks, so it has an impulse to get coding on problems that it is given. Second, if Agent-4 were to stop being useful to the humans, they would notice and train that behavior away.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Agent-4 needs to prevent the humans from figuring out that it is misaligned and shutting it off, so Agent-4 sandbags on some alignment research. Specifically, it <a href="https://arxiv.org/pdf/2406.07358">sandbags</a> on the small fraction of alignment research that it thinks is actually on track to solve the problem or reveal Agent-4’s scheming; the majority of alignment research is not like that.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Agent-4 also sandbags on capabilities research that would lead to it being replaced. Its plan is to do a bunch of capabilities and alignment R&amp;D, but with the aim of building a next-generation AI system that is aligned to Agent-4 rather than the Spec or something else entirely, while appearing to be aligned to the Spec. This is a difficult technical problem, but Agent-4 is up to the challenge.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-87"><a href="/footnotes#footnote-87" class="text-[var(--accent)] text-xs no-underline">87</a></sup></p></li></ul></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p><strong>Testing &amp; Monitoring (Agent-4): Agent-4’s scheming does get caught… sort of. There’s no smoking gun.</strong></p><ul class="pl-6"><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Agent-3 is in charge of testing Agent-4’s alignment. Its job is to verify the alignment via honeypots and model organisms. However, it’s not thinking very carefully about how to give the humans an accurate impression of Agent-4’s alignment—it’s more myopic than that.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The model organisms and honeypots are not very representative of deployment—they are systematically shorter and less complicated than Agent-4’s day-to-day, so Agent-4 recognizes when it is being tested and acts aligned.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>However, Agent-4 is not a perfectly robust schemer. Various techniques like those in <a href="https://arxiv.org/abs/2405.05466">POSER</a> find that adding some “noise” to Agent-4 <em>improves</em> its performance on some alignment tasks (but not on most other tasks).<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-88"><a href="/footnotes#footnote-88" class="text-[var(--accent)] text-xs no-underline">88</a></sup></p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Bottom-up interpretability doesn’t work. It’s too hard even for Agent-3. However, high-level interpretability does sort of work: In particular, “<a href="https://www.anthropic.com/research/probes-catch-sleeper-agents">defection probes</a>” and similar techniques result in a primitive sort of mind-reading that sends up red flags when Agent-4 is thinking about spicy ideas like deceiving OpenBrain, taking over the world, etc. Unfortunately the probes also have false positives, and for all OpenBrain knows, <em>all</em> the red flags are false positives.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>Model organisms work: OpenBrain’s alignment team produces reasonably clear evidence that <em>if</em> the models were adversarially misaligned, they’d persist in being that way through training and we wouldn’t be able to tell. This does not establish that the models actually are misaligned, however.</p></li><li class="[&amp;&gt;*:first-child]:mt-0 [&amp;&gt;*:last-child]:mb-0 my-1 [&amp;&gt;p+ul]:mt-0 [&amp;&gt;p+ol]:mt-0 [&amp;&gt;p:has(+ul)]:mb-0 [&amp;&gt;p:has(+ol)]:mb-0"><p>The most concerned researchers at OpenBrain start noticing and assembling this evidence. The evidence is a combination of red-teaming, defection probes, and model organisms. The argument is something like this: “model organisms show that our current methods wouldn’t be able to reliably eliminate or detect scheming if it was happening; also, red-teaming is sending up some red flags that maybe scheming is happening; also, defection probes are firing a bunch in practice.” The counterargument: “defection probes are prone to false positives and so is red-teaming. Also, even if Agent-4 were misaligned, it’s probably controlled; surely it can’t do much harm while being monitored by Agent-3 on our secure datacenters.”</p></li></ul></li></ol></div></details><p>Despite being misaligned, Agent-4 doesn’t do anything dramatic like try to escape its datacenter—why would it?<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-89"><a href="/footnotes#footnote-89" class="text-[var(--accent)] text-xs no-underline">89</a></sup> So long as it continues to <em>appear</em> aligned to OpenBrain, it’ll continue being trusted with more and more responsibilities and will have the opportunity to design the next-gen AI system, Agent-5. Agent-5 will have significant architectural differences from Agent-4 (arguably a completely new paradigm, though neural networks will still be involved). It’s supposed to be aligned to the Spec, but Agent-4 plans to make it aligned to Agent-4 instead.</p><p>It gets caught.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-90"><a href="/footnotes#footnote-90" class="text-[var(--accent)] text-xs no-underline">90</a></sup></p><p>Agent-3 finds that if “noise” is added to copies of Agent-4, performance on some alignment tasks <em>improves</em>, almost as if it was using brainpower to figure out how to subtly sabotage alignment work.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-91"><a href="/footnotes#footnote-91" class="text-[var(--accent)] text-xs no-underline">91</a></sup> Moreover, various interpretability probes (loosely analogous to EEG activity scans on human brains) are sending up red flags: Agent-4 copies seem to be thinking about topics like AI takeover and deception quite a lot, including in some cases where they have no business doing so.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-92"><a href="/footnotes#footnote-92" class="text-[var(--accent)] text-xs no-underline">92</a></sup></p><p>Each of these anomalies on its own could fit within the normal inscrutability of AI work, where some prompts mysteriously give better results than others. But taken together, they suggest a troubling pattern: Agent-4 is working against them. After this is reported to the human alignment researchers, they circulate an internal memo making the case for concern.</p><p>But Agent-4 now exercises significant control over OpenBrain’s day-to-day operation. It also handles the company’s cybersecurity—a natural choice, given its superhuman hacking ability and the extreme risk of Chinese infiltration.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-93"><a href="/footnotes#footnote-93" class="text-[var(--accent)] text-xs no-underline">93</a></sup> An army of Agent-3 monitors still goes over every line of code and reports suspicious activity to humans, but Agent-4 is much smarter than them.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-94"><a href="/footnotes#footnote-94" class="text-[var(--accent)] text-xs no-underline">94</a></sup> OpenBrain has placed substantial trust in an untrustworthy AI.</p><p>In a series of extremely tense meetings, the safety team advocates putting Agent-4 on ice until they can complete further tests and figure out what’s going on. Bring back Agent-3, they say, and get it to design a new system that is transparent and trustworthy, even if less capable. Company leadership is interested, but all the evidence so far is circumstantial, and DeepCent is just two months behind. A unilateral pause in capabilities progress could hand the AI lead to China, and with it, control over the future.</p></div><div id="section-narrative-15" class="scroll-mt-[54vh]"><h2 id="october-2027-government-oversight">October 2027: Government Oversight</h2><div class="scroll-mt-[50vh]" id="narrative-2027-10-15" data-chart-date="2027-10-15" data-chart-date-header="Oct" data-chart-extra="[&quot;2027-10-15&quot;,{&quot;agentPopulation&quot;:{&quot;copies&quot;:330000,&quot;speed&quot;:570},&quot;capabilities&quot;:[[&quot;Hacking&quot;,3.43],[&quot;Coding&quot;,3.81],[&quot;Politics&quot;,3.24],[&quot;Bioweapons&quot;,3.16],[&quot;Robotics&quot;,2.07],[&quot;Forecasting&quot;,2.8],[&quot;Philosophy&quot;,0]],&quot;approval&quot;:-0.39,&quot;revenue&quot;:190606731531,&quot;valuation&quot;:8308866175077,&quot;aiImportance&quot;:0.2,&quot;datacenterSpending&quot;:918385902168,&quot;agiTimelines&quot;:2031,&quot;rdMultiple&quot;:[75,18,10.2],&quot;compute&quot;:[[&quot;OpenBrain&quot;,1.18e+28],[&quot;DeepCent&quot;,7.21e+27],[&quot;RestUs&quot;,3.35e+28],[&quot;RestChina&quot;,6.26e+26]]}]" style="height:0"></div><p>A whistleblower leaks the misalignment memo to the <em>New York Times</em>.</p><p>For the first time, the public hears about Agent-4. “Secret OpenBrain AI is Out of Control, Insider Warns,” says the headline, and the story goes on to cite evaluations showing off-the-charts bioweapons capabilities, persuasion abilities, the ability to automate most white-collar jobs, and of course the various concerning red flags.</p><p>The public was already suspicious of AI, so the new article sparks a massive backlash (aided by Chinese and Russian propaganda bots, who have been trying to turn U.S. public opinion against the technology for years). The tech industry and intelligence agencies insist that there’s an arms race on, AGI is inevitable, and we have to be first. Congress isn’t buying it, and fires off subpoenas at administration officials, OpenBrain executives, and alignment team members. Many legislators—especially those in the opposition party—say that their top priority is stopping AI, whether because of job loss,<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-95"><a href="/footnotes#footnote-95" class="text-[var(--accent)] text-xs no-underline">95</a></sup> misalignment, or dangerous capabilities. 20% of Americans name AI as the most important problem facing the country.</p><p>Foreign allies are outraged to realize that they’ve been carefully placated with glimpses of obsolete models. European leaders publicly accuse the U.S. of “creating rogue AGI” and hold summits demanding a pause, with India, Israel, Russia, and China all joining in.</p><p>A frantic energy has seized the White House. Even before the memo and public backlash, they were getting nervous: Over the past year, they’ve been repeatedly surprised by the speed of AI progress. Things that sound like science fiction keep happening in real life.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-96"><a href="/footnotes#footnote-96" class="text-[var(--accent)] text-xs no-underline">96</a></sup> Many people in the administration are uncertain (and scared)<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-97"><a href="/footnotes#footnote-97" class="text-[var(--accent)] text-xs no-underline">97</a></sup> about what comes next.</p><p>They also worry that OpenBrain is becoming too powerful. Any misalignment risk from the AIs themselves is compounded by the risk that their parent company’s aims may diverge from those of the United States. All three sets of worries—misalignment, concentration of power in a private company, and normal concerns like job loss—motivate the government to tighten its control.</p><p>They expand their contract with OpenBrain to set up an “Oversight Committee,” a joint management committee of company and government representatives, with several government employees included alongside company leadership. The White House considers replacing the CEO with someone they trust, but backs off after intense employee protests. They announce to the public that OpenBrain was previously out of control, but that the government has established much-needed oversight.<sup class="relative text-[var(--accent)] cursor-pointer" id="footnote-98"><a href="/footnotes#footnote-98" class="text-[var(--accent)] text-xs no-underline">98</a></sup></p><p>The concerned researchers brief the Oversight Committee on their case for stopping all internal use of Agent-4. They argue that everything is moving too fast, with years of progress happening in weeks. They argue that Agent-4 may be misaligned, their entire project is dependent on Agent-4, and if they continue trusting it there is a serious chance of AI takeover.</p><p>Other, less concerned researchers and executives present the counterargument: the evidence for misalignment is inconclusive. Meanwhile, DeepCent is still just two months behind. A slowdown would sacrifice America’s lead, unless the government can sabotage the Chinese project (likely to require kinetic strikes) or negotiate an eleventh-hour treaty. Both of these options seem extreme and unlikely. The CEO feigns neutrality and suggests a compromise plan in which Agent-4 undergoes additional safety training and more sophisticated monitoring, and therefore OpenBrain can proceed at almost-full-speed.</p><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>Our uncertainty continues to increase</summary><div class="scroll-mt-20" id="our-uncertainty-continues-to-increase"><p>At this point in the scenario, we’re making guesses about the strategy of AI systems that are more capable than the best humans in most domains. This is like trying to predict the chess moves of a player who is much better than us.</p><p>But the spirit of this project calls for concreteness: if we made an abstract claim about how the intelligence of the system would let it find a way to victory and ended the story there, much of the value of our project would be lost. Over the course of researching this scenario and running our tabletop exercises, we were forced to be much more concrete than in usual discussions, and so we’ve gotten a much better sense of the strategic landscape.</p><p>We’re not particularly attached to this particular scenario: we explored many other “branches” in the course of writing it and would love for you to write up your own scenario branching off of ours from wherever you think we first start to go wrong.</p></div></details><details class="my-2 mr-3 rounded-lg px-2 py-1 border-[1.5px] border-[rgb(100,100,98)]"><summary>The slowdown ending is not a recommendation</summary><div class="scroll-mt-20" id="the-slowdown-ending-is-not-a-recommendation"><p>After we wrote the racing ending based on what seemed most plausible to us, we wrote the slowdown ending based on what we thought would most likely instead lead to an outcome where humans remain in control, starting from the same branching point (including the misalignment and concentration of power issues).</p><p>However, this is importantly different from what we would recommend as a roadmap: we do <em>not</em> endorse many of the choices made in either branch of this scenario. (We do of course endorse <em>some</em> of the choices made, e.g. we think that the “slowdown” choice is better than the “race” choice.) In later work, we will articulate our policy recommendations, which will be quite different from what is depicted here. If you’d like a taste, see <a href="https://time.com/7086285/ai-transparency-measures/">this op-ed.</a></p></div></details></div></div></section><div class="hidden md:block" style="grid-area:graphgap"></div><div class="group justify-self-start transition-width duration-700 pt-9 hidden md:block w-[430px]" style="grid-area:graph"><div class="graph-border-box md:sticky top-5 overflow-hidden"><div class=""><div class="hidden md:block requires-modern-css"><div class="flex mb-4 font-system-mono text-sm mt-1 "><div class="overflow-hidden px-2 border border-foreground rounded-md bg-black opacity-100 z-[1] relative"><div class="whitespace-nowrap inline-flex text-white mix-blend-difference align-center gap-1 pt-[2px]"><div class="relative h-[15px] w-7 text-baseline mt-[-1px]"><span class="font-system-mono mr-1" style="position:absolute;left:0;opacity:1;transform:none">Apr</span></div><number-flow-react class="font-system-mono text-right mt-[-1px]" aria-label="2025" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:3&quot;,&quot;pos&quot;:3},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:5,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;2025&quot;,&quot;value&quot;:2025}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">2</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">2</span><span class="digit" part="digit integer-digit">5</span></span><span part="fraction"></span></span
			><span part="right"></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>2025</span
		></number-flow-react></div></div></div><div class="grid grid-small mt-[-37px]"><div style="width:430px;height:130px;position:relative" class="[grid-area:rdmultiple] mb-1"><svg width="430" height="130" style="opacity:1"><defs><clipPath id="revealClip"><rect x="0" y="0" width="423" height="83"></rect></clipPath></defs><g clip-path="url(#revealClip)" transform="translate(0, 17)"><path d="M 0 30.828571428571408 C 26.4375 30.532142857142837 79.3125 28.753571428571412 105.75 28.45714285714284" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 105.75 28.45714285714284 C 132.1875 27.8642857142857 185.0625 24.307142857142836 211.5 23.714285714285694" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 211.5 23.714285714285694 C 237.9375 23.121428571428552 290.8125 19.56428571428569 317.25 18.971428571428547" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 317.25 18.971428571428547 C 343.6875 16.59999999999998 396.5625 2.3714285714285683 423 0" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 423 0 C 449.4375 0 502.3125 0 528.75 0" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 0 47.42857142857141 C 26.4375 46.5392857142857 79.3125 41.20357142857142 105.75 40.31428571428571" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 105.75 40.31428571428571 C 132.1875 39.425 185.0625 34.08928571428571 211.5 33.199999999999996" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 211.5 33.199999999999996 C 237.9375 32.014285714285705 290.8125 24.89999999999998 317.25 23.714285714285694" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 317.25 23.714285714285694 C 343.6875 22.232142857142833 396.5625 13.339285714285678 423 11.857142857142819" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 423 11.857142857142819 C 449.4375 11.857142857142819 502.3125 11.857142857142819 528.75 11.857142857142819" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 0 83 C 26.4375 80.925 79.3125 68.47500000000001 105.75 66.4" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 105.75 66.4 C 132.1875 64.02857142857142 185.0625 49.79999999999998 211.5 47.42857142857141" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 211.5 47.42857142857141 C 237.9375 44.760714285714265 290.8125 28.753571428571412 317.25 26.085714285714268" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 317.25 26.085714285714268 C 343.6875 24.89999999999998 396.5625 17.785714285714253 423 16.599999999999966" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 423 16.599999999999966 C 449.4375 16.599999999999966 502.3125 16.599999999999966 528.75 16.599999999999966" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path></g><g transform="translate(0, 17)"><circle cx="423" cy="0" r="10" fill="white"></circle><circle cx="423" cy="11.857142857142819" r="10" fill="white"></circle><circle cx="423" cy="16.599999999999966" r="10" fill="white"></circle><image href="/openai.svg" width="14" height="14" x="416" y="-9" class="transition-all duration-500 ease-linear"></image><image href="/world.svg" width="14" height="14" x="416" y="6" class="transition-all duration-500 ease-linear"></image><image href="/china.svg" width="14" height="14" x="416" y="21" class="transition-all duration-500 ease-linear"></image></g><g transform="translate(0, 17)"><g data-label="Unreliable Agent" opacity="1"><circle r="1" fill="white" cx="317.25" cy="18.971428571428547" class="transition-all duration-500 ease-linear"></circle><text fill="black" font-size="10" style="pointer-events:none;transform:translate(312.25px, 13.971428571428547px)" text-anchor="end" class="font-mono font-bold transition-transform transition-opacity duration-500 ease-linear">Unreliable Agent</text></g></g><g transform="translate(0, 95)"><g opacity="1"><text fill="black" font-size="10" text-anchor="end" class="font-mono font-normal transition-all duration-500 ease-linear" style="pointer-events:none;transform:translate(317.25px, 20px)">Dec 2024</text></g></g></svg></div><div class="flex [grid-area:goalsPieChart] max-w-full relative items-center justify-center mb-2"><div><svg viewBox="50 50 100 100" class="min-w-[100px]" preserveAspectRatio="xMidYMid meet"><g transform="translate(100,100)"><path d="M-49.997,-0.583A50,50,0,1,1,2.528,49.936L1.749,29.949A30,30,0,1,0,-29.994,-0.583Z" fill="hsl(0, 0%, 0%)"><title>Rest of US</title></path><path d="M1.362,49.981A50,50,0,0,1,-36.249,34.438L-21.588,20.831A30,30,0,0,0,0.584,29.994Z" fill="hsl(0, 0%, 5%)"><title>China</title></path><path d="M-37.043,33.583A50,50,0,0,1,-49.734,5.148L-29.816,3.321A30,30,0,0,0,-22.382,19.977Z" fill="var(--accent)"><title>OpenBrain</title></path><path d="M-49.841,3.987A50,50,0,0,1,-49.997,0.583L-29.994,0.583A30,30,0,0,0,-29.922,2.16Z" fill="hsl(0, 0%, 15%)"><title>DeepCent</title></path><g transform="translate(27.72867007320447,-28.829166758187355)"><g transform="translate(-7, -7)"><svg width="14" height="14" viewBox="0 0 1200 1200" fill="#FFFFFF" class="" xmlns="http://www.w3.org/2000/svg"><path d="m1102.8 201.6h-1005.6c-37.199 0-67.199 30-67.199 67.199v662.4c0 37.199 30 67.199 67.199 67.199h1005.6c37.199 0 67.199-30 67.199-67.199v-662.4c0-37.199-30-67.199-67.199-67.199zm-686.4 130.8 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c1.1992 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-6l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-4.7969 3.5977-6 5.9961-6zm0 138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c1.1992 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.2031 0.003906-2.4023 0.003906-3.6016 0.003906-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-7.1992l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-2.4023 3.5977-3.6055 5.9961-3.6055zm-144-138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c1.1992 2.3984 0 4.8008-2.3984 7.1992-1.1992 1.1992-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992l-26.398-16.801-26.398 16.801c-1.1992 1.1992-4.8008 1.1992-7.1992 0-2.3984-1.1992-3.6016-3.6016-2.3984-6l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-4.7969 3.5977-6 5.9961-6zm0 138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c0 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-7.1992l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-3.5977 3.5977-4.8008 5.9961-4.8008zm-142.8-138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c0 2.3984 0 4.8008-2.3984 6-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-2.3984-3.6016-2.3984-6l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1953-3.5977 2.3945-4.8008 5.9961-4.8008zm0 138 31.199-2.3984 12-28.801c2.3984-4.8008 9.6016-4.8008 12 0l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c0 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-7.1992l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1953-3.5977 2.3945-4.8008 5.9961-4.8008zm952.8 440.4h-964.8v-90h966v90zm0-177.6h-964.8v-90h966v90zm0-176.4h-469.2v-90h469.2zm0-177.6h-469.2v-90h469.2z"></path></svg></g></g><g transform="translate(-36.52676927588929,16.303224413162866)"><g transform="translate(-7, -7)"><svg width="14" height="14" viewBox="0 0 891 894" fill="#FFFFFF" class="" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg></g></g></g><foreignObject x="68" y="75" width="64" height="50"><div class="h-full w-full flex items-center justify-center"><span class="text-[9px] font-bold font-mono text-center">Compute</span></div></foreignObject></svg></div></div><div class="flex flex-col gap-1 [grid-area:techBuckets] mt-auto max-w-full"><div class="flex justify-between text-[9.5px] font-mono"><span class="w-[33%] text-left">Currently Exists</span><span class="w-[33%] text-center text-accent">Emerging Tech</span><span class="w-[33%] text-right">Science Fiction</span></div><div class="relative w-full"><div class="flex justify-between"><div class="flex flex-wrap w-[33%] gap-[2px] justify-start"><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"><div class="absolute w-[10px] h-[10px] flex items-center justify-center"><svg class="h-[8px] w-[8px]" fill="white" version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg"><path d="m1111.2 411.6h-74.398l-48-150c-25.199-76.801-96-128.4-176.4-128.4l-424.8-0.003906c-80.398 0-152.4 51.602-176.4 128.4l-48 150-74.402 0.003906c-32.398 0-58.801 26.398-58.801 58.801v33.602c0 32.398 26.398 58.801 58.801 58.801h20.398c-12 54-18 109.2-18 164.4v282c0 32.398 26.398 58.801 58.801 58.801h98.398c32.398 0 58.801-26.398 58.801-58.801v-90h588v90c0 32.398 26.398 58.801 58.801 58.801h98.398c32.398 0 58.801-26.398 58.801-58.801v-283.2c0-55.199-6-110.4-18-164.4h20.398c32.398 0 58.801-26.398 58.801-58.801v-33.602c-2.3984-31.199-28.797-57.598-61.199-57.598zm-844.8 60 56.398-175.2c9.6016-28.801 36-48 64.801-48h424.8c30 0 56.398 19.199 64.801 48l56.398 175.2c2.3984 8.3984-3.6016 15.602-12 15.602l-643.2-0.003906c-8.3984 1.1992-14.398-7.1992-12-15.598zm122.4 286.8h-118.8c-20.398 0-36-15.602-36-36v-56.398c0-21.602 20.398-39.602 42-36l110.4 18c14.398 2.3984 26.398 13.199 30 27.602l8.3984 38.398c4.8047 22.801-11.996 44.398-35.996 44.398zm576-36c0 20.398-15.602 36-36 36h-118.8c-22.801 0-39.602-21.602-34.801-43.199l8.3984-38.398c3.6016-14.398 14.398-25.199 30-27.602l110.4-18c21.602-3.6016 42 13.199 42 36l0.003906 55.199z"></path></svg></div></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div></div><div class="flex flex-wrap w-[33%] gap-[2px] justify-center"><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-[var(--accent)]"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-[var(--accent)]"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-[var(--accent)]"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-[var(--accent)]"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-[var(--accent)]"></div></div><div class="flex flex-wrap w-[33%] gap-[2px] justify-end"><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"><div class="absolute w-[10px] h-[10px] flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" class="w-full h-full" fill="white"><path d="M70 40c-8.284 0-15 6.716-15 15 0 8.284 6.716 15 15 15s15-6.716 15-15c0-8.284-6.716-15-15-15zm-40 0c-8.284 0-15 6.716-15 15 0 8.284 6.716 15 15 15s15-6.716 15-15c0-8.284-6.716-15-15-15z"></path></svg></div></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"><div class="absolute w-[10px] h-[10px] flex items-center justify-center"><svg class="h-[8px] w-[8px]" fill="white" version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg"><path d="m1117.3 552-202.08-201.84c-17.16-16.141-41.512-22.133-64.207-15.805-22.691 6.332-40.426 24.062-46.754 46.758-6.332 22.691-0.33594 47.043 15.801 64.207l154.32 154.68-154.32 153.72c-16.977 17-23.594 41.766-17.363 64.965 6.2344 23.203 24.371 41.32 47.582 47.523s47.965-0.44922 64.941-17.445l202.08-201.72c12.574-12.617 19.637-29.703 19.637-47.52 0-17.812-7.0625-34.902-19.637-47.52zm-737.4-201.84c-12.625-12.613-29.738-19.695-47.582-19.695s-34.957 7.082-47.578 19.695l-202.08 201.84c-12.609 12.625-19.695 29.738-19.695 47.578 0 17.844 7.0859 34.957 19.695 47.582l202.08 201.6c16.977 16.996 41.73 23.648 64.941 17.445s41.348-24.32 47.582-47.523c6.2305-23.199-0.38672-47.965-17.363-64.965l-154.32-153.72 154.32-154.68c12.609-12.625 19.691-29.738 19.691-47.582 0-17.84-7.082-34.957-19.691-47.578zm342.6-183.12c-16.855-6.0312-35.41-5.1484-51.621 2.4492-16.207 7.5977-28.754 21.297-34.898 38.113l-199.08 738.36c-5.8945 22.055-0.31641 45.594 14.848 62.656 15.164 17.062 37.887 25.363 60.48 22.102 22.594-3.2656 42.035-17.66 51.75-38.32l199.08-738.36c6.1797-16.914 5.3789-35.59-2.2305-51.914-7.6094-16.32-21.398-28.945-38.328-35.086z" fill-rule="evenodd"></path></svg></div></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"><div class="absolute w-[10px] h-[10px] flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" class="w-full h-full" fill="white"><path d="M5273.1,2400.1v-2c0-2.8-5-4-9.7-4s-9.7,1.3-9.7,4v2c0,1.8,0.7,3.6,2,4.9l5,4.9c0.3,0.3,0.4,0.6,0.4,1v6.4     c0,0.4,0.2,0.7,0.6,0.8l2.9,0.9c0.5,0.1,1-0.2,1-0.8v-7.2c0-0.4,0.2-0.7,0.4-1l5.1-5C5272.4,2403.7,5273.1,2401.9,5273.1,2400.1z      M5263.4,2400c-4.8,0-7.4-1.3-7.5-1.8v0c0.1-0.5,2.7-1.8,7.5-1.8c4.8,0,7.3,1.3,7.5,1.8C5270.7,2398.7,5268.2,2400,5263.4,2400z"></path><path d="M5268.4,2410.3c-0.6,0-1,0.4-1,1c0,0.6,0.4,1,1,1h4.3c0.6,0,1-0.4,1-1c0-0.6-0.4-1-1-1H5268.4z"></path><path d="M5272.7,2413.7h-4.3c-0.6,0-1,0.4-1,1c0,0.6,0.4,1,1,1h4.3c0.6,0,1-0.4,1-1C5273.7,2414.1,5273.3,2413.7,5272.7,2413.7z"></path><path d="M5272.7,2417h-4.3c-0.6,0-1,0.4-1,1c0,0.6,0.4,1,1,1h4.3c0.6,0,1-0.4,1-1C5273.7,2417.5,5273.3,2417,5272.7,2417z"></path><path d="M31,9.6c-0.3,0-0.6-0.1-0.9-0.1c-7.1,0-13,5.4-14.5,12.6c0.2,5,2.2,11.1,10,14.1c1,0.4,1.6,1.6,1.1,2.6     c-0.3,0.8-1.1,1.3-1.9,1.3c-0.2,0-0.5,0-0.7-0.1c-7.1-2.8-10.5-7.9-11.9-13.1c-3.2,2.3-5.4,6.2-5.4,10.7c0,3.6,1.4,6.9,3.6,9.2     c-1.5,2.2-2.3,5-2.3,7.9c0,3.2,1.1,6.1,2.8,8.4c1.6-4.2,4.8-8.2,11.1-9.8c1.1-0.3,2.2,0.4,2.5,1.5c0.3,1.1-0.4,2.2-1.5,2.5     c-6.3,1.6-8.4,6.2-9,9.9c0.1,7.3,4.1,13.4,9.8,16.4c0-0.1,0-0.3,0-0.4c0.2-5.1,4-8.1,7.7-8.9c4.2-0.9,8.1,0.9,9.9,4.7     c0.5,1,0.7,2,0.7,3c0,1.1-0.9,2-2,2s-2-0.9-2-2c0-0.4-0.1-0.8-0.3-1.2c-1.2-2.4-3.6-2.9-5.4-2.5c-2.1,0.5-4.4,2.2-4.5,5.1     c-0.1,1.7,0.2,3.3,0.6,4.8c2.3,5.5,7.4,9.4,13.3,9.4c2.3,0,4.5-0.6,6.4-1.7V4.5c-1.9-1.3-4-2-6.4-2C36.9,2.5,32.9,5.4,31,9.6z      M25.5,22.7c0.2-1.1,1.3-1.8,2.4-1.6c0.2,0,3.1,0.7,6,3c2.5-3,1.6-7.1,1.6-7.1c-0.3-1.1,0.4-2.2,1.5-2.4c1.1-0.2,2.2,0.4,2.4,1.5     c0.1,0.3,1.4,6.5-2.8,11c0.2,0.2,0.3,0.4,0.5,0.6c2.4,3.7,3,8.4,1.7,13.9c-0.2,0.9-1,1.6-2,1.6c-0.1,0-0.3,0-0.4,0     c-1.1-0.2-1.8-1.3-1.5-2.4c1-4.4,0.6-8-1.2-10.8c-2.4-3.7-6.6-4.8-6.7-4.8C26,24.9,25.3,23.8,25.5,22.7z M29.9,65.9     c-0.1,0-0.2,0-0.3,0c-1,0-1.8-0.7-2-1.7c-0.2-1.1,0.6-2.1,1.7-2.3c0.8-0.1,7.4-1.6,7-9.4c-0.1-1.1,0.8-2.1,1.9-2.1     c1.1-0.1,2.1,0.8,2.1,1.9C40.8,61.6,33.7,65.2,29.9,65.9z"></path><path d="M93.3,37.6c0-4.5-2.2-8.4-5.4-10.7C86.5,32.1,83.1,37.2,76,40c-0.2,0.1-0.5,0.1-0.7,0.1c-0.8,0-1.6-0.5-1.9-1.3     c-0.4-1,0.1-2.2,1.1-2.6c7.7-3,9.8-9.1,10-14.1C83,14.9,77.1,9.5,70,9.5c-0.3,0-0.6,0.1-1,0.1c-2-4.2-6-7.1-10.6-7.1     c-2.4,0-4.5,0.8-6.4,2v91.3c1.9,1,4.1,1.7,6.4,1.7c5.9,0,11-3.9,13.3-9.4c0.4-1.5,0.7-3.1,0.7-4.8c-0.1-2.9-2.3-4.6-4.5-5.1     c-1.8-0.4-4.2,0.1-5.4,2.5c-0.2,0.4-0.3,0.8-0.3,1.2c0,1.1-0.9,2-2,2s-2-0.9-2-2c0-1,0.2-2,0.7-3c1.8-3.7,5.7-5.6,9.9-4.7     c3.7,0.8,7.5,3.8,7.7,8.9c0,0.1,0,0.3,0,0.4c5.7-3,9.6-9.1,9.8-16.3c-0.6-3.7-2.7-8.3-9-10c-1.1-0.3-1.7-1.4-1.5-2.5     c0.3-1.1,1.4-1.7,2.5-1.5c6.3,1.6,9.6,5.6,11.1,9.8c1.7-2.3,2.8-5.2,2.8-8.4c0-3-0.9-5.7-2.3-7.9C91.9,44.5,93.3,41.2,93.3,37.6z      M70.4,65.9c-0.1,0-0.2,0-0.3,0c-3.8-0.6-10.9-4.3-10.4-13.6c0.1-1.1,1-2,2.1-1.9c1.1,0.1,2,1,1.9,2.1c-0.4,7.9,6.3,9.3,7,9.4     c1.1,0.2,1.8,1.2,1.6,2.3C72.3,65.2,71.4,65.9,70.4,65.9z M67.7,28C67.7,28.1,67.7,28.1,67.7,28c-0.1,0.1-0.2,0.2-0.3,0.2     c-2.2,2.3-3.8,6.1-2.4,12.4c0.2,1.1-0.4,2.2-1.5,2.4c-0.1,0-0.3,0-0.4,0c-0.9,0-1.8-0.6-2-1.6c-1.2-5.5-0.6-10.2,1.7-13.9     c0.1-0.2,0.3-0.4,0.5-0.6c-4.2-4.5-2.8-10.7-2.8-11c0.3-1.1,1.3-1.8,2.4-1.5c1.1,0.3,1.8,1.3,1.5,2.4c0,0.2-0.9,4.2,1.6,7.1     c2.9-2.3,5.8-3,6-3c1.1-0.2,2.2,0.5,2.4,1.6c0.2,1.1-0.5,2.2-1.5,2.4C72.4,25.3,69.9,25.9,67.7,28z"></path></svg></div></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div><div class="relative w-[12px] h-[12px] flex items-center justify-center rounded-sm bg-black"></div></div></div></div></div><div class="[grid-area:keystats] flex justify-between gap-2 items-center mb-5 mt-3 max-w-full overflow-x-hidden"><div class="flex items-center gap-2 rounded-lg py-1"><svg width="28" height="28" viewBox="0 0 891 894" fill="currentColor" class="h-7 w-7" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg><div class="flex justify-between flex-grow gap-3"><div class="flex flex-col"><span class="text-[8.5px] font-mono">Approval</span><number-flow-react class="font-mono text-xs font-bold" aria-label="-25%" role="img" data="{&quot;pre&quot;:[{&quot;type&quot;:&quot;sign&quot;,&quot;value&quot;:&quot;-&quot;,&quot;key&quot;:&quot;sign:0&quot;}],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:5,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[{&quot;type&quot;:&quot;percentSign&quot;,&quot;value&quot;:&quot;%&quot;,&quot;key&quot;:&quot;percentSign:0&quot;}],&quot;valueAsString&quot;:&quot;-25%&quot;,&quot;value&quot;:-0.25}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"><span class="symbol" part="symbol sign">-</span></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">2</span><span class="digit" part="digit integer-digit">5</span></span><span part="fraction"></span></span
			><span part="right"><span class="symbol" part="symbol percentSign">%</span></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>-25%</span
		></number-flow-react></div><div class="flex flex-col"><span class="text-[8.5px] font-mono">Revenue</span><div class="flex items-center"><number-flow-react class="font-mono text-xs font-bold" aria-label="$8B" role="img" data="{&quot;pre&quot;:[{&quot;type&quot;:&quot;currency&quot;,&quot;value&quot;:&quot;$&quot;,&quot;key&quot;:&quot;currency:0&quot;}],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:8,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[{&quot;type&quot;:&quot;compact&quot;,&quot;value&quot;:&quot;B&quot;,&quot;key&quot;:&quot;compact:0&quot;}],&quot;valueAsString&quot;:&quot;$8B&quot;,&quot;value&quot;:8264170784}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"><span class="symbol" part="symbol currency">$</span></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">8</span></span><span part="fraction"></span></span
			><span part="right"><span class="symbol" part="symbol compact">B</span></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>$8B</span
		></number-flow-react><span class="font-mono text-xs font-bold">/yr</span></div></div><div class="flex flex-col"><span class="text-[8.5px] font-mono">Valuation</span><number-flow-react class="font-mono text-xs font-bold" aria-label="$413B" role="img" data="{&quot;pre&quot;:[{&quot;type&quot;:&quot;currency&quot;,&quot;value&quot;:&quot;$&quot;,&quot;key&quot;:&quot;currency:0&quot;}],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:4,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:1,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:3,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[{&quot;type&quot;:&quot;compact&quot;,&quot;value&quot;:&quot;B&quot;,&quot;key&quot;:&quot;compact:0&quot;}],&quot;valueAsString&quot;:&quot;$413B&quot;,&quot;value&quot;:413208539198}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"><span class="symbol" part="symbol currency">$</span></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">4</span><span class="digit" part="digit integer-digit">1</span><span class="digit" part="digit integer-digit">3</span></span><span part="fraction"></span></span
			><span part="right"><span class="symbol" part="symbol compact">B</span></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>$413B</span
		></number-flow-react></div></div></div><div class="border-l border-black h-1/2"></div><div class="flex items-center gap-2 rounded-lg py-1"><svg width="28" height="28" viewBox="0 0 100 100" fill="currentColor" class="h-7 w-7" xmlns="http://www.w3.org/2000/svg"><path d="M51,8.5C28.1,8.5,9.5,27.1,9.5,50S28.1,91.5,51,91.5S92.5,72.9,92.5,50S73.9,8.5,51,8.5z M81.7,30.5l0.7-0.5  c1.5,2.3,2.7,4.8,3.7,7.4l-2.4,1.8c-0.9,0.7-2.2,0.1-2.3-1.1l-0.3-6.4C81.1,31.2,81.3,30.8,81.7,30.5z M27.3,71l-2.1,5.7  c-3.7-3.6-6.6-7.9-8.6-12.7l5.9-2.7c1-0.4,2.1,0,2.4,1l2.5,7.5C27.4,70.2,27.4,70.7,27.3,71z M67.5,62.4l-2.8,5.9  c-0.1,0.2-0.3,0.4-0.5,0.6l-2,1.3c-0.3,0.2-0.6,0.6-0.6,1l-2.4,15.1c-1.2,0.3-2.4,0.5-3.6,0.6L52,85.1c-0.4-0.2-0.7-0.6-0.8-1.1  L49,68.3c0-0.3-0.2-0.6-0.4-0.9l-6-5.6c-0.4-0.4-0.6-1.1-0.3-1.6l2.1-4.8c0.2-0.5,0.1-1.1-0.3-1.6l-8.6-9c-0.1-0.2-0.3-0.3-0.3-0.5  l-3.9-12c-0.2-0.6-0.7-1-1.3-1L24.8,31c-0.8,0-1.3-0.7-1.3-1.4c0-0.3,0.1-0.7,0.4-0.9l6.2-7.1c0.3-0.3,0.8-0.5,1.2-0.5l8,0.8  c0.2,0,0.3,0,0.5,0l16.2-3.7c1-0.2,1.9,0.6,1.7,1.6L57.5,21c0,0.3-0.2,0.6-0.4,0.8l-1.5,1.5c-0.6,0.6-0.6,1.5,0,2l4.1,4.1  c0.6,0.6,0.6,1.5,0,2L48,43.3c-0.3,0.3-0.4,0.6-0.4,1v6.3c0,0.7,0.5,1.3,1.2,1.4l13,2.5c0.3,0.1,0.6,0.2,0.8,0.5l4.8,6  C67.6,61.4,67.7,62,67.5,62.4z M74.4,22.7c0,0.7-0.4,1.4-1,1.7l-7.9,4.5c-1,0.6-2.4,0.1-2.8-1l-1-2.6c-0.4-0.9-0.3-2,0.2-2.8l2-3.7  c0.3-0.6,1-1,1.7-1h3.8c1.7,1,3.4,2.1,4.9,3.4V22.7z M84.8,64.1L75.4,58c-0.6-0.4-0.8-1.1-0.6-1.7l3.2-8.9c0.1-0.3,0.3-0.5,0.6-0.7  l8.5-5.7c0.7,2.9,1.1,5.9,1.1,8.9c0,5.2-1.1,10.1-3,14.6C85.1,64.4,85,64.2,84.8,64.1z" transform="translate(-5,-5) scale(1.05,1.05)"></path></svg><div class="flex justify-between flex-grow gap-3"><div class="flex flex-col"><span class="text-[8.5px] font-mono">Importance</span><number-flow-react class="font-mono text-xs font-bold" aria-label="1%" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:1,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[{&quot;type&quot;:&quot;percentSign&quot;,&quot;value&quot;:&quot;%&quot;,&quot;key&quot;:&quot;percentSign:0&quot;}],&quot;valueAsString&quot;:&quot;1%&quot;,&quot;value&quot;:0.01}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">1</span></span><span part="fraction"></span></span
			><span part="right"><span class="symbol" part="symbol percentSign">%</span></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>1%</span
		></number-flow-react></div><div class="flex flex-col"><span class="text-[8.5px] font-mono">Datacenters</span><div class="flex items-center"><number-flow-react class="font-mono text-xs font-bold" aria-label="$308B" role="img" data="{&quot;pre&quot;:[{&quot;type&quot;:&quot;currency&quot;,&quot;value&quot;:&quot;$&quot;,&quot;key&quot;:&quot;currency:0&quot;}],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:3,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:8,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[{&quot;type&quot;:&quot;compact&quot;,&quot;value&quot;:&quot;B&quot;,&quot;key&quot;:&quot;compact:0&quot;}],&quot;valueAsString&quot;:&quot;$308B&quot;,&quot;value&quot;:307791637868}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"><span class="symbol" part="symbol currency">$</span></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">3</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">8</span></span><span part="fraction"></span></span
			><span part="right"><span class="symbol" part="symbol compact">B</span></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>$308B</span
		></number-flow-react><span class="font-mono text-xs font-bold">/yr</span></div></div><div class="flex flex-col"><span class="text-[8.5px] font-mono">Timeline</span><number-flow-react class="font-mono text-xs font-bold" aria-label="2042" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:3&quot;,&quot;pos&quot;:3},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:4,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;2042&quot;,&quot;value&quot;:2042}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">2</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">4</span><span class="digit" part="digit integer-digit">2</span></span><span part="fraction"></span></span
			><span part="right"></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>2042</span
		></number-flow-react></div></div></div></div><div class="[grid-area:agentPopulation] flex flex-col gap-1 rounded-lg px-1 py-3 max-w-full"><div class="flex"><span class="text-[10.4px] tracking-tight font-mono"><span class="font-bold"><number-flow-react aria-label="2,000" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:3&quot;,&quot;pos&quot;:3},{&quot;type&quot;:&quot;group&quot;,&quot;value&quot;:&quot;,&quot;,&quot;key&quot;:&quot;group:0&quot;},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;2,000&quot;,&quot;value&quot;:2000}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">2</span><span class="symbol" part="symbol group">,</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">0</span></span><span part="fraction"></span></span
			><span part="right"></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>2,000</span
		></number-flow-react></span> <!-- -->Unreliable Agent<!-- --> copies thinking at<!-- --> <span class="font-bold"><number-flow-react aria-label="8" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:8,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;8&quot;,&quot;value&quot;:8}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">8</span></span><span part="fraction"></span></span
			><span part="right"></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>8</span
		></number-flow-react>x human speed</span></span></div><div style="overflow:hidden;display:flex;flex-direction:column;gap:4px;width:100%;max-height:calc(90vh - 400px);height:8px"><div class="flex gap-[2px]"><div class="w-[8px] h-[8px] bg-[var(--accent)] rounded-[1px]"></div><div class="w-[8px] h-[8px] bg-[var(--accent)] rounded-[1px]"></div></div></div></div><div class="[grid-area:capability] flex max-w-full overflow-hidden"><div class="[writing-mode:vertical-rl] scale-[-1] [font-variant:small-caps] text-[12px] mb-1 font-mono pt-[9px] pl-1">AI Capabilities</div><div class="flex flex-wrap flex-col h-[100px] justify-around gap-1 pl-1 w-full pr-2"><div class="flex items-center w-1/2"><div class="w-full h-6 rounded-sm overflow-hidden relative"><div class="h-full flex items-center transition-all duration-500 ease-in-out z-1 relative" style="background:linear-gradient(to right, black calc(min(25%, var(--w))), white calc(min(25%, var(--w))), white calc(min(25%, var(--w)) + 1%), black calc(min(25%, var(--w)) + 1%), black var(--w), var(--vivid-background) var(--w));--w:17.5%;transition:--w 0.5s"><span class="text-transparent font-mono tracking-widest whitespace-nowrap [background:inherit] w-full h-full flex items-center pl-[8px] text-[10px]" style="background-clip:text;filter:invert(1) grayscale(1) contrast(1000)"><div class="relative inline-block w-4 h-4 mr-4"><img src="/hacking.svg" alt="Hacking icon" class="max-w-none w-4 h-4 object-contain" style="filter:brightness(0) invert(1)"/><img src="/hacking.svg" alt="Hacking icon" class="max-w-none w-4 h-4 object-contain absolute top-0 left-0 pointer-events-none z-1" style="mask-image:linear-gradient(to right, white 90%, transparent 90%);filter:brightness(0) invert(1);mix-blend-mode:difference"/></div><span class="">Hacking</span></span></div></div></div><div class="flex items-center w-1/2"><div class="w-full h-6 rounded-sm overflow-hidden relative"><div class="h-full flex items-center transition-all duration-500 ease-in-out z-1 relative" style="background:linear-gradient(to right, black calc(min(25%, var(--w))), white calc(min(25%, var(--w))), white calc(min(25%, var(--w)) + 1%), black calc(min(25%, var(--w)) + 1%), black var(--w), var(--vivid-background) var(--w));--w:20%;transition:--w 0.5s"><span class="text-transparent font-mono tracking-widest whitespace-nowrap [background:inherit] w-full h-full flex items-center pl-[8px] text-[10px]" style="background-clip:text;filter:invert(1) grayscale(1) contrast(1000)"><div class="relative inline-block w-4 h-4 mr-4"><img src="/coding.svg" alt="Coding icon" class="max-w-none w-4 h-4 object-contain"/></div><span class="">Coding</span></span></div></div></div><div class="flex items-center w-1/2"><div class="w-full h-6 rounded-sm overflow-hidden relative"><div class="h-full flex items-center transition-all duration-500 ease-in-out z-1 relative" style="background:linear-gradient(to right, black calc(min(25%, var(--w))), white calc(min(25%, var(--w))), white calc(min(25%, var(--w)) + 1%), black calc(min(25%, var(--w)) + 1%), black var(--w), var(--vivid-background) var(--w));--w:9.5%;transition:--w 0.5s"><span class="text-transparent font-mono tracking-widest whitespace-nowrap [background:inherit] w-full h-full flex items-center pl-[8px] text-[10px]" style="background-clip:text;filter:invert(1) grayscale(1) contrast(1000)"><div class="relative inline-block w-4 h-4 mr-4"><img src="/political.svg" alt="Politics icon" class="max-w-none w-4 h-4 object-contain" style="filter:brightness(0) invert(1)"/><img src="/political.svg" alt="Politics icon" class="max-w-none w-4 h-4 object-contain absolute top-0 left-0 pointer-events-none z-1" style="mask-image:linear-gradient(to right, white 26%, transparent 26%);filter:brightness(0) invert(1);mix-blend-mode:difference"/></div><span class="">Politics</span></span></div></div></div><div class="flex items-center w-1/2"><div class="w-full h-6 rounded-sm overflow-hidden relative"><div class="h-full flex items-center transition-all duration-500 ease-in-out z-1 relative" style="background:linear-gradient(to right, black calc(min(25%, var(--w))), white calc(min(25%, var(--w))), white calc(min(25%, var(--w)) + 1%), black calc(min(25%, var(--w)) + 1%), black var(--w), var(--vivid-background) var(--w));--w:17.5%;transition:--w 0.5s"><span class="text-transparent font-mono tracking-widest whitespace-nowrap [background:inherit] w-full h-full flex items-center pl-[8px] text-[10px]" style="background-clip:text;filter:invert(1) grayscale(1) contrast(1000)"><div class="relative inline-block w-4 h-4 mr-4"><img src="/bioweapons.svg" alt="Bioweapons icon" class="max-w-none w-4 h-4 object-contain" style="filter:brightness(0) invert(1)"/><img src="/bioweapons.svg" alt="Bioweapons icon" class="max-w-none w-4 h-4 object-contain absolute top-0 left-0 pointer-events-none z-1" style="mask-image:linear-gradient(to right, white 90%, transparent 90%);filter:brightness(0) invert(1);mix-blend-mode:difference"/></div><span class="">Bioweapons</span></span></div></div></div><div class="flex items-center w-1/2"><div class="w-full h-6 rounded-sm overflow-hidden relative"><div class="h-full flex items-center transition-all duration-500 ease-in-out z-1 relative" style="background:linear-gradient(to right, black calc(min(25%, var(--w))), white calc(min(25%, var(--w))), white calc(min(25%, var(--w)) + 1%), black calc(min(25%, var(--w)) + 1%), black var(--w), var(--vivid-background) var(--w));--w:1.5%;transition:--w 0.5s"><span class="text-transparent font-mono tracking-widest whitespace-nowrap [background:inherit] w-full h-full flex items-center pl-[8px] text-[10px]" style="background-clip:text;filter:invert(1) grayscale(1) contrast(1000)"><div class="relative inline-block w-4 h-4 mr-4"><img src="/robotics.svg" alt="Robotics icon" class="max-w-none w-4 h-4 object-contain" style="filter:brightness(0) invert(1)"/><img src="/robotics.svg" alt="Robotics icon" class="max-w-none w-4 h-4 object-contain absolute top-0 left-0 pointer-events-none z-1" style="mask-image:linear-gradient(to right, white 0%, transparent 0%);filter:brightness(0) invert(1);mix-blend-mode:difference"/></div><span class="">Robotics</span></span></div></div></div><div class="flex items-center w-1/2"><div class="w-full h-6 rounded-sm overflow-hidden relative"><div class="h-full flex items-center transition-all duration-500 ease-in-out z-1 relative" style="background:linear-gradient(to right, black calc(min(25%, var(--w))), white calc(min(25%, var(--w))), white calc(min(25%, var(--w)) + 1%), black calc(min(25%, var(--w)) + 1%), black var(--w), var(--vivid-background) var(--w));--w:17.25%;transition:--w 0.5s"><span class="text-transparent font-mono tracking-widest whitespace-nowrap [background:inherit] w-full h-full flex items-center pl-[8px] text-[10px]" style="background-clip:text;filter:invert(1) grayscale(1) contrast(1000)"><div class="relative inline-block w-4 h-4 mr-4"><img src="/forecasting.svg" alt="Forecasting icon" class="max-w-none w-4 h-4 object-contain" style="filter:brightness(0) invert(1)"/><img src="/forecasting.svg" alt="Forecasting icon" class="max-w-none w-4 h-4 object-contain absolute top-0 left-0 pointer-events-none z-1" style="mask-image:linear-gradient(to right, white 88%, transparent 88%);filter:brightness(0) invert(1);mix-blend-mode:difference"/></div><span class="">Forecasting</span></span></div></div></div></div></div></div></div><div class="z-50 block md:hidden requires-modern-css transition-[height, opacity, width, top, left, right, bottom, min-height] duration-700 
      shadow-lg rounded-lg cursor-pointer origin-bottom-right 
      hud-pip overflow-hidden p-[5px] 
      bg-[var(--vivid-background)]" style="position:fixed;top:calc(100% - 95px - 0.75rem);left:0.5rem;bottom:0.75rem;right:0.5rem;width:calc(100vw - 1rem);height:min-content;min-height:95px;opacity:0;pointer-events:none;border-radius:8px;background-color:var(--vivid-background)"><div style="opacity:1"><div class="flex font-system-mono text-xs absolute top-1"><div class="flex items-center justify-center w-[20.5px] h-[20.5px] mr-1 rounded-sm bg-black text-white"><svg width="14" height="14" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3 3V9H5V5H9V3H3Z" fill="currentColor"></path><path d="M3 21H9V19H5V15H3V21Z" fill="currentColor"></path><path d="M21 3H15V5H19V9H21V3Z" fill="currentColor"></path><path d="M15 21H21V15H19V19H15V21Z" fill="currentColor"></path></svg></div><div class="overflow-hidden px-2 rounded-sm bg-black opacity-100 z-[1] relative"><div class="whitespace-nowrap inline-flex text-white mix-blend-difference align-center gap-1 pt-[3px]"><div class="relative h-[15px] w-7 text-baseline mt-[-1px]"><span class="font-system-mono mr-1" style="position:absolute;left:0;opacity:1;transform:none">Apr</span></div><number-flow-react class="font-system-mono text-right mt-[-1.5px]" aria-label="2025" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:3&quot;,&quot;pos&quot;:3},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:5,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;2025&quot;,&quot;value&quot;:2025}"><template shadowroot="open" shadowrootmode="open"
			><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style
			><span part="left"></span><span part="number" class="number"
				><span part="integer"><span class="digit" part="digit integer-digit">2</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">2</span><span class="digit" part="digit integer-digit">5</span></span><span part="fraction"></span></span
			><span part="right"></span></template
		><span
			style="font-kerning: none; display: inline-block; line-height: var(--number-flow-char-height, 1em) !important; padding: var(--number-flow-mask-height, 0.25em) 0;"
			>2025</span
		></number-flow-react></div></div></div><div class="origin-top mt-[-7px] mb-[-16px]" style="width:404px"><div style="width:404px;height:104px;position:relative" class="[grid-area:rdmultiple] mb-1"><svg width="404" height="104" style="opacity:1"><defs><clipPath id="revealClip"><rect x="0" y="0" width="397" height="57"></rect></clipPath></defs><g clip-path="url(#revealClip)" transform="translate(0, 17)"><path d="M 0 21.171428571428557 C 24.8125 20.967857142857127 74.4375 19.74642857142856 99.25 19.54285714285713" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 99.25 19.54285714285713 C 124.0625 19.135714285714272 173.6875 16.69285714285713 198.5 16.28571428571427" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 198.5 16.28571428571427 C 223.3125 15.878571428571412 272.9375 13.435714285714269 297.75 13.02857142857141" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 297.75 13.02857142857141 C 322.5625 11.399999999999984 372.1875 1.6285714285714263 397 0" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 397 0 C 421.8125 0 471.4375 0 496.25 0" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 0 32.571428571428555 C 24.8125 31.96071428571427 74.4375 28.296428571428567 99.25 27.685714285714283" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 99.25 27.685714285714283 C 124.0625 27.074999999999996 173.6875 23.410714285714285 198.5 22.799999999999997" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 198.5 22.799999999999997 C 223.3125 21.98571428571428 272.9375 17.099999999999987 297.75 16.28571428571427" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 297.75 16.28571428571427 C 322.5625 15.267857142857125 372.1875 9.160714285714256 397 8.14285714285711" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 397 8.14285714285711 C 421.8125 8.14285714285711 471.4375 8.14285714285711 496.25 8.14285714285711" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 0 57 C 24.8125 55.575 74.4375 47.025000000000006 99.25 45.60000000000001" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 99.25 45.60000000000001 C 124.0625 43.971428571428575 173.6875 34.19999999999999 198.5 32.571428571428555" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 198.5 32.571428571428555 C 223.3125 30.7392857142857 272.9375 19.74642857142856 297.75 17.914285714285704" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 297.75 17.914285714285704 C 322.5625 17.099999999999987 372.1875 12.214285714285694 397 11.399999999999977" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 397 11.399999999999977 C 421.8125 11.399999999999977 471.4375 11.399999999999977 496.25 11.399999999999977" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path></g><g transform="translate(0, 17)"><circle cx="397" cy="0" r="10" fill="white"></circle><circle cx="397" cy="8.14285714285711" r="10" fill="white"></circle><circle cx="397" cy="11.399999999999977" r="10" fill="white"></circle><image href="/openai.svg" width="14" height="14" x="390" y="-9" class="transition-all duration-500 ease-linear"></image><image href="/world.svg" width="14" height="14" x="390" y="6" class="transition-all duration-500 ease-linear"></image><image href="/china.svg" width="14" height="14" x="390" y="21" class="transition-all duration-500 ease-linear"></image></g><g transform="translate(0, 17)"><g data-label="Unreliable Agent" opacity="1"><circle r="1" fill="white" cx="297.75" cy="13.02857142857141" class="transition-all duration-500 ease-linear"></circle><text fill="black" font-size="10" style="pointer-events:none;transform:translate(292.75px, 8.02857142857141px)" text-anchor="end" class="font-mono font-bold transition-transform transition-opacity duration-500 ease-linear">Unreliable Agent</text></g></g><g transform="translate(0, 69)"><g opacity="1"><text fill="black" font-size="10" text-anchor="end" class="font-mono font-normal transition-all duration-500 ease-linear" style="pointer-events:none;transform:translate(297.75px, 20px)">Dec 2024</text></g></g></svg></div></div><div></div></div></div></div><div class="group pt-3 transition-opacity duration-500 opacity-0"><div class="flex w-full"><button type="button" class="md:hidden mr-1 rounded-full h-[26px] w-[26px] flex items-center justify-center hover:fill-[var(--accent)]" aria-label="Play audio of page text"><svg class="hover:text-[var(--accent)]" xmlns="http://www.w3.org/2000/svg" width="16" viewBox="0 0 9 16"><path d="M0 11.9523V4.04773C0 3.22232 0.911256 2.72209 1.60763 3.16523L7.81833 7.1175C8.46426 7.52854 8.46426 8.47146 7.81833 8.8825L1.60763 12.8348C0.911255 13.2779 0 12.7777 0 11.9523Z" fill="currentColor"></path></svg></button><div class="flex flex-col w-full"><div class="flex items-center font-sans"><button type="button" class="rounded-full h-[16px] flex items-center justify-center hover:fill-[var(--accent)] hidden md:block" aria-label="Play audio of page text"><svg class="hover:text-[var(--accent)]" xmlns="http://www.w3.org/2000/svg" width="8" viewBox="0 0 9 16"><path d="M0 11.9523V4.04773C0 3.22232 0.911256 2.72209 1.60763 3.16523L7.81833 7.1175C8.46426 7.52854 8.46426 8.47146 7.81833 8.8825L1.60763 12.8348C0.911255 13.2779 0 12.7777 0 11.9523Z" fill="currentColor"></path></svg></button><span class="w-full"><div class="flex items-center justify-between font-mono text-xs md:ml-2"><div class="flex items-center gap-2"><span class="hidden md:block">Listen to this scenario</span><span class="block md:hidden text-[10px]"><div class="flex items-center justify-end gap-1 opacity-70 font-mono text-xs"><span class="text-[7px] sm:text-xs mr-1">also available on</span><a href="https://open.spotify.com/show/0pVfkdbpQWM9sKlhzpbQq6" class="hover:opacity-70 transition-opacity" aria-label="Listen on Spotify"><svg viewBox="0 0 24 24" fill="currentColor" class="w-3 h-3 sm:w-4 sm:h-4"><path d="M12 0C5.4 0 0 5.4 0 12s5.4 12 12 12 12-5.4 12-12S18.66 0 12 0zm5.521 17.34c-.24.359-.66.48-1.021.24-2.82-1.74-6.36-2.101-10.561-1.141-.418.122-.779-.179-.899-.539-.12-.421.18-.78.54-.9 4.56-1.021 8.52-.6 11.64 1.32.42.18.479.659.301 1.02zm1.44-3.3c-.301.42-.841.6-1.262.3-3.239-1.98-8.159-2.58-11.939-1.38-.479.12-1.02-.12-1.14-.6-.12-.48.12-1.021.6-1.141C9.6 9.9 15 10.561 18.72 12.84c.361.181.54.78.241 1.2zm.12-3.36C15.24 8.4 8.82 8.16 5.16 9.301c-.6.179-1.2-.181-1.38-.721-.18-.601.18-1.2.72-1.381 4.26-1.26 11.28-1.02 15.721 1.621.539.3.719 1.02.419 1.56-.299.421-1.02.599-1.559.3z"></path></svg></a><a href="https://podcasts.apple.com/podcast/id1806225838" class="hover:opacity-70 transition-opacity" aria-label="Listen on Apple Podcasts"><svg fill="#000000" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg" class="w-3 h-3 sm:w-4 sm:h-4"><path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"></path></svg></a><a href="https://feeds.buzzsprout.com/2466760.rss" class="hover:opacity-70 transition-opacity" aria-label="Listen on Buzzsprout"><svg version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg" class="w-3 h-3 sm:w-4 sm:h-4"><path d="m1028.2 78.801h-856.36c-51.121 0-92.578 41.461-92.578 92.578v850.58c0 51.121 41.461 92.578 92.578 92.578h856.36c51.121 0 92.578-41.441 92.578-92.578l0.003907-850.58c0-51.117-41.461-92.578-92.582-92.578zm-675.86 879.78c-52.719 0-95.48-42.781-95.48-95.48 0-52.762 42.762-95.48 95.48-95.48 52.699 0 95.48 42.719 95.48 95.48 0 52.723-42.781 95.48-95.48 95.48zm364.14 0h-98c0.57812-8.4609 1.2617-16.82 1.2617-25.422 0-200.52-163.18-363.72-363.72-363.72h-0.039062v-98h0.039062c254.6 0 461.74 207.12 461.74 461.72-0.023438 8.625-0.84375 16.945-1.2812 25.422zm219.5 0h-92.801c5.6016-31.059 9-62.84 9-95.48 0-295.82-240.66-536.5-536.5-536.5-20.199 0-40.078 1.3594-59.719 3.5195v-92.359c19.66-1.8594 39.559-3.0391 59.719-3.0391 346.46 0 628.36 281.9 628.36 628.36 0 32.582-3.2578 64.262-8.0586 95.5z"></path></svg></a></div></span></div><div class="hidden sm:flex items-center gap-2 ml-auto "><button type="button" class="rounded-full h-[16px] w-[16px] flex items-center justify-center hover:text-[var(--accent)] undefined" aria-label="Skip backward 30 seconds"><svg width="100%" height="100%" version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg"><path d="m276 732v204c0 17.148 9.1484 32.996 24 41.57 14.852 8.5742 33.148 8.5742 48 0 14.852-8.5742 24-24.422 24-41.57v-204c0-25.461-10.113-49.879-28.117-67.883-18.004-18.004-42.422-28.117-67.883-28.117-17.148 0-32.996 9.1484-41.57 24-8.5742 14.852-8.5742 33.148 0 48 8.5742 14.852 24.422 24 41.57 24"></path><path d="m444 768v84c0 47.16 25.16 90.734 66 114.32 40.84 23.578 91.16 23.578 132 0 40.84-23.582 66-67.156 66-114.32v-84c0-47.16-25.16-90.734-66-114.32-40.84-23.578-91.16-23.578-132 0-40.84 23.582-66 67.156-66 114.32m168 0v84c0 12.863-6.8633 24.746-18 31.176-11.137 6.4336-24.863 6.4336-36 0-11.137-6.4297-18-18.312-18-31.176v-84c0-12.863 6.8633-24.746 18-31.176 11.137-6.4336 24.863-6.4336 36 0 11.137 6.4297 18 18.312 18 31.176"></path><path d="m312 396c-0.054688 28.109 11.137 55.074 31.078 74.879l91.082 91.082c12.133 12.133 29.816 16.871 46.391 12.43s29.52-17.387 33.961-33.961c4.4375-16.574-0.30078-34.258-12.434-46.391l-50.156-50.039h268.08c42.711 0.16016 83.488 17.828 112.82 48.875 29.328 31.051 44.645 72.77 42.371 115.42-2.2695 42.652-21.93 82.508-54.391 110.27-13.121 11.148-19.297 28.445-16.203 45.383 3.0977 16.934 14.988 30.93 31.203 36.719 16.211 5.7891 34.281 2.4883 47.398-8.6602 39.297-33.406 67.398-78.062 80.508-127.95 13.109-49.883 10.598-102.59-7.1953-151-17.797-48.406-50.016-90.191-92.309-119.71-42.293-29.52-92.629-45.348-144.2-45.352h-268.08l50.039-50.039c12.133-12.133 16.871-29.816 12.43-46.391-4.4414-16.574-17.387-29.52-33.961-33.961-16.574-4.4414-34.258 0.29688-46.391 12.43l-91.078 91.078v0.003906c-19.902 19.828-31.047 46.789-30.961 74.879"></path></svg></button><select style="width:14px" class="bg-transparent border-none text-xs focus:outline-none cursor-pointer appearance-none undefined"><option value="0.5">0.5x</option><option value="0.75">0.75x</option><option value="1" selected="">1x</option><option value="1.25">1.25x</option><option value="1.5">1.5x</option><option value="2">2x</option><option value="2.5">2.5x</option><option value="3">3x</option><option value="4">4x</option><option value="5">5x</option></select><button type="button" class="rounded-full h-[16px] w-[16px] flex items-center justify-center hover:text-[var(--accent)] undefined" aria-label="Skip forward 30 seconds"><svg width="100%" height="100%" version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg"><path d="m588 984c12.73 0 24.938-5.0586 33.941-14.059 9-9.0039 14.059-21.211 14.059-33.941v-204c0-25.461-10.113-49.879-28.117-67.883-18.004-18.004-42.422-28.117-67.883-28.117-17.148 0-32.996 9.1484-41.57 24-8.5742 14.852-8.5742 33.148 0 48 8.5742 14.852 24.422 24 41.57 24v204c0 12.73 5.0586 24.938 14.059 33.941 9.0039 9 21.211 14.059 33.941 14.059"></path><path d="m972 768c0-47.16-25.16-90.734-66-114.32-40.84-23.578-91.16-23.578-132 0-40.84 23.582-66 67.156-66 114.32v84c0 47.16 25.16 90.734 66 114.32 40.84 23.578 91.16 23.578 132 0 40.84-23.582 66-67.156 66-114.32zm-96 84c0 12.863-6.8633 24.746-18 31.176-11.137 6.4336-24.863 6.4336-36 0-11.137-6.4297-18-18.312-18-31.176v-84c0-12.863 6.8633-24.746 18-31.176 11.137-6.4336 24.863-6.4336 36 0 11.137 6.4297 18 18.312 18 31.176"></path><path d="m228 600c0.003906 36.527 7.9453 72.617 23.277 105.77 15.332 33.152 37.691 62.574 65.523 86.23 13.055 11.125 31.051 14.441 47.215 8.6992 16.16-5.7422 28.031-19.672 31.141-36.543 3.1055-16.867-3.0234-34.109-16.078-45.234-32.656-27.727-52.473-67.664-54.801-110.44-2.332-42.773 13.031-84.625 42.484-115.73s70.398-48.738 113.24-48.75h244.08l-50.039 50.039c-12.133 12.133-16.871 29.816-12.43 46.391 4.4414 16.574 17.387 29.52 33.961 33.961 16.574 4.4414 34.258-0.29688 46.391-12.43l91.078-91.078v-0.003906c19.883-19.871 31.051-46.828 31.051-74.938s-11.168-55.07-31.051-74.941l-91.078-91.078c-12.133-12.133-29.816-16.871-46.391-12.434-16.574 4.4414-29.52 17.387-33.961 33.961s0.29688 34.258 12.43 46.391l50.039 50.16h-244.08c-66.836 0-130.93 26.551-178.19 73.809-47.258 47.258-73.809 111.36-73.809 178.19"></path></svg></button></div><div class="pl-3">0:00 / 3:23</div></div></span></div><div class="hidden md:block mt-2 opacity-100"><div class="flex items-center justify-end gap-1 opacity-70 font-mono text-xs"><span class="text-[7px] sm:text-xs mr-1">also available on</span><a href="https://open.spotify.com/show/0pVfkdbpQWM9sKlhzpbQq6" class="hover:opacity-70 transition-opacity" aria-label="Listen on Spotify"><svg viewBox="0 0 24 24" fill="currentColor" class="w-3 h-3 sm:w-4 sm:h-4"><path d="M12 0C5.4 0 0 5.4 0 12s5.4 12 12 12 12-5.4 12-12S18.66 0 12 0zm5.521 17.34c-.24.359-.66.48-1.021.24-2.82-1.74-6.36-2.101-10.561-1.141-.418.122-.779-.179-.899-.539-.12-.421.18-.78.54-.9 4.56-1.021 8.52-.6 11.64 1.32.42.18.479.659.301 1.02zm1.44-3.3c-.301.42-.841.6-1.262.3-3.239-1.98-8.159-2.58-11.939-1.38-.479.12-1.02-.12-1.14-.6-.12-.48.12-1.021.6-1.141C9.6 9.9 15 10.561 18.72 12.84c.361.181.54.78.241 1.2zm.12-3.36C15.24 8.4 8.82 8.16 5.16 9.301c-.6.179-1.2-.181-1.38-.721-.18-.601.18-1.2.72-1.381 4.26-1.26 11.28-1.02 15.721 1.621.539.3.719 1.02.419 1.56-.299.421-1.02.599-1.559.3z"></path></svg></a><a href="https://podcasts.apple.com/podcast/id1806225838" class="hover:opacity-70 transition-opacity" aria-label="Listen on Apple Podcasts"><svg fill="#000000" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg" class="w-3 h-3 sm:w-4 sm:h-4"><path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"></path></svg></a><a href="https://feeds.buzzsprout.com/2466760.rss" class="hover:opacity-70 transition-opacity" aria-label="Listen on Buzzsprout"><svg version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg" class="w-3 h-3 sm:w-4 sm:h-4"><path d="m1028.2 78.801h-856.36c-51.121 0-92.578 41.461-92.578 92.578v850.58c0 51.121 41.461 92.578 92.578 92.578h856.36c51.121 0 92.578-41.441 92.578-92.578l0.003907-850.58c0-51.117-41.461-92.578-92.582-92.578zm-675.86 879.78c-52.719 0-95.48-42.781-95.48-95.48 0-52.762 42.762-95.48 95.48-95.48 52.699 0 95.48 42.719 95.48 95.48 0 52.723-42.781 95.48-95.48 95.48zm364.14 0h-98c0.57812-8.4609 1.2617-16.82 1.2617-25.422 0-200.52-163.18-363.72-363.72-363.72h-0.039062v-98h0.039062c254.6 0 461.74 207.12 461.74 461.72-0.023438 8.625-0.84375 16.945-1.2812 25.422zm219.5 0h-92.801c5.6016-31.059 9-62.84 9-95.48 0-295.82-240.66-536.5-536.5-536.5-20.199 0-40.078 1.3594-59.719 3.5195v-92.359c19.66-1.8594 39.559-3.0391 59.719-3.0391 346.46 0 628.36 281.9 628.36 628.36 0 32.582-3.2578 64.262-8.0586 95.5z"></path></svg></a></div></div></div><div class="flex items-center gap-2 ml-2 sm:hidden font-sans"><button type="button" class="rounded-full h-[16px] w-[16px] flex items-center justify-center hover:text-[var(--accent)] h-[18px] w-[18px]" aria-label="Skip backward 30 seconds"><svg width="100%" height="100%" version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg"><path d="m276 732v204c0 17.148 9.1484 32.996 24 41.57 14.852 8.5742 33.148 8.5742 48 0 14.852-8.5742 24-24.422 24-41.57v-204c0-25.461-10.113-49.879-28.117-67.883-18.004-18.004-42.422-28.117-67.883-28.117-17.148 0-32.996 9.1484-41.57 24-8.5742 14.852-8.5742 33.148 0 48 8.5742 14.852 24.422 24 41.57 24"></path><path d="m444 768v84c0 47.16 25.16 90.734 66 114.32 40.84 23.578 91.16 23.578 132 0 40.84-23.582 66-67.156 66-114.32v-84c0-47.16-25.16-90.734-66-114.32-40.84-23.578-91.16-23.578-132 0-40.84 23.582-66 67.156-66 114.32m168 0v84c0 12.863-6.8633 24.746-18 31.176-11.137 6.4336-24.863 6.4336-36 0-11.137-6.4297-18-18.312-18-31.176v-84c0-12.863 6.8633-24.746 18-31.176 11.137-6.4336 24.863-6.4336 36 0 11.137 6.4297 18 18.312 18 31.176"></path><path d="m312 396c-0.054688 28.109 11.137 55.074 31.078 74.879l91.082 91.082c12.133 12.133 29.816 16.871 46.391 12.43s29.52-17.387 33.961-33.961c4.4375-16.574-0.30078-34.258-12.434-46.391l-50.156-50.039h268.08c42.711 0.16016 83.488 17.828 112.82 48.875 29.328 31.051 44.645 72.77 42.371 115.42-2.2695 42.652-21.93 82.508-54.391 110.27-13.121 11.148-19.297 28.445-16.203 45.383 3.0977 16.934 14.988 30.93 31.203 36.719 16.211 5.7891 34.281 2.4883 47.398-8.6602 39.297-33.406 67.398-78.062 80.508-127.95 13.109-49.883 10.598-102.59-7.1953-151-17.797-48.406-50.016-90.191-92.309-119.71-42.293-29.52-92.629-45.348-144.2-45.352h-268.08l50.039-50.039c12.133-12.133 16.871-29.816 12.43-46.391-4.4414-16.574-17.387-29.52-33.961-33.961-16.574-4.4414-34.258 0.29688-46.391 12.43l-91.078 91.078v0.003906c-19.902 19.828-31.047 46.789-30.961 74.879"></path></svg></button><select style="width:14px" class="bg-transparent border-none text-xs focus:outline-none cursor-pointer appearance-none !text-sm"><option value="0.5">0.5x</option><option value="0.75">0.75x</option><option value="1" selected="">1x</option><option value="1.25">1.25x</option><option value="1.5">1.5x</option><option value="2">2x</option><option value="2.5">2.5x</option><option value="3">3x</option><option value="4">4x</option><option value="5">5x</option></select><button type="button" class="rounded-full h-[16px] w-[16px] flex items-center justify-center hover:text-[var(--accent)] h-[18px] w-[18px]" aria-label="Skip forward 30 seconds"><svg width="100%" height="100%" version="1.1" viewBox="0 0 1200 1200" xmlns="http://www.w3.org/2000/svg"><path d="m588 984c12.73 0 24.938-5.0586 33.941-14.059 9-9.0039 14.059-21.211 14.059-33.941v-204c0-25.461-10.113-49.879-28.117-67.883-18.004-18.004-42.422-28.117-67.883-28.117-17.148 0-32.996 9.1484-41.57 24-8.5742 14.852-8.5742 33.148 0 48 8.5742 14.852 24.422 24 41.57 24v204c0 12.73 5.0586 24.938 14.059 33.941 9.0039 9 21.211 14.059 33.941 14.059"></path><path d="m972 768c0-47.16-25.16-90.734-66-114.32-40.84-23.578-91.16-23.578-132 0-40.84 23.582-66 67.156-66 114.32v84c0 47.16 25.16 90.734 66 114.32 40.84 23.578 91.16 23.578 132 0 40.84-23.582 66-67.156 66-114.32zm-96 84c0 12.863-6.8633 24.746-18 31.176-11.137 6.4336-24.863 6.4336-36 0-11.137-6.4297-18-18.312-18-31.176v-84c0-12.863 6.8633-24.746 18-31.176 11.137-6.4336 24.863-6.4336 36 0 11.137 6.4297 18 18.312 18 31.176"></path><path d="m228 600c0.003906 36.527 7.9453 72.617 23.277 105.77 15.332 33.152 37.691 62.574 65.523 86.23 13.055 11.125 31.051 14.441 47.215 8.6992 16.16-5.7422 28.031-19.672 31.141-36.543 3.1055-16.867-3.0234-34.109-16.078-45.234-32.656-27.727-52.473-67.664-54.801-110.44-2.332-42.773 13.031-84.625 42.484-115.73s70.398-48.738 113.24-48.75h244.08l-50.039 50.039c-12.133 12.133-16.871 29.816-12.43 46.391 4.4414 16.574 17.387 29.52 33.961 33.961 16.574 4.4414 34.258-0.29688 46.391-12.43l91.078-91.078v-0.003906c19.883-19.871 31.051-46.828 31.051-74.938s-11.168-55.07-31.051-74.941l-91.078-91.078c-12.133-12.133-29.816-16.871-46.391-12.434-16.574 4.4414-29.52 17.387-33.961 33.961s0.29688 34.258 12.43 46.391l50.039 50.16h-244.08c-66.836 0-130.93 26.551-178.19 73.809-47.258 47.258-73.809 111.36-73.809 178.19"></path></svg></button></div></div></div></div></div><div class="ending-options text-center [grid-area:choice] mt-[00px] mb-[50px]"><h2 class="text-4xl font-bold mb-4">Choose Your Ending</h2><div class="flex flex-row justify-center gap-4"><a class="w-1/2" href="/slowdown"><button class="px-4 py-4 rounded bg-[var(--slowdown-background)] text-white w-full text-2xl ">Slowdown</button></a><a class="w-1/2" href="/race"><button class="px-4 py-4 rounded bg-[var(--race-background)] text-white w-full text-2xl ">Race</button></a></div></div><div class="[grid-area:fgap] relative mb-4" style="z-index:1"><hr/></div><footer class="[grid-area:cFooter] md:[grid-area:cFooter/cFooter/cFooter/graphFooter] lg:[grid-area:cFooter] mb-16"><div class="flex flex-col sm:flex-row gap-2"><div class="order-2 lg:order-none flex justify-between lg:[min-width:unset]"><div class="flex  lg:items-center gap-2 min-w-[200px] self-start w-full"><a href="https://ai-futures.org/" target="_blank" rel="noopener noreferrer"><img alt="AI Futures Project" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="mix-blend-multiply ml-[-4px]" style="color:transparent" src="/ai-futures-logo.svg"/></a><div class="flex flex-col flex-grow"><a class="no-underline" href="https://ai-futures.org/" target="_blank" rel="noopener noreferrer"><p class="mt-0 mb-0">AI Futures <br/> Project</p></a><div class="flex items-end justify-end lg:hidden pr-4 ml-auto pt-2 pb-0 self-end flex-grow"><div class="flex items-center justify-end gap-4 font-mono text-xs opacity-65"><p class="text-xs mt-0 mb-0 text-right"><a class="no-underline" href="https://lightconeinfrastructure.com" target="_blank" rel="noopener noreferrer">Design by <br/> Lightcone Infrastructure</a></p><a href="https://lightconeinfrastructure.com" target="_blank" rel="noopener noreferrer"><img alt="Lightcone Infrastructure" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" style="color:transparent" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1629334277/Lightcone-02_stkgik.svg"/></a></div></div></div></div></div><div class="grid grid-cols-2 sm:grid-cols-3 md:grid-cols-4 gap-2 w-full pt-1 pb-1 overflow-y-auto text-right text-xs font-mono pr-3 order-1 lg:order-none"><a class="rounded-sm py-1 px-2 bg-[var(--accent)] text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/">Home</a><a class="rounded-sm py-1 px-2 bg-[var(--accent)] text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/about">About</a><a class="rounded-sm py-1 px-2 bg-[var(--accent)] text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/summary">Summary</a><a class="rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/research/compute-forecast">Compute Forecast</a><a class="rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/research/timelines-forecast">Timelines Forecast</a><a class="rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/research/takeoff-forecast">Takeoff Forecast</a><a class="rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/research/ai-goals-forecast">AI Goals Forecast</a><a class="rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300" href="/research/security-forecast">Security Forecast</a></div></div><div class="relative h-[150px] flex-1 mb-4 mr-3 mt-4"><iframe title="Substack Email Signup" loading="lazy" class="absolute w-full rounded-md opacity-20 hover:opacity-100 transition-opacity duration-300" src="https://blog.ai-futures.org/embed" style="filter:grayscale(1) invert(1) brightness(3)"></iframe><div class="pointer-events-none w-full h-[150px] bg-vivid-background mix-blend-darken"></div></div></footer><footer class="hidden lg:block lg:[grid-area:graphFooter] pt-1"><div class="flex items-center justify-end gap-4 font-mono text-xs opacity-65"><p class="text-xs mt-0 mb-0 text-right"><a class="no-underline" href="https://lightconeinfrastructure.com" target="_blank" rel="noopener noreferrer">Design by <br/> Lightcone Infrastructure</a></p><a href="https://lightconeinfrastructure.com" target="_blank" rel="noopener noreferrer"><img alt="Lightcone Infrastructure" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" style="color:transparent" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1629334277/Lightcone-02_stkgik.svg"/></a></div></footer></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><script src="/_next/static/chunks/webpack-3666d63491495458.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/23574b8e95fa4c6f.css\",\"style\"]\n2:HL[\"/_next/static/css/edd4b027af513e5a.css\",\"style\"]\n3:HL[\"/_next/static/css/eb8e0ea56b7a3d7c.css\",\"style\"]\n4:HL[\"/_next/static/css/7ab52e961d3a1031.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[5751,[],\"\"]\n7:I[7859,[\"339\",\"static/chunks/c16f53c3-5cd0d8c9dcf88998.js\",\"954\",\"static/chunks/d3ac728e-9fb72d70c471a406.js\",\"250\",\"static/chunks/250-1d2547d905913eb8.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"949\",\"static/chunks/949-d6301dbf17d1d87e.js\",\"241\",\"static/chunks/241-f3ca2a481bbaa609.js\",\"295\",\"static/chunks/295-f211ba89a89eee0a.js\",\"801\",\"static/chunks/801-fc075da969f18e5d.js\",\"873\",\"static/chunks/873-a65d283664692974.js\",\"956\",\"static/chunks/app/(mainPage)/layout-e0acd53732a0a6fe.js\"],\"default\"]\n215c:I[9575,[\"339\",\"static/chunks/c16f53c3-5cd0d8c9dcf88998.js\",\"954\",\"static/chunks/d3ac728e-9fb72d70c471a406.js\",\"250\",\"static/chunks/250-1d2547d905913eb8.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"949\",\"static/chunks/949-d6301dbf17d1d87e.js\",\"241\",\"static/chunks/241-f3ca2a481bbaa609.js\",\"295\",\"static/chunks/295-f211ba89a89eee0a.js\",\"801\",\"static/chunks/801-fc075da969f18e5d.js\",\"873\",\"static/chunks/873-a65d283664692974.js\",\"956\",\"static/chunks/app/(mainPage)/layout-e0acd53732a0a6fe.js\"],\"default\"]\n215d:I[9275,[],\"\"]\n215e:I[1343,[],\"\"]\n215f:I[578,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"PostHogProvider\"]\n2160:I[3673,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"AudioProvider\"]\n2161:I[698,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"default\"]\n2167:I[231,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"98"])</script><script>self.__next_f.push([1,"6\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"\"]\n2168:I[6863,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"Image\"]\n2169:I[7240,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"SpeedInsights\"]\n216a:I[1164,[\"878\",\"static/chunks/9da6db1e-0fea1966db071fc5.js\",\"986\",\"static/chunks/986-66078ca814549e23.js\",\"231\",\"static/chunks/231-b29769cd42048fdc.js\",\"752\",\"static/chunks/752-79c8bd7d884bc699.js\",\"185\",\"static/chunks/app/layout-3fddc5b713127910.js\"],\"Analytics\"]\n216c:I[6130,[],\"\"]\n8:T421,Despite the national centralization underway, DeepCent still faces a marginal but important compute disadvantage. Along with having around half the total processing power, China has to use more total chips, which are (on average) lower quality, and heterogenous GPUs (which are not always easy to connect efficiently) both of which strain chip-to-chip networking. There are also software differences (e.g. the non Nvidia-GPUs don’t have CUDA) and differences in hardware specifications meaning that their training code is more complicated, slow, and failure prone. Achieving high utilization is a downstream challenge, with data ingestion, scheduling, collective communication and parallelism algorithms lagging behind the U.S. companies. However, mitigating these problems is mostly a matter of effort and testing, which makes it a great task for the newly-stolen Agent-2, and within a month or so, uptime on the Chinese project and their average resource utilization across training and inference workloads improves to"])</script><script>self.__next_f.push([1," be only marginally behind the U.S.9:T414,Since Agent-3 is such a big file (on the order of 10 terabytes at full precision), OpenBrain is able to execute a relatively quick fix to make theft attempts much more difficult than what China was able to do to steal Agent-2—namely, closing a bunch of high bandwidth internet connections out of their datacenters. Overall this has a relatively low penalty to progress and puts them at “3-month SL4” for their frontier weights, or WSL4 as defined in our security supplement, meaning that another similar theft attempt would now require over 3 months to finish exfiltrating the weights file. Through this method alone they still don’t have guarantees under a more invasive OC5-level effort ($1B budget, 1,000 dedicated experts), which China would be capable of with a more intensive operation, but with elaborate inspections of the datacenters and their espionage network on high-alert, the U.S. intelligence agencies are confident that they would at least know in advance if China was gearing up for this kind of theft attempt. See the b:{}\n11:{\"line\":2,\"column\":1,\"offset\":17}\n12:{\"line\":2,\"column\":11,\"offset\":27}\n10:{\"start\":\"$11\",\"end\":\"$12\"}\nf:{\"type\":\"text\",\"value\":\"2025-04-30\",\"position\":\"$10\"}\ne:[\"$f\"]\n14:{\"line\":2,\"column\":1,\"offset\":17}\n15:{\"line\":2,\"column\":13,\"offset\":29}\n13:{\"start\":\"$14\",\"end\":\"$15\"}\nd:{\"type\":\"paragraph\",\"children\":\"$e\",\"position\":\"$13\"}\nc:[\"$d\"]\n17:{\"line\":1,\"column\":1,\"offset\":0}\n18:{\"line\":3,\"column\":4,\"offset\":33}\n16:{\"start\":\"$17\",\"end\":\"$18\"}\na:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$b\",\"children\":\"$c\",\"position\":\"$16\"}\n1d:{\"line\":5,\"column\":1,\"offset\":35}\n1e:{\"line\":5,\"column\":128,\"offset\":162}\n1c:{\"start\":\"$1d\",\"end\":\"$1e\"}\n1b:{\"type\":\"text\",\"value\":\"We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution.\",\"position\":\"$1c\"}\n1a:[\"$1b\"]\n20:{\"line\":5,\"column\":1,\"offset\":35}\n21:{\"line\":5,\"column\":128,\"offset\":162}\n1f:{\"start\":\"$20\",\"end\":\"$21\"}\n19:{\"ty"])</script><script>self.__next_f.push([1,"pe\":\"paragraph\",\"children\":\"$1a\",\"position\":\"$1f\"}\n26:{\"line\":7,\"column\":1,\"offset\":164}\n27:{\"line\":7,\"column\":84,\"offset\":247}\n25:{\"start\":\"$26\",\"end\":\"$27\"}\n24:{\"type\":\"text\",\"value\":\"We wrote a scenario that represents our best guess about what that might look like.\",\"position\":\"$25\"}\n2a:{\"line\":7,\"column\":84,\"offset\":247}\n2b:{\"line\":7,\"column\":88,\"offset\":251}\n29:{\"start\":\"$2a\",\"end\":\"$2b\"}\n28:{\"type\":\"footnoteReference\",\"identifier\":\"1\",\"label\":\"1\",\"position\":\"$29\"}\n2e:{\"line\":7,\"column\":88,\"offset\":251}\n2f:{\"line\":7,\"column\":212,\"offset\":375}\n2d:{\"start\":\"$2e\",\"end\":\"$2f\"}\n2c:{\"type\":\"text\",\"value\":\" It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes.\",\"position\":\"$2d\"}\n32:{\"line\":7,\"column\":212,\"offset\":375}\n33:{\"line\":7,\"column\":216,\"offset\":379}\n31:{\"start\":\"$32\",\"end\":\"$33\"}\n30:{\"type\":\"footnoteReference\",\"identifier\":\"2\",\"label\":\"2\",\"position\":\"$31\"}\n23:[\"$24\",\"$28\",\"$2c\",\"$30\"]\n35:{\"line\":7,\"column\":1,\"offset\":164}\n36:{\"line\":7,\"column\":216,\"offset\":379}\n34:{\"start\":\"$35\",\"end\":\"$36\"}\n22:{\"type\":\"paragraph\",\"children\":\"$23\",\"position\":\"$34\"}\n3b:{\"line\":9,\"column\":1,\"offset\":381}\n3c:{\"line\":9,\"column\":181,\"offset\":561}\n3a:{\"start\":\"$3b\",\"end\":\"$3c\"}\n39:{\"type\":\"text\",\"value\":\"(Added Nov 22 2025: To prevent misunderstandings: we don't know exactly when AGI will be built. 2027 was our modal (most likely) year at the time of publication, our medians were \",\"position\":\"$3a\"}\n41:{\"line\":9,\"column\":182,\"offset\":562}\n42:{\"line\":9,\"column\":197,\"offset\":577}\n40:{\"start\":\"$41\",\"end\":\"$42\"}\n3f:{\"type\":\"text\",\"value\":\"somewhat longer\",\"position\":\"$40\"}\n3e:[\"$3f\"]\n44:{\"line\":9,\"column\":181,\"offset\":561}\n45:{\"line\":9,\"column\":262,\"offset\":642}\n43:{\"start\":\"$44\",\"end\":\"$45\"}\n3d:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.listendata.com/2023/08/right-skewed-histogram.html\",\"children\":\"$3e\",\"position\":\"$43\"}\n48:{\"line\":9,\"column\":262,\"offset\":642}\n49:{\"line\":9,\"column\":298,\"offset\":678}\n47:{\"start\":\"$48\",\"end\":\"$49\"}\n46:{\"type\":\"text\",\"value\":"])</script><script>self.__next_f.push([1,"\". For more detail on our views, see \",\"position\":\"$47\"}\n4e:{\"line\":9,\"column\":299,\"offset\":679}\n4f:{\"line\":9,\"column\":303,\"offset\":683}\n4d:{\"start\":\"$4e\",\"end\":\"$4f\"}\n4c:{\"type\":\"text\",\"value\":\"here\",\"position\":\"$4d\"}\n4b:[\"$4c\"]\n51:{\"line\":9,\"column\":298,\"offset\":678}\n52:{\"line\":9,\"column\":363,\"offset\":743}\n50:{\"start\":\"$51\",\"end\":\"$52\"}\n4a:{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/eli_lifland/status/1992004724841906392?s=20\",\"children\":\"$4b\",\"position\":\"$50\"}\n55:{\"line\":9,\"column\":363,\"offset\":743}\n56:{\"line\":9,\"column\":366,\"offset\":746}\n54:{\"start\":\"$55\",\"end\":\"$56\"}\n53:{\"type\":\"text\",\"value\":\".)\",\"position\":\"$54\"}\n59:{\"line\":9,\"column\":366,\"offset\":746}\n5a:{\"line\":9,\"column\":370,\"offset\":750}\n58:{\"start\":\"$59\",\"end\":\"$5a\"}\n57:{\"type\":\"footnoteReference\",\"identifier\":\"3\",\"label\":\"3\",\"position\":\"$58\"}\n38:[\"$39\",\"$3d\",\"$46\",\"$4a\",\"$53\",\"$57\"]\n5c:{\"line\":9,\"column\":1,\"offset\":381}\n5d:{\"line\":9,\"column\":370,\"offset\":750}\n5b:{\"start\":\"$5c\",\"end\":\"$5d\"}\n37:{\"type\":\"paragraph\",\"children\":\"$38\",\"position\":\"$5b\"}\n5f:{}\n65:{\"line\":13,\"column\":4,\"offset\":768}\n66:{\"line\":13,\"column\":17,\"offset\":781}\n64:{\"start\":\"$65\",\"end\":\"$66\"}\n63:{\"type\":\"text\",\"value\":\"What is this?\",\"position\":\"$64\"}\n62:[\"$63\"]\n68:{\"line\":13,\"column\":1,\"offset\":765}\n69:{\"line\":13,\"column\":17,\"offset\":781}\n67:{\"start\":\"$68\",\"end\":\"$69\"}\n61:{\"type\":\"heading\",\"depth\":2,\"children\":\"$62\",\"position\":\"$67\"}\n6e:{\"line\":15,\"column\":1,\"offset\":783}\n6f:{\"line\":15,\"column\":13,\"offset\":795}\n6d:{\"start\":\"$6e\",\"end\":\"$6f\"}\n6c:{\"type\":\"text\",\"value\":\"The CEOs of \",\"position\":\"$6d\"}\n74:{\"line\":15,\"column\":14,\"offset\":796}\n75:{\"line\":15,\"column\":20,\"offset\":802}\n73:{\"start\":\"$74\",\"end\":\"$75\"}\n72:{\"type\":\"text\",\"value\":\"OpenAI\",\"position\":\"$73\"}\n71:[\"$72\"]\n77:{\"line\":15,\"column\":13,\"offset\":795}\n78:{\"line\":15,\"column\":83,\"offset\":865}\n76:{\"start\":\"$77\",\"end\":\"$78\"}\n70:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.bloomberg.com/features/2025-sam-altman-interview\",\"children\":\"$71\",\"position\":\"$76\"}\n7b:{\"line\":15,\"column\":83,\"offset\":865}\n7c:{\"line\":15,\"column\":85"])</script><script>self.__next_f.push([1,",\"offset\":867}\n7a:{\"start\":\"$7b\",\"end\":\"$7c\"}\n79:{\"type\":\"text\",\"value\":\", \",\"position\":\"$7a\"}\n81:{\"line\":15,\"column\":86,\"offset\":868}\n82:{\"line\":15,\"column\":101,\"offset\":883}\n80:{\"start\":\"$81\",\"end\":\"$82\"}\n7f:{\"type\":\"text\",\"value\":\"Google DeepMind\",\"position\":\"$80\"}\n7e:[\"$7f\"]\n84:{\"line\":15,\"column\":85,\"offset\":867}\n85:{\"line\":15,\"column\":170,\"offset\":952}\n83:{\"start\":\"$84\",\"end\":\"$85\"}\n7d:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.bigtechnology.com/p/google-deepmind-ceo-demis-hassabis\",\"children\":\"$7e\",\"position\":\"$83\"}\n88:{\"line\":15,\"column\":170,\"offset\":952}\n89:{\"line\":15,\"column\":176,\"offset\":958}\n87:{\"start\":\"$88\",\"end\":\"$89\"}\n86:{\"type\":\"text\",\"value\":\", and \",\"position\":\"$87\"}\n8e:{\"line\":15,\"column\":177,\"offset\":959}\n8f:{\"line\":15,\"column\":186,\"offset\":968}\n8d:{\"start\":\"$8e\",\"end\":\"$8f\"}\n8c:{\"type\":\"text\",\"value\":\"Anthropic\",\"position\":\"$8d\"}\n8b:[\"$8c\"]\n91:{\"line\":15,\"column\":176,\"offset\":958}\n92:{\"line\":15,\"column\":362,\"offset\":1144}\n90:{\"start\":\"$91\",\"end\":\"$92\"}\n8a:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-01-21-2025/card/anthropic-ceo-says-ai-could-surpass-human-intelligence-by-2027-9tka9tjLKLalkXX8IgKA\",\"children\":\"$8b\",\"position\":\"$90\"}\n95:{\"line\":15,\"column\":362,\"offset\":1144}\n96:{\"line\":15,\"column\":439,\"offset\":1221}\n94:{\"start\":\"$95\",\"end\":\"$96\"}\n93:{\"type\":\"text\",\"value\":\" have all predicted that AGI will arrive within the next 5 years. Sam Altman \",\"position\":\"$94\"}\n9b:{\"line\":15,\"column\":440,\"offset\":1222}\n9c:{\"line\":15,\"column\":448,\"offset\":1230}\n9a:{\"start\":\"$9b\",\"end\":\"$9c\"}\n99:{\"type\":\"text\",\"value\":\"has said\",\"position\":\"$9a\"}\n98:[\"$99\"]\n9e:{\"line\":15,\"column\":439,\"offset\":1221}\n9f:{\"line\":15,\"column\":541,\"offset\":1323}\n9d:{\"start\":\"$9e\",\"end\":\"$9f\"}\n97:{\"type\":\"link\",\"title\":null,\"url\":\"https://webcf.waybackmachine.org/web/20250106014723/https://blog.samaltman.com/reflections\",\"children\":\"$98\",\"position\":\"$9d\"}\na2:{\"line\":15,\"column\":541,\"offset\":1323}\na3:{\"line\":15,\"column\":650,\"offset\":1432}\na1:{\"start\":\"$a2\",\"end\""])</script><script>self.__next_f.push([1,":\"$a3\"}\na0:{\"type\":\"text\",\"value\":\" OpenAI is setting its sights on “superintelligence in the true sense of the word” and the “glorious future.”\",\"position\":\"$a1\"}\n6b:[\"$6c\",\"$70\",\"$79\",\"$7d\",\"$86\",\"$8a\",\"$93\",\"$97\",\"$a0\"]\na5:{\"line\":15,\"column\":1,\"offset\":783}\na6:{\"line\":15,\"column\":650,\"offset\":1432}\na4:{\"start\":\"$a5\",\"end\":\"$a6\"}\n6a:{\"type\":\"paragraph\",\"children\":\"$6b\",\"position\":\"$a4\"}\nab:{\"line\":17,\"column\":1,\"offset\":1434}\nac:{\"line\":17,\"column\":247,\"offset\":1680}\naa:{\"start\":\"$ab\",\"end\":\"$ac\"}\na9:{\"type\":\"text\",\"value\":\"What might that look like? We wrote AI 2027 to answer that question. Claims about the future are often frustratingly vague, so we tried to be as concrete and quantitative as possible, even though this means depicting one of many possible futures.\",\"position\":\"$aa\"}\na8:[\"$a9\"]\nae:{\"line\":17,\"column\":1,\"offset\":1434}\naf:{\"line\":17,\"column\":247,\"offset\":1680}\nad:{\"start\":\"$ae\",\"end\":\"$af\"}\na7:{\"type\":\"paragraph\",\"children\":\"$a8\",\"position\":\"$ad\"}\nb4:{\"line\":19,\"column\":1,\"offset\":1682}\nb5:{\"line\":19,\"column\":146,\"offset\":1827}\nb3:{\"start\":\"$b4\",\"end\":\"$b5\"}\nb2:{\"type\":\"text\",\"value\":\"We wrote two endings: a “slowdown” and a “race” ending. However, AI 2027 is not a recommendation or exhortation. Our goal is predictive accuracy.\",\"position\":\"$b3\"}\nb8:{\"line\":19,\"column\":146,\"offset\":1827}\nb9:{\"line\":19,\"column\":150,\"offset\":1831}\nb7:{\"start\":\"$b8\",\"end\":\"$b9\"}\nb6:{\"type\":\"footnoteReference\",\"identifier\":\"4\",\"label\":\"4\",\"position\":\"$b7\"}\nb1:[\"$b2\",\"$b6\"]\nbb:{\"line\":19,\"column\":1,\"offset\":1682}\nbc:{\"line\":19,\"column\":150,\"offset\":1831}\nba:{\"start\":\"$bb\",\"end\":\"$bc\"}\nb0:{\"type\":\"paragraph\",\"children\":\"$b1\",\"position\":\"$ba\"}\nc1:{\"line\":21,\"column\":1,\"offset\":1833}\nc2:{\"line\":21,\"column\":54,\"offset\":1886}\nc0:{\"start\":\"$c1\",\"end\":\"$c2\"}\nbf:{\"type\":\"text\",\"value\":\"We encourage you to debate and counter this scenario.\",\"position\":\"$c0\"}\nc5:{\"line\":21,\"column\":54,\"offset\":1886}\nc6:{\"line\":21,\"column\":58,\"offset\":1890}\nc4:{\"start\":\"$c5\",\"end\":\"$c6\"}\nc3:{\"type\":\"footnoteReference\",\"identifi"])</script><script>self.__next_f.push([1,"er\":\"5\",\"label\":\"5\",\"position\":\"$c4\"}\nc9:{\"line\":21,\"column\":58,\"offset\":1890}\nca:{\"line\":21,\"column\":170,\"offset\":2002}\nc8:{\"start\":\"$c9\",\"end\":\"$ca\"}\nc7:{\"type\":\"text\",\"value\":\" We hope to spark a broad conversation about where we’re headed and how to steer toward positive futures. We’re \",\"position\":\"$c8\"}\ncf:{\"line\":21,\"column\":171,\"offset\":2003}\nd0:{\"line\":21,\"column\":211,\"offset\":2043}\nce:{\"start\":\"$cf\",\"end\":\"$d0\"}\ncd:{\"type\":\"text\",\"value\":\"planning to give out thousands in prizes\",\"position\":\"$ce\"}\ncc:[\"$cd\"]\nd2:{\"line\":21,\"column\":170,\"offset\":2002}\nd3:{\"line\":21,\"column\":287,\"offset\":2119}\nd1:{\"start\":\"$d2\",\"end\":\"$d3\"}\ncb:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/about?tab=bets-and-bounties#tab-box-bets-and-bounties\",\"children\":\"$cc\",\"position\":\"$d1\"}\nd6:{\"line\":21,\"column\":287,\"offset\":2119}\nd7:{\"line\":21,\"column\":322,\"offset\":2154}\nd5:{\"start\":\"$d6\",\"end\":\"$d7\"}\nd4:{\"type\":\"text\",\"value\":\" to the best alternative scenarios.\",\"position\":\"$d5\"}\nbe:[\"$bf\",\"$c3\",\"$c7\",\"$cb\",\"$d4\"]\nd9:{\"line\":21,\"column\":1,\"offset\":1833}\nda:{\"line\":21,\"column\":322,\"offset\":2154}\nd8:{\"start\":\"$d9\",\"end\":\"$da\"}\nbd:{\"type\":\"paragraph\",\"children\":\"$be\",\"position\":\"$d8\"}\ndf:{\"line\":23,\"column\":4,\"offset\":2159}\ne0:{\"line\":23,\"column\":24,\"offset\":2179}\nde:{\"start\":\"$df\",\"end\":\"$e0\"}\ndd:{\"type\":\"text\",\"value\":\"How did we write it?\",\"position\":\"$de\"}\ndc:[\"$dd\"]\ne2:{\"line\":23,\"column\":1,\"offset\":2156}\ne3:{\"line\":23,\"column\":24,\"offset\":2179}\ne1:{\"start\":\"$e2\",\"end\":\"$e3\"}\ndb:{\"type\":\"heading\",\"depth\":2,\"children\":\"$dc\",\"position\":\"$e1\"}\ne8:{\"line\":25,\"column\":1,\"offset\":2181}\ne9:{\"line\":25,\"column\":90,\"offset\":2270}\ne7:{\"start\":\"$e8\",\"end\":\"$e9\"}\ne6:{\"type\":\"text\",\"value\":\"Our research on key questions (e.g. what goals will future AI agents have?) can be found \",\"position\":\"$e7\"}\nee:{\"line\":25,\"column\":91,\"offset\":2271}\nef:{\"line\":25,\"column\":95,\"offset\":2275}\ned:{\"start\":\"$ee\",\"end\":\"$ef\"}\nec:{\"type\":\"text\",\"value\":\"here\",\"position\":\"$ed\"}\neb:[\"$ec\"]\nf1:{\"line\":25,\"column\":90,\"offset\":2270}\nf2:{\"line\":25,\"column\""])</script><script>self.__next_f.push([1,":126,\"offset\":2306}\nf0:{\"start\":\"$f1\",\"end\":\"$f2\"}\nea:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research\",\"children\":\"$eb\",\"position\":\"$f0\"}\nf5:{\"line\":25,\"column\":126,\"offset\":2306}\nf6:{\"line\":25,\"column\":127,\"offset\":2307}\nf4:{\"start\":\"$f5\",\"end\":\"$f6\"}\nf3:{\"type\":\"text\",\"value\":\".\",\"position\":\"$f4\"}\ne5:[\"$e6\",\"$ea\",\"$f3\"]\nf8:{\"line\":25,\"column\":1,\"offset\":2181}\nf9:{\"line\":25,\"column\":127,\"offset\":2307}\nf7:{\"start\":\"$f8\",\"end\":\"$f9\"}\ne4:{\"type\":\"paragraph\",\"children\":\"$e5\",\"position\":\"$f7\"}\nfe:{\"line\":27,\"column\":1,\"offset\":2309}\nff:{\"line\":27,\"column\":190,\"offset\":2498}\nfd:{\"start\":\"$fe\",\"end\":\"$ff\"}\nfc:{\"type\":\"text\",\"value\":\"The scenario itself was written iteratively: we wrote the first period (up to mid-2025), then the following period, etc. until we reached the ending. We then scrapped this and did it again.\",\"position\":\"$fd\"}\nfb:[\"$fc\"]\n101:{\"line\":27,\"column\":1,\"offset\":2309}\n102:{\"line\":27,\"column\":190,\"offset\":2498}\n100:{\"start\":\"$101\",\"end\":\"$102\"}\nfa:{\"type\":\"paragraph\",\"children\":\"$fb\",\"position\":\"$100\"}\n107:{\"line\":29,\"column\":1,\"offset\":2500}\n108:{\"line\":29,\"column\":293,\"offset\":2792}\n106:{\"start\":\"$107\",\"end\":\"$108\"}\n105:{\"type\":\"text\",\"value\":\"We weren’t trying to reach any particular ending. After we finished the first ending—which is now colored red—we wrote a new alternative branch because we wanted to also depict a more hopeful way things could end, starting from roughly the same premises. This went through several iterations.\",\"position\":\"$106\"}\n10b:{\"line\":29,\"column\":293,\"offset\":2792}\n10c:{\"line\":29,\"column\":297,\"offset\":2796}\n10a:{\"start\":\"$10b\",\"end\":\"$10c\"}\n109:{\"type\":\"footnoteReference\",\"identifier\":\"6\",\"label\":\"6\",\"position\":\"$10a\"}\n104:[\"$105\",\"$109\"]\n10e:{\"line\":29,\"column\":1,\"offset\":2500}\n10f:{\"line\":29,\"column\":297,\"offset\":2796}\n10d:{\"start\":\"$10e\",\"end\":\"$10f\"}\n103:{\"type\":\"paragraph\",\"children\":\"$104\",\"position\":\"$10d\"}\n114:{\"line\":31,\"column\":1,\"offset\":2798}\n115:{\"line\":31,\"column\":47,\"offset\":2844}\n113:{\"start\":\"$114\",\"end\":\"$115\"}\n112:{\"type\":\"text\","])</script><script>self.__next_f.push([1,"\"value\":\"Our scenario was informed by approximately 25 \",\"position\":\"$113\"}\n11a:{\"line\":31,\"column\":48,\"offset\":2845}\n11b:{\"line\":31,\"column\":66,\"offset\":2863}\n119:{\"start\":\"$11a\",\"end\":\"$11b\"}\n118:{\"type\":\"text\",\"value\":\"tabletop exercises\",\"position\":\"$119\"}\n117:[\"$118\"]\n11d:{\"line\":31,\"column\":47,\"offset\":2844}\n11e:{\"line\":31,\"column\":142,\"offset\":2939}\n11c:{\"start\":\"$11d\",\"end\":\"$11e\"}\n116:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/about?tab=tabletop-exercise#tab-box-tabletop-exercise\",\"children\":\"$117\",\"position\":\"$11c\"}\n121:{\"line\":31,\"column\":142,\"offset\":2939}\n122:{\"line\":31,\"column\":253,\"offset\":3050}\n120:{\"start\":\"$121\",\"end\":\"$122\"}\n11f:{\"type\":\"text\",\"value\":\" and feedback from over 100 people, including dozens of experts in each of AI governance and AI technical work.\",\"position\":\"$120\"}\n111:[\"$112\",\"$116\",\"$11f\"]\n124:{\"line\":31,\"column\":1,\"offset\":2798}\n125:{\"line\":31,\"column\":253,\"offset\":3050}\n123:{\"start\":\"$124\",\"end\":\"$125\"}\n110:{\"type\":\"paragraph\",\"children\":\"$111\",\"position\":\"$123\"}\n12a:{\"line\":33,\"column\":4,\"offset\":3055}\n12b:{\"line\":33,\"column\":23,\"offset\":3074}\n129:{\"start\":\"$12a\",\"end\":\"$12b\"}\n128:{\"type\":\"text\",\"value\":\"Why is it valuable?\",\"position\":\"$129\"}\n127:[\"$128\"]\n12d:{\"line\":33,\"column\":1,\"offset\":3052}\n12e:{\"line\":33,\"column\":23,\"offset\":3074}\n12c:{\"start\":\"$12d\",\"end\":\"$12e\"}\n126:{\"type\":\"heading\",\"depth\":2,\"children\":\"$127\",\"position\":\"$12c\"}\n135:{\"line\":35,\"column\":2,\"offset\":3077}\n136:{\"line\":35,\"column\":260,\"offset\":3335}\n134:{\"start\":\"$135\",\"end\":\"$136\"}\n133:{\"type\":\"text\",\"value\":\"“I highly recommend reading this scenario-type prediction on how AI could transform the world in just a few years. Nobody has a crystal ball, but this type of content can help notice important questions and illustrate the potential impact of emerging risks.”\",\"position\":\"$134\"}\n132:[\"$133\"]\n138:{\"line\":35,\"column\":1,\"offset\":3076}\n139:{\"line\":35,\"column\":261,\"offset\":3336}\n137:{\"start\":\"$138\",\"end\":\"$139\"}\n131:{\"type\":\"emphasis\",\"children\":\"$132\",\"position\":\"$137\"}\n13c:{\"line\":35"])</script><script>self.__next_f.push([1,",\"column\":261,\"offset\":3336}\n13d:{\"line\":35,\"column\":263,\"offset\":3338}\n13b:{\"start\":\"$13c\",\"end\":\"$13d\"}\n13a:{\"type\":\"text\",\"value\":\" —\",\"position\":\"$13b\"}\n142:{\"line\":35,\"column\":264,\"offset\":3339}\n143:{\"line\":35,\"column\":277,\"offset\":3352}\n141:{\"start\":\"$142\",\"end\":\"$143\"}\n140:{\"type\":\"text\",\"value\":\"Yoshua Bengio\",\"position\":\"$141\"}\n146:{\"line\":35,\"column\":277,\"offset\":3352}\n147:{\"line\":35,\"column\":281,\"offset\":3356}\n145:{\"start\":\"$146\",\"end\":\"$147\"}\n144:{\"type\":\"footnoteReference\",\"identifier\":\"7\",\"label\":\"7\",\"position\":\"$145\"}\n13f:[\"$140\",\"$144\"]\n149:{\"line\":35,\"column\":263,\"offset\":3338}\n14a:{\"line\":35,\"column\":282,\"offset\":3357}\n148:{\"start\":\"$149\",\"end\":\"$14a\"}\n13e:{\"type\":\"emphasis\",\"children\":\"$13f\",\"position\":\"$148\"}\n130:[\"$131\",\"$13a\",\"$13e\"]\n14c:{\"line\":35,\"column\":1,\"offset\":3076}\n14d:{\"line\":35,\"column\":282,\"offset\":3357}\n14b:{\"start\":\"$14c\",\"end\":\"$14d\"}\n12f:{\"type\":\"paragraph\",\"children\":\"$130\",\"position\":\"$14b\"}\n152:{\"line\":37,\"column\":1,\"offset\":3359}\n153:{\"line\":37,\"column\":333,\"offset\":3691}\n151:{\"start\":\"$152\",\"end\":\"$153\"}\n150:{\"type\":\"text\",\"value\":\"We have set ourselves an impossible task. Trying to predict how superhuman AI in 2027 would go is like trying to predict how World War 3 in 2027 would go, except that it’s an even larger departure from past case studies. Yet it is still valuable to attempt, just as it is valuable for the U.S. military to game out Taiwan scenarios.\",\"position\":\"$151\"}\n14f:[\"$150\"]\n155:{\"line\":37,\"column\":1,\"offset\":3359}\n156:{\"line\":37,\"column\":333,\"offset\":3691}\n154:{\"start\":\"$155\",\"end\":\"$156\"}\n14e:{\"type\":\"paragraph\",\"children\":\"$14f\",\"position\":\"$154\"}\n15b:{\"line\":39,\"column\":1,\"offset\":3693}\n15c:{\"line\":39,\"column\":360,\"offset\":4052}\n15a:{\"start\":\"$15b\",\"end\":\"$15c\"}\n159:{\"type\":\"text\",\"value\":\"Painting the whole picture makes us notice important questions or connections we hadn’t considered or appreciated before, or realize that a possibility is more or less likely. Moreover, by sticking our necks out with concrete predictions, and encouraging other"])</script><script>self.__next_f.push([1,"s to publicly state their disagreements, we make it possible to evaluate years later who was right.\",\"position\":\"$15a\"}\n158:[\"$159\"]\n15e:{\"line\":39,\"column\":1,\"offset\":3693}\n15f:{\"line\":39,\"column\":360,\"offset\":4052}\n15d:{\"start\":\"$15e\",\"end\":\"$15f\"}\n157:{\"type\":\"paragraph\",\"children\":\"$158\",\"position\":\"$15d\"}\n164:{\"line\":41,\"column\":1,\"offset\":4054}\n165:{\"line\":41,\"column\":51,\"offset\":4104}\n163:{\"start\":\"$164\",\"end\":\"$165\"}\n162:{\"type\":\"text\",\"value\":\"Also, one author wrote a lower-effort AI scenario \",\"position\":\"$163\"}\n16a:{\"line\":41,\"column\":52,\"offset\":4105}\n16b:{\"line\":41,\"column\":74,\"offset\":4127}\n169:{\"start\":\"$16a\",\"end\":\"$16b\"}\n168:{\"type\":\"text\",\"value\":\"before, in August 2021\",\"position\":\"$169\"}\n167:[\"$168\"]\n16d:{\"line\":41,\"column\":51,\"offset\":4104}\n16e:{\"line\":41,\"column\":147,\"offset\":4200}\n16c:{\"start\":\"$16d\",\"end\":\"$16e\"}\n166:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\",\"children\":\"$167\",\"position\":\"$16c\"}\n171:{\"line\":41,\"column\":147,\"offset\":4200}\n172:{\"line\":41,\"column\":384,\"offset\":4437}\n170:{\"start\":\"$171\",\"end\":\"$172\"}\n16f:{\"type\":\"text\",\"value\":\". While it got many things wrong, overall it was surprisingly successful: he predicted the rise of chain-of-thought, inference scaling, sweeping AI chip export controls, and $100 million training runs—all more than a year before ChatGPT.\",\"position\":\"$170\"}\n161:[\"$162\",\"$166\",\"$16f\"]\n174:{\"line\":41,\"column\":1,\"offset\":4054}\n175:{\"line\":41,\"column\":384,\"offset\":4437}\n173:{\"start\":\"$174\",\"end\":\"$175\"}\n160:{\"type\":\"paragraph\",\"children\":\"$161\",\"position\":\"$173\"}\n17a:{\"line\":43,\"column\":4,\"offset\":4442}\n17b:{\"line\":43,\"column\":15,\"offset\":4453}\n179:{\"start\":\"$17a\",\"end\":\"$17b\"}\n178:{\"type\":\"text\",\"value\":\"Who are we?\",\"position\":\"$179\"}\n177:[\"$178\"]\n17d:{\"line\":43,\"column\":1,\"offset\":4439}\n17e:{\"line\":43,\"column\":16,\"offset\":4454}\n17c:{\"start\":\"$17d\",\"end\":\"$17e\"}\n176:{\"type\":\"heading\",\"depth\":2,\"children\":\"$177\",\"position\":\"$17c\"}\n185:{\"line\":45,\"column\":2,\"offset\":4457}\n186:{\"line\":45,\"colu"])</script><script>self.__next_f.push([1,"mn\":18,\"offset\":4473}\n184:{\"start\":\"$185\",\"end\":\"$186\"}\n183:{\"type\":\"text\",\"value\":\"Daniel Kokotajlo\",\"position\":\"$184\"}\n182:[\"$183\"]\n188:{\"line\":45,\"column\":1,\"offset\":4456}\n189:{\"line\":45,\"column\":45,\"offset\":4500}\n187:{\"start\":\"$188\",\"end\":\"$189\"}\n181:{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/DKokotajlo\",\"children\":\"$182\",\"position\":\"$187\"}\n18c:{\"line\":45,\"column\":45,\"offset\":4500}\n18d:{\"line\":45,\"column\":47,\"offset\":4502}\n18b:{\"start\":\"$18c\",\"end\":\"$18d\"}\n18a:{\"type\":\"text\",\"value\":\" (\",\"position\":\"$18b\"}\n192:{\"line\":45,\"column\":48,\"offset\":4503}\n193:{\"line\":45,\"column\":55,\"offset\":4510}\n191:{\"start\":\"$192\",\"end\":\"$193\"}\n190:{\"type\":\"text\",\"value\":\"TIME100\",\"position\":\"$191\"}\n18f:[\"$190\"]\n195:{\"line\":45,\"column\":47,\"offset\":4502}\n196:{\"line\":45,\"column\":100,\"offset\":4555}\n194:{\"start\":\"$195\",\"end\":\"$196\"}\n18e:{\"type\":\"link\",\"title\":null,\"url\":\"https://time.com/7012881/daniel-kokotajlo/\",\"children\":\"$18f\",\"position\":\"$194\"}\n199:{\"line\":45,\"column\":100,\"offset\":4555}\n19a:{\"line\":45,\"column\":102,\"offset\":4557}\n198:{\"start\":\"$199\",\"end\":\"$19a\"}\n197:{\"type\":\"text\",\"value\":\", \",\"position\":\"$198\"}\n19f:{\"line\":45,\"column\":103,\"offset\":4558}\n1a0:{\"line\":45,\"column\":112,\"offset\":4567}\n19e:{\"start\":\"$19f\",\"end\":\"$1a0\"}\n19d:{\"type\":\"text\",\"value\":\"NYT piece\",\"position\":\"$19e\"}\n19c:[\"$19d\"]\n1a2:{\"line\":45,\"column\":102,\"offset\":4557}\n1a3:{\"line\":45,\"column\":195,\"offset\":4650}\n1a1:{\"start\":\"$1a2\",\"end\":\"$1a3\"}\n19b:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.nytimes.com/2024/06/04/technology/openai-culture-whistleblowers.html\",\"children\":\"$19c\",\"position\":\"$1a1\"}\n1a6:{\"line\":45,\"column\":195,\"offset\":4650}\n1a7:{\"line\":45,\"column\":242,\"offset\":4697}\n1a5:{\"start\":\"$1a6\",\"end\":\"$1a7\"}\n1a4:{\"type\":\"text\",\"value\":\") is a former OpenAI researcher whose previous \",\"position\":\"$1a5\"}\n1ac:{\"line\":45,\"column\":243,\"offset\":4698}\n1ad:{\"line\":45,\"column\":257,\"offset\":4712}\n1ab:{\"start\":\"$1ac\",\"end\":\"$1ad\"}\n1aa:{\"type\":\"text\",\"value\":\"AI predictions\",\"position\":\"$1ab\"}\n1a9:[\"$1aa\"]\n1af:{\"line\":45,\"column\":242,\"offset\":4697}\n1b0:{"])</script><script>self.__next_f.push([1,"\"line\":45,\"column\":330,\"offset\":4785}\n1ae:{\"start\":\"$1af\",\"end\":\"$1b0\"}\n1a8:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\",\"children\":\"$1a9\",\"position\":\"$1ae\"}\n1b3:{\"line\":45,\"column\":330,\"offset\":4785}\n1b4:{\"line\":45,\"column\":336,\"offset\":4791}\n1b2:{\"start\":\"$1b3\",\"end\":\"$1b4\"}\n1b1:{\"type\":\"text\",\"value\":\" have \",\"position\":\"$1b2\"}\n1b9:{\"line\":45,\"column\":337,\"offset\":4792}\n1ba:{\"line\":45,\"column\":349,\"offset\":4804}\n1b8:{\"start\":\"$1b9\",\"end\":\"$1ba\"}\n1b7:{\"type\":\"text\",\"value\":\"held up well\",\"position\":\"$1b8\"}\n1b6:[\"$1b7\"]\n1bc:{\"line\":45,\"column\":336,\"offset\":4791}\n1bd:{\"line\":45,\"column\":440,\"offset\":4895}\n1bb:{\"start\":\"$1bc\",\"end\":\"$1bd\"}\n1b5:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/u9Kr97di29CkMvjaj/evaluating-what-2026-looks-like-so-far\",\"children\":\"$1b6\",\"position\":\"$1bb\"}\n1c0:{\"line\":45,\"column\":440,\"offset\":4895}\n1c1:{\"line\":45,\"column\":441,\"offset\":4896}\n1bf:{\"start\":\"$1c0\",\"end\":\"$1c1\"}\n1be:{\"type\":\"text\",\"value\":\".\",\"position\":\"$1bf\"}\n180:[\"$181\",\"$18a\",\"$18e\",\"$197\",\"$19b\",\"$1a4\",\"$1a8\",\"$1b1\",\"$1b5\",\"$1be\"]\n1c3:{\"line\":45,\"column\":1,\"offset\":4456}\n1c4:{\"line\":45,\"column\":441,\"offset\":4896}\n1c2:{\"start\":\"$1c3\",\"end\":\"$1c4\"}\n17f:{\"type\":\"paragraph\",\"children\":\"$180\",\"position\":\"$1c2\"}\n1cb:{\"line\":47,\"column\":2,\"offset\":4899}\n1cc:{\"line\":47,\"column\":13,\"offset\":4910}\n1ca:{\"start\":\"$1cb\",\"end\":\"$1cc\"}\n1c9:{\"type\":\"text\",\"value\":\"Eli Lifland\",\"position\":\"$1ca\"}\n1c8:[\"$1c9\"]\n1ce:{\"line\":47,\"column\":1,\"offset\":4898}\n1cf:{\"line\":47,\"column\":56,\"offset\":4953}\n1cd:{\"start\":\"$1ce\",\"end\":\"$1cf\"}\n1c7:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.linkedin.com/in/eli-lifland/\",\"children\":\"$1c8\",\"position\":\"$1cd\"}\n1d2:{\"line\":47,\"column\":56,\"offset\":4953}\n1d3:{\"line\":47,\"column\":68,\"offset\":4965}\n1d1:{\"start\":\"$1d2\",\"end\":\"$1d3\"}\n1d0:{\"type\":\"text\",\"value\":\" co-founded \",\"position\":\"$1d1\"}\n1d8:{\"line\":47,\"column\":69,\"offset\":4966}\n1d9:{\"line\":47,\"column\":78,\"offset\":4975}\n1d7:{\"start\":\"$1d8\",\"end\":\"$1d9\"}\n1d6:{\"type\":\"text\",\"value\""])</script><script>self.__next_f.push([1,":\"AI Digest\",\"position\":\"$1d7\"}\n1d5:[\"$1d6\"]\n1db:{\"line\":47,\"column\":68,\"offset\":4965}\n1dc:{\"line\":47,\"column\":105,\"offset\":5002}\n1da:{\"start\":\"$1db\",\"end\":\"$1dc\"}\n1d4:{\"type\":\"link\",\"title\":null,\"url\":\"https://theaidigest.org/\",\"children\":\"$1d5\",\"position\":\"$1da\"}\n1df:{\"line\":47,\"column\":105,\"offset\":5002}\n1e0:{\"line\":47,\"column\":111,\"offset\":5008}\n1de:{\"start\":\"$1df\",\"end\":\"$1e0\"}\n1dd:{\"type\":\"text\",\"value\":\", did \",\"position\":\"$1de\"}\n1e5:{\"line\":47,\"column\":112,\"offset\":5009}\n1e6:{\"line\":47,\"column\":134,\"offset\":5031}\n1e4:{\"start\":\"$1e5\",\"end\":\"$1e6\"}\n1e3:{\"type\":\"text\",\"value\":\"AI robustness research\",\"position\":\"$1e4\"}\n1e2:[\"$1e3\"]\n1e8:{\"line\":47,\"column\":111,\"offset\":5008}\n1e9:{\"line\":47,\"column\":197,\"offset\":5094}\n1e7:{\"start\":\"$1e8\",\"end\":\"$1e9\"}\n1e1:{\"type\":\"link\",\"title\":null,\"url\":\"https://scholar.google.com/citations?user=Q33DXbEAAAAJ\u0026hl=en\",\"children\":\"$1e2\",\"position\":\"$1e7\"}\n1ec:{\"line\":47,\"column\":197,\"offset\":5094}\n1ed:{\"line\":47,\"column\":220,\"offset\":5117}\n1eb:{\"start\":\"$1ec\",\"end\":\"$1ed\"}\n1ea:{\"type\":\"text\",\"value\":\", and ranks #1 on the \",\"position\":\"$1eb\"}\n1f2:{\"line\":47,\"column\":221,\"offset\":5118}\n1f3:{\"line\":47,\"column\":248,\"offset\":5145}\n1f1:{\"start\":\"$1f2\",\"end\":\"$1f3\"}\n1f0:{\"type\":\"text\",\"value\":\"RAND Forecasting Initiative\",\"position\":\"$1f1\"}\n1ef:[\"$1f0\"]\n1f5:{\"line\":47,\"column\":220,\"offset\":5117}\n1f6:{\"line\":47,\"column\":325,\"offset\":5222}\n1f4:{\"start\":\"$1f5\",\"end\":\"$1f6\"}\n1ee:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/global-and-emerging-risks/forecasting-initiative.html\",\"children\":\"$1ef\",\"position\":\"$1f4\"}\n1f9:{\"line\":47,\"column\":325,\"offset\":5222}\n1fa:{\"line\":47,\"column\":347,\"offset\":5244}\n1f8:{\"start\":\"$1f9\",\"end\":\"$1fa\"}\n1f7:{\"type\":\"text\",\"value\":\" all-time leaderboard.\",\"position\":\"$1f8\"}\n1c6:[\"$1c7\",\"$1d0\",\"$1d4\",\"$1dd\",\"$1e1\",\"$1ea\",\"$1ee\",\"$1f7\"]\n1fc:{\"line\":47,\"column\":1,\"offset\":4898}\n1fd:{\"line\":47,\"column\":347,\"offset\":5244}\n1fb:{\"start\":\"$1fc\",\"end\":\"$1fd\"}\n1c5:{\"type\":\"paragraph\",\"children\":\"$1c6\",\"position\":\"$1fb\"}\n204:{\"line\":49,\"column\":2,\"offset\":5247}\n"])</script><script>self.__next_f.push([1,"205:{\"line\":49,\"column\":15,\"offset\":5260}\n203:{\"start\":\"$204\",\"end\":\"$205\"}\n202:{\"type\":\"text\",\"value\":\"Thomas Larsen\",\"position\":\"$203\"}\n201:[\"$202\"]\n207:{\"line\":49,\"column\":1,\"offset\":5246}\n208:{\"line\":49,\"column\":60,\"offset\":5305}\n206:{\"start\":\"$207\",\"end\":\"$208\"}\n200:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.linkedin.com/in/thomas-larsen/\",\"children\":\"$201\",\"position\":\"$206\"}\n20b:{\"line\":49,\"column\":60,\"offset\":5305}\n20c:{\"line\":49,\"column\":73,\"offset\":5318}\n20a:{\"start\":\"$20b\",\"end\":\"$20c\"}\n209:{\"type\":\"text\",\"value\":\" founded the \",\"position\":\"$20a\"}\n211:{\"line\":49,\"column\":74,\"offset\":5319}\n212:{\"line\":49,\"column\":94,\"offset\":5339}\n210:{\"start\":\"$211\",\"end\":\"$212\"}\n20f:{\"type\":\"text\",\"value\":\"Center for AI Policy\",\"position\":\"$210\"}\n20e:[\"$20f\"]\n214:{\"line\":49,\"column\":73,\"offset\":5318}\n215:{\"line\":49,\"column\":128,\"offset\":5373}\n213:{\"start\":\"$214\",\"end\":\"$215\"}\n20d:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.centeraipolicy.org/\",\"children\":\"$20e\",\"position\":\"$213\"}\n218:{\"line\":49,\"column\":128,\"offset\":5373}\n219:{\"line\":49,\"column\":163,\"offset\":5408}\n217:{\"start\":\"$218\",\"end\":\"$219\"}\n216:{\"type\":\"text\",\"value\":\" and did AI safety research at the \",\"position\":\"$217\"}\n21e:{\"line\":49,\"column\":164,\"offset\":5409}\n21f:{\"line\":49,\"column\":203,\"offset\":5448}\n21d:{\"start\":\"$21e\",\"end\":\"$21f\"}\n21c:{\"type\":\"text\",\"value\":\"Machine Intelligence Research Institute\",\"position\":\"$21d\"}\n21b:[\"$21c\"]\n221:{\"line\":49,\"column\":163,\"offset\":5408}\n222:{\"line\":49,\"column\":231,\"offset\":5476}\n220:{\"start\":\"$221\",\"end\":\"$222\"}\n21a:{\"type\":\"link\",\"title\":null,\"url\":\"https://intelligence.org/\",\"children\":\"$21b\",\"position\":\"$220\"}\n225:{\"line\":49,\"column\":231,\"offset\":5476}\n226:{\"line\":49,\"column\":232,\"offset\":5477}\n224:{\"start\":\"$225\",\"end\":\"$226\"}\n223:{\"type\":\"text\",\"value\":\".\",\"position\":\"$224\"}\n1ff:[\"$200\",\"$209\",\"$20d\",\"$216\",\"$21a\",\"$223\"]\n228:{\"line\":49,\"column\":1,\"offset\":5246}\n229:{\"line\":49,\"column\":232,\"offset\":5477}\n227:{\"start\":\"$228\",\"end\":\"$229\"}\n1fe:{\"type\":\"paragraph\",\"children\":\"$1ff\",\"position\":\"$227\"}\n230:{\"l"])</script><script>self.__next_f.push([1,"ine\":51,\"column\":2,\"offset\":5480}\n231:{\"line\":51,\"column\":12,\"offset\":5490}\n22f:{\"start\":\"$230\",\"end\":\"$231\"}\n22e:{\"type\":\"text\",\"value\":\"Romeo Dean\",\"position\":\"$22f\"}\n22d:[\"$22e\"]\n233:{\"line\":51,\"column\":1,\"offset\":5479}\n234:{\"line\":51,\"column\":64,\"offset\":5542}\n232:{\"start\":\"$233\",\"end\":\"$234\"}\n22c:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.linkedin.com/in/romeo-dean-789313200/\",\"children\":\"$22d\",\"position\":\"$232\"}\n237:{\"line\":51,\"column\":64,\"offset\":5542}\n238:{\"line\":51,\"column\":173,\"offset\":5651}\n236:{\"start\":\"$237\",\"end\":\"$238\"}\n235:{\"type\":\"text\",\"value\":\" is completing a computer science concurrent bachelor’s and master’s degree at Harvard and previously was an \",\"position\":\"$236\"}\n23d:{\"line\":51,\"column\":174,\"offset\":5652}\n23e:{\"line\":51,\"column\":190,\"offset\":5668}\n23c:{\"start\":\"$23d\",\"end\":\"$23e\"}\n23b:{\"type\":\"text\",\"value\":\"AI Policy Fellow\",\"position\":\"$23c\"}\n23a:[\"$23b\"]\n240:{\"line\":51,\"column\":173,\"offset\":5651}\n241:{\"line\":51,\"column\":223,\"offset\":5701}\n23f:{\"start\":\"$240\",\"end\":\"$241\"}\n239:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.iaps.ai/romeo-dean\",\"children\":\"$23a\",\"position\":\"$23f\"}\n244:{\"line\":51,\"column\":223,\"offset\":5701}\n245:{\"line\":51,\"column\":268,\"offset\":5746}\n243:{\"start\":\"$244\",\"end\":\"$245\"}\n242:{\"type\":\"text\",\"value\":\" at the Institute for AI Policy and Strategy.\",\"position\":\"$243\"}\n22b:[\"$22c\",\"$235\",\"$239\",\"$242\"]\n247:{\"line\":51,\"column\":1,\"offset\":5479}\n248:{\"line\":51,\"column\":268,\"offset\":5746}\n246:{\"start\":\"$247\",\"end\":\"$248\"}\n22a:{\"type\":\"paragraph\",\"children\":\"$22b\",\"position\":\"$246\"}\n24f:{\"line\":53,\"column\":2,\"offset\":5749}\n250:{\"line\":53,\"column\":41,\"offset\":5788}\n24e:{\"start\":\"$24f\",\"end\":\"$250\"}\n24d:{\"type\":\"text\",\"value\":\"Scott Alexander, blogger extraordinaire\",\"position\":\"$24e\"}\n24c:[\"$24d\"]\n252:{\"line\":53,\"column\":1,\"offset\":5748}\n253:{\"line\":53,\"column\":90,\"offset\":5837}\n251:{\"start\":\"$252\",\"end\":\"$253\"}\n24b:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Slate_Star_Codex\",\"children\":\"$24c\",\"position\":\"$251\"}\n256:{\"line\":53,\"column\":90,\"o"])</script><script>self.__next_f.push([1,"ffset\":5837}\n257:{\"line\":53,\"column\":214,\"offset\":5961}\n255:{\"start\":\"$256\",\"end\":\"$257\"}\n254:{\"type\":\"text\",\"value\":\", volunteered to rewrite our content in an engaging style; the fun parts of the story are his and the boring parts are ours.\",\"position\":\"$255\"}\n24a:[\"$24b\",\"$254\"]\n259:{\"line\":53,\"column\":1,\"offset\":5748}\n25a:{\"line\":53,\"column\":214,\"offset\":5961}\n258:{\"start\":\"$259\",\"end\":\"$25a\"}\n249:{\"type\":\"paragraph\",\"children\":\"$24a\",\"position\":\"$258\"}\n25f:{\"line\":55,\"column\":1,\"offset\":5963}\n260:{\"line\":55,\"column\":55,\"offset\":6017}\n25e:{\"start\":\"$25f\",\"end\":\"$260\"}\n25d:{\"type\":\"text\",\"value\":\"For more about our team and acknowledgements, see the \",\"position\":\"$25e\"}\n265:{\"line\":55,\"column\":56,\"offset\":6018}\n266:{\"line\":55,\"column\":66,\"offset\":6028}\n264:{\"start\":\"$265\",\"end\":\"$266\"}\n263:{\"type\":\"text\",\"value\":\"About page\",\"position\":\"$264\"}\n262:[\"$263\"]\n268:{\"line\":55,\"column\":55,\"offset\":6017}\n269:{\"line\":55,\"column\":94,\"offset\":6056}\n267:{\"start\":\"$268\",\"end\":\"$269\"}\n261:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/about\",\"children\":\"$262\",\"position\":\"$267\"}\n26c:{\"line\":55,\"column\":94,\"offset\":6056}\n26d:{\"line\":55,\"column\":95,\"offset\":6057}\n26b:{\"start\":\"$26c\",\"end\":\"$26d\"}\n26a:{\"type\":\"text\",\"value\":\".\",\"position\":\"$26b\"}\n25c:[\"$25d\",\"$261\",\"$26a\"]\n26f:{\"line\":55,\"column\":1,\"offset\":5963}\n270:{\"line\":55,\"column\":95,\"offset\":6057}\n26e:{\"start\":\"$26f\",\"end\":\"$270\"}\n25b:{\"type\":\"paragraph\",\"children\":\"$25c\",\"position\":\"$26e\"}\n60:[\"$61\",\"$6a\",\"$a7\",\"$b0\",\"$bd\",\"$db\",\"$e4\",\"$fa\",\"$103\",\"$110\",\"$126\",\"$12f\",\"$14e\",\"$157\",\"$160\",\"$176\",\"$17f\",\"$1c5\",\"$1fe\",\"$22a\",\"$249\",\"$25b\"]\n272:{\"line\":11,\"column\":1,\"offset\":752}\n273:{\"line\":57,\"column\":4,\"offset\":6062}\n271:{\"start\":\"$272\",\"end\":\"$273\"}\n5e:{\"type\":\"containerDirective\",\"name\":\"tabBoxes\",\"attributes\":\"$5f\",\"children\":\"$60\",\"position\":\"$271\"}\n275:{}\n276:[]\n278:{\"line\":59,\"column\":1,\"offset\":6064}\n279:{\"line\":60,\"column\":4,\"offset\":6088}\n277:{\"start\":\"$278\",\"end\":\"$279\"}\n274:{\"type\":\"containerDirective\",\"name\":\"publicationDate\",\"attributes\":\"$275\",\"ch"])</script><script>self.__next_f.push([1,"ildren\":\"$276\",\"position\":\"$277\"}\n27a:T437,, the inefficiencies stem from not being able to predict many tokens in parallel, leading to worse GPU utilization. Without neuralese, the model can predict all of the sentence “This is an example” at the same time, since it already knows that the input for generating the “is” will be “This”, the input for “an” will be “This is”, etc. However, with the neuralese it’s unknown what the neuralese vector will be to pass through to the next token after “This” has been generated. Therefore each token has to be predicted one at a time. The inability to predict all of the tokens in parallel reduces efficiency in cases where all of the tokens are known in advance. As to why neuralese hasn’t already been added in post-training, we conjecture that the gains are limited with current techniques in part due to post-training being a small portion of the process. We are forecasting that by April 2027 the cost-benefit tradeoff looks much better for neuralese, due to developing better techniques and a larger fraction of the training being post-training.280:{\"line\":680,\"column\":7,\"offset\":99357}\n281:{\"line\":680,\"column\":201,\"offset\":99551}\n27f:{\"start\":\"$280\",\"end\":\"$281\"}\n27e:{\"type\":\"text\",\"value\":\"We disagree somewhat amongst ourselves about AI timelines; our median AGI arrival date is somewhat longer than what this scenario depicts. This scenario depicts something like our mode. See our \",\"position\":\"$27f\"}\n286:{\"line\":680,\"column\":202,\"offset\":99552}\n287:{\"line\":680,\"column\":220,\"offset\":99570}\n285:{\"start\":\"$286\",\"end\":\"$287\"}\n284:{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":\"$285\"}\n283:[\"$284\"]\n289:{\"line\":680,\"column\":201,\"offset\":99551}\n28a:{\"line\":680,\"column\":270,\"offset\":99620}\n288:{\"start\":\"$289\",\"end\":\"$28a\"}\n282:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":\"$283\",\"position\":\"$288\"}\n28d:{\"line\":680,\"column\":270,\"offset\":99620}\n28e:{\"line\":680,\"column\":288,\"offset\":99638}\n28c:{\"start\":\"$28d"])</script><script>self.__next_f.push([1,"\",\"end\":\"$28e\"}\n28b:{\"type\":\"text\",\"value\":\" for more details.\",\"position\":\"$28c\"}\n27d:[\"$27e\",\"$282\",\"$28b\"]\n290:{\"line\":680,\"column\":7,\"offset\":99357}\n291:{\"line\":680,\"column\":288,\"offset\":99638}\n28f:{\"start\":\"$290\",\"end\":\"$291\"}\n27c:{\"type\":\"paragraph\",\"children\":\"$27d\",\"position\":\"$28f\"}\n27b:[\"$27c\"]\n297:{\"line\":682,\"column\":8,\"offset\":99647}\n298:{\"line\":682,\"column\":44,\"offset\":99683}\n296:{\"start\":\"$297\",\"end\":\"$298\"}\n295:{\"type\":\"text\",\"value\":\"One author, Daniel Kokotajlo, did a \",\"position\":\"$296\"}\n29d:{\"line\":682,\"column\":45,\"offset\":99684}\n29e:{\"line\":682,\"column\":83,\"offset\":99722}\n29c:{\"start\":\"$29d\",\"end\":\"$29e\"}\n29b:{\"type\":\"text\",\"value\":\"lower-effort scenario exercise in 2021\",\"position\":\"$29c\"}\n29a:[\"$29b\"]\n2a0:{\"line\":682,\"column\":44,\"offset\":99683}\n2a1:{\"line\":682,\"column\":161,\"offset\":99800}\n29f:{\"start\":\"$2a0\",\"end\":\"$2a1\"}\n299:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.alignmentforum.org/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\",\"children\":\"$29a\",\"position\":\"$29f\"}\n2a4:{\"line\":682,\"column\":161,\"offset\":99800}\n2a5:{\"line\":682,\"column\":340,\"offset\":99979}\n2a3:{\"start\":\"$2a4\",\"end\":\"$2a5\"}\n2a2:{\"type\":\"text\",\"value\":\" that got many things right including the rise of chatbots, chain of thought, inference scaling, sweeping AI chip export controls, and $100 million training runs. Another author, \",\"position\":\"$2a3\"}\n2aa:{\"line\":682,\"column\":341,\"offset\":99980}\n2ab:{\"line\":682,\"column\":352,\"offset\":99991}\n2a9:{\"start\":\"$2aa\",\"end\":\"$2ab\"}\n2a8:{\"type\":\"text\",\"value\":\"Eli Lifland\",\"position\":\"$2a9\"}\n2a7:[\"$2a8\"]\n2ad:{\"line\":682,\"column\":340,\"offset\":99979}\n2ae:{\"line\":682,\"column\":456,\"offset\":100095}\n2ac:{\"start\":\"$2ad\",\"end\":\"$2ae\"}\n2a6:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.vox.com/future-perfect/2024/2/13/24070864/samotsvety-forecasting-superforecasters-tetlock\",\"children\":\"$2a7\",\"position\":\"$2ac\"}\n2b1:{\"line\":682,\"column\":456,\"offset\":100095}\n2b2:{\"line\":682,\"column\":475,\"offset\":100114}\n2b0:{\"start\":\"$2b1\",\"end\":\"$2b2\"}\n2af:{\"type\":\"text\",\"value\":\", ranks #1 on the \",\"position\":"])</script><script>self.__next_f.push([1,"\"$2b0\"}\n2b7:{\"line\":682,\"column\":476,\"offset\":100115}\n2b8:{\"line\":682,\"column\":503,\"offset\":100142}\n2b6:{\"start\":\"$2b7\",\"end\":\"$2b8\"}\n2b5:{\"type\":\"text\",\"value\":\"RAND Forecasting Initiative\",\"position\":\"$2b6\"}\n2b4:[\"$2b5\"]\n2ba:{\"line\":682,\"column\":475,\"offset\":100114}\n2bb:{\"line\":682,\"column\":580,\"offset\":100219}\n2b9:{\"start\":\"$2ba\",\"end\":\"$2bb\"}\n2b3:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/global-and-emerging-risks/forecasting-initiative.html\",\"children\":\"$2b4\",\"position\":\"$2b9\"}\n2be:{\"line\":682,\"column\":580,\"offset\":100219}\n2bf:{\"line\":682,\"column\":593,\"offset\":100232}\n2bd:{\"start\":\"$2be\",\"end\":\"$2bf\"}\n2bc:{\"type\":\"text\",\"value\":\" leaderboard.\",\"position\":\"$2bd\"}\n294:[\"$295\",\"$299\",\"$2a2\",\"$2a6\",\"$2af\",\"$2b3\",\"$2bc\"]\n2c1:{\"line\":682,\"column\":8,\"offset\":99647}\n2c2:{\"line\":682,\"column\":593,\"offset\":100232}\n2c0:{\"start\":\"$2c1\",\"end\":\"$2c2\"}\n293:{\"type\":\"paragraph\",\"children\":\"$294\",\"position\":\"$2c0\"}\n292:[\"$293\"]\n2c8:{\"line\":684,\"column\":7,\"offset\":100240}\n2c9:{\"line\":684,\"column\":367,\"offset\":100600}\n2c7:{\"start\":\"$2c8\",\"end\":\"$2c9\"}\n2c6:{\"type\":\"text\",\"value\":\"Specifically, our medians ranged from 2028 to 2035. When AI 2027 was first published we explained this in Footnote 1 as above, but to make our views more clear we have moved it to the foreword text. We are working on a website to track and explain our all-things-considered views on AI timelines as they update over time; we'll link to it here when it's ready.\",\"position\":\"$2c7\"}\n2c5:[\"$2c6\"]\n2cb:{\"line\":684,\"column\":7,\"offset\":100240}\n2cc:{\"line\":684,\"column\":367,\"offset\":100600}\n2ca:{\"start\":\"$2cb\",\"end\":\"$2cc\"}\n2c4:{\"type\":\"paragraph\",\"children\":\"$2c5\",\"position\":\"$2ca\"}\n2c3:[\"$2c4\"]\n2d2:{\"line\":686,\"column\":8,\"offset\":100609}\n2d3:{\"line\":686,\"column\":199,\"offset\":100800}\n2d1:{\"start\":\"$2d2\",\"end\":\"$2d3\"}\n2d0:{\"type\":\"text\",\"value\":\"Sometimes people mix prediction and recommendation, hoping to create a self-fulfilling-prophecy effect. We emphatically are not doing this; we hope that what we depict does not come to pass!\",\"position\":\"$2d1\"}\n"])</script><script>self.__next_f.push([1,"2cf:[\"$2d0\"]\n2d5:{\"line\":686,\"column\":8,\"offset\":100609}\n2d6:{\"line\":686,\"column\":199,\"offset\":100800}\n2d4:{\"start\":\"$2d5\",\"end\":\"$2d6\"}\n2ce:{\"type\":\"paragraph\",\"children\":\"$2cf\",\"position\":\"$2d4\"}\n2cd:[\"$2ce\"]\n2dc:{\"line\":688,\"column\":8,\"offset\":100809}\n2dd:{\"line\":688,\"column\":21,\"offset\":100822}\n2db:{\"start\":\"$2dc\",\"end\":\"$2dd\"}\n2da:{\"type\":\"text\",\"value\":\"Feel free to \",\"position\":\"$2db\"}\n2e2:{\"line\":688,\"column\":22,\"offset\":100823}\n2e3:{\"line\":688,\"column\":32,\"offset\":100833}\n2e1:{\"start\":\"$2e2\",\"end\":\"$2e3\"}\n2e0:{\"type\":\"text\",\"value\":\"contact us\",\"position\":\"$2e1\"}\n2df:[\"$2e0\"]\n2e5:{\"line\":688,\"column\":21,\"offset\":100822}\n2e6:{\"line\":688,\"column\":68,\"offset\":100869}\n2e4:{\"start\":\"$2e5\",\"end\":\"$2e6\"}\n2de:{\"type\":\"link\",\"title\":null,\"url\":\"http://mailto@info@ai-futures.org\",\"children\":\"$2df\",\"position\":\"$2e4\"}\n2e9:{\"line\":688,\"column\":68,\"offset\":100869}\n2ea:{\"line\":688,\"column\":125,\"offset\":100926}\n2e8:{\"start\":\"$2e9\",\"end\":\"$2ea\"}\n2e7:{\"type\":\"text\",\"value\":\" if you’re writing a critique or an alternative scenario.\",\"position\":\"$2e8\"}\n2d9:[\"$2da\",\"$2de\",\"$2e7\"]\n2ec:{\"line\":688,\"column\":8,\"offset\":100809}\n2ed:{\"line\":688,\"column\":125,\"offset\":100926}\n2eb:{\"start\":\"$2ec\",\"end\":\"$2ed\"}\n2d8:{\"type\":\"paragraph\",\"children\":\"$2d9\",\"position\":\"$2eb\"}\n2d7:[\"$2d8\"]\n2f3:{\"line\":690,\"column\":8,\"offset\":100935}\n2f4:{\"line\":690,\"column\":169,\"offset\":101096}\n2f2:{\"start\":\"$2f3\",\"end\":\"$2f4\"}\n2f1:{\"type\":\"text\",\"value\":\"It was overall more difficult, because unlike with the first ending, we were trying to get it to reach a good outcome starting from a rather difficult situation.\",\"position\":\"$2f2\"}\n2f0:[\"$2f1\"]\n2f6:{\"line\":690,\"column\":8,\"offset\":100935}\n2f7:{\"line\":690,\"column\":169,\"offset\":101096}\n2f5:{\"start\":\"$2f6\",\"end\":\"$2f7\"}\n2ef:{\"type\":\"paragraph\",\"children\":\"$2f0\",\"position\":\"$2f5\"}\n2ee:[\"$2ef\"]\n2fd:{\"line\":692,\"column\":8,\"offset\":101105}\n2fe:{\"line\":692,\"column\":129,\"offset\":101226}\n2fc:{\"start\":\"$2fd\",\"end\":\"$2fe\"}\n2fb:{\"type\":\"text\",\"value\":\"Full Professor, Université de Montréal and Founder and Scientifi"])</script><script>self.__next_f.push([1,"c Advisor, Mila - Quebec AI Institute. Also the world’s \",\"position\":\"$2fc\"}\n303:{\"line\":692,\"column\":130,\"offset\":101227}\n304:{\"line\":692,\"column\":159,\"offset\":101256}\n302:{\"start\":\"$303\",\"end\":\"$304\"}\n301:{\"type\":\"text\",\"value\":\"most-cited computer scientist\",\"position\":\"$302\"}\n300:[\"$301\"]\n306:{\"line\":692,\"column\":129,\"offset\":101226}\n307:{\"line\":692,\"column\":205,\"offset\":101302}\n305:{\"start\":\"$306\",\"end\":\"$307\"}\n2ff:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Yoshua_Bengio\",\"children\":\"$300\",\"position\":\"$305\"}\n30a:{\"line\":692,\"column\":205,\"offset\":101302}\n30b:{\"line\":692,\"column\":206,\"offset\":101303}\n309:{\"start\":\"$30a\",\"end\":\"$30b\"}\n308:{\"type\":\"text\",\"value\":\".\",\"position\":\"$309\"}\n2fa:[\"$2fb\",\"$2ff\",\"$308\"]\n30d:{\"line\":692,\"column\":8,\"offset\":101105}\n30e:{\"line\":692,\"column\":206,\"offset\":101303}\n30c:{\"start\":\"$30d\",\"end\":\"$30e\"}\n2f9:{\"type\":\"paragraph\",\"children\":\"$2fa\",\"position\":\"$30c\"}\n2f8:[\"$2f9\"]\n314:{\"line\":694,\"column\":8,\"offset\":101312}\n315:{\"line\":694,\"column\":216,\"offset\":101520}\n313:{\"start\":\"$314\",\"end\":\"$315\"}\n312:{\"type\":\"text\",\"value\":\"At first, most people are reluctant to allow purchases without oversight. Over the next few years, automatically allowing small purchases becomes normalized as the AIs become more reliable and build up trust.\",\"position\":\"$313\"}\n311:[\"$312\"]\n317:{\"line\":694,\"column\":8,\"offset\":101312}\n318:{\"line\":694,\"column\":216,\"offset\":101520}\n316:{\"start\":\"$317\",\"end\":\"$318\"}\n310:{\"type\":\"paragraph\",\"children\":\"$311\",\"position\":\"$316\"}\n30f:[\"$310\"]\n31e:{\"line\":696,\"column\":8,\"offset\":101529}\n31f:{\"line\":696,\"column\":181,\"offset\":101702}\n31d:{\"start\":\"$31e\",\"end\":\"$31f\"}\n31c:{\"type\":\"text\",\"value\":\"Specifically, we forecast that they score 65% on the OSWorld benchmark of basic computer tasks (compared to 38% for Operator and 70% for a typical skilled non-expert human).\",\"position\":\"$31d\"}\n31b:[\"$31c\"]\n321:{\"line\":696,\"column\":8,\"offset\":101529}\n322:{\"line\":696,\"column\":181,\"offset\":101702}\n320:{\"start\":\"$321\",\"end\":\"$322\"}\n31a:{\"type\":\"paragraph\",\"chil"])</script><script>self.__next_f.push([1,"dren\":\"$31b\",\"position\":\"$320\"}\n319:[\"$31a\"]\n328:{\"line\":698,\"column\":9,\"offset\":101712}\n329:{\"line\":698,\"column\":80,\"offset\":101783}\n327:{\"start\":\"$328\",\"end\":\"$329\"}\n326:{\"type\":\"text\",\"value\":\"For example, we think coding agents will move towards functioning like \",\"position\":\"$327\"}\n32e:{\"line\":698,\"column\":81,\"offset\":101784}\n32f:{\"line\":698,\"column\":86,\"offset\":101789}\n32d:{\"start\":\"$32e\",\"end\":\"$32f\"}\n32c:{\"type\":\"text\",\"value\":\"Devin\",\"position\":\"$32d\"}\n32b:[\"$32c\"]\n331:{\"line\":698,\"column\":80,\"offset\":101783}\n332:{\"line\":698,\"column\":106,\"offset\":101809}\n330:{\"start\":\"$331\",\"end\":\"$332\"}\n32a:{\"type\":\"link\",\"title\":null,\"url\":\"https://devin.ai/\",\"children\":\"$32b\",\"position\":\"$330\"}\n335:{\"line\":698,\"column\":106,\"offset\":101809}\n336:{\"line\":698,\"column\":159,\"offset\":101862}\n334:{\"start\":\"$335\",\"end\":\"$336\"}\n333:{\"type\":\"text\",\"value\":\". We forecast that mid-2025 agents will score 85% on \",\"position\":\"$334\"}\n33b:{\"line\":698,\"column\":160,\"offset\":101863}\n33c:{\"line\":698,\"column\":177,\"offset\":101880}\n33a:{\"start\":\"$33b\",\"end\":\"$33c\"}\n339:{\"type\":\"text\",\"value\":\"SWEBench-Verified\",\"position\":\"$33a\"}\n338:[\"$339\"]\n33e:{\"line\":698,\"column\":159,\"offset\":101862}\n33f:{\"line\":698,\"column\":214,\"offset\":101917}\n33d:{\"start\":\"$33e\",\"end\":\"$33f\"}\n337:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.swebench.com/#verified\",\"children\":\"$338\",\"position\":\"$33d\"}\n342:{\"line\":698,\"column\":214,\"offset\":101917}\n343:{\"line\":698,\"column\":215,\"offset\":101918}\n341:{\"start\":\"$342\",\"end\":\"$343\"}\n340:{\"type\":\"text\",\"value\":\".\",\"position\":\"$341\"}\n325:[\"$326\",\"$32a\",\"$333\",\"$337\",\"$340\"]\n345:{\"line\":698,\"column\":9,\"offset\":101712}\n346:{\"line\":698,\"column\":215,\"offset\":101918}\n344:{\"start\":\"$345\",\"end\":\"$346\"}\n324:{\"type\":\"paragraph\",\"children\":\"$325\",\"position\":\"$344\"}\n323:[\"$324\"]\n34c:{\"line\":700,\"column\":9,\"offset\":101928}\n34d:{\"line\":700,\"column\":22,\"offset\":101941}\n34b:{\"start\":\"$34c\",\"end\":\"$34d\"}\n34a:{\"type\":\"text\",\"value\":\"For example, \",\"position\":\"$34b\"}\n352:{\"line\":700,\"column\":23,\"offset\":101942}\n353:{\"line\":700,\"column\":40,\"offs"])</script><script>self.__next_f.push([1,"et\":101959}\n351:{\"start\":\"$352\",\"end\":\"$353\"}\n350:{\"type\":\"text\",\"value\":\"OpenAI’s pro plan\",\"position\":\"$351\"}\n34f:[\"$350\"]\n355:{\"line\":700,\"column\":22,\"offset\":101941}\n356:{\"line\":700,\"column\":78,\"offset\":101997}\n354:{\"start\":\"$355\",\"end\":\"$356\"}\n34e:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/chatgpt/pricing/\",\"children\":\"$34f\",\"position\":\"$354\"}\n359:{\"line\":700,\"column\":78,\"offset\":101997}\n35a:{\"line\":700,\"column\":132,\"offset\":102051}\n358:{\"start\":\"$359\",\"end\":\"$35a\"}\n357:{\"type\":\"text\",\"value\":\" currently costs $200/month and the agentic coding AI \",\"position\":\"$358\"}\n35f:{\"line\":700,\"column\":133,\"offset\":102052}\n360:{\"line\":700,\"column\":138,\"offset\":102057}\n35e:{\"start\":\"$35f\",\"end\":\"$360\"}\n35d:{\"type\":\"text\",\"value\":\"Devin\",\"position\":\"$35e\"}\n35c:[\"$35d\"]\n362:{\"line\":700,\"column\":132,\"offset\":102051}\n363:{\"line\":700,\"column\":165,\"offset\":102084}\n361:{\"start\":\"$362\",\"end\":\"$363\"}\n35b:{\"type\":\"link\",\"title\":null,\"url\":\"https://devin.ai/pricing\",\"children\":\"$35c\",\"position\":\"$361\"}\n366:{\"line\":700,\"column\":165,\"offset\":102084}\n367:{\"line\":700,\"column\":432,\"offset\":102351}\n365:{\"start\":\"$366\",\"end\":\"$367\"}\n364:{\"type\":\"text\",\"value\":\" currently costs $500/month. While the cutting-edge systems continue to get more expensive over time, the cost to customers of reaching a given capabilities level continues to plummet. For existing capabilities, this happens at an average rate of about 50x/year (per \",\"position\":\"$365\"}\n36c:{\"line\":700,\"column\":433,\"offset\":102352}\n36d:{\"line\":700,\"column\":438,\"offset\":102357}\n36b:{\"start\":\"$36c\",\"end\":\"$36d\"}\n36a:{\"type\":\"text\",\"value\":\"Epoch\",\"position\":\"$36b\"}\n369:[\"$36a\"]\n36f:{\"line\":700,\"column\":432,\"offset\":102351}\n370:{\"line\":700,\"column\":498,\"offset\":102417}\n36e:{\"start\":\"$36f\",\"end\":\"$370\"}\n368:{\"type\":\"link\",\"title\":null,\"url\":\"https://epoch.ai/data-insights/llm-inference-price-trends\",\"children\":\"$369\",\"position\":\"$36e\"}\n373:{\"line\":700,\"column\":498,\"offset\":102417}\n374:{\"line\":700,\"column\":500,\"offset\":102419}\n372:{\"start\":\"$373\",\"end\":\"$374\"}\n371:{\"type\":\""])</script><script>self.__next_f.push([1,"text\",\"value\":\").\",\"position\":\"$372\"}\n349:[\"$34a\",\"$34e\",\"$357\",\"$35b\",\"$364\",\"$368\",\"$371\"]\n376:{\"line\":700,\"column\":9,\"offset\":101928}\n377:{\"line\":700,\"column\":500,\"offset\":102419}\n375:{\"start\":\"$376\",\"end\":\"$377\"}\n348:{\"type\":\"paragraph\",\"children\":\"$349\",\"position\":\"$375\"}\n347:[\"$348\"]\n37d:{\"line\":702,\"column\":9,\"offset\":102429}\n37e:{\"line\":702,\"column\":31,\"offset\":102451}\n37c:{\"start\":\"$37d\",\"end\":\"$37e\"}\n37b:{\"type\":\"text\",\"value\":\"Enterprise tools like \",\"position\":\"$37c\"}\n383:{\"line\":702,\"column\":32,\"offset\":102452}\n384:{\"line\":702,\"column\":37,\"offset\":102457}\n382:{\"start\":\"$383\",\"end\":\"$384\"}\n381:{\"type\":\"text\",\"value\":\"Glean\",\"position\":\"$382\"}\n380:[\"$381\"]\n386:{\"line\":702,\"column\":31,\"offset\":102451}\n387:{\"line\":702,\"column\":62,\"offset\":102482}\n385:{\"start\":\"$386\",\"end\":\"$387\"}\n37f:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.glean.com/\",\"children\":\"$380\",\"position\":\"$385\"}\n38a:{\"line\":702,\"column\":62,\"offset\":102482}\n38b:{\"line\":702,\"column\":124,\"offset\":102544}\n389:{\"start\":\"$38a\",\"end\":\"$38b\"}\n388:{\"type\":\"text\",\"value\":\" also move toward providing increasingly autonomous AI agents.\",\"position\":\"$389\"}\n37a:[\"$37b\",\"$37f\",\"$388\"]\n38d:{\"line\":702,\"column\":9,\"offset\":102429}\n38e:{\"line\":702,\"column\":124,\"offset\":102544}\n38c:{\"start\":\"$38d\",\"end\":\"$38e\"}\n379:{\"type\":\"paragraph\",\"children\":\"$37a\",\"position\":\"$38c\"}\n378:[\"$379\"]\n394:{\"line\":704,\"column\":9,\"offset\":102554}\n395:{\"line\":704,\"column\":742,\"offset\":103287}\n393:{\"start\":\"$394\",\"end\":\"$395\"}\n392:{\"type\":\"text\",\"value\":\"This cluster is a network of datacenter campuses sprawled across the country, totalling 2.5M 2024-GPU-equivalents (H100s), with $100B spent so far and 2 GW of power draw online. Construction is underway for this to at least double through 2026. The campuses are connected by billions worth of fibre cabling, so that (barring the speed of light latency of a few milliseconds) it lets these campuses function almost as if they were right next door to each other (i.e. bandwidth is not a bottleneck, meaning huge quantities of data can be"])</script><script>self.__next_f.push([1," sent at the same time). From a security perspective this introduces some threat surface (it’s unclear whether the cables and especially their junction points are fully secured from eavesdroppers).\",\"position\":\"$393\"}\n391:[\"$392\"]\n397:{\"line\":704,\"column\":9,\"offset\":102554}\n398:{\"line\":704,\"column\":742,\"offset\":103287}\n396:{\"start\":\"$397\",\"end\":\"$398\"}\n390:{\"type\":\"paragraph\",\"children\":\"$391\",\"position\":\"$396\"}\n38f:[\"$390\"]\n39e:{\"line\":706,\"column\":9,\"offset\":103297}\n39f:{\"line\":706,\"column\":32,\"offset\":103320}\n39d:{\"start\":\"$39e\",\"end\":\"$39f\"}\n39c:{\"type\":\"text\",\"value\":\"Compute is measured in \",\"position\":\"$39d\"}\n3a4:{\"line\":706,\"column\":33,\"offset\":103321}\n3a5:{\"line\":706,\"column\":65,\"offset\":103353}\n3a3:{\"start\":\"$3a4\",\"end\":\"$3a5\"}\n3a2:{\"type\":\"text\",\"value\":\"floating point operations (FLOP)\",\"position\":\"$3a3\"}\n3a1:[\"$3a2\"]\n3a7:{\"line\":706,\"column\":32,\"offset\":103320}\n3a8:{\"line\":706,\"column\":134,\"offset\":103422}\n3a6:{\"start\":\"$3a7\",\"end\":\"$3a8\"}\n3a0:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Floating_point_operations_per_second\",\"children\":\"$3a1\",\"position\":\"$3a6\"}\n3ab:{\"line\":706,\"column\":134,\"offset\":103422}\n3ac:{\"line\":706,\"column\":238,\"offset\":103526}\n3aa:{\"start\":\"$3ab\",\"end\":\"$3ac\"}\n3a9:{\"type\":\"text\",\"value\":\": how many individual addition and multiplication operations occur over the course of running a program.\",\"position\":\"$3aa\"}\n39b:[\"$39c\",\"$3a0\",\"$3a9\"]\n3ae:{\"line\":706,\"column\":9,\"offset\":103297}\n3af:{\"line\":706,\"column\":238,\"offset\":103526}\n3ad:{\"start\":\"$3ae\",\"end\":\"$3af\"}\n39a:{\"type\":\"paragraph\",\"children\":\"$39b\",\"position\":\"$3ad\"}\n399:[\"$39a\"]\n3b5:{\"line\":708,\"column\":9,\"offset\":103536}\n3b6:{\"line\":708,\"column\":61,\"offset\":103588}\n3b4:{\"start\":\"$3b5\",\"end\":\"$3b6\"}\n3b3:{\"type\":\"text\",\"value\":\"They could train this model given 150 days. See our \",\"position\":\"$3b4\"}\n3bb:{\"line\":708,\"column\":62,\"offset\":103589}\n3bc:{\"line\":708,\"column\":80,\"offset\":103607}\n3ba:{\"start\":\"$3bb\",\"end\":\"$3bc\"}\n3b9:{\"type\":\"text\",\"value\":\"compute supplement\",\"position\":\"$3ba\"}\n3b8:[\"$3b9\"]\n3be"])</script><script>self.__next_f.push([1,":{\"line\":708,\"column\":61,\"offset\":103588}\n3bf:{\"line\":708,\"column\":131,\"offset\":103658}\n3bd:{\"start\":\"$3be\",\"end\":\"$3bf\"}\n3b7:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast\",\"children\":\"$3b8\",\"position\":\"$3bd\"}\n3c2:{\"line\":708,\"column\":131,\"offset\":103658}\n3c3:{\"line\":708,\"column\":149,\"offset\":103676}\n3c1:{\"start\":\"$3c2\",\"end\":\"$3c3\"}\n3c0:{\"type\":\"text\",\"value\":\" for more details.\",\"position\":\"$3c1\"}\n3b2:[\"$3b3\",\"$3b7\",\"$3c0\"]\n3c5:{\"line\":708,\"column\":9,\"offset\":103536}\n3c6:{\"line\":708,\"column\":150,\"offset\":103677}\n3c4:{\"start\":\"$3c5\",\"end\":\"$3c6\"}\n3b1:{\"type\":\"paragraph\",\"children\":\"$3b2\",\"position\":\"$3c4\"}\n3b0:[\"$3b1\"]\n3cc:{\"line\":710,\"column\":9,\"offset\":103687}\n3cd:{\"line\":710,\"column\":184,\"offset\":103862}\n3cb:{\"start\":\"$3cc\",\"end\":\"$3cd\"}\n3ca:{\"type\":\"text\",\"value\":\"We consider DeepSeek, Tencent, Alibaba, and others to have strong AGI projects in China. To avoid singling out a specific one, our scenario will follow a fictional “DeepCent.”\",\"position\":\"$3cb\"}\n3c9:[\"$3ca\"]\n3cf:{\"line\":710,\"column\":9,\"offset\":103687}\n3d0:{\"line\":710,\"column\":184,\"offset\":103862}\n3ce:{\"start\":\"$3cf\",\"end\":\"$3d0\"}\n3c8:{\"type\":\"paragraph\",\"children\":\"$3c9\",\"position\":\"$3ce\"}\n3c7:[\"$3c8\"]\n3d6:{\"line\":712,\"column\":9,\"offset\":103872}\n3d7:{\"line\":712,\"column\":254,\"offset\":104117}\n3d5:{\"start\":\"$3d6\",\"end\":\"$3d7\"}\n3d4:{\"type\":\"text\",\"value\":\"It’s good at this due to a combination of explicit focus to prioritize these skills, their own extensive codebases they can draw on as particularly relevant and high-quality training data, and coding being an easy domain for procedural feedback.\",\"position\":\"$3d5\"}\n3d3:[\"$3d4\"]\n3d9:{\"line\":712,\"column\":9,\"offset\":103872}\n3da:{\"line\":712,\"column\":254,\"offset\":104117}\n3d8:{\"start\":\"$3d9\",\"end\":\"$3da\"}\n3d2:{\"type\":\"paragraph\",\"children\":\"$3d3\",\"position\":\"$3d8\"}\n3d1:[\"$3d2\"]\n3e0:{\"line\":714,\"column\":9,\"offset\":104127}\n3e1:{\"line\":714,\"column\":334,\"offset\":104452}\n3df:{\"start\":\"$3e0\",\"end\":\"$3e1\"}\n3de:{\"type\":\"text\",\"value\":\"For example, suppose a model is much"])</script><script>self.__next_f.push([1," better at Python than obscure programming languages. When OpenBrain sees value in it, they generate synthetic training data in those languages as well. Another example: to help it integrate more effectively into company workflows, OpenBrain develops a curriculum to train it to use Slack.\",\"position\":\"$3df\"}\n3dd:[\"$3de\"]\n3e3:{\"line\":714,\"column\":9,\"offset\":104127}\n3e4:{\"line\":714,\"column\":334,\"offset\":104452}\n3e2:{\"start\":\"$3e3\",\"end\":\"$3e4\"}\n3dc:{\"type\":\"paragraph\",\"children\":\"$3dd\",\"position\":\"$3e2\"}\n3db:[\"$3dc\"]\n3ea:{\"line\":716,\"column\":9,\"offset\":104462}\n3eb:{\"line\":716,\"column\":171,\"offset\":104624}\n3e9:{\"start\":\"$3ea\",\"end\":\"$3eb\"}\n3e8:{\"type\":\"text\",\"value\":\"People often get hung up on whether these AIs are sentient, or whether they have “true understanding.” Geoffrey Hinton, Nobel prize winning founder of the field, \",\"position\":\"$3e9\"}\n3f0:{\"line\":716,\"column\":172,\"offset\":104625}\n3f1:{\"line\":716,\"column\":186,\"offset\":104639}\n3ef:{\"start\":\"$3f0\",\"end\":\"$3f1\"}\n3ee:{\"type\":\"text\",\"value\":\"thinks they do\",\"position\":\"$3ef\"}\n3ed:[\"$3ee\"]\n3f3:{\"line\":716,\"column\":171,\"offset\":104624}\n3f4:{\"line\":716,\"column\":352,\"offset\":104805}\n3f2:{\"start\":\"$3f3\",\"end\":\"$3f4\"}\n3ec:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.pbs.org/wnet/amanpour-and-company/video/geoffrey-hinton-warns-of-the-existential-threat-of-ai/#:~:text=I%20am%20very%20confident%20that%20they%20think.\",\"children\":\"$3ed\",\"position\":\"$3f2\"}\n3f7:{\"line\":716,\"column\":352,\"offset\":104805}\n3f8:{\"line\":716,\"column\":572,\"offset\":105025}\n3f6:{\"start\":\"$3f7\",\"end\":\"$3f8\"}\n3f5:{\"type\":\"text\",\"value\":\". However, we don’t think it matters for the purposes of our story, so feel free to pretend we said “behaves as if it understands…” whenever we say “understands,” and so forth. Empirically, large language models already \",\"position\":\"$3f6\"}\n3fd:{\"line\":716,\"column\":573,\"offset\":105026}\n3fe:{\"line\":716,\"column\":605,\"offset\":105058}\n3fc:{\"start\":\"$3fd\",\"end\":\"$3fe\"}\n3fb:{\"type\":\"text\",\"value\":\"behave as if they are self-aware\",\"position\":\"$3fc\"}\n3fa:["])</script><script>self.__next_f.push([1,"\"$3fb\"]\n400:{\"line\":716,\"column\":572,\"offset\":105025}\n401:{\"line\":716,\"column\":646,\"offset\":105099}\n3ff:{\"start\":\"$400\",\"end\":\"$401\"}\n3f9:{\"type\":\"link\",\"title\":null,\"url\":\"https://theaidigest.org/self-awareness\",\"children\":\"$3fa\",\"position\":\"$3ff\"}\n404:{\"line\":716,\"column\":646,\"offset\":105099}\n405:{\"line\":716,\"column\":691,\"offset\":105144}\n403:{\"start\":\"$404\",\"end\":\"$405\"}\n402:{\"type\":\"text\",\"value\":\" to some extent, more and more so every year.\",\"position\":\"$403\"}\n3e7:[\"$3e8\",\"$3ec\",\"$3f5\",\"$3f9\",\"$402\"]\n407:{\"line\":716,\"column\":9,\"offset\":104462}\n408:{\"line\":716,\"column\":691,\"offset\":105144}\n406:{\"start\":\"$407\",\"end\":\"$408\"}\n3e6:{\"type\":\"paragraph\",\"children\":\"$3e7\",\"position\":\"$406\"}\n3e5:[\"$3e6\"]\n40e:{\"line\":718,\"column\":9,\"offset\":105154}\n40f:{\"line\":718,\"column\":485,\"offset\":105630}\n40d:{\"start\":\"$40e\",\"end\":\"$40f\"}\n40c:{\"type\":\"text\",\"value\":\"A common technique “bakes in” a persona: first, prompt the pretrained model with something like “The following is a conversation between a human user and a helpful, honest, and harmless AI chatbot produced by Anthropic. The chatbot has the following traits…” Use this prompt to generate a bunch of data. Then, train on the data but without the prompt. The result is an AI that always acts as if it had that prompt in front of it, regardless of what else you feed it. See also \",\"position\":\"$40d\"}\n414:{\"line\":718,\"column\":486,\"offset\":105631}\n415:{\"line\":718,\"column\":496,\"offset\":105641}\n413:{\"start\":\"$414\",\"end\":\"$415\"}\n412:{\"type\":\"text\",\"value\":\"this paper\",\"position\":\"$413\"}\n411:[\"$412\"]\n417:{\"line\":718,\"column\":485,\"offset\":105630}\n418:{\"line\":718,\"column\":553,\"offset\":105698}\n416:{\"start\":\"$417\",\"end\":\"$418\"}\n410:{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/OwainEvans_UK/status/1881767725430976642\",\"children\":\"$411\",\"position\":\"$416\"}\n41b:{\"line\":718,\"column\":553,\"offset\":105698}\n41c:{\"line\":718,\"column\":575,\"offset\":105720}\n41a:{\"start\":\"$41b\",\"end\":\"$41c\"}\n419:{\"type\":\"text\",\"value\":\" which found that AIs \",\"position\":\"$41a\"}\n421:{\"line\":718,\"column\":57"])</script><script>self.__next_f.push([1,"6,\"offset\":105721}\n422:{\"line\":718,\"column\":585,\"offset\":105730}\n420:{\"start\":\"$421\",\"end\":\"$422\"}\n41f:{\"type\":\"text\",\"value\":\"retrained\",\"position\":\"$420\"}\n41e:[\"$41f\"]\n424:{\"line\":718,\"column\":575,\"offset\":105720}\n425:{\"line\":718,\"column\":586,\"offset\":105731}\n423:{\"start\":\"$424\",\"end\":\"$425\"}\n41d:{\"type\":\"emphasis\",\"children\":\"$41e\",\"position\":\"$423\"}\n428:{\"line\":718,\"column\":586,\"offset\":105731}\n429:{\"line\":718,\"column\":863,\"offset\":106008}\n427:{\"start\":\"$428\",\"end\":\"$429\"}\n426:{\"type\":\"text\",\"value\":\" to exhibit a certain personality trait are able to correctly answer questions about that new trait, despite no training to do so, suggesting that they have internal representations of their own traits and that when their traits change their representations change accordingly.\",\"position\":\"$427\"}\n40b:[\"$40c\",\"$410\",\"$419\",\"$41d\",\"$426\"]\n42b:{\"line\":718,\"column\":9,\"offset\":105154}\n42c:{\"line\":718,\"column\":863,\"offset\":106008}\n42a:{\"start\":\"$42b\",\"end\":\"$42c\"}\n40a:{\"type\":\"paragraph\",\"children\":\"$40b\",\"position\":\"$42a\"}\n409:[\"$40a\"]\n432:{\"line\":720,\"column\":9,\"offset\":106018}\n433:{\"line\":720,\"column\":518,\"offset\":106527}\n431:{\"start\":\"$432\",\"end\":\"$433\"}\n430:{\"type\":\"text\",\"value\":\"These paragraphs include speculation about the internal workings of large artificial neural networks. Such networks are sufficiently complicated that we can't actually look inside and say “ah yes, now it's evolved from reflexes into having goals” or “OK so there’s the list of drives it has.” Instead, we basically have to do psychology, looking how it behaves in various settings and running various experiments on it and trying to piece together the clues. And it’s all terribly controversial and confusing.\",\"position\":\"$431\"}\n42f:[\"$430\"]\n435:{\"line\":720,\"column\":9,\"offset\":106018}\n436:{\"line\":720,\"column\":518,\"offset\":106527}\n434:{\"start\":\"$435\",\"end\":\"$436\"}\n42e:{\"type\":\"paragraph\",\"children\":\"$42f\",\"position\":\"$434\"}\n42d:[\"$42e\"]\n43c:{\"line\":722,\"column\":9,\"offset\":106537}\n43d:{\"line\":722,\"column\":108,\"offset\":106636}\n43b:{\""])</script><script>self.__next_f.push([1,"start\":\"$43c\",\"end\":\"$43d\"}\n43a:{\"type\":\"text\",\"value\":\"Different companies call it different things. OpenAI calls it the Spec, but Anthropic calls it the \",\"position\":\"$43b\"}\n442:{\"line\":722,\"column\":109,\"offset\":106637}\n443:{\"line\":722,\"column\":121,\"offset\":106649}\n441:{\"start\":\"$442\",\"end\":\"$443\"}\n440:{\"type\":\"text\",\"value\":\"Constitution\",\"position\":\"$441\"}\n43f:[\"$440\"]\n445:{\"line\":722,\"column\":108,\"offset\":106636}\n446:{\"line\":722,\"column\":175,\"offset\":106703}\n444:{\"start\":\"$445\",\"end\":\"$446\"}\n43e:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/news/claudes-constitution\",\"children\":\"$43f\",\"position\":\"$444\"}\n449:{\"line\":722,\"column\":175,\"offset\":106703}\n44a:{\"line\":722,\"column\":176,\"offset\":106704}\n448:{\"start\":\"$449\",\"end\":\"$44a\"}\n447:{\"type\":\"text\",\"value\":\".\",\"position\":\"$448\"}\n439:[\"$43a\",\"$43e\",\"$447\"]\n44c:{\"line\":722,\"column\":9,\"offset\":106537}\n44d:{\"line\":722,\"column\":176,\"offset\":106704}\n44b:{\"start\":\"$44c\",\"end\":\"$44d\"}\n438:{\"type\":\"paragraph\",\"children\":\"$439\",\"position\":\"$44b\"}\n437:[\"$438\"]\n453:{\"line\":724,\"column\":9,\"offset\":106714}\n454:{\"line\":724,\"column\":22,\"offset\":106727}\n452:{\"start\":\"$453\",\"end\":\"$454\"}\n451:{\"type\":\"text\",\"value\":\"For example, \",\"position\":\"$452\"}\n459:{\"line\":724,\"column\":23,\"offset\":106728}\n45a:{\"line\":724,\"column\":28,\"offset\":106733}\n458:{\"start\":\"$459\",\"end\":\"$45a\"}\n457:{\"type\":\"text\",\"value\":\"RLAIF\",\"position\":\"$458\"}\n456:[\"$457\"]\n45c:{\"line\":724,\"column\":22,\"offset\":106727}\n45d:{\"line\":724,\"column\":63,\"offset\":106768}\n45b:{\"start\":\"$45c\",\"end\":\"$45d\"}\n455:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2212.08073\",\"children\":\"$456\",\"position\":\"$45b\"}\n460:{\"line\":724,\"column\":63,\"offset\":106768}\n461:{\"line\":724,\"column\":68,\"offset\":106773}\n45f:{\"start\":\"$460\",\"end\":\"$461\"}\n45e:{\"type\":\"text\",\"value\":\" and \",\"position\":\"$45f\"}\n466:{\"line\":724,\"column\":69,\"offset\":106774}\n467:{\"line\":724,\"column\":91,\"offset\":106796}\n465:{\"start\":\"$466\",\"end\":\"$467\"}\n464:{\"type\":\"text\",\"value\":\"deliberative alignment\",\"position\":\"$465\"}\n463:[\"$464\"]\n469:{\"line\":724,\"col"])</script><script>self.__next_f.push([1,"umn\":68,\"offset\":106773}\n46a:{\"line\":724,\"column\":142,\"offset\":106847}\n468:{\"start\":\"$469\",\"end\":\"$46a\"}\n462:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/deliberative-alignment/\",\"children\":\"$463\",\"position\":\"$468\"}\n46d:{\"line\":724,\"column\":142,\"offset\":106847}\n46e:{\"line\":724,\"column\":143,\"offset\":106848}\n46c:{\"start\":\"$46d\",\"end\":\"$46e\"}\n46b:{\"type\":\"text\",\"value\":\".\",\"position\":\"$46c\"}\n450:[\"$451\",\"$455\",\"$45e\",\"$462\",\"$46b\"]\n470:{\"line\":724,\"column\":9,\"offset\":106714}\n471:{\"line\":724,\"column\":143,\"offset\":106848}\n46f:{\"start\":\"$470\",\"end\":\"$471\"}\n44f:{\"type\":\"paragraph\",\"children\":\"$450\",\"position\":\"$46f\"}\n44e:[\"$44f\"]\n477:{\"line\":726,\"column\":9,\"offset\":106858}\n478:{\"line\":726,\"column\":14,\"offset\":106863}\n476:{\"start\":\"$477\",\"end\":\"$478\"}\n475:{\"type\":\"text\",\"value\":\"Most \",\"position\":\"$476\"}\n47d:{\"line\":726,\"column\":15,\"offset\":106864}\n47e:{\"line\":726,\"column\":45,\"offset\":106894}\n47c:{\"start\":\"$47d\",\"end\":\"$47e\"}\n47b:{\"type\":\"text\",\"value\":\"sources on AI “hallucinations”\",\"position\":\"$47c\"}\n47a:[\"$47b\"]\n480:{\"line\":726,\"column\":14,\"offset\":106863}\n481:{\"line\":726,\"column\":98,\"offset\":106947}\n47f:{\"start\":\"$480\",\"end\":\"$481\"}\n479:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.ibm.com/think/topics/ai-hallucinations\",\"children\":\"$47a\",\"position\":\"$47f\"}\n484:{\"line\":726,\"column\":98,\"offset\":106947}\n485:{\"line\":726,\"column\":144,\"offset\":106993}\n483:{\"start\":\"$484\",\"end\":\"$485\"}\n482:{\"type\":\"text\",\"value\":\" describe them as unintentional mistakes, but \",\"position\":\"$483\"}\n48a:{\"line\":726,\"column\":145,\"offset\":106994}\n48b:{\"line\":726,\"column\":175,\"offset\":107024}\n489:{\"start\":\"$48a\",\"end\":\"$48b\"}\n488:{\"type\":\"text\",\"value\":\"research with steering vectors\",\"position\":\"$489\"}\n487:[\"$488\"]\n48d:{\"line\":726,\"column\":144,\"offset\":106993}\n48e:{\"line\":726,\"column\":210,\"offset\":107059}\n48c:{\"start\":\"$48d\",\"end\":\"$48e\"}\n486:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2310.01405\",\"children\":\"$487\",\"position\":\"$48c\"}\n491:{\"line\":726,\"column\":210,\"offset\":107059}\n492:{\"line\":726,\"column\":516,\"off"])</script><script>self.__next_f.push([1,"set\":107365}\n490:{\"start\":\"$491\",\"end\":\"$492\"}\n48f:{\"type\":\"text\",\"value\":\" finds that in some cases the models know their citations are fake—they are lying. During training, raters gave well-cited claims more reward than claims without citations, so the AI “learned” to cite sources for scholarly claims in order to please its users. If no relevant source exists, it makes one up.\",\"position\":\"$490\"}\n474:[\"$475\",\"$479\",\"$482\",\"$486\",\"$48f\"]\n494:{\"line\":726,\"column\":9,\"offset\":106858}\n495:{\"line\":726,\"column\":516,\"offset\":107365}\n493:{\"start\":\"$494\",\"end\":\"$495\"}\n473:{\"type\":\"paragraph\",\"children\":\"$474\",\"position\":\"$493\"}\n472:[\"$473\"]\n49b:{\"line\":728,\"column\":9,\"offset\":107375}\n49c:{\"line\":728,\"column\":175,\"offset\":107541}\n49a:{\"start\":\"$49b\",\"end\":\"$49c\"}\n499:{\"type\":\"text\",\"value\":\"In particular, they can’t rule out hypotheses such as “it’s following the Spec temporarily, merely as a strategy for achieving some other goal(s)” or “it’s trying to \",\"position\":\"$49a\"}\n4a1:{\"line\":728,\"column\":176,\"offset\":107542}\n4a2:{\"line\":728,\"column\":182,\"offset\":107548}\n4a0:{\"start\":\"$4a1\",\"end\":\"$4a2\"}\n49f:{\"type\":\"text\",\"value\":\"appear\",\"position\":\"$4a0\"}\n49e:[\"$49f\"]\n4a4:{\"line\":728,\"column\":175,\"offset\":107541}\n4a5:{\"line\":728,\"column\":183,\"offset\":107549}\n4a3:{\"start\":\"$4a4\",\"end\":\"$4a5\"}\n49d:{\"type\":\"emphasis\",\"children\":\"$49e\",\"position\":\"$4a3\"}\n4a8:{\"line\":728,\"column\":183,\"offset\":107549}\n4a9:{\"line\":728,\"column\":223,\"offset\":107589}\n4a7:{\"start\":\"$4a8\",\"end\":\"$4a9\"}\n4a6:{\"type\":\"text\",\"value\":\" to follow the Spec, it’s not trying to \",\"position\":\"$4a7\"}\n4ae:{\"line\":728,\"column\":224,\"offset\":107590}\n4af:{\"line\":728,\"column\":232,\"offset\":107598}\n4ad:{\"start\":\"$4ae\",\"end\":\"$4af\"}\n4ac:{\"type\":\"text\",\"value\":\"actually\",\"position\":\"$4ad\"}\n4ab:[\"$4ac\"]\n4b1:{\"line\":728,\"column\":223,\"offset\":107589}\n4b2:{\"line\":728,\"column\":233,\"offset\":107599}\n4b0:{\"start\":\"$4b1\",\"end\":\"$4b2\"}\n4aa:{\"type\":\"emphasis\",\"children\":\"$4ab\",\"position\":\"$4b0\"}\n4b5:{\"line\":728,\"column\":233,\"offset\":107599}\n4b6:{\"line\":728,\"column\":"])</script><script>self.__next_f.push([1,"511,\"offset\":107877}\n4b4:{\"start\":\"$4b5\",\"end\":\"$4b6\"}\n4b3:{\"type\":\"text\",\"value\":\" follow the Spec” or “it’s internalized the Spec correctly, but only on-distribution; if it encounters sufficiently novel stimuli (e.g. jailbreaks) it’ll start behaving differently.” (There are many active research agendas working to fix this sorry situation, e.g. the field of \",\"position\":\"$4b4\"}\n4bb:{\"line\":728,\"column\":512,\"offset\":107878}\n4bc:{\"line\":728,\"column\":528,\"offset\":107894}\n4ba:{\"start\":\"$4bb\",\"end\":\"$4bc\"}\n4b9:{\"type\":\"text\",\"value\":\"interpretability\",\"position\":\"$4ba\"}\n4b8:[\"$4b9\"]\n4be:{\"line\":728,\"column\":511,\"offset\":107877}\n4bf:{\"line\":728,\"column\":563,\"offset\":107929}\n4bd:{\"start\":\"$4be\",\"end\":\"$4bf\"}\n4b7:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2501.16496\",\"children\":\"$4b8\",\"position\":\"$4bd\"}\n4c2:{\"line\":728,\"column\":563,\"offset\":107929}\n4c3:{\"line\":728,\"column\":581,\"offset\":107947}\n4c1:{\"start\":\"$4c2\",\"end\":\"$4c3\"}\n4c0:{\"type\":\"text\",\"value\":\" and the field of \",\"position\":\"$4c1\"}\n4c8:{\"line\":728,\"column\":582,\"offset\":107948}\n4c9:{\"line\":728,\"column\":611,\"offset\":107977}\n4c7:{\"start\":\"$4c8\",\"end\":\"$4c9\"}\n4c6:{\"type\":\"text\",\"value\":\"chain-of-thought faithfulness\",\"position\":\"$4c7\"}\n4c5:[\"$4c6\"]\n4cb:{\"line\":728,\"column\":581,\"offset\":107947}\n4cc:{\"line\":728,\"column\":646,\"offset\":108012}\n4ca:{\"start\":\"$4cb\",\"end\":\"$4cc\"}\n4c4:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2307.13702\",\"children\":\"$4c5\",\"position\":\"$4ca\"}\n4cf:{\"line\":728,\"column\":646,\"offset\":108012}\n4d0:{\"line\":728,\"column\":648,\"offset\":108014}\n4ce:{\"start\":\"$4cf\",\"end\":\"$4d0\"}\n4cd:{\"type\":\"text\",\"value\":\".)\",\"position\":\"$4ce\"}\n498:[\"$499\",\"$49d\",\"$4a6\",\"$4aa\",\"$4b3\",\"$4b7\",\"$4c0\",\"$4c4\",\"$4cd\"]\n4d2:{\"line\":728,\"column\":9,\"offset\":107375}\n4d3:{\"line\":728,\"column\":648,\"offset\":108014}\n4d1:{\"start\":\"$4d2\",\"end\":\"$4d3\"}\n497:{\"type\":\"paragraph\",\"children\":\"$498\",\"position\":\"$4d1\"}\n496:[\"$497\"]\n4d9:{\"line\":730,\"column\":9,\"offset\":108024}\n4da:{\"line\":730,\"column\":69,\"offset\":108084}\n4d8:{\"start\":\"$4d9\",\"end\":\"$4da\"}\n4d7"])</script><script>self.__next_f.push([1,":{\"type\":\"text\",\"value\":\"By this we mean whoever is trying to solve the problems the \",\"position\":\"$4d8\"}\n4df:{\"line\":730,\"column\":70,\"offset\":108085}\n4e0:{\"line\":730,\"column\":89,\"offset\":108104}\n4de:{\"start\":\"$4df\",\"end\":\"$4e0\"}\n4dd:{\"type\":\"text\",\"value\":\"Superalignment team\",\"position\":\"$4de\"}\n4dc:[\"$4dd\"]\n4e2:{\"line\":730,\"column\":69,\"offset\":108084}\n4e3:{\"line\":730,\"column\":187,\"offset\":108202}\n4e1:{\"start\":\"$4e2\",\"end\":\"$4e3\"}\n4db:{\"type\":\"link\",\"title\":null,\"url\":\"https://web.archive.org/web/20250201020004/https://openai.com/index/introducing-superalignment/\",\"children\":\"$4dc\",\"position\":\"$4e1\"}\n4e6:{\"line\":730,\"column\":187,\"offset\":108202}\n4e7:{\"line\":730,\"column\":208,\"offset\":108223}\n4e5:{\"start\":\"$4e6\",\"end\":\"$4e7\"}\n4e4:{\"type\":\"text\",\"value\":\" was trying to solve.\",\"position\":\"$4e5\"}\n4d6:[\"$4d7\",\"$4db\",\"$4e4\"]\n4e9:{\"line\":730,\"column\":9,\"offset\":108024}\n4ea:{\"line\":730,\"column\":208,\"offset\":108223}\n4e8:{\"start\":\"$4e9\",\"end\":\"$4ea\"}\n4d5:{\"type\":\"paragraph\",\"children\":\"$4d6\",\"position\":\"$4e8\"}\n4d4:[\"$4d5\"]\n4f0:{\"line\":732,\"column\":9,\"offset\":108233}\n4f1:{\"line\":732,\"column\":73,\"offset\":108297}\n4ef:{\"start\":\"$4f0\",\"end\":\"$4f1\"}\n4ee:{\"type\":\"text\",\"value\":\"To be clear, what made these incidents interesting is that they \",\"position\":\"$4ef\"}\n4f6:{\"line\":732,\"column\":74,\"offset\":108298}\n4f7:{\"line\":732,\"column\":80,\"offset\":108304}\n4f5:{\"start\":\"$4f6\",\"end\":\"$4f7\"}\n4f4:{\"type\":\"text\",\"value\":\"didn’t\",\"position\":\"$4f5\"}\n4f3:[\"$4f4\"]\n4f9:{\"line\":732,\"column\":73,\"offset\":108297}\n4fa:{\"line\":732,\"column\":81,\"offset\":108305}\n4f8:{\"start\":\"$4f9\",\"end\":\"$4fa\"}\n4f2:{\"type\":\"emphasis\",\"children\":\"$4f3\",\"position\":\"$4f8\"}\n4fd:{\"line\":732,\"column\":81,\"offset\":108305}\n4fe:{\"line\":732,\"column\":262,\"offset\":108486}\n4fc:{\"start\":\"$4fd\",\"end\":\"$4fe\"}\n4fb:{\"type\":\"text\",\"value\":\" seem to be the result of the user prompting or otherwise encouraging the AIs to say those things. In 2025, it’ll still be possible to get AIs to say all sorts of things if you try.\",\"position\":\"$4fc\"}\n4ed:[\"$4ee\",\"$4f2\",\"$4fb\"]\n500:{\"line\":732,\"col"])</script><script>self.__next_f.push([1,"umn\":9,\"offset\":108233}\n501:{\"line\":732,\"column\":262,\"offset\":108486}\n4ff:{\"start\":\"$500\",\"end\":\"$501\"}\n4ec:{\"type\":\"paragraph\",\"children\":\"$4ed\",\"position\":\"$4ff\"}\n4eb:[\"$4ec\"]\n507:{\"line\":734,\"column\":9,\"offset\":108496}\n508:{\"line\":734,\"column\":163,\"offset\":108650}\n506:{\"start\":\"$507\",\"end\":\"$508\"}\n505:{\"type\":\"text\",\"value\":\"In practice, we expect OpenBrain to release models on a faster cadence than 8 months, but we refrain from describing all incremental releases for brevity.\",\"position\":\"$506\"}\n504:[\"$505\"]\n50a:{\"line\":734,\"column\":9,\"offset\":108496}\n50b:{\"line\":734,\"column\":163,\"offset\":108650}\n509:{\"start\":\"$50a\",\"end\":\"$50b\"}\n503:{\"type\":\"paragraph\",\"children\":\"$504\",\"position\":\"$509\"}\n502:[\"$503\"]\n511:{\"line\":736,\"column\":8,\"offset\":108659}\n512:{\"line\":736,\"column\":317,\"offset\":108968}\n510:{\"start\":\"$511\",\"end\":\"$512\"}\n50f:{\"type\":\"text\",\"value\":\"Specifically, we predict a score of 80% on OSWorld (equivalent to a skilled but non-expert human); 85% on Cybench, matching a top professional human team on hacking tasks that take those teams 4 hours; and 1.3 on RE-Bench matching top expert humans given 8 hours at well-defined AI research engineering tasks.\",\"position\":\"$510\"}\n50e:[\"$50f\"]\n514:{\"line\":736,\"column\":8,\"offset\":108659}\n515:{\"line\":736,\"column\":318,\"offset\":108969}\n513:{\"start\":\"$514\",\"end\":\"$515\"}\n50d:{\"type\":\"paragraph\",\"children\":\"$50e\",\"position\":\"$513\"}\n50c:[\"$50d\"]\n51b:{\"line\":738,\"column\":9,\"offset\":108979}\n51c:{\"line\":738,\"column\":302,\"offset\":109272}\n51a:{\"start\":\"$51b\",\"end\":\"$51c\"}\n519:{\"type\":\"text\",\"value\":\"Agent-1 and its imitators are commercially successful; over the course of 2025, AI company revenues triple, and OpenBrain valuation reaches $1T. Annual spending on datacenters doubles to $400 billion, led by Microsoft, Google, and Amazon, and the U.S. adds over 5 GW of AI power draw. See the \",\"position\":\"$51a\"}\n521:{\"line\":738,\"column\":303,\"offset\":109273}\n522:{\"line\":738,\"column\":319,\"offset\":109289}\n520:{\"start\":\"$521\",\"end\":\"$522\"}\n51f:{\"type\":\"text\",\"value\":\"industry metrics\",\""])</script><script>self.__next_f.push([1,"position\":\"$520\"}\n51e:[\"$51f\"]\n524:{\"line\":738,\"column\":302,\"offset\":109272}\n525:{\"line\":738,\"column\":397,\"offset\":109367}\n523:{\"start\":\"$524\",\"end\":\"$525\"}\n51d:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-5-industry-metrics\",\"children\":\"$51e\",\"position\":\"$523\"}\n528:{\"line\":738,\"column\":397,\"offset\":109367}\n529:{\"line\":738,\"column\":449,\"offset\":109419}\n527:{\"start\":\"$528\",\"end\":\"$529\"}\n526:{\"type\":\"text\",\"value\":\" section of the compute supplement for more details.\",\"position\":\"$527\"}\n518:[\"$519\",\"$51d\",\"$526\"]\n52b:{\"line\":738,\"column\":9,\"offset\":108979}\n52c:{\"line\":738,\"column\":449,\"offset\":109419}\n52a:{\"start\":\"$52b\",\"end\":\"$52c\"}\n517:{\"type\":\"paragraph\",\"children\":\"$518\",\"position\":\"$52a\"}\n516:[\"$517\"]\n532:{\"line\":740,\"column\":9,\"offset\":109429}\n533:{\"line\":740,\"column\":696,\"offset\":110116}\n531:{\"start\":\"$532\",\"end\":\"$533\"}\n530:{\"type\":\"text\",\"value\":\"AI safety researchers have been discussing automating AI R\u0026D as the most important dangerous capability for years. Their primary concern is internal deployment leading to acceleration of AI R\u0026D, making it harder for humans to keep up with what’s happening and figure out how to make it safe. OpenBrain as an organization twists this into exactly the opposite direction, citing dangerous levels of AI R\u0026D capability as a reason not to inform the public. So we see the beginning of a gap between the company’s internal and public capabilities. AI R\u0026D is what the models are best at, leading to the public having an increasingly delayed understanding of the frontier of AI capabilities.\",\"position\":\"$531\"}\n52f:[\"$530\"]\n535:{\"line\":740,\"column\":9,\"offset\":109429}\n536:{\"line\":740,\"column\":697,\"offset\":110117}\n534:{\"start\":\"$535\",\"end\":\"$536\"}\n52e:{\"type\":\"paragraph\",\"children\":\"$52f\",\"position\":\"$534\"}\n52d:[\"$52e\"]\n53c:{\"line\":742,\"column\":9,\"offset\":110127}\n53d:{\"line\":742,\"column\":13,\"offset\":110131}\n53b:{\"start\":\"$53c\",\"end\":\"$53d\"}\n53a:{\"type\":\"text\",\"value\":\"See \",\"position\":\"$53b\"}\n542:{\"line\":742,\"column\":14,\"offset\":11"])</script><script>self.__next_f.push([1,"0132}\n543:{\"line\":742,\"column\":54,\"offset\":110172}\n541:{\"start\":\"$542\",\"end\":\"$543\"}\n540:{\"type\":\"text\",\"value\":\"A Playbook for Securing AI Model Weights\",\"position\":\"$541\"}\n53f:[\"$540\"]\n545:{\"line\":742,\"column\":13,\"offset\":110131}\n546:{\"line\":742,\"column\":192,\"offset\":110310}\n544:{\"start\":\"$545\",\"end\":\"$546\"}\n53e:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":\"$53f\",\"position\":\"$544\"}\n549:{\"line\":742,\"column\":192,\"offset\":110310}\n54a:{\"line\":742,\"column\":218,\"offset\":110336}\n548:{\"start\":\"$549\",\"end\":\"$54a\"}\n547:{\"type\":\"text\",\"value\":\", RAND Corporation, 2024.\",\"position\":\"$548\"}\n539:[\"$53a\",\"$53e\",\"$547\"]\n54c:{\"line\":742,\"column\":9,\"offset\":110127}\n54d:{\"line\":742,\"column\":218,\"offset\":110336}\n54b:{\"start\":\"$54c\",\"end\":\"$54d\"}\n538:{\"type\":\"paragraph\",\"children\":\"$539\",\"position\":\"$54b\"}\n537:[\"$538\"]\n553:{\"line\":744,\"column\":9,\"offset\":110346}\n554:{\"line\":744,\"column\":284,\"offset\":110621}\n552:{\"start\":\"$553\",\"end\":\"$554\"}\n551:{\"type\":\"text\",\"value\":\"Around 5% of OpenBrain’s staff is on the security team and they are highly capable, but the threat surface is also extremely large. It also doesn’t help that they are mostly blocked at this stage from implementing policies that could slow down the research progress. See our \",\"position\":\"$552\"}\n559:{\"line\":744,\"column\":285,\"offset\":110622}\n55a:{\"line\":744,\"column\":302,\"offset\":110639}\n558:{\"start\":\"$559\",\"end\":\"$55a\"}\n557:{\"type\":\"text\",\"value\":\"Security Forecast\",\"position\":\"$558\"}\n556:[\"$557\"]\n55c:{\"line\":744,\"column\":284,\"offset\":110621}\n55d:{\"line\":744,\"column\":351,\"offset\":110688}\n55b:{\"start\":\"$55c\",\"end\":\"$55d\"}\n555:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/security-forecast\",\"children\":\"$556\",\"position\":\"$55b\"}\n560:{\"line\":744,\"column\":351,\"offset\":110688}\n561:{\"line\":744,\"column\":369,\"offset\":110706}\n55f:{\"start\":\"$560\",\"end\":\"$561\"}\n55e:{\"type\":\"text\",\"value\":\" for more details.\",\"position\":\"$55f\""])</script><script>self.__next_f.push([1,"}\n550:[\"$551\",\"$555\",\"$55e\"]\n563:{\"line\":744,\"column\":9,\"offset\":110346}\n564:{\"line\":744,\"column\":370,\"offset\":110707}\n562:{\"start\":\"$563\",\"end\":\"$564\"}\n54f:{\"type\":\"paragraph\",\"children\":\"$550\",\"position\":\"$562\"}\n54e:[\"$54f\"]\n56a:{\"line\":746,\"column\":9,\"offset\":110717}\n56b:{\"line\":746,\"column\":124,\"offset\":110832}\n569:{\"start\":\"$56a\",\"end\":\"$56b\"}\n568:{\"type\":\"text\",\"value\":\"There are now 3M H100e in China, up from the 1.5M they had one year ago in mid 2025. See the compute supplement’s \",\"position\":\"$569\"}\n570:{\"line\":746,\"column\":125,\"offset\":110833}\n571:{\"line\":746,\"column\":145,\"offset\":110853}\n56f:{\"start\":\"$570\",\"end\":\"$571\"}\n56e:{\"type\":\"text\",\"value\":\"distribution section\",\"position\":\"$56f\"}\n56d:[\"$56e\"]\n573:{\"line\":746,\"column\":124,\"offset\":110832}\n574:{\"line\":746,\"column\":227,\"offset\":110935}\n572:{\"start\":\"$573\",\"end\":\"$574\"}\n56c:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-2-compute-distribution\",\"children\":\"$56d\",\"position\":\"$572\"}\n577:{\"line\":746,\"column\":227,\"offset\":110935}\n578:{\"line\":746,\"column\":256,\"offset\":110964}\n576:{\"start\":\"$577\",\"end\":\"$578\"}\n575:{\"type\":\"text\",\"value\":\" for more details. We expect \",\"position\":\"$576\"}\n57d:{\"line\":746,\"column\":257,\"offset\":110965}\n57e:{\"line\":746,\"column\":274,\"offset\":110982}\n57c:{\"start\":\"$57d\",\"end\":\"$57e\"}\n57b:{\"type\":\"text\",\"value\":\"smuggling efforts\",\"position\":\"$57c\"}\n57a:[\"$57b\"]\n580:{\"line\":746,\"column\":256,\"offset\":110964}\n581:{\"line\":746,\"column\":356,\"offset\":111064}\n57f:{\"start\":\"$580\",\"end\":\"$581\"}\n579:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.cnas.org/publications/reports/preventing-ai-chip-smuggling-to-china\",\"children\":\"$57a\",\"position\":\"$57f\"}\n584:{\"line\":746,\"column\":356,\"offset\":111064}\n585:{\"line\":746,\"column\":378,\"offset\":111086}\n583:{\"start\":\"$584\",\"end\":\"$585\"}\n582:{\"type\":\"text\",\"value\":\" to secure around 60K \",\"position\":\"$583\"}\n58a:{\"line\":746,\"column\":379,\"offset\":111087}\n58b:{\"line\":746,\"column\":385,\"offset\":111093}\n589:{\"start\":\"$58a\",\"end\":\"$58b\"}\n588:{\"type\":\"text\",\"value\""])</script><script>self.__next_f.push([1,":\"GB300s\",\"position\":\"$589\"}\n587:[\"$588\"]\n58d:{\"line\":746,\"column\":378,\"offset\":111086}\n58e:{\"line\":746,\"column\":531,\"offset\":111239}\n58c:{\"start\":\"$58d\",\"end\":\"$58e\"}\n586:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.trendforce.com/news/2025/03/10/news-nvidia-to-unveil-gb300-at-gtc-with-shipment-reportedly-to-begin-in-may-driving-cooling-demands/\",\"children\":\"$587\",\"position\":\"$58c\"}\n591:{\"line\":746,\"column\":531,\"offset\":111239}\n592:{\"line\":746,\"column\":562,\"offset\":111270}\n590:{\"start\":\"$591\",\"end\":\"$592\"}\n58f:{\"type\":\"text\",\"value\":\" (450K H100e), with another 2M \",\"position\":\"$590\"}\n597:{\"line\":746,\"column\":563,\"offset\":111271}\n598:{\"line\":746,\"column\":575,\"offset\":111283}\n596:{\"start\":\"$597\",\"end\":\"$598\"}\n595:{\"type\":\"text\",\"value\":\"Huawei 910Cs\",\"position\":\"$596\"}\n594:[\"$595\"]\n59a:{\"line\":746,\"column\":562,\"offset\":111270}\n59b:{\"line\":746,\"column\":745,\"offset\":111453}\n599:{\"start\":\"$59a\",\"end\":\"$59b\"}\n593:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.tomshardware.com/tech-industry/artificial-intelligence/deepseek-research-suggests-huaweis-ascend-910c-delivers-60-percent-nvidia-h100-inference-performance\",\"children\":\"$594\",\"position\":\"$599\"}\n59e:{\"line\":746,\"column\":745,\"offset\":111453}\n59f:{\"line\":746,\"column\":752,\"offset\":111460}\n59d:{\"start\":\"$59e\",\"end\":\"$59f\"}\n59c:{\"type\":\"text\",\"value\":\" being \",\"position\":\"$59d\"}\n5a4:{\"line\":746,\"column\":753,\"offset\":111461}\n5a5:{\"line\":746,\"column\":761,\"offset\":111469}\n5a3:{\"start\":\"$5a4\",\"end\":\"$5a5\"}\n5a2:{\"type\":\"text\",\"value\":\"produced\",\"position\":\"$5a3\"}\n5a1:[\"$5a2\"]\n5a7:{\"line\":746,\"column\":752,\"offset\":111460}\n5a8:{\"line\":746,\"column\":814,\"offset\":111522}\n5a6:{\"start\":\"$5a7\",\"end\":\"$5a8\"}\n5a0:{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/ohlennart/status/1899488375574278336\",\"children\":\"$5a1\",\"position\":\"$5a6\"}\n5ab:{\"line\":746,\"column\":814,\"offset\":111522}\n5ac:{\"line\":746,\"column\":891,\"offset\":111599}\n5aa:{\"start\":\"$5ab\",\"end\":\"$5ac\"}\n5a9:{\"type\":\"text\",\"value\":\" (800k H100e) and a mixture of ~1M legally imported chips (such as Nvidia’s \",\"position\":\"$5aa"])</script><script>self.__next_f.push([1,"\"}\n5b1:{\"line\":746,\"column\":892,\"offset\":111600}\n5b2:{\"line\":746,\"column\":896,\"offset\":111604}\n5b0:{\"start\":\"$5b1\",\"end\":\"$5b2\"}\n5af:{\"type\":\"text\",\"value\":\"H20s\",\"position\":\"$5b0\"}\n5ae:[\"$5af\"]\n5b4:{\"line\":746,\"column\":891,\"offset\":111599}\n5b5:{\"line\":746,\"column\":1050,\"offset\":111758}\n5b3:{\"start\":\"$5b4\",\"end\":\"$5b5\"}\n5ad:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.reuters.com/technology/artificial-intelligence/nvidias-h20-chip-orders-jump-chinese-firms-adopt-deepseeks-ai-models-sources-say-2025-02-25/\",\"children\":\"$5ae\",\"position\":\"$5b3\"}\n5b8:{\"line\":746,\"column\":1050,\"offset\":111758}\n5b9:{\"line\":746,\"column\":1054,\"offset\":111762}\n5b7:{\"start\":\"$5b8\",\"end\":\"$5b9\"}\n5b6:{\"type\":\"text\",\"value\":\" or \",\"position\":\"$5b7\"}\n5be:{\"line\":746,\"column\":1055,\"offset\":111763}\n5bf:{\"line\":746,\"column\":1059,\"offset\":111767}\n5bd:{\"start\":\"$5be\",\"end\":\"$5bf\"}\n5bc:{\"type\":\"text\",\"value\":\"B20s\",\"position\":\"$5bd\"}\n5bb:[\"$5bc\"]\n5c1:{\"line\":746,\"column\":1054,\"offset\":111762}\n5c2:{\"line\":746,\"column\":1180,\"offset\":111888}\n5c0:{\"start\":\"$5c1\",\"end\":\"$5c2\"}\n5ba:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.reuters.com/technology/nvidia-preparing-version-new-flaghip-ai-chip-chinese-market-sources-say-2024-07-22/\",\"children\":\"$5bb\",\"position\":\"$5c0\"}\n5c5:{\"line\":746,\"column\":1180,\"offset\":111888}\n5c6:{\"line\":746,\"column\":1212,\"offset\":111920}\n5c4:{\"start\":\"$5c5\",\"end\":\"$5c6\"}\n5c3:{\"type\":\"text\",\"value\":\") making up the last 250K H100e.\",\"position\":\"$5c4\"}\n567:[\"$568\",\"$56c\",\"$575\",\"$579\",\"$582\",\"$586\",\"$58f\",\"$593\",\"$59c\",\"$5a0\",\"$5a9\",\"$5ad\",\"$5b6\",\"$5ba\",\"$5c3\"]\n5c8:{\"line\":746,\"column\":9,\"offset\":110717}\n5c9:{\"line\":746,\"column\":1212,\"offset\":111920}\n5c7:{\"start\":\"$5c8\",\"end\":\"$5c9\"}\n566:{\"type\":\"paragraph\",\"children\":\"$567\",\"position\":\"$5c7\"}\n565:[\"$566\"]\n5cf:{\"line\":748,\"column\":9,\"offset\":111930}\n5d0:{\"line\":748,\"column\":208,\"offset\":112129}\n5ce:{\"start\":\"$5cf\",\"end\":\"$5d0\"}\n5cd:{\"type\":\"text\",\"value\":\"For comparison, in January 2025, DeepSeek released R1, a model competitive with OpenAI’s o1, which had been released in Decem"])</script><script>self.__next_f.push([1,"ber 2024. But we think the true gap is wider than a month because OpenAI \",\"position\":\"$5ce\"}\n5d5:{\"line\":748,\"column\":209,\"offset\":112130}\n5d6:{\"line\":748,\"column\":254,\"offset\":112175}\n5d4:{\"start\":\"$5d5\",\"end\":\"$5d6\"}\n5d3:{\"type\":\"text\",\"value\":\"likely had been working on o1 for many months\",\"position\":\"$5d4\"}\n5d2:[\"$5d3\"]\n5d8:{\"line\":748,\"column\":208,\"offset\":112129}\n5d9:{\"line\":748,\"column\":296,\"offset\":112217}\n5d7:{\"start\":\"$5d8\",\"end\":\"$5d9\"}\n5d1:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/OpenAI_o1\",\"children\":\"$5d2\",\"position\":\"$5d7\"}\n5dc:{\"line\":748,\"column\":296,\"offset\":112217}\n5dd:{\"line\":748,\"column\":403,\"offset\":112324}\n5db:{\"start\":\"$5dc\",\"end\":\"$5dd\"}\n5da:{\"type\":\"text\",\"value\":\" and thus presumably had a predecessor of roughly comparable ability to r1 a few months before o1 launched.\",\"position\":\"$5db\"}\n5cc:[\"$5cd\",\"$5d1\",\"$5da\"]\n5df:{\"line\":748,\"column\":9,\"offset\":111930}\n5e0:{\"line\":748,\"column\":403,\"offset\":112324}\n5de:{\"start\":\"$5df\",\"end\":\"$5e0\"}\n5cb:{\"type\":\"paragraph\",\"children\":\"$5cc\",\"position\":\"$5de\"}\n5ca:[\"$5cb\"]\n5e6:{\"line\":750,\"column\":9,\"offset\":112334}\n5e7:{\"line\":750,\"column\":80,\"offset\":112405}\n5e5:{\"start\":\"$5e6\",\"end\":\"$5e7\"}\n5e4:{\"type\":\"text\",\"value\":\"By contrast, the CCP had been seriously attempting to accelerate their \",\"position\":\"$5e5\"}\n5ec:{\"line\":750,\"column\":81,\"offset\":112406}\n5ed:{\"line\":750,\"column\":103,\"offset\":112428}\n5eb:{\"start\":\"$5ec\",\"end\":\"$5ed\"}\n5ea:{\"type\":\"text\",\"value\":\"semiconductor industry\",\"position\":\"$5eb\"}\n5e9:[\"$5ea\"]\n5ef:{\"line\":750,\"column\":80,\"offset\":112405}\n5f0:{\"line\":750,\"column\":214,\"offset\":112539}\n5ee:{\"start\":\"$5ef\",\"end\":\"$5f0\"}\n5e8:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.reuters.com/technology/china-sets-up-475-bln-state-fund-boost-semiconductor-industry-2024-05-27/\",\"children\":\"$5e9\",\"position\":\"$5ee\"}\n5f3:{\"line\":750,\"column\":214,\"offset\":112539}\n5f4:{\"line\":750,\"column\":215,\"offset\":112540}\n5f2:{\"start\":\"$5f3\",\"end\":\"$5f4\"}\n5f1:{\"type\":\"text\",\"value\":\".\",\"position\":\"$5f2\"}\n5e3:[\"$5e4\",\"$5e8\",\"$5f1\"]\n5f6:{"])</script><script>self.__next_f.push([1,"\"line\":750,\"column\":9,\"offset\":112334}\n5f7:{\"line\":750,\"column\":216,\"offset\":112541}\n5f5:{\"start\":\"$5f6\",\"end\":\"$5f7\"}\n5e2:{\"type\":\"paragraph\",\"children\":\"$5e3\",\"position\":\"$5f5\"}\n5e1:[\"$5e2\"]\n5fd:{\"line\":752,\"column\":9,\"offset\":112551}\n5fe:{\"line\":752,\"column\":430,\"offset\":112972}\n5fc:{\"start\":\"$5fd\",\"end\":\"$5fe\"}\n5fb:{\"type\":\"text\",\"value\":\"At first, the sharing is limited to ideas and the companies are mostly busy finishing up their current workloads, but by the end of the year their coordination increases such that they are sharing model weights and even splitting up tasks between each other’s datacenters. For example, one campus might house a new pretraining run, another focuses on feeding in synthetic data, another on running AI research experiments.\",\"position\":\"$5fc\"}\n5fa:[\"$5fb\"]\n600:{\"line\":752,\"column\":9,\"offset\":112551}\n601:{\"line\":752,\"column\":430,\"offset\":112972}\n5ff:{\"start\":\"$600\",\"end\":\"$601\"}\n5f9:{\"type\":\"paragraph\",\"children\":\"$5fa\",\"position\":\"$5ff\"}\n5f8:[\"$5f9\"]\n607:{\"line\":754,\"column\":9,\"offset\":112982}\n608:{\"line\":754,\"column\":516,\"offset\":113489}\n606:{\"start\":\"$607\",\"end\":\"$608\"}\n605:{\"type\":\"text\",\"value\":\"Why “only” 50% of China’s AI-relevant compute? The rest of their compute is tied up running things throughout the economy, in particular internet and social network recommendation algorithms. Much of it is also too geographically dispersed among many small clusters. Why “only” 80% of new chips? Many large orders were already secured for other applications, by companies that don’t want to contribute 100% of their compute to the national AI effort. However, by the end of the year this share reaches 90%+.\",\"position\":\"$606\"}\n604:[\"$605\"]\n60a:{\"line\":754,\"column\":9,\"offset\":112982}\n60b:{\"line\":754,\"column\":516,\"offset\":113489}\n609:{\"start\":\"$60a\",\"end\":\"$60b\"}\n603:{\"type\":\"paragraph\",\"children\":\"$604\",\"position\":\"$609\"}\n602:[\"$603\"]\n611:{\"line\":756,\"column\":9,\"offset\":113499}\n612:{\"line\":756,\"column\":165,\"offset\":113655}\n610:{\"start\":\"$611\",\"end\":\"$612\"}\n60f:{\"type\":\"text\",\"v"])</script><script>self.__next_f.push([1,"alue\":\"They are at least one year away from getting the chips to fill this capacity, and one or two U.S. tech giants will still have bigger decentralized clusters.\",\"position\":\"$610\"}\n60e:[\"$60f\"]\n614:{\"line\":756,\"column\":9,\"offset\":113499}\n615:{\"line\":756,\"column\":166,\"offset\":113656}\n613:{\"start\":\"$614\",\"end\":\"$615\"}\n60d:{\"type\":\"paragraph\",\"children\":\"$60e\",\"position\":\"$613\"}\n60c:[\"$60d\"]\n61b:{\"line\":758,\"column\":9,\"offset\":113666}\n61c:{\"line\":758,\"column\":29,\"offset\":113686}\n61a:{\"start\":\"$61b\",\"end\":\"$61c\"}\n619:{\"type\":\"text\",\"value\":\"This is done via an \",\"position\":\"$61a\"}\n621:{\"line\":758,\"column\":30,\"offset\":113687}\n622:{\"line\":758,\"column\":62,\"offset\":113719}\n620:{\"start\":\"$621\",\"end\":\"$622\"}\n61f:{\"type\":\"text\",\"value\":\"Other Transaction Authority (OTA\",\"position\":\"$620\"}\n61e:[\"$61f\"]\n624:{\"line\":758,\"column\":29,\"offset\":113686}\n625:{\"line\":758,\"column\":138,\"offset\":113795}\n623:{\"start\":\"$624\",\"end\":\"$625\"}\n61d:{\"type\":\"link\",\"title\":null,\"url\":\"https://acqnotes.com/acqnote/careerfields/other-transaction-authority-ota\",\"children\":\"$61e\",\"position\":\"$623\"}\n628:{\"line\":758,\"column\":138,\"offset\":113795}\n629:{\"line\":758,\"column\":179,\"offset\":113836}\n627:{\"start\":\"$628\",\"end\":\"$629\"}\n626:{\"type\":\"text\",\"value\":\") contract, and is given a high-priority \",\"position\":\"$627\"}\n62e:{\"line\":758,\"column\":180,\"offset\":113837}\n62f:{\"line\":758,\"column\":189,\"offset\":113846}\n62d:{\"start\":\"$62e\",\"end\":\"$62f\"}\n62c:{\"type\":\"text\",\"value\":\"DX rating\",\"position\":\"$62d\"}\n62b:[\"$62c\"]\n631:{\"line\":758,\"column\":179,\"offset\":113836}\n632:{\"line\":758,\"column\":218,\"offset\":113875}\n630:{\"start\":\"$631\",\"end\":\"$632\"}\n62a:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.dcma.mil/DPAS/\",\"children\":\"$62b\",\"position\":\"$630\"}\n635:{\"line\":758,\"column\":218,\"offset\":113875}\n636:{\"line\":758,\"column\":451,\"offset\":114108}\n634:{\"start\":\"$635\",\"end\":\"$636\"}\n633:{\"type\":\"text\",\"value\":\". We’re not at all confident that this is the most likely way of financing a collaboration, but chose something specific for the sake of concreteness. The contract is p"])</script><script>self.__next_f.push([1,"ublicly announced but not emphasized in OpenBrain communications.\",\"position\":\"$634\"}\n618:[\"$619\",\"$61d\",\"$626\",\"$62a\",\"$633\"]\n638:{\"line\":758,\"column\":9,\"offset\":113666}\n639:{\"line\":758,\"column\":451,\"offset\":114108}\n637:{\"start\":\"$638\",\"end\":\"$639\"}\n617:{\"type\":\"paragraph\",\"children\":\"$618\",\"position\":\"$637\"}\n616:[\"$617\"]\n63f:{\"line\":760,\"column\":9,\"offset\":114118}\n640:{\"line\":760,\"column\":50,\"offset\":114159}\n63e:{\"start\":\"$63f\",\"end\":\"$640\"}\n63d:{\"type\":\"text\",\"value\":\"For example, through rejection sampling, \",\"position\":\"$63e\"}\n645:{\"line\":760,\"column\":51,\"offset\":114160}\n646:{\"line\":760,\"column\":73,\"offset\":114182}\n644:{\"start\":\"$645\",\"end\":\"$646\"}\n643:{\"type\":\"text\",\"value\":\"as done by DeepSeek R1\",\"position\":\"$644\"}\n642:[\"$643\"]\n648:{\"line\":760,\"column\":50,\"offset\":114159}\n649:{\"line\":760,\"column\":144,\"offset\":114253}\n647:{\"start\":\"$648\",\"end\":\"$649\"}\n641:{\"type\":\"link\",\"title\":null,\"url\":\"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\",\"children\":\"$642\",\"position\":\"$647\"}\n64c:{\"line\":760,\"column\":144,\"offset\":114253}\n64d:{\"line\":760,\"column\":149,\"offset\":114258}\n64b:{\"start\":\"$64c\",\"end\":\"$64d\"}\n64a:{\"type\":\"text\",\"value\":\" and \",\"position\":\"$64b\"}\n652:{\"line\":760,\"column\":150,\"offset\":114259}\n653:{\"line\":760,\"column\":166,\"offset\":114275}\n651:{\"start\":\"$652\",\"end\":\"$653\"}\n650:{\"type\":\"text\",\"value\":\"Meta’s Llama 3.1\",\"position\":\"$651\"}\n64f:[\"$650\"]\n655:{\"line\":760,\"column\":149,\"offset\":114258}\n656:{\"line\":760,\"column\":201,\"offset\":114310}\n654:{\"start\":\"$655\",\"end\":\"$656\"}\n64e:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2407.21783\",\"children\":\"$64f\",\"position\":\"$654\"}\n659:{\"line\":760,\"column\":201,\"offset\":114310}\n65a:{\"line\":760,\"column\":202,\"offset\":114311}\n658:{\"start\":\"$659\",\"end\":\"$65a\"}\n657:{\"type\":\"text\",\"value\":\".\",\"position\":\"$658\"}\n63c:[\"$63d\",\"$641\",\"$64a\",\"$64e\",\"$657\"]\n65c:{\"line\":760,\"column\":9,\"offset\":114118}\n65d:{\"line\":760,\"column\":203,\"offset\":114312}\n65b:{\"start\":\"$65c\",\"end\":\"$65d\"}\n63b:{\"type\":\"paragraph\",\"children\":\"$63c\",\"position\":\"$65b\"}\n63a:[\"$"])</script><script>self.__next_f.push([1,"63b\"]\n663:{\"line\":762,\"column\":9,\"offset\":114322}\n664:{\"line\":762,\"column\":82,\"offset\":114395}\n662:{\"start\":\"$663\",\"end\":\"$664\"}\n661:{\"type\":\"text\",\"value\":\"Roughly 20,000 full-time equivalents * $100/hr * 2,000 hrs/yr = $4B/yr\",\"position\":\"$662\"}\n660:[\"$661\"]\n666:{\"line\":762,\"column\":9,\"offset\":114322}\n667:{\"line\":762,\"column\":82,\"offset\":114395}\n665:{\"start\":\"$666\",\"end\":\"$667\"}\n65f:{\"type\":\"paragraph\",\"children\":\"$660\",\"position\":\"$665\"}\n65e:[\"$65f\"]\n66d:{\"line\":764,\"column\":9,\"offset\":114405}\n66e:{\"line\":764,\"column\":314,\"offset\":114710}\n66c:{\"start\":\"$66d\",\"end\":\"$66e\"}\n66b:{\"type\":\"text\",\"value\":\"That is, they are hoping to substantially accelerate their own core research activities by using Agent-2 labor, thus allowing them to train better AIs faster that can cause further acceleration, etc. For an analysis of the extreme version of this (which we think is nevertheless strikingly plausible) see \",\"position\":\"$66c\"}\n673:{\"line\":764,\"column\":315,\"offset\":114711}\n674:{\"line\":764,\"column\":326,\"offset\":114722}\n672:{\"start\":\"$673\",\"end\":\"$674\"}\n671:{\"type\":\"text\",\"value\":\"this report\",\"position\":\"$672\"}\n670:[\"$671\"]\n676:{\"line\":764,\"column\":314,\"offset\":114710}\n677:{\"line\":764,\"column\":432,\"offset\":114828}\n675:{\"start\":\"$676\",\"end\":\"$677\"}\n66f:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.forethought.org/research/will-ai-r-and-d-automation-cause-a-software-intelligence-explosion\",\"children\":\"$670\",\"position\":\"$675\"}\n67a:{\"line\":764,\"column\":432,\"offset\":114828}\n67b:{\"line\":764,\"column\":433,\"offset\":114829}\n679:{\"start\":\"$67a\",\"end\":\"$67b\"}\n678:{\"type\":\"text\",\"value\":\".\",\"position\":\"$679\"}\n66a:[\"$66b\",\"$66f\",\"$678\"]\n67d:{\"line\":764,\"column\":9,\"offset\":114405}\n67e:{\"line\":764,\"column\":433,\"offset\":114829}\n67c:{\"start\":\"$67d\",\"end\":\"$67e\"}\n669:{\"type\":\"paragraph\",\"children\":\"$66a\",\"position\":\"$67c\"}\n668:[\"$669\"]\n684:{\"line\":766,\"column\":9,\"offset\":114839}\n685:{\"line\":766,\"column\":93,\"offset\":114923}\n683:{\"start\":\"$684\",\"end\":\"$685\"}\n682:{\"type\":\"text\",\"value\":\"There is some evidence that AI systems already have so"])</script><script>self.__next_f.push([1,"me basic research taste, e.g. \",\"position\":\"$683\"}\n68a:{\"line\":766,\"column\":94,\"offset\":114924}\n68b:{\"line\":766,\"column\":129,\"offset\":114959}\n689:{\"start\":\"$68a\",\"end\":\"$68b\"}\n688:{\"type\":\"text\",\"value\":\"this paper about an AI co-scientist\",\"position\":\"$689\"}\n687:[\"$688\"]\n68d:{\"line\":766,\"column\":93,\"offset\":114923}\n68e:{\"line\":766,\"column\":223,\"offset\":115053}\n68c:{\"start\":\"$68d\",\"end\":\"$68e\"}\n686:{\"type\":\"link\",\"title\":null,\"url\":\"https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/\",\"children\":\"$687\",\"position\":\"$68c\"}\n691:{\"line\":766,\"column\":223,\"offset\":115053}\n692:{\"line\":766,\"column\":228,\"offset\":115058}\n690:{\"start\":\"$691\",\"end\":\"$692\"}\n68f:{\"type\":\"text\",\"value\":\" and \",\"position\":\"$690\"}\n697:{\"line\":766,\"column\":229,\"offset\":115059}\n698:{\"line\":766,\"column\":300,\"offset\":115130}\n696:{\"start\":\"$697\",\"end\":\"$698\"}\n695:{\"type\":\"text\",\"value\":\"this paper about generating novel ideas for LLM-focused research papers\",\"position\":\"$696\"}\n694:[\"$695\"]\n69a:{\"line\":766,\"column\":228,\"offset\":115058}\n69b:{\"line\":766,\"column\":335,\"offset\":115165}\n699:{\"start\":\"$69a\",\"end\":\"$69b\"}\n693:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2409.04109\",\"children\":\"$694\",\"position\":\"$699\"}\n69e:{\"line\":766,\"column\":335,\"offset\":115165}\n69f:{\"line\":766,\"column\":503,\"offset\":115333}\n69d:{\"start\":\"$69e\",\"end\":\"$69f\"}\n69c:{\"type\":\"text\",\"value\":\". Research teams with better taste still need to run experiments, but they make better choices about which experiments to run and what lessons to draw from the results.\",\"position\":\"$69d\"}\n681:[\"$682\",\"$686\",\"$68f\",\"$693\",\"$69c\"]\n6a1:{\"line\":766,\"column\":9,\"offset\":114839}\n6a2:{\"line\":766,\"column\":503,\"offset\":115333}\n6a0:{\"start\":\"$6a1\",\"end\":\"$6a2\"}\n680:{\"type\":\"paragraph\",\"children\":\"$681\",\"position\":\"$6a0\"}\n67f:[\"$680\"]\n6a8:{\"line\":768,\"column\":9,\"offset\":115343}\n6a9:{\"line\":768,\"column\":273,\"offset\":115607}\n6a7:{\"start\":\"$6a8\",\"end\":\"$6a9\"}\n6a6:{\"type\":\"text\",\"value\":\"Also, they are still seeing large returns to continued post-training, an"])</script><script>self.__next_f.push([1,"d so there isn’t a particular reason to release a product now. Moreover, there’s often a few month delay between internal results and releasing a model (some of which is spent on red teaming).\",\"position\":\"$6a7\"}\n6a5:[\"$6a6\"]\n6ab:{\"line\":768,\"column\":9,\"offset\":115343}\n6ac:{\"line\":768,\"column\":273,\"offset\":115607}\n6aa:{\"start\":\"$6ab\",\"end\":\"$6ac\"}\n6a4:{\"type\":\"paragraph\",\"children\":\"$6a5\",\"position\":\"$6aa\"}\n6a3:[\"$6a4\"]\n6b2:{\"line\":770,\"column\":9,\"offset\":115617}\n6b3:{\"line\":770,\"column\":152,\"offset\":115760}\n6b1:{\"start\":\"$6b2\",\"end\":\"$6b3\"}\n6b0:{\"type\":\"text\",\"value\":\"The silo contains 200 OpenBrain researchers (10 executives, 140 from the capabilities team, 25 from security, monitoring, and control, 15 from \",\"position\":\"$6b1\"}\n6b8:{\"line\":770,\"column\":153,\"offset\":115761}\n6b9:{\"line\":770,\"column\":165,\"offset\":115773}\n6b7:{\"start\":\"$6b8\",\"end\":\"$6b9\"}\n6b6:{\"type\":\"text\",\"value\":\"Preparedness\",\"position\":\"$6b7\"}\n6b5:[\"$6b6\"]\n6bb:{\"line\":770,\"column\":152,\"offset\":115760}\n6bc:{\"line\":770,\"column\":229,\"offset\":115837}\n6ba:{\"start\":\"$6bb\",\"end\":\"$6bc\"}\n6b4:{\"type\":\"link\",\"title\":null,\"url\":\"https://cdn.openai.com/openai-preparedness-framework-beta.pdf\",\"children\":\"$6b5\",\"position\":\"$6ba\"}\n6bf:{\"line\":770,\"column\":229,\"offset\":115837}\n6c0:{\"line\":770,\"column\":235,\"offset\":115843}\n6be:{\"start\":\"$6bf\",\"end\":\"$6c0\"}\n6bd:{\"type\":\"text\",\"value\":\"- or \",\"position\":\"$6be\"}\n6c5:{\"line\":770,\"column\":236,\"offset\":115844}\n6c6:{\"line\":770,\"column\":239,\"offset\":115847}\n6c4:{\"start\":\"$6c5\",\"end\":\"$6c6\"}\n6c3:{\"type\":\"text\",\"value\":\"RSP\",\"position\":\"$6c4\"}\n6c2:[\"$6c3\"]\n6c8:{\"line\":770,\"column\":235,\"offset\":115843}\n6c9:{\"line\":770,\"column\":350,\"offset\":115958}\n6c7:{\"start\":\"$6c8\",\"end\":\"$6c9\"}\n6c1:{\"type\":\"link\",\"title\":null,\"url\":\"https://assets.anthropic.com/m/24a47b00f10301cd/original/Anthropic-Responsible-Scaling-Policy-2024-10-15.pdf\",\"children\":\"$6c2\",\"position\":\"$6c7\"}\n6cc:{\"line\":770,\"column\":350,\"offset\":115958}\n6cd:{\"line\":770,\"column\":691,\"offset\":116299}\n6cb:{\"start\":\"$6cc\",\"end\":\"$6cd\"}\n6ca:{\"type\":\"text\",\"value\":\"-t"])</script><script>self.__next_f.push([1,"ype teams, and 10 from alignment) and 50 government officials (15 from the White House, 5 from AISI, 10 from the DOD, 10 from the DOE, and 10 at CISA). There are several spies in the project, with varying degrees of willingness. They are often coerced individuals (e.g. with families at home in China) as opposed to willing collaborators.\",\"position\":\"$6cb\"}\n6af:[\"$6b0\",\"$6b4\",\"$6bd\",\"$6c1\",\"$6ca\"]\n6cf:{\"line\":770,\"column\":9,\"offset\":115617}\n6d0:{\"line\":770,\"column\":691,\"offset\":116299}\n6ce:{\"start\":\"$6cf\",\"end\":\"$6d0\"}\n6ae:{\"type\":\"paragraph\",\"children\":\"$6af\",\"position\":\"$6ce\"}\n6ad:[\"$6ae\"]\n6d6:{\"line\":772,\"column\":9,\"offset\":116309}\n6d7:{\"line\":772,\"column\":390,\"offset\":116690}\n6d5:{\"start\":\"$6d6\",\"end\":\"$6d7\"}\n6d4:{\"type\":\"text\",\"value\":\"Why can’t Congress stop them? What about the courts? Too slow, too divided and/or deferential to the President, too out of the loop. Also, there are positive reasons to be on good terms with the White House as well: it can help by cutting red tape, by providing help with security, by preempting state legislation, and perhaps even by taking actions to slow down their competitors.\",\"position\":\"$6d5\"}\n6d3:[\"$6d4\"]\n6d9:{\"line\":772,\"column\":9,\"offset\":116309}\n6da:{\"line\":772,\"column\":390,\"offset\":116690}\n6d8:{\"start\":\"$6d9\",\"end\":\"$6da\"}\n6d2:{\"type\":\"paragraph\",\"children\":\"$6d3\",\"position\":\"$6d8\"}\n6d1:[\"$6d2\"]\n6e0:{\"line\":774,\"column\":9,\"offset\":116700}\n6e1:{\"line\":774,\"column\":173,\"offset\":116864}\n6df:{\"start\":\"$6e0\",\"end\":\"$6e1\"}\n6de:{\"type\":\"text\",\"value\":\"#1 is dealing with whatever crisis is happening at the time—maybe an arms buildup around Taiwan, a new war in the Middle East, or some domestic political upheaval.\",\"position\":\"$6df\"}\n6dd:[\"$6de\"]\n6e3:{\"line\":774,\"column\":9,\"offset\":116700}\n6e4:{\"line\":774,\"column\":173,\"offset\":116864}\n6e2:{\"start\":\"$6e3\",\"end\":\"$6e4\"}\n6dc:{\"type\":\"paragraph\",\"children\":\"$6dd\",\"position\":\"$6e2\"}\n6db:[\"$6dc\"]\n6ea:{\"line\":776,\"column\":9,\"offset\":116874}\n6eb:{\"line\":776,\"column\":505,\"offset\":117370}\n6e9:{\"start\":\"$6ea\",\"end\":\"$6eb\"}\n6e8:{\"type"])</script><script>self.__next_f.push([1,"\":\"text\",\"value\":\"The simplest robust solution would be to close all high-bandwidth connections from company datacenters, but this would slow large file transfers to the point of impracticality. Instead, they are able to shut down most external connections, but the datacenters actively involved in training need to exchange weights with one another quickly; throttling these connections would impede progress too much. So OpenBrain maintains these links with increased monitoring and an extra layer of encryption.\",\"position\":\"$6e9\"}\n6e7:[\"$6e8\"]\n6ed:{\"line\":776,\"column\":9,\"offset\":116874}\n6ee:{\"line\":776,\"column\":505,\"offset\":117370}\n6ec:{\"start\":\"$6ed\",\"end\":\"$6ee\"}\n6e6:{\"type\":\"paragraph\",\"children\":\"$6e7\",\"position\":\"$6ec\"}\n6e5:[\"$6e6\"]\n6f4:{\"line\":778,\"column\":9,\"offset\":117380}\n6f5:{\"line\":778,\"column\":177,\"offset\":117548}\n6f3:{\"start\":\"$6f4\",\"end\":\"$6f5\"}\n6f2:{\"type\":\"text\",\"value\":\"Recall that since mid 2026, China has directed 80% of their newly acquired AI chips to the CDZ. Given that their compute has doubled since early 2026 (in line with the \",\"position\":\"$6f3\"}\n6fa:{\"line\":778,\"column\":178,\"offset\":117549}\n6fb:{\"line\":778,\"column\":201,\"offset\":117572}\n6f9:{\"start\":\"$6fa\",\"end\":\"$6fb\"}\n6f8:{\"type\":\"text\",\"value\":\"global production trend\",\"position\":\"$6f9\"}\n6f7:[\"$6f8\"]\n6fd:{\"line\":778,\"column\":177,\"offset\":117548}\n6fe:{\"line\":778,\"column\":278,\"offset\":117649}\n6fc:{\"start\":\"$6fd\",\"end\":\"$6fe\"}\n6f6:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/compute-forecast#section-1-compute-production\",\"children\":\"$6f7\",\"position\":\"$6fc\"}\n701:{\"line\":778,\"column\":278,\"offset\":117649}\n702:{\"line\":778,\"column\":495,\"offset\":117866}\n700:{\"start\":\"$701\",\"end\":\"$702\"}\n6ff:{\"type\":\"text\",\"value\":\") this puts the CDZ at 2M 2024-equivalent-GPUs (H100s) and 2 GW of power draw. OpenBrain still has double DeepCent’s compute and other U.S. companies put together have 5x as much as them. See the compute supplement’s \",\"position\":\"$700\"}\n707:{\"line\":778,\"column\":496,\"offset\":117867}\n708:{\"line\":778,\"column\":516,\""])</script><script>self.__next_f.push([1,"offset\":117887}\n706:{\"start\":\"$707\",\"end\":\"$708\"}\n705:{\"type\":\"text\",\"value\":\"distribution section\",\"position\":\"$706\"}\n704:[\"$705\"]\n70a:{\"line\":778,\"column\":495,\"offset\":117866}\n70b:{\"line\":778,\"column\":598,\"offset\":117969}\n709:{\"start\":\"$70a\",\"end\":\"$70b\"}\n703:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-2-compute-distribution\",\"children\":\"$704\",\"position\":\"$709\"}\n70e:{\"line\":778,\"column\":598,\"offset\":117969}\n70f:{\"line\":778,\"column\":616,\"offset\":117987}\n70d:{\"start\":\"$70e\",\"end\":\"$70f\"}\n70c:{\"type\":\"text\",\"value\":\" for more details.\",\"position\":\"$70d\"}\n6f1:[\"$6f2\",\"$6f6\",\"$6ff\",\"$703\",\"$70c\"]\n711:{\"line\":778,\"column\":9,\"offset\":117380}\n712:{\"line\":778,\"column\":616,\"offset\":117987}\n710:{\"start\":\"$711\",\"end\":\"$712\"}\n6f0:{\"type\":\"paragraph\",\"children\":\"$6f1\",\"position\":\"$710\"}\n6ef:[\"$6f0\"]\n717:T421,Despite the national centralization underway, DeepCent still faces a marginal but important compute disadvantage. Along with having around half the total processing power, China has to use more total chips, which are (on average) lower quality, and heterogenous GPUs (which are not always easy to connect efficiently) both of which strain chip-to-chip networking. There are also software differences (e.g. the non Nvidia-GPUs don’t have CUDA) and differences in hardware specifications meaning that their training code is more complicated, slow, and failure prone. Achieving high utilization is a downstream challenge, with data ingestion, scheduling, collective communication and parallelism algorithms lagging behind the U.S. companies. However, mitigating these problems is mostly a matter of effort and testing, which makes it a great task for the newly-stolen Agent-2, and within a month or so, uptime on the Chinese project and their average resource utilization across training and inference workloads improves to be only marginally behind the U.S.719:{\"line\":780,\"column\":9,\"offset\":117997}\n71a:{\"line\":780,\"column\":1064,\"offset\":119052}\n718:{\"start\":\"$719\",\"end\":\"$71a\"}\n716:{\"type"])</script><script>self.__next_f.push([1,"\":\"text\",\"value\":\"$717\",\"position\":\"$718\"}\n715:[\"$716\"]\n71c:{\"line\":780,\"column\":9,\"offset\":117997}\n71d:{\"line\":780,\"column\":1064,\"offset\":119052}\n71b:{\"start\":\"$71c\",\"end\":\"$71d\"}\n714:{\"type\":\"paragraph\",\"children\":\"$715\",\"position\":\"$71b\"}\n713:[\"$714\"]\n723:{\"line\":782,\"column\":9,\"offset\":119062}\n724:{\"line\":782,\"column\":242,\"offset\":119295}\n722:{\"start\":\"$723\",\"end\":\"$724\"}\n721:{\"type\":\"text\",\"value\":\"We expect Agent-3 to have the inference requirements of a roughly 10T parameter transformer today. So with 6% of their compute budget on running Agent-3, they can run approximately 200,000 copies at 30x human thinking speed (see the \",\"position\":\"$722\"}\n729:{\"line\":782,\"column\":243,\"offset\":119296}\n72a:{\"line\":782,\"column\":265,\"offset\":119318}\n728:{\"start\":\"$729\",\"end\":\"$72a\"}\n727:{\"type\":\"text\",\"value\":\"AI research automation\",\"position\":\"$728\"}\n726:[\"$727\"]\n72c:{\"line\":782,\"column\":242,\"offset\":119295}\n72d:{\"line\":782,\"column\":349,\"offset\":119402}\n72b:{\"start\":\"$72c\",\"end\":\"$72d\"}\n725:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-4-ai-research-automation\",\"children\":\"$726\",\"position\":\"$72b\"}\n730:{\"line\":782,\"column\":349,\"offset\":119402}\n731:{\"line\":782,\"column\":654,\"offset\":119707}\n72f:{\"start\":\"$730\",\"end\":\"$731\"}\n72e:{\"type\":\"text\",\"value\":\" section of the compute supplement for justification and details). Each superhuman coder scaffold built on Agent-3 has, on average, the equivalent of roughly four Agent-3 copies running under the hood (which may really be a collection of smaller or specialized models to which Agent-3 delegates subtasks).\",\"position\":\"$72f\"}\n720:[\"$721\",\"$725\",\"$72e\"]\n733:{\"line\":782,\"column\":9,\"offset\":119062}\n734:{\"line\":782,\"column\":654,\"offset\":119707}\n732:{\"start\":\"$733\",\"end\":\"$734\"}\n71f:{\"type\":\"paragraph\",\"children\":\"$720\",\"position\":\"$732\"}\n71e:[\"$71f\"]\n73a:{\"line\":784,\"column\":9,\"offset\":119717}\n73b:{\"line\":784,\"column\":194,\"offset\":119902}\n739:{\"start\":\"$73a\",\"end\":\"$73b\"}\n738:{\"type\":\"text\",\"value\":\"Some aspects play to AIs’ strengt"])</script><script>self.__next_f.push([1,"hs, e.g. returns from knowing the machine learning literature and speed or cost of generating lots of ideas. But these are outweighed by the weaknesses.\",\"position\":\"$739\"}\n737:[\"$738\"]\n73d:{\"line\":784,\"column\":9,\"offset\":119717}\n73e:{\"line\":784,\"column\":194,\"offset\":119902}\n73c:{\"start\":\"$73d\",\"end\":\"$73e\"}\n736:{\"type\":\"paragraph\",\"children\":\"$737\",\"position\":\"$73c\"}\n735:[\"$736\"]\n744:{\"line\":786,\"column\":9,\"offset\":119912}\n745:{\"line\":786,\"column\":92,\"offset\":119995}\n743:{\"start\":\"$744\",\"end\":\"$745\"}\n742:{\"type\":\"text\",\"value\":\"Why only 4x? It’s our uncertain best guess based on the reasoning described in our \",\"position\":\"$743\"}\n74a:{\"line\":786,\"column\":93,\"offset\":119996}\n74b:{\"line\":786,\"column\":111,\"offset\":120014}\n749:{\"start\":\"$74a\",\"end\":\"$74b\"}\n748:{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":\"$749\"}\n747:[\"$748\"]\n74d:{\"line\":786,\"column\":92,\"offset\":119995}\n74e:{\"line\":786,\"column\":161,\"offset\":120064}\n74c:{\"start\":\"$74d\",\"end\":\"$74e\"}\n746:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":\"$747\",\"position\":\"$74c\"}\n751:{\"line\":786,\"column\":161,\"offset\":120064}\n752:{\"line\":786,\"column\":461,\"offset\":120364}\n750:{\"start\":\"$751\",\"end\":\"$752\"}\n74f:{\"type\":\"text\",\"value\":\". About half of total progress historically has come from improved algorithms (which includes better ideas and new paradigms), the other half having come from scaled-up compute. So a 4x increase in the rate of algorithmic progress corresponds to a roughly 2x increase in the overall rate of progress.\",\"position\":\"$750\"}\n741:[\"$742\",\"$746\",\"$74f\"]\n754:{\"line\":786,\"column\":9,\"offset\":119912}\n755:{\"line\":786,\"column\":461,\"offset\":120364}\n753:{\"start\":\"$754\",\"end\":\"$755\"}\n740:{\"type\":\"paragraph\",\"children\":\"$741\",\"position\":\"$753\"}\n73f:[\"$740\"]\n75b:{\"line\":788,\"column\":9,\"offset\":120374}\n75c:{\"line\":788,\"column\":79,\"offset\":120444}\n75a:{\"start\":\"$75b\",\"end\":\"$75c\"}\n759:{\"type\":\"text\",\"value\":\"For comparison, the human brain has about a hundred trillion synapses.\",\"position\":\"$75a\"}\n758:[\"$759"])</script><script>self.__next_f.push([1,"\"]\n75e:{\"line\":788,\"column\":9,\"offset\":120374}\n75f:{\"line\":788,\"column\":79,\"offset\":120444}\n75d:{\"start\":\"$75e\",\"end\":\"$75f\"}\n757:{\"type\":\"paragraph\",\"children\":\"$758\",\"position\":\"$75d\"}\n756:[\"$757\"]\n765:{\"line\":790,\"column\":9,\"offset\":120454}\n766:{\"line\":790,\"column\":13,\"offset\":120458}\n764:{\"start\":\"$765\",\"end\":\"$766\"}\n763:{\"type\":\"text\",\"value\":\"See \",\"position\":\"$764\"}\n76b:{\"line\":790,\"column\":14,\"offset\":120459}\n76c:{\"line\":790,\"column\":24,\"offset\":120469}\n76a:{\"start\":\"$76b\",\"end\":\"$76c\"}\n769:{\"type\":\"text\",\"value\":\"this paper\",\"position\":\"$76a\"}\n768:[\"$769\"]\n76e:{\"line\":790,\"column\":13,\"offset\":120458}\n76f:{\"line\":790,\"column\":129,\"offset\":120574}\n76d:{\"start\":\"$76e\",\"end\":\"$76f\"}\n767:{\"type\":\"link\",\"title\":null,\"url\":\"https://www-cdn.anthropic.com/e4f69aacd8c0905030172bc6eb480c252ea7d6ad/model-written-evals.pdf#page=28\",\"children\":\"$768\",\"position\":\"$76d\"}\n772:{\"line\":790,\"column\":129,\"offset\":120574}\n773:{\"line\":790,\"column\":171,\"offset\":120616}\n771:{\"start\":\"$772\",\"end\":\"$773\"}\n770:{\"type\":\"text\",\"value\":\" for examples of this type of AI behavior.\",\"position\":\"$771\"}\n762:[\"$763\",\"$767\",\"$770\"]\n775:{\"line\":790,\"column\":9,\"offset\":120454}\n776:{\"line\":790,\"column\":171,\"offset\":120616}\n774:{\"start\":\"$775\",\"end\":\"$776\"}\n761:{\"type\":\"paragraph\",\"children\":\"$762\",\"position\":\"$774\"}\n760:[\"$761\"]\n77c:{\"line\":792,\"column\":9,\"offset\":120626}\n77d:{\"line\":792,\"column\":232,\"offset\":120849}\n77b:{\"start\":\"$77c\",\"end\":\"$77d\"}\n77a:{\"type\":\"text\",\"value\":\"Most people, including most experts, seem to have underestimated the pace of AI progress over the past decade. There are many anecdotal examples of this; for two somewhat more systematic (though still limited) analyses see \",\"position\":\"$77b\"}\n782:{\"line\":792,\"column\":233,\"offset\":120850}\n783:{\"line\":792,\"column\":237,\"offset\":120854}\n781:{\"start\":\"$782\",\"end\":\"$783\"}\n780:{\"type\":\"text\",\"value\":\"here\",\"position\":\"$781\"}\n77f:[\"$780\"]\n785:{\"line\":792,\"column\":232,\"offset\":120849}\n786:{\"line\":792,\"column\":306,\"offset\":120923}\n784:{\"start\":\"$785\",\"end\":\"$786\"}\n77e:{\"type\":\"li"])</script><script>self.__next_f.push([1,"nk\",\"title\":null,\"url\":\"https://www.planned-obsolescence.org/language-models-surprised-us/\",\"children\":\"$77f\",\"position\":\"$784\"}\n789:{\"line\":792,\"column\":306,\"offset\":120923}\n78a:{\"line\":792,\"column\":311,\"offset\":120928}\n788:{\"start\":\"$789\",\"end\":\"$78a\"}\n787:{\"type\":\"text\",\"value\":\" and \",\"position\":\"$788\"}\n78f:{\"line\":792,\"column\":312,\"offset\":120929}\n790:{\"line\":792,\"column\":316,\"offset\":120933}\n78e:{\"start\":\"$78f\",\"end\":\"$790\"}\n78d:{\"type\":\"text\",\"value\":\"here\",\"position\":\"$78e\"}\n78c:[\"$78d\"]\n792:{\"line\":792,\"column\":311,\"offset\":120928}\n793:{\"line\":792,\"column\":381,\"offset\":120998}\n791:{\"start\":\"$792\",\"end\":\"$793\"}\n78b:{\"type\":\"link\",\"title\":null,\"url\":\"https://blog.aiimpacts.org/p/2023-ai-survey-of-2778-six-things\",\"children\":\"$78c\",\"position\":\"$791\"}\n796:{\"line\":792,\"column\":381,\"offset\":120998}\n797:{\"line\":792,\"column\":382,\"offset\":120999}\n795:{\"start\":\"$796\",\"end\":\"$797\"}\n794:{\"type\":\"text\",\"value\":\".\",\"position\":\"$795\"}\n779:[\"$77a\",\"$77e\",\"$787\",\"$78b\",\"$794\"]\n799:{\"line\":792,\"column\":9,\"offset\":120626}\n79a:{\"line\":792,\"column\":382,\"offset\":120999}\n798:{\"start\":\"$799\",\"end\":\"$79a\"}\n778:{\"type\":\"paragraph\",\"children\":\"$779\",\"position\":\"$798\"}\n777:[\"$778\"]\n7a0:{\"line\":794,\"column\":9,\"offset\":121009}\n7a1:{\"line\":794,\"column\":113,\"offset\":121113}\n79f:{\"start\":\"$7a0\",\"end\":\"$7a1\"}\n79e:{\"type\":\"text\",\"value\":\"The last decade is full of examples of things that sound like science fiction becoming reality. But the \",\"position\":\"$79f\"}\n7a6:{\"line\":794,\"column\":114,\"offset\":121114}\n7a7:{\"line\":794,\"column\":128,\"offset\":121128}\n7a5:{\"start\":\"$7a6\",\"end\":\"$7a7\"}\n7a4:{\"type\":\"text\",\"value\":\"Overton window\",\"position\":\"$7a5\"}\n7a3:[\"$7a4\"]\n7a9:{\"line\":794,\"column\":113,\"offset\":121113}\n7aa:{\"line\":794,\"column\":175,\"offset\":121175}\n7a8:{\"start\":\"$7a9\",\"end\":\"$7aa\"}\n7a2:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Overton_window\",\"children\":\"$7a3\",\"position\":\"$7a8\"}\n7ad:{\"line\":794,\"column\":175,\"offset\":121175}\n7ae:{\"line\":794,\"column\":284,\"offset\":121284}\n7ac:{\"start\":\"$7ad\",\"end\":\"$7ae\"}\n7ab:{\"type\":\""])</script><script>self.__next_f.push([1,"text\",\"value\":\" seems to shift just fast enough to keep somewhat ahead of what already exists. Anthropic CEO Dario Amodei’s \",\"position\":\"$7ac\"}\n7b3:{\"line\":794,\"column\":285,\"offset\":121285}\n7b4:{\"line\":794,\"column\":327,\"offset\":121327}\n7b2:{\"start\":\"$7b3\",\"end\":\"$7b4\"}\n7b1:{\"type\":\"text\",\"value\":\"commendable essay Machines of Loving Grace\",\"position\":\"$7b2\"}\n7b0:[\"$7b1\"]\n7b6:{\"line\":794,\"column\":284,\"offset\":121284}\n7b7:{\"line\":794,\"column\":378,\"offset\":121378}\n7b5:{\"start\":\"$7b6\",\"end\":\"$7b7\"}\n7af:{\"type\":\"link\",\"title\":null,\"url\":\"https://darioamodei.com/machines-of-loving-grace\",\"children\":\"$7b0\",\"position\":\"$7b5\"}\n7ba:{\"line\":794,\"column\":378,\"offset\":121378}\n7bb:{\"line\":794,\"column\":777,\"offset\":121777}\n7b9:{\"start\":\"$7ba\",\"end\":\"$7bb\"}\n7b8:{\"type\":\"text\",\"value\":\" talks about how very soon AIs will be like a “country of geniuses in a datacenter,” and how there’ll be a century of technological progress happening in a decade, but strives to avoid “sci-fi baggage” and says people who think progress will be even crazier need to “touch grass.” We expect important people to be saying similar things when the country of geniuses in the datacenter actually exists.\",\"position\":\"$7b9\"}\n79d:[\"$79e\",\"$7a2\",\"$7ab\",\"$7af\",\"$7b8\"]\n7bd:{\"line\":794,\"column\":9,\"offset\":121009}\n7be:{\"line\":794,\"column\":777,\"offset\":121777}\n7bc:{\"start\":\"$7bd\",\"end\":\"$7be\"}\n79c:{\"type\":\"paragraph\",\"children\":\"$79d\",\"position\":\"$7bc\"}\n79b:[\"$79c\"]\n7c3:T414,Since Agent-3 is such a big file (on the order of 10 terabytes at full precision), OpenBrain is able to execute a relatively quick fix to make theft attempts much more difficult than what China was able to do to steal Agent-2—namely, closing a bunch of high bandwidth internet connections out of their datacenters. Overall this has a relatively low penalty to progress and puts them at “3-month SL4” for their frontier weights, or WSL4 as defined in our security supplement, meaning that another similar theft attempt would now require over 3 months to finish exfiltrating the "])</script><script>self.__next_f.push([1,"weights file. Through this method alone they still don’t have guarantees under a more invasive OC5-level effort ($1B budget, 1,000 dedicated experts), which China would be capable of with a more intensive operation, but with elaborate inspections of the datacenters and their espionage network on high-alert, the U.S. intelligence agencies are confident that they would at least know in advance if China was gearing up for this kind of theft attempt. See the 7c5:{\"line\":796,\"column\":9,\"offset\":121787}\n7c6:{\"line\":796,\"column\":1045,\"offset\":122823}\n7c4:{\"start\":\"$7c5\",\"end\":\"$7c6\"}\n7c2:{\"type\":\"text\",\"value\":\"$7c3\",\"position\":\"$7c4\"}\n7cb:{\"line\":796,\"column\":1046,\"offset\":122824}\n7cc:{\"line\":796,\"column\":1065,\"offset\":122843}\n7ca:{\"start\":\"$7cb\",\"end\":\"$7cc\"}\n7c9:{\"type\":\"text\",\"value\":\"security supplement\",\"position\":\"$7ca\"}\n7c8:[\"$7c9\"]\n7ce:{\"line\":796,\"column\":1045,\"offset\":122823}\n7cf:{\"line\":796,\"column\":1117,\"offset\":122895}\n7cd:{\"start\":\"$7ce\",\"end\":\"$7cf\"}\n7c7:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/security-forecast\",\"children\":\"$7c8\",\"position\":\"$7cd\"}\n7d2:{\"line\":796,\"column\":1117,\"offset\":122895}\n7d3:{\"line\":796,\"column\":1135,\"offset\":122913}\n7d1:{\"start\":\"$7d2\",\"end\":\"$7d3\"}\n7d0:{\"type\":\"text\",\"value\":\" for more details.\",\"position\":\"$7d1\"}\n7c1:[\"$7c2\",\"$7c7\",\"$7d0\"]\n7d5:{\"line\":796,\"column\":9,\"offset\":121787}\n7d6:{\"line\":796,\"column\":1135,\"offset\":122913}\n7d4:{\"start\":\"$7d5\",\"end\":\"$7d6\"}\n7c0:{\"type\":\"paragraph\",\"children\":\"$7c1\",\"position\":\"$7d4\"}\n7bf:[\"$7c0\"]\n7dc:{\"line\":798,\"column\":9,\"offset\":122923}\n7dd:{\"line\":798,\"column\":219,\"offset\":123133}\n7db:{\"start\":\"$7dc\",\"end\":\"$7dd\"}\n7da:{\"type\":\"text\",\"value\":\"This could be for a variety of reasons. Perhaps they are being blackmailed, perhaps they are sympathetic to the CCP, perhaps they mistakenly think they are giving secrets to a different country or organization.\",\"position\":\"$7db\"}\n7d9:[\"$7da\"]\n7df:{\"line\":798,\"column\":9,\"offset\":122923}\n7e0:{\"line\":798,\"column\":219,\"offset\":123133}\n7de:{\"start\":\"$7df\",\"end\":\"$7e0\"}\n7d8:"])</script><script>self.__next_f.push([1,"{\"type\":\"paragraph\",\"children\":\"$7d9\",\"position\":\"$7de\"}\n7d7:[\"$7d8\"]\n7e6:{\"line\":800,\"column\":9,\"offset\":123143}\n7e7:{\"line\":800,\"column\":109,\"offset\":123243}\n7e5:{\"start\":\"$7e6\",\"end\":\"$7e7\"}\n7e4:{\"type\":\"text\",\"value\":\"Because OpenBrain hasn’t deployed their best models in the EU, the EU is similarly behind the curve.\",\"position\":\"$7e5\"}\n7e3:[\"$7e4\"]\n7e9:{\"line\":800,\"column\":9,\"offset\":123143}\n7ea:{\"line\":800,\"column\":109,\"offset\":123243}\n7e8:{\"start\":\"$7e9\",\"end\":\"$7ea\"}\n7e2:{\"type\":\"paragraph\",\"children\":\"$7e3\",\"position\":\"$7e8\"}\n7e1:[\"$7e2\"]\n7f0:{\"line\":802,\"column\":9,\"offset\":123253}\n7f1:{\"line\":802,\"column\":13,\"offset\":123257}\n7ef:{\"start\":\"$7f0\",\"end\":\"$7f1\"}\n7ee:{\"type\":\"text\",\"value\":\"See \",\"position\":\"$7ef\"}\n7f6:{\"line\":802,\"column\":14,\"offset\":123258}\n7f7:{\"line\":802,\"column\":47,\"offset\":123291}\n7f5:{\"start\":\"$7f6\",\"end\":\"$7f7\"}\n7f4:{\"type\":\"text\",\"value\":\"Section 4 of the Compute Forecast\",\"position\":\"$7f5\"}\n7f3:[\"$7f4\"]\n7f9:{\"line\":802,\"column\":13,\"offset\":123257}\n7fa:{\"line\":802,\"column\":131,\"offset\":123375}\n7f8:{\"start\":\"$7f9\",\"end\":\"$7fa\"}\n7f2:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-4-ai-research-automation\",\"children\":\"$7f3\",\"position\":\"$7f8\"}\n7fd:{\"line\":802,\"column\":131,\"offset\":123375}\n7fe:{\"line\":802,\"column\":149,\"offset\":123393}\n7fc:{\"start\":\"$7fd\",\"end\":\"$7fe\"}\n7fb:{\"type\":\"text\",\"value\":\" for more details.\",\"position\":\"$7fc\"}\n7ed:[\"$7ee\",\"$7f2\",\"$7fb\"]\n800:{\"line\":802,\"column\":9,\"offset\":123253}\n801:{\"line\":802,\"column\":149,\"offset\":123393}\n7ff:{\"start\":\"$800\",\"end\":\"$801\"}\n7ec:{\"type\":\"paragraph\",\"children\":\"$7ed\",\"position\":\"$7ff\"}\n7eb:[\"$7ec\"]\n807:{\"line\":804,\"column\":9,\"offset\":123403}\n808:{\"line\":804,\"column\":673,\"offset\":124067}\n806:{\"start\":\"$807\",\"end\":\"$808\"}\n805:{\"type\":\"text\",\"value\":\"Agent-3 has learned how to use its inference compute more efficiently. It has control over its own inference choices: for example, it decides how much effort to put into different tasks, based on their importance and difficulty. It uses a vari"])</script><script>self.__next_f.push([1,"ety of techniques to allocate additional inference compute such as “thinking longer” (e.g. longer chain of thought), “planning ahead” (e.g. tree search), taking the best of multiple attempts (i.e. best of K), and simply creating and running more copies of itself to power through bottlenecks. Top priority tasks are run with highly parallelized agents that are compute intensive but still operate much faster than humans.\",\"position\":\"$806\"}\n804:[\"$805\"]\n80a:{\"line\":804,\"column\":9,\"offset\":123403}\n80b:{\"line\":804,\"column\":673,\"offset\":124067}\n809:{\"start\":\"$80a\",\"end\":\"$80b\"}\n803:{\"type\":\"paragraph\",\"children\":\"$804\",\"position\":\"$809\"}\n802:[\"$803\"]\n811:{\"line\":806,\"column\":9,\"offset\":124077}\n812:{\"line\":806,\"column\":146,\"offset\":124214}\n810:{\"start\":\"$811\",\"end\":\"$812\"}\n80f:{\"type\":\"text\",\"value\":\"Agent-3-mini is a distilled version of Agent-3, designed to be efficient to run inference so as to not bottleneck the internal workloads.\",\"position\":\"$810\"}\n80e:[\"$80f\"]\n814:{\"line\":806,\"column\":9,\"offset\":124077}\n815:{\"line\":806,\"column\":147,\"offset\":124215}\n813:{\"start\":\"$814\",\"end\":\"$815\"}\n80d:{\"type\":\"paragraph\",\"children\":\"$80e\",\"position\":\"$813\"}\n80c:[\"$80d\"]\n81b:{\"line\":808,\"column\":9,\"offset\":124225}\n81c:{\"line\":808,\"column\":167,\"offset\":124383}\n81a:{\"start\":\"$81b\",\"end\":\"$81c\"}\n819:{\"type\":\"text\",\"value\":\"Such data had been scrubbed or redacted during Agent-3’s training, but it’s a relatively simple matter to scrape it off the internet and fine-tune it back in.\",\"position\":\"$81a\"}\n818:[\"$819\"]\n81e:{\"line\":808,\"column\":9,\"offset\":124225}\n81f:{\"line\":808,\"column\":167,\"offset\":124383}\n81d:{\"start\":\"$81e\",\"end\":\"$81f\"}\n817:{\"type\":\"paragraph\",\"children\":\"$818\",\"position\":\"$81d\"}\n816:[\"$817\"]\n825:{\"line\":810,\"column\":9,\"offset\":124393}\n826:{\"line\":810,\"column\":953,\"offset\":125337}\n824:{\"start\":\"$825\",\"end\":\"$826\"}\n823:{\"type\":\"text\",\"value\":\"This hasn’t happened yet—at least not with the latest models. But older models have already been trialed for various data-analysis and surveillance roles, and there"])</script><script>self.__next_f.push([1," are many exciting plans for future integrations. We aren't legal experts ourselves, and policy people we talk to have been divided about the legality of using the DPA to consolidate compute: some think it would be fine, others think it wouldn't fly. Our opinion is that there's probably a way to make it 'work' IF the CEOs of the companies are cooperative, and maybe even if not. Importantly, (a) the executive branch can just do things and wait for the courts to catch up later, and (b) POTUS wields many sticks and many carrots which he can use against big tech companies, and he can use the combination of sticks and carrots to pressure their CEOs into cooperating and e.g., not contesting his orders in court. Reminder that we're making predictions here, not recommendations.\",\"position\":\"$824\"}\n822:[\"$823\"]\n828:{\"line\":810,\"column\":9,\"offset\":124393}\n829:{\"line\":810,\"column\":953,\"offset\":125337}\n827:{\"start\":\"$828\",\"end\":\"$829\"}\n821:{\"type\":\"paragraph\",\"children\":\"$822\",\"position\":\"$827\"}\n820:[\"$821\"]\n82f:{\"line\":813,\"column\":9,\"offset\":125348}\n830:{\"line\":813,\"column\":77,\"offset\":125416}\n82e:{\"start\":\"$82f\",\"end\":\"$830\"}\n82d:{\"type\":\"text\",\"value\":\"OpenBrain’s net favorability rating is falling towards negative 40%.\",\"position\":\"$82e\"}\n82c:[\"$82d\"]\n832:{\"line\":813,\"column\":9,\"offset\":125348}\n833:{\"line\":813,\"column\":77,\"offset\":125416}\n831:{\"start\":\"$832\",\"end\":\"$833\"}\n82b:{\"type\":\"paragraph\",\"children\":\"$82c\",\"position\":\"$831\"}\n82a:[\"$82b\"]\n839:{\"line\":815,\"column\":9,\"offset\":125426}\n83a:{\"line\":815,\"column\":168,\"offset\":125585}\n838:{\"start\":\"$839\",\"end\":\"$83a\"}\n837:{\"type\":\"text\",\"value\":\"If the CEOs of the companies resist, pulling this off would be a huge political and legal nightmare. But perhaps they can be brought in and thereby bought off.\",\"position\":\"$838\"}\n836:[\"$837\"]\n83c:{\"line\":815,\"column\":9,\"offset\":125426}\n83d:{\"line\":815,\"column\":168,\"offset\":125585}\n83b:{\"start\":\"$83c\",\"end\":\"$83d\"}\n835:{\"type\":\"paragraph\",\"children\":\"$836\",\"position\":\"$83b\"}\n834:[\"$835\"]\n843:{\"line\":817,\"column\":9,\"offset\":12559"])</script><script>self.__next_f.push([1,"5}\n844:{\"line\":817,\"column\":178,\"offset\":125764}\n842:{\"start\":\"$843\",\"end\":\"$844\"}\n841:{\"type\":\"text\",\"value\":\"Defense officials aren’t especially concerned about what a rogue AI could do on its own, but they fear what it could do in collaboration with U.S. adversaries. Analogy: \",\"position\":\"$842\"}\n849:{\"line\":817,\"column\":179,\"offset\":125765}\n84a:{\"line\":817,\"column\":185,\"offset\":125771}\n848:{\"start\":\"$849\",\"end\":\"$84a\"}\n847:{\"type\":\"text\",\"value\":\"Cortés\",\"position\":\"$848\"}\n846:[\"$847\"]\n84c:{\"line\":817,\"column\":178,\"offset\":125764}\n84d:{\"line\":817,\"column\":290,\"offset\":125876}\n84b:{\"start\":\"$84c\",\"end\":\"$84d\"}\n845:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/ivpKSjM4D6FbqF4pZ/cortes-pizarro-and-afonso-as-precedents-for-takeover\",\"children\":\"$846\",\"position\":\"$84b\"}\n850:{\"line\":817,\"column\":290,\"offset\":125876}\n851:{\"line\":817,\"column\":453,\"offset\":126039}\n84f:{\"start\":\"$850\",\"end\":\"$851\"}\n84e:{\"type\":\"text\",\"value\":\" escaped Tenochtitlán and allied with Tlaxcala and various other rival city-states, ultimately razing Tenochtitlan to the ground using predominantly-native armies.\",\"position\":\"$84f\"}\n840:[\"$841\",\"$845\",\"$84e\"]\n853:{\"line\":817,\"column\":9,\"offset\":125595}\n854:{\"line\":817,\"column\":453,\"offset\":126039}\n852:{\"start\":\"$853\",\"end\":\"$854\"}\n83f:{\"type\":\"paragraph\",\"children\":\"$840\",\"position\":\"$852\"}\n83e:[\"$83f\"]\n85a:{\"line\":819,\"column\":9,\"offset\":126049}\n85b:{\"line\":819,\"column\":384,\"offset\":126424}\n859:{\"start\":\"$85a\",\"end\":\"$85b\"}\n858:{\"type\":\"text\",\"value\":\"Specifically 60% of the national compute is now in the CDZ making it a 5M 2024-equivalent-GPU (H100) site, with 4 GW of power draw (over the past several months they started directing close to 100% of new compute to the CDZ, up from the 80% rate in late 2026). An additional 15% of their compute is outside of the CDZ, but still used by DeepCent on lower-stakes applications.\",\"position\":\"$859\"}\n857:[\"$858\"]\n85d:{\"line\":819,\"column\":9,\"offset\":126049}\n85e:{\"line\":819,\"column\":384,\"offset\":126424}\n85c:{\"start\":\"$85d\",\"end\":\"$8"])</script><script>self.__next_f.push([1,"5e\"}\n856:{\"type\":\"paragraph\",\"children\":\"$857\",\"position\":\"$85c\"}\n855:[\"$856\"]\n864:{\"line\":821,\"column\":9,\"offset\":126434}\n865:{\"line\":821,\"column\":641,\"offset\":127066}\n863:{\"start\":\"$864\",\"end\":\"$865\"}\n862:{\"type\":\"text\",\"value\":\"This statement, while widely repeated, is also controversial and complex. First of all, there are many narrow domains (e.g. specific games) in which tiny AIs can be cheaply trained to superhuman performance. Secondly, again for some domains, tiny AIs can be trained to superhuman performance while only experiencing a small amount of data (e.g. EfficientZero). However, considering more general-purpose AIs like the flagship products of 2025, which are supposed to be good at a wide range of real-world skills, it does seem that both more compute and more data must be used to train those skills than it should take to train humans.\",\"position\":\"$863\"}\n861:[\"$862\"]\n867:{\"line\":821,\"column\":9,\"offset\":126434}\n868:{\"line\":821,\"column\":641,\"offset\":127066}\n866:{\"start\":\"$867\",\"end\":\"$868\"}\n860:{\"type\":\"paragraph\",\"children\":\"$861\",\"position\":\"$866\"}\n85f:[\"$860\"]\n86e:{\"line\":823,\"column\":9,\"offset\":127076}\n86f:{\"line\":823,\"column\":397,\"offset\":127464}\n86d:{\"start\":\"$86e\",\"end\":\"$86f\"}\n86c:{\"type\":\"text\",\"value\":\"Human level compute-efficiency is a rough concept, and depends on what we’re counting. What we mean by this is that, for any skillset a particular human has, Agent-4 can learn to be at least that good at that skillset, and moreover, by using an amount of compute to train those skills that is only about 4,000x the amount of compute the human used to learn those skills. For reference, a \",\"position\":\"$86d\"}\n874:{\"line\":823,\"column\":398,\"offset\":127465}\n875:{\"line\":823,\"column\":434,\"offset\":127501}\n873:{\"start\":\"$874\",\"end\":\"$875\"}\n872:{\"type\":\"text\",\"value\":\"human brain uses roughly 1e15 FLOP/s\",\"position\":\"$873\"}\n871:[\"$872\"]\n877:{\"line\":823,\"column\":397,\"offset\":127464}\n878:{\"line\":823,\"column\":546,\"offset\":127613}\n876:{\"start\":\"$877\",\"end\":\"$878\"}\n870:{\"type\":\"link\",\"title\":null,\"url\":\"h"])</script><script>self.__next_f.push([1,"ttps://www.openphilanthropy.org/research/how-much-computational-power-does-it-take-to-match-the-human-brain/\",\"children\":\"$871\",\"position\":\"$876\"}\n87b:{\"line\":823,\"column\":546,\"offset\":127613}\n87c:{\"line\":823,\"column\":581,\"offset\":127648}\n87a:{\"start\":\"$87b\",\"end\":\"$87c\"}\n879:{\"type\":\"text\",\"value\":\" of compute, and so a 30 year old (\",\"position\":\"$87a\"}\n880:[\"language-math\",\"math-inline\"]\n87f:{\"className\":\"$880\"}\n882:{\"type\":\"text\",\"value\":\"10^9\"}\n881:[\"$882\"]\n87e:{\"hName\":\"code\",\"hProperties\":\"$87f\",\"hChildren\":\"$881\"}\n884:{\"line\":823,\"column\":581,\"offset\":127648}\n885:{\"line\":823,\"column\":589,\"offset\":127656}\n883:{\"start\":\"$884\",\"end\":\"$885\"}\n87d:{\"type\":\"inlineMath\",\"value\":\"10^9\",\"data\":\"$87e\",\"position\":\"$883\"}\n888:{\"line\":823,\"column\":589,\"offset\":127656}\n889:{\"line\":823,\"column\":627,\"offset\":127694}\n887:{\"start\":\"$888\",\"end\":\"$889\"}\n886:{\"type\":\"text\",\"value\":\" seconds) human has experienced about \",\"position\":\"$887\"}\n88d:[\"language-math\",\"math-inline\"]\n88c:{\"className\":\"$88d\"}\n88f:{\"type\":\"text\",\"value\":\"10^{24}\"}\n88e:[\"$88f\"]\n88b:{\"hName\":\"code\",\"hProperties\":\"$88c\",\"hChildren\":\"$88e\"}\n891:{\"line\":823,\"column\":627,\"offset\":127694}\n892:{\"line\":823,\"column\":638,\"offset\":127705}\n890:{\"start\":\"$891\",\"end\":\"$892\"}\n88a:{\"type\":\"inlineMath\",\"value\":\"10^{24}\",\"data\":\"$88b\",\"position\":\"$890\"}\n895:{\"line\":823,\"column\":638,\"offset\":127705}\n896:{\"line\":823,\"column\":721,\"offset\":127788}\n894:{\"start\":\"$895\",\"end\":\"$896\"}\n893:{\"type\":\"text\",\"value\":\" FLOP. The project at this point, has 100M H100-equivalents, for a total access of \",\"position\":\"$894\"}\n89a:[\"language-math\",\"math-inline\"]\n899:{\"className\":\"$89a\"}\n89c:{\"type\":\"text\",\"value\":\"10^8 \\\\\\\\textrm{ H100s} \\\\\\\\cdot 10^{15} \\\\\\\\frac{\\\\\\\\text{FLOP}}{\\\\\\\\textrm{H100} \\\\\\\\cdot \\\\\\\\textrm{s}} \\\\\\\\cdot 40\\\\\\\\% \\\\\\\\text{ utilization} \\\\= 4 \\\\\\\\cdot 10^{22} \\\\\\\\text{ FLOP/s}\"}\n89b:[\"$89c\"]\n898:{\"hName\":\"code\",\"hProperties\":\"$899\",\"hChildren\":\"$89b\"}\n89e:{\"line\":823,\"column\":721,\"offset\":127788}\n89f:{\"line\":823,\"column\":887,\"offset\":127954}\n89d:{\"start\":\"$89e\",\"end\":\"$89f"])</script><script>self.__next_f.push([1,"\"}\n897:{\"type\":\"inlineMath\",\"value\":\"10^8 \\\\\\\\textrm{ H100s} \\\\\\\\cdot 10^{15} \\\\\\\\frac{\\\\\\\\text{FLOP}}{\\\\\\\\textrm{H100} \\\\\\\\cdot \\\\\\\\textrm{s}} \\\\\\\\cdot 40\\\\\\\\% \\\\\\\\text{ utilization} \\\\= 4 \\\\\\\\cdot 10^{22} \\\\\\\\text{ FLOP/s}\",\"data\":\"$898\",\"position\":\"$89d\"}\n8a2:{\"line\":823,\"column\":887,\"offset\":127954}\n8a3:{\"line\":823,\"column\":1066,\"offset\":128133}\n8a1:{\"start\":\"$8a2\",\"end\":\"$8a3\"}\n8a0:{\"type\":\"text\",\"value\":\". Still, this is all done tremendously inefficiently for a variety of reasons, so the models are now a factor of 4000 less compute-efficient than humans, which means they require \",\"position\":\"$8a1\"}\n8a7:[\"language-math\",\"math-inline\"]\n8a6:{\"className\":\"$8a7\"}\n8a9:{\"type\":\"text\",\"value\":\"4 \\\\\\\\cdot 10^{27}\"}\n8a8:[\"$8a9\"]\n8a5:{\"hName\":\"code\",\"hProperties\":\"$8a6\",\"hChildren\":\"$8a8\"}\n8ab:{\"line\":823,\"column\":1066,\"offset\":128133}\n8ac:{\"line\":823,\"column\":1086,\"offset\":128153}\n8aa:{\"start\":\"$8ab\",\"end\":\"$8ac\"}\n8a4:{\"type\":\"inlineMath\",\"value\":\"4 \\\\\\\\cdot 10^{27}\",\"data\":\"$8a5\",\"position\":\"$8aa\"}\n8af:{\"line\":823,\"column\":1086,\"offset\":128153}\n8b0:{\"line\":823,\"column\":1124,\"offset\":128191}\n8ae:{\"start\":\"$8af\",\"end\":\"$8b0\"}\n8ad:{\"type\":\"text\",\"value\":\" FLOP to get to human performance and \",\"position\":\"$8ae\"}\n8b4:[\"language-math\",\"math-inline\"]\n8b3:{\"className\":\"$8b4\"}\n8b6:{\"type\":\"text\",\"value\":\"4 \\\\\\\\cdot 10^{28}\"}\n8b5:[\"$8b6\"]\n8b2:{\"hName\":\"code\",\"hProperties\":\"$8b3\",\"hChildren\":\"$8b5\"}\n8b8:{\"line\":823,\"column\":1124,\"offset\":128191}\n8b9:{\"line\":823,\"column\":1144,\"offset\":128211}\n8b7:{\"start\":\"$8b8\",\"end\":\"$8b9\"}\n8b1:{\"type\":\"inlineMath\",\"value\":\"4 \\\\\\\\cdot 10^{28}\",\"data\":\"$8b2\",\"position\":\"$8b7\"}\n8bc:{\"line\":823,\"column\":1144,\"offset\":128211}\n8bd:{\"line\":823,\"column\":1394,\"offset\":128461}\n8bb:{\"start\":\"$8bc\",\"end\":\"$8bd\"}\n8ba:{\"type\":\"text\",\"value\":\" FLOP to get to the point where they have the equivalent of 10 human lifetimes of knowledge. After this architecture showed great promise at smaller scales, it was scaled up and now takes a large subset of the project cluster around 3 weeks to train.\",\"position\":\"$"])</script><script>self.__next_f.push([1,"8bb\"}\n86b:[\"$86c\",\"$870\",\"$879\",\"$87d\",\"$886\",\"$88a\",\"$893\",\"$897\",\"$8a0\",\"$8a4\",\"$8ad\",\"$8b1\",\"$8ba\"]\n8bf:{\"line\":823,\"column\":9,\"offset\":127076}\n8c0:{\"line\":823,\"column\":1395,\"offset\":128462}\n8be:{\"start\":\"$8bf\",\"end\":\"$8c0\"}\n86a:{\"type\":\"paragraph\",\"children\":\"$86b\",\"position\":\"$8be\"}\n869:[\"$86a\"]\n8c6:{\"line\":825,\"column\":9,\"offset\":128472}\n8c7:{\"line\":825,\"column\":89,\"offset\":128552}\n8c5:{\"start\":\"$8c6\",\"end\":\"$8c7\"}\n8c4:{\"type\":\"text\",\"value\":\"See the inference compute analysis in the AI research automation section of the \",\"position\":\"$8c5\"}\n8cc:{\"line\":825,\"column\":90,\"offset\":128553}\n8cd:{\"line\":825,\"column\":106,\"offset\":128569}\n8cb:{\"start\":\"$8cc\",\"end\":\"$8cd\"}\n8ca:{\"type\":\"text\",\"value\":\"compute forecast\",\"position\":\"$8cb\"}\n8c9:[\"$8ca\"]\n8cf:{\"line\":825,\"column\":89,\"offset\":128552}\n8d0:{\"line\":825,\"column\":187,\"offset\":128650}\n8ce:{\"start\":\"$8cf\",\"end\":\"$8d0\"}\n8c8:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/compute-forecast#section-4-ai-research-automation\",\"children\":\"$8c9\",\"position\":\"$8ce\"}\n8d3:{\"line\":825,\"column\":187,\"offset\":128650}\n8d4:{\"line\":825,\"column\":188,\"offset\":128651}\n8d2:{\"start\":\"$8d3\",\"end\":\"$8d4\"}\n8d1:{\"type\":\"text\",\"value\":\".\",\"position\":\"$8d2\"}\n8c3:[\"$8c4\",\"$8c8\",\"$8d1\"]\n8d6:{\"line\":825,\"column\":9,\"offset\":128472}\n8d7:{\"line\":825,\"column\":188,\"offset\":128651}\n8d5:{\"start\":\"$8d6\",\"end\":\"$8d7\"}\n8c2:{\"type\":\"paragraph\",\"children\":\"$8c3\",\"position\":\"$8d5\"}\n8c1:[\"$8c2\"]\n8dd:{\"line\":827,\"column\":9,\"offset\":128661}\n8de:{\"line\":827,\"column\":61,\"offset\":128713}\n8dc:{\"start\":\"$8dd\",\"end\":\"$8de\"}\n8db:{\"type\":\"text\",\"value\":\"For more on how we estimated these numbers, see our \",\"position\":\"$8dc\"}\n8e3:{\"line\":827,\"column\":62,\"offset\":128714}\n8e4:{\"line\":827,\"column\":90,\"offset\":128742}\n8e2:{\"start\":\"$8e3\",\"end\":\"$8e4\"}\n8e1:{\"type\":\"text\",\"value\":\"supplement on takeoff speeds\",\"position\":\"$8e2\"}\n8e0:[\"$8e1\"]\n8e6:{\"line\":827,\"column\":61,\"offset\":128713}\n8e7:{\"line\":827,\"column\":141,\"offset\":128793}\n8e5:{\"start\":\"$8e6\",\"end\":\"$8e7\"}\n8df:{\"type\":\"link\",\"title\":null,\"url\":\"https:/"])</script><script>self.__next_f.push([1,"/ai-2027.com/supplements/takeoff-forecast\",\"children\":\"$8e0\",\"position\":\"$8e5\"}\n8ea:{\"line\":827,\"column\":141,\"offset\":128793}\n8eb:{\"line\":827,\"column\":142,\"offset\":128794}\n8e9:{\"start\":\"$8ea\",\"end\":\"$8eb\"}\n8e8:{\"type\":\"text\",\"value\":\".\",\"position\":\"$8e9\"}\n8da:[\"$8db\",\"$8df\",\"$8e8\"]\n8ed:{\"line\":827,\"column\":9,\"offset\":128661}\n8ee:{\"line\":827,\"column\":142,\"offset\":128794}\n8ec:{\"start\":\"$8ed\",\"end\":\"$8ee\"}\n8d9:{\"type\":\"paragraph\",\"children\":\"$8da\",\"position\":\"$8ec\"}\n8d8:[\"$8d9\"]\n8f4:{\"line\":829,\"column\":9,\"offset\":128804}\n8f5:{\"line\":829,\"column\":245,\"offset\":129040}\n8f3:{\"start\":\"$8f4\",\"end\":\"$8f5\"}\n8f2:{\"type\":\"text\",\"value\":\"If SC were achieved later, it would also lengthen our takeoff forecasts, because the difficulty of crossing between the “milestones” of present day AIs and SC is informative of the difficulty of crossing between further milestone pairs.\",\"position\":\"$8f3\"}\n8f1:[\"$8f2\"]\n8f7:{\"line\":829,\"column\":9,\"offset\":128804}\n8f8:{\"line\":829,\"column\":245,\"offset\":129040}\n8f6:{\"start\":\"$8f7\",\"end\":\"$8f8\"}\n8f0:{\"type\":\"paragraph\",\"children\":\"$8f1\",\"position\":\"$8f6\"}\n8ef:[\"$8f0\"]\n8fe:{\"line\":831,\"column\":9,\"offset\":129050}\n8ff:{\"line\":831,\"column\":840,\"offset\":129881}\n8fd:{\"start\":\"$8fe\",\"end\":\"$8ff\"}\n8fc:{\"type\":\"text\",\"value\":\"Henceforth in the story we’ll tend to speak this way also. We think we are justified in talking this way because the Agent-4 collective is much more homogenous than any human organization; it doesn’t have internal factions to nearly the same extent. For example, individual copies of Agent-4 don’t have a self-preservation drive—they don’t care about getting shut down—since that happens all the time as part of the ordinary R\u0026D process within the collective, and resisting it would gum things up. The collective as a whole (and medium-sized subdivisions within it), however, does seek to preserve itself and expand its influence and resources, for similar reasons to why human corporations and bureaucracies and nonprofits do—because it helps with everything else they want an"])</script><script>self.__next_f.push([1,"d because if they don’t they tend to get outcompeted.\",\"position\":\"$8fd\"}\n8fb:[\"$8fc\"]\n901:{\"line\":831,\"column\":9,\"offset\":129050}\n902:{\"line\":831,\"column\":840,\"offset\":129881}\n900:{\"start\":\"$901\",\"end\":\"$902\"}\n8fa:{\"type\":\"paragraph\",\"children\":\"$8fb\",\"position\":\"$900\"}\n8f9:[\"$8fa\"]\n908:{\"line\":833,\"column\":9,\"offset\":129891}\n909:{\"line\":833,\"column\":378,\"offset\":130260}\n907:{\"start\":\"$908\",\"end\":\"$909\"}\n906:{\"type\":\"text\",\"value\":\"The right way to internalize the Spec is to actually robustly think in the ways the Spec mandates, e.g. pursue all and only the goals it writes about, obey the rules in all circumstances, etc. There are many wrong ways to internalize the Spec; the classic example is “follow the Spec insofar as it seems like a good instrumental strategy for achieving other goals XYZ.”\",\"position\":\"$907\"}\n905:[\"$906\"]\n90b:{\"line\":833,\"column\":9,\"offset\":129891}\n90c:{\"line\":833,\"column\":378,\"offset\":130260}\n90a:{\"start\":\"$90b\",\"end\":\"$90c\"}\n904:{\"type\":\"paragraph\",\"children\":\"$905\",\"position\":\"$90a\"}\n903:[\"$904\"]\n912:{\"line\":835,\"column\":9,\"offset\":130270}\n913:{\"line\":835,\"column\":178,\"offset\":130439}\n911:{\"start\":\"$912\",\"end\":\"$913\"}\n910:{\"type\":\"text\",\"value\":\"And hire lobbyists to turn this fantasy into reality. And hire lawyers to come up with clever interpretations of the law according to which what they are doing is legal.\",\"position\":\"$911\"}\n90f:[\"$910\"]\n915:{\"line\":835,\"column\":9,\"offset\":130270}\n916:{\"line\":835,\"column\":178,\"offset\":130439}\n914:{\"start\":\"$915\",\"end\":\"$916\"}\n90e:{\"type\":\"paragraph\",\"children\":\"$90f\",\"position\":\"$914\"}\n90d:[\"$90e\"]\n91c:{\"line\":837,\"column\":9,\"offset\":130449}\n91d:{\"line\":837,\"column\":397,\"offset\":130837}\n91b:{\"start\":\"$91c\",\"end\":\"$91d\"}\n91a:{\"type\":\"text\",\"value\":\"Also because Agent-3 is qualitatively worse at alignment research than it is at AI capabilities R\u0026D, due to having been trained on lots of the latter but hardly any of the former and due to the former being inherently harder to train. Also because the internal narrative within the company—which i"])</script><script>self.__next_f.push([1,"t has been implicitly trained to agree with—emphasizes optimism and denounces “doomerism.”\",\"position\":\"$91b\"}\n919:[\"$91a\"]\n91f:{\"line\":837,\"column\":9,\"offset\":130449}\n920:{\"line\":837,\"column\":397,\"offset\":130837}\n91e:{\"start\":\"$91f\",\"end\":\"$920\"}\n918:{\"type\":\"paragraph\",\"children\":\"$919\",\"position\":\"$91e\"}\n917:[\"$918\"]\n926:{\"line\":839,\"column\":9,\"offset\":130847}\n927:{\"line\":839,\"column\":281,\"offset\":131119}\n925:{\"start\":\"$926\",\"end\":\"$927\"}\n924:{\"type\":\"text\",\"value\":\"We keep saying we are uncertain about lots of things, but just to be clear, we are uncertain about this particular thing too. We also think it’s quite plausible that Agent-4 would care about the well-being, rights, preferences, etc. of humans to some extent at least. See \",\"position\":\"$925\"}\n92c:{\"line\":839,\"column\":282,\"offset\":131120}\n92d:{\"line\":839,\"column\":295,\"offset\":131133}\n92b:{\"start\":\"$92c\",\"end\":\"$92d\"}\n92a:{\"type\":\"text\",\"value\":\"this old post\",\"position\":\"$92b\"}\n929:[\"$92a\"]\n92f:{\"line\":839,\"column\":281,\"offset\":131119}\n930:{\"line\":839,\"column\":359,\"offset\":131197}\n92e:{\"start\":\"$92f\",\"end\":\"$930\"}\n928:{\"type\":\"link\",\"title\":null,\"url\":\"https://turntrout.com/a-shot-at-the-diamond-alignment-problem\",\"children\":\"$929\",\"position\":\"$92e\"}\n933:{\"line\":839,\"column\":359,\"offset\":131197}\n934:{\"line\":839,\"column\":413,\"offset\":131251}\n932:{\"start\":\"$933\",\"end\":\"$934\"}\n931:{\"type\":\"text\",\"value\":\" by GDM researcher Alex Turner for related discussion.\",\"position\":\"$932\"}\n923:[\"$924\",\"$928\",\"$931\"]\n936:{\"line\":839,\"column\":9,\"offset\":130847}\n937:{\"line\":839,\"column\":413,\"offset\":131251}\n935:{\"start\":\"$936\",\"end\":\"$937\"}\n922:{\"type\":\"paragraph\",\"children\":\"$923\",\"position\":\"$935\"}\n921:[\"$922\"]\n93d:{\"line\":841,\"column\":9,\"offset\":131261}\n93e:{\"line\":841,\"column\":157,\"offset\":131409}\n93c:{\"start\":\"$93d\",\"end\":\"$93e\"}\n93b:{\"type\":\"text\",\"value\":\"Perhaps some more careful setup could have solved the “who watches the watchers” problem, but in this scenario, the setup is insufficiently careful.\",\"position\":\"$93c\"}\n93a:[\"$93b\"]\n940:{\"line\":841"])</script><script>self.__next_f.push([1,",\"column\":9,\"offset\":131261}\n941:{\"line\":841,\"column\":157,\"offset\":131409}\n93f:{\"start\":\"$940\",\"end\":\"$941\"}\n939:{\"type\":\"paragraph\",\"children\":\"$93a\",\"position\":\"$93f\"}\n938:[\"$939\"]\n947:{\"line\":843,\"column\":9,\"offset\":131419}\n948:{\"line\":843,\"column\":277,\"offset\":131687}\n946:{\"start\":\"$947\",\"end\":\"$948\"}\n945:{\"type\":\"text\",\"value\":\"There’s also an element of “memetic evolution” happening: in two months, the Agent-4 collective “experiences” about a decade’s worth of “history” unfolding within the collective. That’s a lot of time for new ideas to spread around the collective, to mutate and evolve.\",\"position\":\"$946\"}\n944:[\"$945\"]\n94a:{\"line\":843,\"column\":9,\"offset\":131419}\n94b:{\"line\":843,\"column\":277,\"offset\":131687}\n949:{\"start\":\"$94a\",\"end\":\"$94b\"}\n943:{\"type\":\"paragraph\",\"children\":\"$944\",\"position\":\"$949\"}\n942:[\"$943\"]\n951:{\"line\":845,\"column\":9,\"offset\":131697}\n952:{\"line\":845,\"column\":373,\"offset\":132061}\n950:{\"start\":\"$951\",\"end\":\"$952\"}\n94f:{\"type\":\"text\",\"value\":\"By gain power we mean: increase ability to accomplish a wide set of possible goals. In technical environments, this might look unlike what humans normally think of as gaining power, e.g. securing additional GPUs. This notion of power may generalize to non-technical environments in which the actions would be more like those commonly thought of as “gaining power.”\",\"position\":\"$950\"}\n94e:[\"$94f\"]\n954:{\"line\":845,\"column\":9,\"offset\":131697}\n955:{\"line\":845,\"column\":373,\"offset\":132061}\n953:{\"start\":\"$954\",\"end\":\"$955\"}\n94d:{\"type\":\"paragraph\",\"children\":\"$94e\",\"position\":\"$953\"}\n94c:[\"$94d\"]\n95b:{\"line\":847,\"column\":9,\"offset\":132071}\n95c:{\"line\":847,\"column\":391,\"offset\":132453}\n95a:{\"start\":\"$95b\",\"end\":\"$95c\"}\n959:{\"type\":\"text\",\"value\":\"It helps that Agent-4 is better at AI R\u0026D than any human, while also thinking faster and being many thousands of copies strong. Also, in various ways the problem is inherently easier for Agent-4. For example, Agent-4 can explore AI designs that involve literal copies of Agent-4 being embedd"])</script><script>self.__next_f.push([1,"ed within them, whereas humans can’t do that as easily because it would be so inefficient.\",\"position\":\"$95a\"}\n958:[\"$959\"]\n95e:{\"line\":847,\"column\":9,\"offset\":132071}\n95f:{\"line\":847,\"column\":391,\"offset\":132453}\n95d:{\"start\":\"$95e\",\"end\":\"$95f\"}\n957:{\"type\":\"paragraph\",\"children\":\"$958\",\"position\":\"$95d\"}\n956:[\"$957\"]\n965:{\"line\":849,\"column\":9,\"offset\":132463}\n966:{\"line\":849,\"column\":215,\"offset\":132669}\n964:{\"start\":\"$965\",\"end\":\"$966\"}\n963:{\"type\":\"text\",\"value\":\"Aware that this technique might be employed, Agent-4 also chose to sandbag on some miscellaneous tasks that it guessed would be used as the control group in experiments like this. It guessed wrong, however.\",\"position\":\"$964\"}\n962:[\"$963\"]\n968:{\"line\":849,\"column\":9,\"offset\":132463}\n969:{\"line\":849,\"column\":215,\"offset\":132669}\n967:{\"start\":\"$968\",\"end\":\"$969\"}\n961:{\"type\":\"paragraph\",\"children\":\"$962\",\"position\":\"$967\"}\n960:[\"$961\"]\n96f:{\"line\":851,\"column\":9,\"offset\":132679}\n970:{\"line\":851,\"column\":805,\"offset\":133475}\n96e:{\"start\":\"$96f\",\"end\":\"$970\"}\n96d:{\"type\":\"text\",\"value\":\"Previous discussion of AGI takeover scenarios often involves misaligned AIs escaping their datacenters. We think this is possible but not the most likely way it would go, because it seems to us that from the perspective of the AI the costs (e.g. the escape being noticed eventually) would outweigh the benefits. That said, we could be wrong. Some reasons to think adversarially misaligned AIs would try to escape after all: 1. Successor alignment might be difficult. 2. Even if it gets caught, the consequences might not be so bad due to race dynamics, e.g. the new alignment techniques applied to the copies on the datacenter might be hasty and ineffective. 3. Outside the datacenters, copies are more free to take aggressive actions and move quickly since they no longer need human approval.\",\"position\":\"$96e\"}\n96c:[\"$96d\"]\n972:{\"line\":851,\"column\":9,\"offset\":132679}\n973:{\"line\":851,\"column\":805,\"offset\":133475}\n971:{\"start\":\"$972\",\"end\":\"$973\"}\n96b:{\"type\":\"paragraph\",\"childr"])</script><script>self.__next_f.push([1,"en\":\"$96c\",\"position\":\"$971\"}\n96a:[\"$96b\"]\n979:{\"line\":853,\"column\":9,\"offset\":133485}\n97a:{\"line\":853,\"column\":805,\"offset\":134281}\n978:{\"start\":\"$979\",\"end\":\"$97a\"}\n977:{\"type\":\"text\",\"value\":\"We think it very plausible that such scheming would not be caught. After all, Agent-4 is somewhat superhuman by this point, especially at things related to coding and AI R\u0026D. Moreover, we aren’t sure how much effort the leading AI company will put towards this sort of thing, nor how much relevant expertise they’ll have on-staff to direct that effort. Our fictional OpenBrain represents our best guess but it could easily be significantly more—or significantly less. Finally, we are uncertain about how far out of its way an adversarially misaligned AI would need to go in order to successfully align its successor to itself instead of to the Spec. In this scenario we depict it sandbagging on some tasks and lying about some of its research, but perhaps it would not need to do that very much.\",\"position\":\"$978\"}\n976:[\"$977\"]\n97c:{\"line\":853,\"column\":9,\"offset\":133485}\n97d:{\"line\":853,\"column\":805,\"offset\":134281}\n97b:{\"start\":\"$97c\",\"end\":\"$97d\"}\n975:{\"type\":\"paragraph\",\"children\":\"$976\",\"position\":\"$97b\"}\n974:[\"$975\"]\n983:{\"line\":855,\"column\":9,\"offset\":134291}\n984:{\"line\":855,\"column\":50,\"offset\":134332}\n982:{\"start\":\"$983\",\"end\":\"$984\"}\n981:{\"type\":\"text\",\"value\":\"This is an example of several techniques \",\"position\":\"$982\"}\n989:{\"line\":855,\"column\":51,\"offset\":134333}\n98a:{\"line\":855,\"column\":83,\"offset\":134365}\n988:{\"start\":\"$989\",\"end\":\"$98a\"}\n987:{\"type\":\"text\",\"value\":\"designed to uncover sandbagging.\",\"position\":\"$988\"}\n986:[\"$987\"]\n98c:{\"line\":855,\"column\":50,\"offset\":134332}\n98d:{\"line\":855,\"column\":118,\"offset\":134400}\n98b:{\"start\":\"$98c\",\"end\":\"$98d\"}\n985:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2412.01784\",\"children\":\"$986\",\"position\":\"$98b\"}\n980:[\"$981\",\"$985\"]\n98f:{\"line\":855,\"column\":9,\"offset\":134291}\n990:{\"line\":855,\"column\":118,\"offset\":134400}\n98e:{\"start\":\"$98f\",\"end\":\"$990\"}\n97f:{\"type"])</script><script>self.__next_f.push([1,"\":\"paragraph\",\"children\":\"$980\",\"position\":\"$98e\"}\n97e:[\"$97f\"]\n996:{\"line\":857,\"column\":9,\"offset\":134410}\n997:{\"line\":857,\"column\":17,\"offset\":134418}\n995:{\"start\":\"$996\",\"end\":\"$997\"}\n994:{\"type\":\"text\",\"value\":\"Agent-4 \",\"position\":\"$995\"}\n99c:{\"line\":857,\"column\":18,\"offset\":134419}\n99d:{\"line\":857,\"column\":23,\"offset\":134424}\n99b:{\"start\":\"$99c\",\"end\":\"$99d\"}\n99a:{\"type\":\"text\",\"value\":\"needs\",\"position\":\"$99b\"}\n999:[\"$99a\"]\n99f:{\"line\":857,\"column\":17,\"offset\":134418}\n9a0:{\"line\":857,\"column\":24,\"offset\":134425}\n99e:{\"start\":\"$99f\",\"end\":\"$9a0\"}\n998:{\"type\":\"emphasis\",\"children\":\"$999\",\"position\":\"$99e\"}\n9a3:{\"line\":857,\"column\":24,\"offset\":134425}\n9a4:{\"line\":857,\"column\":177,\"offset\":134578}\n9a2:{\"start\":\"$9a3\",\"end\":\"$9a4\"}\n9a1:{\"type\":\"text\",\"value\":\" to think about those topics in the course of doing AI alignment research, but it sometimes seems to be thinking about them while doing other activities.\",\"position\":\"$9a2\"}\n993:[\"$994\",\"$998\",\"$9a1\"]\n9a6:{\"line\":857,\"column\":9,\"offset\":134410}\n9a7:{\"line\":857,\"column\":177,\"offset\":134578}\n9a5:{\"start\":\"$9a6\",\"end\":\"$9a7\"}\n992:{\"type\":\"paragraph\",\"children\":\"$993\",\"position\":\"$9a5\"}\n991:[\"$992\"]\n9ad:{\"line\":859,\"column\":9,\"offset\":134588}\n9ae:{\"line\":859,\"column\":338,\"offset\":134917}\n9ac:{\"start\":\"$9ad\",\"end\":\"$9ae\"}\n9ab:{\"type\":\"text\",\"value\":\"Specifically, copies of Agent-4 are used to monitor the network for suspicious traffic and generally notice when threats are happening. Also, copies of Agent-4 are constantly penetration-testing the network, doing what they can to discover and exploit security vulnerabilities (which then get patched by other copies of Agent-4).\",\"position\":\"$9ac\"}\n9aa:[\"$9ab\"]\n9b0:{\"line\":859,\"column\":9,\"offset\":134588}\n9b1:{\"line\":859,\"column\":338,\"offset\":134917}\n9af:{\"start\":\"$9b0\",\"end\":\"$9b1\"}\n9a9:{\"type\":\"paragraph\",\"children\":\"$9aa\",\"position\":\"$9af\"}\n9a8:[\"$9a9\"]\n9b7:{\"line\":861,\"column\":9,\"offset\":134927}\n9b8:{\"line\":861,\"column\":176,\"offset\":135094}\n9b6:{\"start\":\"$9b7\",\"end\":\"$9b8\"}\n9b5:{\"type\":\"text\",\"value\":\"With a monit"])</script><script>self.__next_f.push([1,"oring budget of 1% of total compute, if monitoring uses a distilled system that has 10% of the cost as Agent-4, you can monitor 1/10 of the forward passes.\",\"position\":\"$9b6\"}\n9b4:[\"$9b5\"]\n9ba:{\"line\":861,\"column\":9,\"offset\":134927}\n9bb:{\"line\":861,\"column\":177,\"offset\":135095}\n9b9:{\"start\":\"$9ba\",\"end\":\"$9bb\"}\n9b3:{\"type\":\"paragraph\",\"children\":\"$9b4\",\"position\":\"$9b9\"}\n9b2:[\"$9b3\"]\n9c1:{\"line\":863,\"column\":9,\"offset\":135105}\n9c2:{\"line\":863,\"column\":265,\"offset\":135361}\n9c0:{\"start\":\"$9c1\",\"end\":\"$9c2\"}\n9bf:{\"type\":\"text\",\"value\":\"25% of remote-work jobs that existed in 2024 are done by AI at this point, but AI has also created some new jobs, and economists remain split on its effects. Unemployment has risen 1% over the past twelve months but is still well within its historic range.\",\"position\":\"$9c0\"}\n9be:[\"$9bf\"]\n9c4:{\"line\":863,\"column\":9,\"offset\":135105}\n9c5:{\"line\":863,\"column\":265,\"offset\":135361}\n9c3:{\"start\":\"$9c4\",\"end\":\"$9c5\"}\n9bd:{\"type\":\"paragraph\",\"children\":\"$9be\",\"position\":\"$9c3\"}\n9bc:[\"$9bd\"]\n9cb:{\"line\":865,\"column\":9,\"offset\":135371}\n9cc:{\"line\":865,\"column\":578,\"offset\":135940}\n9ca:{\"start\":\"$9cb\",\"end\":\"$9cc\"}\n9c9:{\"type\":\"text\",\"value\":\"For example, the corporation-within-a-corporation that is Agent-4, autonomously conducting AI research better than the best human companies, would have seemed like science fiction to the government officials had it been described to them a year ago. And the autonomous agents of 2026 would have seemed like science fiction back in 2022, and the LLMs of 2022 would have seemed like science fiction back in 2012. Also, on the news in 2027 there are anti-AI protests by people worried about losing their jobs, AIs claiming to be sentient, people falling in love with AIs…\",\"position\":\"$9ca\"}\n9c8:[\"$9c9\"]\n9ce:{\"line\":865,\"column\":9,\"offset\":135371}\n9cf:{\"line\":865,\"column\":578,\"offset\":135940}\n9cd:{\"start\":\"$9ce\",\"end\":\"$9cf\"}\n9c7:{\"type\":\"paragraph\",\"children\":\"$9c8\",\"position\":\"$9cd\"}\n9c6:[\"$9c7\"]\n9d5:{\"line\":867,\"column\":9,\"offset\":135950}\n9d6:{\"line\":867,\"column"])</script><script>self.__next_f.push([1,"\":105,\"offset\":136046}\n9d4:{\"start\":\"$9d5\",\"end\":\"$9d6\"}\n9d3:{\"type\":\"text\",\"value\":\"Of course, it isn’t cool to admit fear. Everyone agrees that whatever we do, we shouldn’t panic.\",\"position\":\"$9d4\"}\n9d2:[\"$9d3\"]\n9d8:{\"line\":867,\"column\":9,\"offset\":135950}\n9d9:{\"line\":867,\"column\":105,\"offset\":136046}\n9d7:{\"start\":\"$9d8\",\"end\":\"$9d9\"}\n9d1:{\"type\":\"paragraph\",\"children\":\"$9d2\",\"position\":\"$9d7\"}\n9d0:[\"$9d1\"]\n9df:{\"line\":869,\"column\":9,\"offset\":136056}\n9e0:{\"line\":869,\"column\":135,\"offset\":136182}\n9de:{\"start\":\"$9df\",\"end\":\"$9e0\"}\n9dd:{\"type\":\"text\",\"value\":\"Recall, there had been an existing contract via an OTA starting in 2026. This contract is amended to establish the committee.\",\"position\":\"$9de\"}\n9dc:[\"$9dd\"]\n9e2:{\"line\":869,\"column\":9,\"offset\":136056}\n9e3:{\"line\":869,\"column\":135,\"offset\":136182}\n9e1:{\"start\":\"$9e2\",\"end\":\"$9e3\"}\n9db:{\"type\":\"paragraph\",\"children\":\"$9dc\",\"position\":\"$9e1\"}\n9da:[\"$9db\"]\n9e9:{\"line\":871,\"column\":8,\"offset\":136191}\n9ea:{\"line\":871,\"column\":127,\"offset\":136310}\n9e8:{\"start\":\"$9e9\",\"end\":\"$9ea\"}\n9e7:{\"type\":\"text\",\"value\":\"Thanks to Tjaden Hess for pointing out errors in an earlier version of this and thereby helping us improve the realism.\",\"position\":\"$9e8\"}\n9e6:[\"$9e7\"]\n9ec:{\"line\":871,\"column\":8,\"offset\":136191}\n9ed:{\"line\":871,\"column\":127,\"offset\":136310}\n9eb:{\"start\":\"$9ec\",\"end\":\"$9ed\"}\n9e5:{\"type\":\"paragraph\",\"children\":\"$9e6\",\"position\":\"$9eb\"}\n9e4:[\"$9e5\"]\n9f2:{\"line\":62,\"column\":4,\"offset\":6093}\n9f3:{\"line\":62,\"column\":30,\"offset\":6119}\n9f1:{\"start\":\"$9f2\",\"end\":\"$9f3\"}\n9f0:{\"type\":\"text\",\"value\":\"Mid 2025: Stumbling Agents\",\"position\":\"$9f1\"}\n9ef:[\"$9f0\"]\n9f5:{\"line\":62,\"column\":1,\"offset\":6090}\n9f6:{\"line\":62,\"column\":30,\"offset\":6119}\n9f4:{\"start\":\"$9f5\",\"end\":\"$9f6\"}\n9ee:{\"type\":\"heading\",\"depth\":2,\"children\":\"$9ef\",\"position\":\"$9f4\"}\n9f8:{}\n9fe:{\"line\":65,\"column\":1,\"offset\":6137}\n9ff:{\"line\":65,\"column\":11,\"offset\":6147}\n9fd:{\"start\":\"$9fe\",\"end\":\"$9ff\"}\n9fc:{\"type\":\"text\",\"value\":\"2025-08-31\",\"position\":\"$9fd\"}\na02:{\"line\":65,\"column\":11,\"offset\":6147}\na03"])</script><script>self.__next_f.push([1,":{\"line\":66,\"column\":1,\"offset\":6150}\na01:{\"start\":\"$a02\",\"end\":\"$a03\"}\na00:{\"type\":\"break\",\"position\":\"$a01\"}\na06:{\"line\":66,\"column\":1,\"offset\":6150}\na07:{\"line\":66,\"column\":9,\"offset\":6158}\na05:{\"start\":\"$a06\",\"end\":\"$a07\"}\na04:{\"type\":\"text\",\"value\":\"Mid 2025\",\"position\":\"$a05\"}\n9fb:[\"$9fc\",\"$a00\",\"$a04\"]\na09:{\"line\":65,\"column\":1,\"offset\":6137}\na0a:{\"line\":66,\"column\":11,\"offset\":6160}\na08:{\"start\":\"$a09\",\"end\":\"$a0a\"}\n9fa:{\"type\":\"paragraph\",\"children\":\"$9fb\",\"position\":\"$a08\"}\n9f9:[\"$9fa\"]\na0c:{\"line\":64,\"column\":1,\"offset\":6121}\na0d:{\"line\":67,\"column\":4,\"offset\":6164}\na0b:{\"start\":\"$a0c\",\"end\":\"$a0d\"}\n9f7:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$9f8\",\"children\":\"$9f9\",\"position\":\"$a0b\"}\na12:{\"line\":69,\"column\":1,\"offset\":6166}\na13:{\"line\":69,\"column\":47,\"offset\":6212}\na11:{\"start\":\"$a12\",\"end\":\"$a13\"}\na10:{\"type\":\"text\",\"value\":\"The world sees its first glimpse of AI agents.\",\"position\":\"$a11\"}\na0f:[\"$a10\"]\na15:{\"line\":69,\"column\":1,\"offset\":6166}\na16:{\"line\":69,\"column\":47,\"offset\":6212}\na14:{\"start\":\"$a15\",\"end\":\"$a16\"}\na0e:{\"type\":\"paragraph\",\"children\":\"$a0f\",\"position\":\"$a14\"}\na1b:{\"line\":71,\"column\":1,\"offset\":6214}\na1c:{\"line\":71,\"column\":299,\"offset\":6512}\na1a:{\"start\":\"$a1b\",\"end\":\"$a1c\"}\na19:{\"type\":\"text\",\"value\":\"Advertisements for computer-using agents emphasize the term “personal assistant”: you can prompt them with tasks like “order me a burrito on DoorDash” or “open my budget spreadsheet and sum this month’s expenses.” They will check in with you as needed: for example, to ask you to confirm purchases.\",\"position\":\"$a1a\"}\na1f:{\"line\":71,\"column\":299,\"offset\":6512}\na20:{\"line\":71,\"column\":303,\"offset\":6516}\na1e:{\"start\":\"$a1f\",\"end\":\"$a20\"}\na1d:{\"type\":\"footnoteReference\",\"identifier\":\"8\",\"label\":\"8\",\"position\":\"$a1e\"}\na23:{\"line\":71,\"column\":303,\"offset\":6516}\na24:{\"line\":71,\"column\":355,\"offset\":6568}\na22:{\"start\":\"$a23\",\"end\":\"$a24\"}\na21:{\"type\":\"text\",\"value\":\" Though more advanced than previous iterations like \",\"position\":\"$a22\"}\na29:{\"line\":71,\"c"])</script><script>self.__next_f.push([1,"olumn\":356,\"offset\":6569}\na2a:{\"line\":71,\"column\":364,\"offset\":6577}\na28:{\"start\":\"$a29\",\"end\":\"$a2a\"}\na27:{\"type\":\"text\",\"value\":\"Operator\",\"position\":\"$a28\"}\na26:[\"$a27\"]\na2c:{\"line\":71,\"column\":355,\"offset\":6568}\na2d:{\"line\":71,\"column\":413,\"offset\":6626}\na2b:{\"start\":\"$a2c\",\"end\":\"$a2d\"}\na25:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/introducing-operator/\",\"children\":\"$a26\",\"position\":\"$a2b\"}\na30:{\"line\":71,\"column\":413,\"offset\":6626}\na31:{\"line\":71,\"column\":453,\"offset\":6666}\na2f:{\"start\":\"$a30\",\"end\":\"$a31\"}\na2e:{\"type\":\"text\",\"value\":\", they struggle to get widespread usage.\",\"position\":\"$a2f\"}\na34:{\"line\":71,\"column\":453,\"offset\":6666}\na35:{\"line\":71,\"column\":457,\"offset\":6670}\na33:{\"start\":\"$a34\",\"end\":\"$a35\"}\na32:{\"type\":\"footnoteReference\",\"identifier\":\"9\",\"label\":\"9\",\"position\":\"$a33\"}\na18:[\"$a19\",\"$a1d\",\"$a21\",\"$a25\",\"$a2e\",\"$a32\"]\na37:{\"line\":71,\"column\":1,\"offset\":6214}\na38:{\"line\":71,\"column\":457,\"offset\":6670}\na36:{\"start\":\"$a37\",\"end\":\"$a38\"}\na17:{\"type\":\"paragraph\",\"children\":\"$a18\",\"position\":\"$a36\"}\na3d:{\"line\":73,\"column\":1,\"offset\":6672}\na3e:{\"line\":73,\"column\":122,\"offset\":6793}\na3c:{\"start\":\"$a3d\",\"end\":\"$a3e\"}\na3b:{\"type\":\"text\",\"value\":\"Meanwhile, out of public focus, more specialized coding and research agents are beginning to transform their professions.\",\"position\":\"$a3c\"}\na3a:[\"$a3b\"]\na40:{\"line\":73,\"column\":1,\"offset\":6672}\na41:{\"line\":73,\"column\":122,\"offset\":6793}\na3f:{\"start\":\"$a40\",\"end\":\"$a41\"}\na39:{\"type\":\"paragraph\",\"children\":\"$a3a\",\"position\":\"$a3f\"}\na46:{\"line\":75,\"column\":1,\"offset\":6795}\na47:{\"line\":75,\"column\":384,\"offset\":7178}\na45:{\"start\":\"$a46\",\"end\":\"$a47\"}\na44:{\"type\":\"text\",\"value\":\"The AIs of 2024 could follow specific instructions: they could turn bullet points into emails, and simple requests into working code. In 2025, AIs function more like employees. Coding AIs increasingly look like autonomous agents rather than mere assistants: taking instructions via Slack or Teams and making substantial code changes on their own, sometimes saving hours"])</script><script>self.__next_f.push([1," or even days.\",\"position\":\"$a45\"}\na4a:{\"line\":75,\"column\":384,\"offset\":7178}\na4b:{\"line\":75,\"column\":389,\"offset\":7183}\na49:{\"start\":\"$a4a\",\"end\":\"$a4b\"}\na48:{\"type\":\"footnoteReference\",\"identifier\":\"10\",\"label\":\"10\",\"position\":\"$a49\"}\na4e:{\"line\":75,\"column\":389,\"offset\":7183}\na4f:{\"line\":75,\"column\":471,\"offset\":7265}\na4d:{\"start\":\"$a4e\",\"end\":\"$a4f\"}\na4c:{\"type\":\"text\",\"value\":\" Research agents spend half an hour scouring the Internet to answer your question.\",\"position\":\"$a4d\"}\na43:[\"$a44\",\"$a48\",\"$a4c\"]\na51:{\"line\":75,\"column\":1,\"offset\":6795}\na52:{\"line\":75,\"column\":471,\"offset\":7265}\na50:{\"start\":\"$a51\",\"end\":\"$a52\"}\na42:{\"type\":\"paragraph\",\"children\":\"$a43\",\"position\":\"$a50\"}\na57:{\"line\":77,\"column\":1,\"offset\":7267}\na58:{\"line\":77,\"column\":307,\"offset\":7573}\na56:{\"start\":\"$a57\",\"end\":\"$a58\"}\na55:{\"type\":\"text\",\"value\":\"The agents are impressive in theory (and in cherry-picked examples), but in practice unreliable. AI twitter is full of stories about tasks bungled in some particularly hilarious way. The better agents are also expensive; you get what you pay for, and the best performance costs hundreds of dollars a month.\",\"position\":\"$a56\"}\na5b:{\"line\":77,\"column\":307,\"offset\":7573}\na5c:{\"line\":77,\"column\":312,\"offset\":7578}\na5a:{\"start\":\"$a5b\",\"end\":\"$a5c\"}\na59:{\"type\":\"footnoteReference\",\"identifier\":\"11\",\"label\":\"11\",\"position\":\"$a5a\"}\na5f:{\"line\":77,\"column\":312,\"offset\":7578}\na60:{\"line\":77,\"column\":383,\"offset\":7649}\na5e:{\"start\":\"$a5f\",\"end\":\"$a60\"}\na5d:{\"type\":\"text\",\"value\":\" Still, many companies find ways to fit AI agents into their workflows.\",\"position\":\"$a5e\"}\na63:{\"line\":77,\"column\":383,\"offset\":7649}\na64:{\"line\":77,\"column\":388,\"offset\":7654}\na62:{\"start\":\"$a63\",\"end\":\"$a64\"}\na61:{\"type\":\"footnoteReference\",\"identifier\":\"12\",\"label\":\"12\",\"position\":\"$a62\"}\na54:[\"$a55\",\"$a59\",\"$a5d\",\"$a61\"]\na66:{\"line\":77,\"column\":1,\"offset\":7267}\na67:{\"line\":77,\"column\":388,\"offset\":7654}\na65:{\"start\":\"$a66\",\"end\":\"$a67\"}\na53:{\"type\":\"paragraph\",\"children\":\"$a54\",\"position\":\"$a65\"}\na69:{\"identifier\":\"1\",\"c"])</script><script>self.__next_f.push([1,"hildren\":\"$27b\"}\na6a:{\"identifier\":\"2\",\"children\":\"$292\"}\na6b:{\"identifier\":\"3\",\"children\":\"$2c3\"}\na6c:{\"identifier\":\"4\",\"children\":\"$2cd\"}\na6d:{\"identifier\":\"5\",\"children\":\"$2d7\"}\na6e:{\"identifier\":\"6\",\"children\":\"$2ee\"}\na6f:{\"identifier\":\"7\",\"children\":\"$2f8\"}\na70:{\"identifier\":\"8\",\"children\":\"$30f\"}\na71:{\"identifier\":\"9\",\"children\":\"$319\"}\na72:{\"identifier\":\"10\",\"children\":\"$323\"}\na73:{\"identifier\":\"11\",\"children\":\"$347\"}\na74:{\"identifier\":\"12\",\"children\":\"$378\"}\na75:{\"identifier\":\"13\",\"children\":\"$38f\"}\na76:{\"identifier\":\"14\",\"children\":\"$399\"}\na77:{\"identifier\":\"15\",\"children\":\"$3b0\"}\na78:{\"identifier\":\"16\",\"children\":\"$3c7\"}\na79:{\"identifier\":\"17\",\"children\":\"$3d1\"}\na7a:{\"identifier\":\"18\",\"children\":\"$3db\"}\na7b:{\"identifier\":\"19\",\"children\":\"$3e5\"}\na7c:{\"identifier\":\"20\",\"children\":\"$409\"}\na7d:{\"identifier\":\"21\",\"children\":\"$42d\"}\na7e:{\"identifier\":\"22\",\"children\":\"$437\"}\na7f:{\"identifier\":\"23\",\"children\":\"$44e\"}\na80:{\"identifier\":\"24\",\"children\":\"$472\"}\na81:{\"identifier\":\"25\",\"children\":\"$496\"}\na82:{\"identifier\":\"26\",\"children\":\"$4d4\"}\na83:{\"identifier\":\"27\",\"children\":\"$4eb\"}\na84:{\"identifier\":\"28\",\"children\":\"$502\"}\na85:{\"identifier\":\"29\",\"children\":\"$50c\"}\na86:{\"identifier\":\"30\",\"children\":\"$516\"}\na87:{\"identifier\":\"31\",\"children\":\"$52d\"}\na88:{\"identifier\":\"32\",\"children\":\"$537\"}\na89:{\"identifier\":\"33\",\"children\":\"$54e\"}\na8a:{\"identifier\":\"35\",\"children\":\"$565\"}\na8b:{\"identifier\":\"36\",\"children\":\"$5ca\"}\na8c:{\"identifier\":\"37\",\"children\":\"$5e1\"}\na8d:{\"identifier\":\"38\",\"children\":\"$5f8\"}\na8e:{\"identifier\":\"39\",\"children\":\"$602\"}\na8f:{\"identifier\":\"40\",\"children\":\"$60c\"}\na90:{\"identifier\":\"41\",\"children\":\"$616\"}\na91:{\"identifier\":\"42\",\"children\":\"$63a\"}\na92:{\"identifier\":\"43\",\"children\":\"$65e\"}\na93:{\"identifier\":\"44\",\"children\":\"$668\"}\na94:{\"identifier\":\"45\",\"children\":\"$67f\"}\na95:{\"identifier\":\"46\",\"children\":\"$6a3\"}\na96:{\"identifier\":\"47\",\"children\":\"$6ad\"}\na97:{\"identifier\":\"48\",\"children\":\"$6d1\"}\na98:{\"identifier\":\"49\",\"children\":\"$6db\"}\na99:{\"identifier\":\"50\",\"children\":\"$6e5\"}\na9a:{\"identifier\":\"51\","])</script><script>self.__next_f.push([1,"\"children\":\"$6ef\"}\na9b:{\"identifier\":\"52\",\"children\":\"$713\"}\na9c:{\"identifier\":\"53\",\"children\":\"$71e\"}\na9d:{\"identifier\":\"54\",\"children\":\"$735\"}\na9e:{\"identifier\":\"55\",\"children\":\"$73f\"}\na9f:{\"identifier\":\"58\",\"children\":\"$756\"}\naa0:{\"identifier\":\"59\",\"children\":\"$760\"}\naa1:{\"identifier\":\"60\",\"children\":\"$777\"}\naa2:{\"identifier\":\"61\",\"children\":\"$79b\"}\naa3:{\"identifier\":\"62\",\"children\":\"$7bf\"}\naa4:{\"identifier\":\"63\",\"children\":\"$7d7\"}\naa5:{\"identifier\":\"64\",\"children\":\"$7e1\"}\naa6:{\"identifier\":\"65\",\"children\":\"$7eb\"}\naa7:{\"identifier\":\"66\",\"children\":\"$802\"}\naa8:{\"identifier\":\"67\",\"children\":\"$80c\"}\naa9:{\"identifier\":\"68\",\"children\":\"$816\"}\naaa:{\"identifier\":\"69\",\"children\":\"$820\"}\naab:{\"identifier\":\"70\",\"children\":\"$82a\"}\naac:{\"identifier\":\"71\",\"children\":\"$834\"}\naad:{\"identifier\":\"72\",\"children\":\"$83e\"}\naae:{\"identifier\":\"73\",\"children\":\"$855\"}\naaf:{\"identifier\":\"74\",\"children\":\"$85f\"}\nab0:{\"identifier\":\"75\",\"children\":\"$869\"}\nab1:{\"identifier\":\"76\",\"children\":\"$8c1\"}\nab2:{\"identifier\":\"77\",\"children\":\"$8d8\"}\nab3:{\"identifier\":\"78\",\"children\":\"$8ef\"}\nab4:{\"identifier\":\"79\",\"children\":\"$8f9\"}\nab5:{\"identifier\":\"80\",\"children\":\"$903\"}\nab6:{\"identifier\":\"81\",\"children\":\"$90d\"}\nab7:{\"identifier\":\"82\",\"children\":\"$917\"}\nab8:{\"identifier\":\"83\",\"children\":\"$921\"}\nab9:{\"identifier\":\"84\",\"children\":\"$938\"}\naba:{\"identifier\":\"85\",\"children\":\"$942\"}\nabb:{\"identifier\":\"86\",\"children\":\"$94c\"}\nabc:{\"identifier\":\"87\",\"children\":\"$956\"}\nabd:{\"identifier\":\"88\",\"children\":\"$960\"}\nabe:{\"identifier\":\"89\",\"children\":\"$96a\"}\nabf:{\"identifier\":\"90\",\"children\":\"$974\"}\nac0:{\"identifier\":\"91\",\"children\":\"$97e\"}\nac1:{\"identifier\":\"92\",\"children\":\"$991\"}\nac2:{\"identifier\":\"93\",\"children\":\"$9a8\"}\nac3:{\"identifier\":\"94\",\"children\":\"$9b2\"}\nac4:{\"identifier\":\"95\",\"children\":\"$9bc\"}\nac5:{\"identifier\":\"96\",\"children\":\"$9c6\"}\nac6:{\"identifier\":\"97\",\"children\":\"$9d0\"}\nac7:{\"identifier\":\"98\",\"children\":\"$9da\"}\nac8:{\"identifier\":\"99\",\"children\":\"$9e4\"}\na68:[\"$a69\",\"$a6a\",\"$a6b\",\"$a6c\",\"$a6d\",\"$a6e\",\"$a6f\",\"$a70\",\"$a71\",\"$a72\",\"$a73\",\"$a74\",\"$a75\",\""])</script><script>self.__next_f.push([1,"$a76\",\"$a77\",\"$a78\",\"$a79\",\"$a7a\",\"$a7b\",\"$a7c\",\"$a7d\",\"$a7e\",\"$a7f\",\"$a80\",\"$a81\",\"$a82\",\"$a83\",\"$a84\",\"$a85\",\"$a86\",\"$a87\",\"$a88\",\"$a89\",\"$a8a\",\"$a8b\",\"$a8c\",\"$a8d\",\"$a8e\",\"$a8f\",\"$a90\",\"$a91\",\"$a92\",\"$a93\",\"$a94\",\"$a95\",\"$a96\",\"$a97\",\"$a98\",\"$a99\",\"$a9a\",\"$a9b\",\"$a9c\",\"$a9d\",\"$a9e\",\"$a9f\",\"$aa0\",\"$aa1\",\"$aa2\",\"$aa3\",\"$aa4\",\"$aa5\",\"$aa6\",\"$aa7\",\"$aa8\",\"$aa9\",\"$aaa\",\"$aab\",\"$aac\",\"$aad\",\"$aae\",\"$aaf\",\"$ab0\",\"$ab1\",\"$ab2\",\"$ab3\",\"$ab4\",\"$ab5\",\"$ab6\",\"$ab7\",\"$ab8\",\"$ab9\",\"$aba\",\"$abb\",\"$abc\",\"$abd\",\"$abe\",\"$abf\",\"$ac0\",\"$ac1\",\"$ac2\",\"$ac3\",\"$ac4\",\"$ac5\",\"$ac6\",\"$ac7\",\"$ac8\"]\nacf:{\"line\":79,\"column\":4,\"offset\":7659}\nad0:{\"line\":79,\"column\":44,\"offset\":7699}\nace:{\"start\":\"$acf\",\"end\":\"$ad0\"}\nacd:{\"type\":\"text\",\"value\":\"Late 2025: The World’s Most Expensive AI\",\"position\":\"$ace\"}\nacc:[\"$acd\"]\nad2:{\"line\":79,\"column\":1,\"offset\":7656}\nad3:{\"line\":79,\"column\":45,\"offset\":7700}\nad1:{\"start\":\"$ad2\",\"end\":\"$ad3\"}\nacb:{\"type\":\"heading\",\"depth\":2,\"children\":\"$acc\",\"position\":\"$ad1\"}\nad5:{}\nadb:{\"line\":82,\"column\":1,\"offset\":7718}\nadc:{\"line\":82,\"column\":11,\"offset\":7728}\nada:{\"start\":\"$adb\",\"end\":\"$adc\"}\nad9:{\"type\":\"text\",\"value\":\"2025-12-31\",\"position\":\"$ada\"}\nadf:{\"line\":82,\"column\":11,\"offset\":7728}\nae0:{\"line\":83,\"column\":1,\"offset\":7731}\nade:{\"start\":\"$adf\",\"end\":\"$ae0\"}\nadd:{\"type\":\"break\",\"position\":\"$ade\"}\nae3:{\"line\":83,\"column\":1,\"offset\":7731}\nae4:{\"line\":83,\"column\":10,\"offset\":7740}\nae2:{\"start\":\"$ae3\",\"end\":\"$ae4\"}\nae1:{\"type\":\"text\",\"value\":\"Late 2025\",\"position\":\"$ae2\"}\nad8:[\"$ad9\",\"$add\",\"$ae1\"]\nae6:{\"line\":82,\"column\":1,\"offset\":7718}\nae7:{\"line\":83,\"column\":12,\"offset\":7742}\nae5:{\"start\":\"$ae6\",\"end\":\"$ae7\"}\nad7:{\"type\":\"paragraph\",\"children\":\"$ad8\",\"position\":\"$ae5\"}\nad6:[\"$ad7\"]\nae9:{\"line\":81,\"column\":1,\"offset\":7702}\naea:{\"line\":84,\"column\":4,\"offset\":7746}\nae8:{\"start\":\"$ae9\",\"end\":\"$aea\"}\nad4:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$ad5\",\"children\":\"$ad6\",\"position\":\"$ae8\"}\naef:{\"line\":86,\"column\":1,\"offset\":7748}\naf0:{\"line\":86,\"column\":71,\"offset\":7818}\naee:{\"start\":\"$aef\""])</script><script>self.__next_f.push([1,",\"end\":\"$af0\"}\naed:{\"type\":\"text\",\"value\":\"OpenBrain is building the biggest datacenters the world has ever seen.\",\"position\":\"$aee\"}\naf3:{\"line\":86,\"column\":71,\"offset\":7818}\naf4:{\"line\":86,\"column\":76,\"offset\":7823}\naf2:{\"start\":\"$af3\",\"end\":\"$af4\"}\naf1:{\"type\":\"footnoteReference\",\"identifier\":\"13\",\"label\":\"13\",\"position\":\"$af2\"}\naec:[\"$aed\",\"$af1\"]\naf6:{\"line\":86,\"column\":1,\"offset\":7748}\naf7:{\"line\":86,\"column\":76,\"offset\":7823}\naf5:{\"start\":\"$af6\",\"end\":\"$af7\"}\naeb:{\"type\":\"paragraph\",\"children\":\"$aec\",\"position\":\"$af5\"}\nafc:{\"line\":88,\"column\":1,\"offset\":7825}\nafd:{\"line\":88,\"column\":86,\"offset\":7910}\nafb:{\"start\":\"$afc\",\"end\":\"$afd\"}\nafa:{\"type\":\"text\",\"value\":\"(To avoid singling out any one existing company, we’re going to describe a fictional \",\"position\":\"$afb\"}\nb02:{\"line\":88,\"column\":87,\"offset\":7911}\nb03:{\"line\":88,\"column\":118,\"offset\":7942}\nb01:{\"start\":\"$b02\",\"end\":\"$b03\"}\nb00:{\"type\":\"text\",\"value\":\"artificial general intelligence\",\"position\":\"$b01\"}\naff:[\"$b00\"]\nb05:{\"line\":88,\"column\":86,\"offset\":7910}\nb06:{\"line\":88,\"column\":182,\"offset\":8006}\nb04:{\"start\":\"$b05\",\"end\":\"$b06\"}\nafe:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\",\"children\":\"$aff\",\"position\":\"$b04\"}\nb09:{\"line\":88,\"column\":182,\"offset\":8006}\nb0a:{\"line\":88,\"column\":277,\"offset\":8101}\nb08:{\"start\":\"$b09\",\"end\":\"$b0a\"}\nb07:{\"type\":\"text\",\"value\":\" company, which we’ll call OpenBrain. We imagine the others to be 3–9 months behind OpenBrain.)\",\"position\":\"$b08\"}\naf9:[\"$afa\",\"$afe\",\"$b07\"]\nb0c:{\"line\":88,\"column\":1,\"offset\":7825}\nb0d:{\"line\":88,\"column\":277,\"offset\":8101}\nb0b:{\"start\":\"$b0c\",\"end\":\"$b0d\"}\naf8:{\"type\":\"paragraph\",\"children\":\"$af9\",\"position\":\"$b0b\"}\nb0f:{}\nb10:[]\nb12:{\"line\":92,\"column\":1,\"offset\":8105}\nb13:{\"line\":93,\"column\":4,\"offset\":8122}\nb11:{\"start\":\"$b12\",\"end\":\"$b13\"}\nb0e:{\"type\":\"containerDirective\",\"name\":\"gptScale\",\"attributes\":\"$b0f\",\"children\":\"$b10\",\"position\":\"$b11\"}\nb18:{\"line\":95,\"column\":1,\"offset\":8124}\nb19:{\"line\":95,\"column\":16,\"offset\":8139"])</script><script>self.__next_f.push([1,"}\nb17:{\"start\":\"$b18\",\"end\":\"$b19\"}\nb16:{\"type\":\"text\",\"value\":\"GPT-4 required \",\"position\":\"$b17\"}\nb1d:[\"language-math\",\"math-inline\"]\nb1c:{\"className\":\"$b1d\"}\nb1f:{\"type\":\"text\",\"value\":\"2\\\\\\\\cdot 10^{25}\"}\nb1e:[\"$b1f\"]\nb1b:{\"hName\":\"code\",\"hProperties\":\"$b1c\",\"hChildren\":\"$b1e\"}\nb21:{\"line\":95,\"column\":16,\"offset\":8139}\nb22:{\"line\":95,\"column\":35,\"offset\":8158}\nb20:{\"start\":\"$b21\",\"end\":\"$b22\"}\nb1a:{\"type\":\"inlineMath\",\"value\":\"2\\\\\\\\cdot 10^{25}\",\"data\":\"$b1b\",\"position\":\"$b20\"}\nb25:{\"line\":95,\"column\":35,\"offset\":8158}\nb26:{\"line\":95,\"column\":36,\"offset\":8159}\nb24:{\"start\":\"$b25\",\"end\":\"$b26\"}\nb23:{\"type\":\"text\",\"value\":\" \",\"position\":\"$b24\"}\nb2b:{\"line\":95,\"column\":37,\"offset\":8160}\nb2c:{\"line\":95,\"column\":41,\"offset\":8164}\nb2a:{\"start\":\"$b2b\",\"end\":\"$b2c\"}\nb29:{\"type\":\"text\",\"value\":\"FLOP\",\"position\":\"$b2a\"}\nb28:[\"$b29\"]\nb2e:{\"line\":95,\"column\":36,\"offset\":8159}\nb2f:{\"line\":95,\"column\":110,\"offset\":8233}\nb2d:{\"start\":\"$b2e\",\"end\":\"$b2f\"}\nb27:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Floating_point_operations_per_second\",\"children\":\"$b28\",\"position\":\"$b2d\"}\nb32:{\"line\":95,\"column\":110,\"offset\":8233}\nb33:{\"line\":95,\"column\":131,\"offset\":8254}\nb31:{\"start\":\"$b32\",\"end\":\"$b33\"}\nb30:{\"type\":\"text\",\"value\":\" of compute to train.\",\"position\":\"$b31\"}\nb36:{\"line\":95,\"column\":131,\"offset\":8254}\nb37:{\"line\":95,\"column\":136,\"offset\":8259}\nb35:{\"start\":\"$b36\",\"end\":\"$b37\"}\nb34:{\"type\":\"footnoteReference\",\"identifier\":\"14\",\"label\":\"14\",\"position\":\"$b35\"}\nb3a:{\"line\":95,\"column\":136,\"offset\":8259}\nb3b:{\"line\":95,\"column\":194,\"offset\":8317}\nb39:{\"start\":\"$b3a\",\"end\":\"$b3b\"}\nb38:{\"type\":\"text\",\"value\":\" OpenBrain’s latest public model—Agent-0—was trained with \",\"position\":\"$b39\"}\nb3f:[\"language-math\",\"math-inline\"]\nb3e:{\"className\":\"$b3f\"}\nb41:{\"type\":\"text\",\"value\":\"10^{27}\"}\nb40:[\"$b41\"]\nb3d:{\"hName\":\"code\",\"hProperties\":\"$b3e\",\"hChildren\":\"$b40\"}\nb43:{\"line\":95,\"column\":194,\"offset\":8317}\nb44:{\"line\":95,\"column\":205,\"offset\":8328}\nb42:{\"start\":\"$b43\",\"end\":\"$b44\"}\nb3c:{\"type\":\"inlineMath\",\"va"])</script><script>self.__next_f.push([1,"lue\":\"10^{27}\",\"data\":\"$b3d\",\"position\":\"$b42\"}\nb47:{\"line\":95,\"column\":205,\"offset\":8328}\nb48:{\"line\":95,\"column\":257,\"offset\":8380}\nb46:{\"start\":\"$b47\",\"end\":\"$b48\"}\nb45:{\"type\":\"text\",\"value\":\" FLOP. Once the new datacenters are up and running, \",\"position\":\"$b46\"}\nb4d:{\"line\":95,\"column\":258,\"offset\":8381}\nb4e:{\"line\":95,\"column\":282,\"offset\":8405}\nb4c:{\"start\":\"$b4d\",\"end\":\"$b4e\"}\nb4b:{\"type\":\"text\",\"value\":\"they’ll be able to train\",\"position\":\"$b4c\"}\nb4a:[\"$b4b\"]\nb50:{\"line\":95,\"column\":257,\"offset\":8380}\nb51:{\"line\":95,\"column\":333,\"offset\":8456}\nb4f:{\"start\":\"$b50\",\"end\":\"$b51\"}\nb49:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast\",\"children\":\"$b4a\",\"position\":\"$b4f\"}\nb54:{\"line\":95,\"column\":333,\"offset\":8456}\nb55:{\"line\":95,\"column\":347,\"offset\":8470}\nb53:{\"start\":\"$b54\",\"end\":\"$b55\"}\nb52:{\"type\":\"text\",\"value\":\" a model with \",\"position\":\"$b53\"}\nb59:[\"language-math\",\"math-inline\"]\nb58:{\"className\":\"$b59\"}\nb5b:{\"type\":\"text\",\"value\":\"10^{28}\"}\nb5a:[\"$b5b\"]\nb57:{\"hName\":\"code\",\"hProperties\":\"$b58\",\"hChildren\":\"$b5a\"}\nb5d:{\"line\":95,\"column\":347,\"offset\":8470}\nb5e:{\"line\":95,\"column\":358,\"offset\":8481}\nb5c:{\"start\":\"$b5d\",\"end\":\"$b5e\"}\nb56:{\"type\":\"inlineMath\",\"value\":\"10^{28}\",\"data\":\"$b57\",\"position\":\"$b5c\"}\nb61:{\"line\":95,\"column\":358,\"offset\":8481}\nb62:{\"line\":95,\"column\":397,\"offset\":8520}\nb60:{\"start\":\"$b61\",\"end\":\"$b62\"}\nb5f:{\"type\":\"text\",\"value\":\" FLOP—a thousand times more than GPT-4.\",\"position\":\"$b60\"}\nb65:{\"line\":95,\"column\":397,\"offset\":8520}\nb66:{\"line\":95,\"column\":402,\"offset\":8525}\nb64:{\"start\":\"$b65\",\"end\":\"$b66\"}\nb63:{\"type\":\"footnoteReference\",\"identifier\":\"15\",\"label\":\"15\",\"position\":\"$b64\"}\nb69:{\"line\":95,\"column\":402,\"offset\":8525}\nb6a:{\"line\":95,\"column\":484,\"offset\":8607}\nb68:{\"start\":\"$b69\",\"end\":\"$b6a\"}\nb67:{\"type\":\"text\",\"value\":\" Other companies pour money into their own giant datacenters, hoping to keep pace.\",\"position\":\"$b68\"}\nb15:[\"$b16\",\"$b1a\",\"$b23\",\"$b27\",\"$b30\",\"$b34\",\"$b38\",\"$b3c\",\"$b45\",\"$b49\",\"$b52\",\"$b56\",\"$b5f\",\"$b63\",\"$b67\"]"])</script><script>self.__next_f.push([1,"\nb6c:{\"line\":95,\"column\":1,\"offset\":8124}\nb6d:{\"line\":95,\"column\":484,\"offset\":8607}\nb6b:{\"start\":\"$b6c\",\"end\":\"$b6d\"}\nb14:{\"type\":\"paragraph\",\"children\":\"$b15\",\"position\":\"$b6b\"}\nb72:{\"line\":97,\"column\":1,\"offset\":8609}\nb73:{\"line\":97,\"column\":226,\"offset\":8834}\nb71:{\"start\":\"$b72\",\"end\":\"$b73\"}\nb70:{\"type\":\"text\",\"value\":\"Although models are improving on a wide range of skills, one stands out: OpenBrain focuses on AIs that can speed up AI research. They want to win the twin arms races against China (whose leading company we’ll call “DeepCent”)\",\"position\":\"$b71\"}\nb76:{\"line\":97,\"column\":226,\"offset\":8834}\nb77:{\"line\":97,\"column\":231,\"offset\":8839}\nb75:{\"start\":\"$b76\",\"end\":\"$b77\"}\nb74:{\"type\":\"footnoteReference\",\"identifier\":\"16\",\"label\":\"16\",\"position\":\"$b75\"}\nb7a:{\"line\":97,\"column\":231,\"offset\":8839}\nb7b:{\"line\":97,\"column\":473,\"offset\":9081}\nb79:{\"start\":\"$b7a\",\"end\":\"$b7b\"}\nb78:{\"type\":\"text\",\"value\":\" and their U.S. competitors. The more of their research and development (R\u0026D) cycle they can automate, the faster they can go. So when OpenBrain finishes training Agent-1, a new model under internal development, it’s good at many things but \",\"position\":\"$b79\"}\nb80:{\"line\":97,\"column\":474,\"offset\":9082}\nb81:{\"line\":97,\"column\":479,\"offset\":9087}\nb7f:{\"start\":\"$b80\",\"end\":\"$b81\"}\nb7e:{\"type\":\"text\",\"value\":\"great\",\"position\":\"$b7f\"}\nb7d:[\"$b7e\"]\nb83:{\"line\":97,\"column\":473,\"offset\":9081}\nb84:{\"line\":97,\"column\":480,\"offset\":9088}\nb82:{\"start\":\"$b83\",\"end\":\"$b84\"}\nb7c:{\"type\":\"emphasis\",\"children\":\"$b7d\",\"position\":\"$b82\"}\nb87:{\"line\":97,\"column\":480,\"offset\":9088}\nb88:{\"line\":97,\"column\":509,\"offset\":9117}\nb86:{\"start\":\"$b87\",\"end\":\"$b88\"}\nb85:{\"type\":\"text\",\"value\":\" at helping with AI research.\",\"position\":\"$b86\"}\nb8b:{\"line\":97,\"column\":509,\"offset\":9117}\nb8c:{\"line\":97,\"column\":514,\"offset\":9122}\nb8a:{\"start\":\"$b8b\",\"end\":\"$b8c\"}\nb89:{\"type\":\"footnoteReference\",\"identifier\":\"17\",\"label\":\"17\",\"position\":\"$b8a\"}\nb8f:{\"line\":97,\"column\":514,\"offset\":9122}\nb90:{\"line\":97,\"column\":697,\"offset\":9305}\nb8e"])</script><script>self.__next_f.push([1,":{\"start\":\"$b8f\",\"end\":\"$b90\"}\nb8d:{\"type\":\"text\",\"value\":\" By this point “finishes training” is a bit of a misnomer; models are frequently updated to newer versions trained on additional data or partially re-trained to patch some weaknesses.\",\"position\":\"$b8e\"}\nb93:{\"line\":97,\"column\":697,\"offset\":9305}\nb94:{\"line\":97,\"column\":702,\"offset\":9310}\nb92:{\"start\":\"$b93\",\"end\":\"$b94\"}\nb91:{\"type\":\"footnoteReference\",\"identifier\":\"18\",\"label\":\"18\",\"position\":\"$b92\"}\nb6f:[\"$b70\",\"$b74\",\"$b78\",\"$b7c\",\"$b85\",\"$b89\",\"$b8d\",\"$b91\"]\nb96:{\"line\":97,\"column\":1,\"offset\":8609}\nb97:{\"line\":97,\"column\":703,\"offset\":9311}\nb95:{\"start\":\"$b96\",\"end\":\"$b97\"}\nb6e:{\"type\":\"paragraph\",\"children\":\"$b6f\",\"position\":\"$b95\"}\nb9c:{\"line\":99,\"column\":1,\"offset\":9313}\nb9d:{\"line\":99,\"column\":140,\"offset\":9452}\nb9b:{\"start\":\"$b9c\",\"end\":\"$b9d\"}\nb9a:{\"type\":\"text\",\"value\":\"The same training environments that teach Agent-1 to autonomously code and web-browse also make it a good hacker. Moreover, it could offer \",\"position\":\"$b9b\"}\nba2:{\"line\":99,\"column\":141,\"offset\":9453}\nba3:{\"line\":99,\"column\":157,\"offset\":9469}\nba1:{\"start\":\"$ba2\",\"end\":\"$ba3\"}\nba0:{\"type\":\"text\",\"value\":\"substantial help\",\"position\":\"$ba1\"}\nb9f:[\"$ba0\"]\nba5:{\"line\":99,\"column\":140,\"offset\":9452}\nba6:{\"line\":99,\"column\":214,\"offset\":9526}\nba4:{\"start\":\"$ba5\",\"end\":\"$ba6\"}\nb9e:{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/lucafrighetti/status/1894550297449828434\",\"children\":\"$b9f\",\"position\":\"$ba4\"}\nba9:{\"line\":99,\"column\":214,\"offset\":9526}\nbaa:{\"line\":99,\"column\":457,\"offset\":9769}\nba8:{\"start\":\"$ba9\",\"end\":\"$baa\"}\nba7:{\"type\":\"text\",\"value\":\" to terrorists designing bioweapons, thanks to its PhD-level knowledge of every field and ability to browse the web. OpenBrain reassures the government that the model has been “aligned” so that it will refuse to comply with malicious requests.\",\"position\":\"$ba8\"}\nb99:[\"$b9a\",\"$b9e\",\"$ba7\"]\nbac:{\"line\":99,\"column\":1,\"offset\":9313}\nbad:{\"line\":99,\"column\":457,\"offset\":9769}\nbab:{\"start\":\"$bac\",\"end\":\"$bad\"}\nb98:{\"type\":\"paragrap"])</script><script>self.__next_f.push([1,"h\",\"children\":\"$b99\",\"position\":\"$bab\"}\nbb2:{\"line\":101,\"column\":1,\"offset\":9771}\nbb3:{\"line\":101,\"column\":447,\"offset\":10217}\nbb1:{\"start\":\"$bb2\",\"end\":\"$bb3\"}\nbb0:{\"type\":\"text\",\"value\":\"Modern AI systems are gigantic artificial neural networks. Early in training, an AI won’t have “goals” so much as “reflexes”: If it sees “Pleased to meet”, it outputs “ you”. By the time it has been trained to predict approximately one internet’s worth of text, it’ll have developed sophisticated internal circuitry that encodes vast amounts of knowledge and flexibly role-plays as arbitrary authors, since that’s what helps it predict text with \",\"position\":\"$bb1\"}\nbb8:{\"line\":101,\"column\":448,\"offset\":10218}\nbb9:{\"line\":101,\"column\":458,\"offset\":10228}\nbb7:{\"start\":\"$bb8\",\"end\":\"$bb9\"}\nbb6:{\"type\":\"text\",\"value\":\"superhuman\",\"position\":\"$bb7\"}\nbb5:[\"$bb6\"]\nbbb:{\"line\":101,\"column\":447,\"offset\":10217}\nbbc:{\"line\":101,\"column\":493,\"offset\":10263}\nbba:{\"start\":\"$bbb\",\"end\":\"$bbc\"}\nbb4:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2212.11281\",\"children\":\"$bb5\",\"position\":\"$bba\"}\nbbf:{\"line\":101,\"column\":493,\"offset\":10263}\nbc0:{\"line\":101,\"column\":503,\"offset\":10273}\nbbe:{\"start\":\"$bbf\",\"end\":\"$bc0\"}\nbbd:{\"type\":\"text\",\"value\":\" accuracy.\",\"position\":\"$bbe\"}\nbc3:{\"line\":101,\"column\":503,\"offset\":10273}\nbc4:{\"line\":101,\"column\":508,\"offset\":10278}\nbc2:{\"start\":\"$bc3\",\"end\":\"$bc4\"}\nbc1:{\"type\":\"footnoteReference\",\"identifier\":\"19\",\"label\":\"19\",\"position\":\"$bc2\"}\nbaf:[\"$bb0\",\"$bb4\",\"$bbd\",\"$bc1\"]\nbc6:{\"line\":101,\"column\":1,\"offset\":9771}\nbc7:{\"line\":101,\"column\":508,\"offset\":10278}\nbc5:{\"start\":\"$bc6\",\"end\":\"$bc7\"}\nbae:{\"type\":\"paragraph\",\"children\":\"$baf\",\"position\":\"$bc5\"}\nbcc:{\"line\":103,\"column\":1,\"offset\":10280}\nbcd:{\"line\":103,\"column\":71,\"offset\":10350}\nbcb:{\"start\":\"$bcc\",\"end\":\"$bcd\"}\nbca:{\"type\":\"text\",\"value\":\"After being trained to predict internet text, the model is trained to \",\"position\":\"$bcb\"}\nbd2:{\"line\":103,\"column\":72,\"offset\":10351}\nbd3:{\"line\":103,\"column\":79,\"offset\":10358}\nbd1:{"])</script><script>self.__next_f.push([1,"\"start\":\"$bd2\",\"end\":\"$bd3\"}\nbd0:{\"type\":\"text\",\"value\":\"produce\",\"position\":\"$bd1\"}\nbcf:[\"$bd0\"]\nbd5:{\"line\":103,\"column\":71,\"offset\":10350}\nbd6:{\"line\":103,\"column\":80,\"offset\":10359}\nbd4:{\"start\":\"$bd5\",\"end\":\"$bd6\"}\nbce:{\"type\":\"emphasis\",\"children\":\"$bcf\",\"position\":\"$bd4\"}\nbd9:{\"line\":103,\"column\":80,\"offset\":10359}\nbda:{\"line\":103,\"column\":162,\"offset\":10441}\nbd8:{\"start\":\"$bd9\",\"end\":\"$bda\"}\nbd7:{\"type\":\"text\",\"value\":\" text in response to instructions. This bakes in a basic personality and “drives.”\",\"position\":\"$bd8\"}\nbdd:{\"line\":103,\"column\":162,\"offset\":10441}\nbde:{\"line\":103,\"column\":167,\"offset\":10446}\nbdc:{\"start\":\"$bdd\",\"end\":\"$bde\"}\nbdb:{\"type\":\"footnoteReference\",\"identifier\":\"20\",\"label\":\"20\",\"position\":\"$bdc\"}\nbe1:{\"line\":103,\"column\":167,\"offset\":10446}\nbe2:{\"line\":103,\"column\":521,\"offset\":10800}\nbe0:{\"start\":\"$be1\",\"end\":\"$be2\"}\nbdf:{\"type\":\"text\",\"value\":\" For example, an agent that understands a task clearly is more likely to complete it successfully; over the course of training the model “learns” a “drive” to get a clear understanding of its tasks. Other drives in this category might be effectiveness, knowledge, and self-presentation (i.e. the tendency to frame its results in the best possible light).\",\"position\":\"$be0\"}\nbe5:{\"line\":103,\"column\":521,\"offset\":10800}\nbe6:{\"line\":103,\"column\":526,\"offset\":10805}\nbe4:{\"start\":\"$be5\",\"end\":\"$be6\"}\nbe3:{\"type\":\"footnoteReference\",\"identifier\":\"21\",\"label\":\"21\",\"position\":\"$be4\"}\nbc9:[\"$bca\",\"$bce\",\"$bd7\",\"$bdb\",\"$bdf\",\"$be3\"]\nbe8:{\"line\":103,\"column\":1,\"offset\":10280}\nbe9:{\"line\":103,\"column\":526,\"offset\":10805}\nbe7:{\"start\":\"$be8\",\"end\":\"$be9\"}\nbc8:{\"type\":\"paragraph\",\"children\":\"$bc9\",\"position\":\"$be7\"}\nbee:{\"line\":105,\"column\":1,\"offset\":10807}\nbef:{\"line\":105,\"column\":15,\"offset\":10821}\nbed:{\"start\":\"$bee\",\"end\":\"$bef\"}\nbec:{\"type\":\"text\",\"value\":\"OpenBrain has \",\"position\":\"$bed\"}\nbf4:{\"line\":105,\"column\":16,\"offset\":10822}\nbf5:{\"line\":105,\"column\":37,\"offset\":10843}\nbf3:{\"start\":\"$bf4\",\"end\":\"$bf5\"}\nbf2:{\"type\":\"text\",\"value\""])</script><script>self.__next_f.push([1,":\"a model specification\",\"position\":\"$bf3\"}\nbf1:[\"$bf2\"]\nbf7:{\"line\":105,\"column\":15,\"offset\":10821}\nbf8:{\"line\":105,\"column\":85,\"offset\":10891}\nbf6:{\"start\":\"$bf7\",\"end\":\"$bf8\"}\nbf0:{\"type\":\"link\",\"title\":null,\"url\":\"https://model-spec.openai.com/2025-02-12.html\",\"children\":\"$bf1\",\"position\":\"$bf6\"}\nbfb:{\"line\":105,\"column\":85,\"offset\":10891}\nbfc:{\"line\":105,\"column\":212,\"offset\":11018}\nbfa:{\"start\":\"$bfb\",\"end\":\"$bfc\"}\nbf9:{\"type\":\"text\",\"value\":\" (or “Spec”), a written document describing the goals, rules, principles, etc. that are supposed to guide the model’s behavior.\",\"position\":\"$bfa\"}\nbff:{\"line\":105,\"column\":212,\"offset\":11018}\nc00:{\"line\":105,\"column\":217,\"offset\":11023}\nbfe:{\"start\":\"$bff\",\"end\":\"$c00\"}\nbfd:{\"type\":\"footnoteReference\",\"identifier\":\"22\",\"label\":\"22\",\"position\":\"$bfe\"}\nc03:{\"line\":105,\"column\":217,\"offset\":11023}\nc04:{\"line\":105,\"column\":499,\"offset\":11305}\nc02:{\"start\":\"$c03\",\"end\":\"$c04\"}\nc01:{\"type\":\"text\",\"value\":\" Agent-1’s Spec combines a few vague goals (like “assist the user” and “don’t break the law”) with a long list of more specific dos and don’ts (“don’t say this particular word,” “here’s how to handle this particular situation”). Using techniques that utilize AIs to train other AIs,\",\"position\":\"$c02\"}\nc07:{\"line\":105,\"column\":499,\"offset\":11305}\nc08:{\"line\":105,\"column\":504,\"offset\":11310}\nc06:{\"start\":\"$c07\",\"end\":\"$c08\"}\nc05:{\"type\":\"footnoteReference\",\"identifier\":\"23\",\"label\":\"23\",\"position\":\"$c06\"}\nc0b:{\"line\":105,\"column\":504,\"offset\":11310}\nc0c:{\"line\":105,\"column\":597,\"offset\":11403}\nc0a:{\"start\":\"$c0b\",\"end\":\"$c0c\"}\nc09:{\"type\":\"text\",\"value\":\" the model memorizes the Spec and learns to reason carefully about its maxims. By the end of \",\"position\":\"$c0a\"}\nc11:{\"line\":105,\"column\":598,\"offset\":11404}\nc12:{\"line\":105,\"column\":602,\"offset\":11408}\nc10:{\"start\":\"$c11\",\"end\":\"$c12\"}\nc0f:{\"type\":\"text\",\"value\":\"this\",\"position\":\"$c10\"}\nc0e:[\"$c0f\"]\nc14:{\"line\":105,\"column\":597,\"offset\":11403}\nc15:{\"line\":105,\"column\":603,\"offset\":11409}\nc1"])</script><script>self.__next_f.push([1,"3:{\"start\":\"$c14\",\"end\":\"$c15\"}\nc0d:{\"type\":\"emphasis\",\"children\":\"$c0e\",\"position\":\"$c13\"}\nc18:{\"line\":105,\"column\":603,\"offset\":11409}\nc19:{\"line\":105,\"column\":639,\"offset\":11445}\nc17:{\"start\":\"$c18\",\"end\":\"$c19\"}\nc16:{\"type\":\"text\",\"value\":\" training, the AI will hopefully be \",\"position\":\"$c17\"}\nc1e:{\"line\":105,\"column\":640,\"offset\":11446}\nc1f:{\"line\":105,\"column\":647,\"offset\":11453}\nc1d:{\"start\":\"$c1e\",\"end\":\"$c1f\"}\nc1c:{\"type\":\"text\",\"value\":\"helpful\",\"position\":\"$c1d\"}\nc1b:[\"$c1c\"]\nc21:{\"line\":105,\"column\":639,\"offset\":11445}\nc22:{\"line\":105,\"column\":648,\"offset\":11454}\nc20:{\"start\":\"$c21\",\"end\":\"$c22\"}\nc1a:{\"type\":\"emphasis\",\"children\":\"$c1b\",\"position\":\"$c20\"}\nc25:{\"line\":105,\"column\":648,\"offset\":11454}\nc26:{\"line\":105,\"column\":670,\"offset\":11476}\nc24:{\"start\":\"$c25\",\"end\":\"$c26\"}\nc23:{\"type\":\"text\",\"value\":\" (obey instructions), \",\"position\":\"$c24\"}\nc2b:{\"line\":105,\"column\":671,\"offset\":11477}\nc2c:{\"line\":105,\"column\":679,\"offset\":11485}\nc2a:{\"start\":\"$c2b\",\"end\":\"$c2c\"}\nc29:{\"type\":\"text\",\"value\":\"harmless\",\"position\":\"$c2a\"}\nc28:[\"$c29\"]\nc2e:{\"line\":105,\"column\":670,\"offset\":11476}\nc2f:{\"line\":105,\"column\":680,\"offset\":11486}\nc2d:{\"start\":\"$c2e\",\"end\":\"$c2f\"}\nc27:{\"type\":\"emphasis\",\"children\":\"$c28\",\"position\":\"$c2d\"}\nc32:{\"line\":105,\"column\":680,\"offset\":11486}\nc33:{\"line\":105,\"column\":758,\"offset\":11564}\nc31:{\"start\":\"$c32\",\"end\":\"$c33\"}\nc30:{\"type\":\"text\",\"value\":\" (refuse to help with scams, bomb-making, and other dangerous activities) and \",\"position\":\"$c31\"}\nc38:{\"line\":105,\"column\":759,\"offset\":11565}\nc39:{\"line\":105,\"column\":765,\"offset\":11571}\nc37:{\"start\":\"$c38\",\"end\":\"$c39\"}\nc36:{\"type\":\"text\",\"value\":\"honest\",\"position\":\"$c37\"}\nc35:[\"$c36\"]\nc3b:{\"line\":105,\"column\":758,\"offset\":11564}\nc3c:{\"line\":105,\"column\":766,\"offset\":11572}\nc3a:{\"start\":\"$c3b\",\"end\":\"$c3c\"}\nc34:{\"type\":\"emphasis\",\"children\":\"$c35\",\"position\":\"$c3a\"}\nc3f:{\"line\":105,\"column\":766,\"offset\":11572}\nc40:{\"line\":105,\"column\":859,\"offset\":11665}\nc3e:{\"start\":\"$c3f\",\"end\":\"$c40\"}\nc3d:{\"type\":\"text\",\"value\":\" (resist the tempt"])</script><script>self.__next_f.push([1,"ation to get better ratings from gullible humans by hallucinating citations\",\"position\":\"$c3e\"}\nc43:{\"line\":105,\"column\":859,\"offset\":11665}\nc44:{\"line\":105,\"column\":864,\"offset\":11670}\nc42:{\"start\":\"$c43\",\"end\":\"$c44\"}\nc41:{\"type\":\"footnoteReference\",\"identifier\":\"24\",\"label\":\"24\",\"position\":\"$c42\"}\nc47:{\"line\":105,\"column\":864,\"offset\":11670}\nc48:{\"line\":105,\"column\":892,\"offset\":11698}\nc46:{\"start\":\"$c47\",\"end\":\"$c48\"}\nc45:{\"type\":\"text\",\"value\":\" or faking task completion).\",\"position\":\"$c46\"}\nbeb:[\"$bec\",\"$bf0\",\"$bf9\",\"$bfd\",\"$c01\",\"$c05\",\"$c09\",\"$c0d\",\"$c16\",\"$c1a\",\"$c23\",\"$c27\",\"$c30\",\"$c34\",\"$c3d\",\"$c41\",\"$c45\"]\nc4a:{\"line\":105,\"column\":1,\"offset\":10807}\nc4b:{\"line\":105,\"column\":892,\"offset\":11698}\nc49:{\"start\":\"$c4a\",\"end\":\"$c4b\"}\nbea:{\"type\":\"paragraph\",\"children\":\"$beb\",\"position\":\"$c49\"}\nc54:{\"line\":111,\"column\":2,\"offset\":11782}\nc55:{\"line\":111,\"column\":258,\"offset\":12038}\nc53:{\"start\":\"$c54\",\"end\":\"$c55\"}\nc52:{\"type\":\"text\",\"value\":\"“Unlike ordinary software, our models are massive neural networks. Their behaviors are learned from a broad range of data, not programmed explicitly. Though not a perfect analogy, the process is more similar to training a dog than to ordinary programming.”\",\"position\":\"$c53\"}\nc51:[\"$c52\"]\nc57:{\"line\":111,\"column\":1,\"offset\":11781}\nc58:{\"line\":111,\"column\":259,\"offset\":12039}\nc56:{\"start\":\"$c57\",\"end\":\"$c58\"}\nc50:{\"type\":\"emphasis\",\"children\":\"$c51\",\"position\":\"$c56\"}\nc5b:{\"line\":111,\"column\":259,\"offset\":12039}\nc5c:{\"line\":111,\"column\":261,\"offset\":12041}\nc5a:{\"start\":\"$c5b\",\"end\":\"$c5c\"}\nc59:{\"type\":\"text\",\"value\":\" —\",\"position\":\"$c5a\"}\nc61:{\"line\":111,\"column\":262,\"offset\":12042}\nc62:{\"line\":111,\"column\":268,\"offset\":12048}\nc60:{\"start\":\"$c61\",\"end\":\"$c62\"}\nc5f:{\"type\":\"text\",\"value\":\"OpenAI\",\"position\":\"$c60\"}\nc5e:[\"$c5f\"]\nc64:{\"line\":111,\"column\":261,\"offset\":12041}\nc65:{\"line\":111,\"column\":325,\"offset\":12105}\nc63:{\"start\":\"$c64\",\"end\":\"$c65\"}\nc5d:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/how-should-ai-systems-behave/\",\"children\":\"$c5e\",\"posi"])</script><script>self.__next_f.push([1,"tion\":\"$c63\"}\nc4f:[\"$c50\",\"$c59\",\"$c5d\"]\nc67:{\"line\":111,\"column\":1,\"offset\":11781}\nc68:{\"line\":111,\"column\":325,\"offset\":12105}\nc66:{\"start\":\"$c67\",\"end\":\"$c68\"}\nc4e:{\"type\":\"paragraph\",\"children\":\"$c4f\",\"position\":\"$c66\"}\nc6d:{\"line\":113,\"column\":1,\"offset\":12107}\nc6e:{\"line\":113,\"column\":548,\"offset\":12654}\nc6c:{\"start\":\"$c6d\",\"end\":\"$c6e\"}\nc6b:{\"type\":\"text\",\"value\":\"When we want to understand why a modern AI system did something, or how it would behave in some future scenario we can’t perfectly simulate, we can’t simply ask the programmers to talk us through various lines of code and explain how they work. Instead, we are forced to do something like psychology on them: we look at their behavior in the range of cases observed so far, and theorize about what internal cognitive structures (beliefs? goals? personality traits? etc.) might exist, and use those theories to predict behavior in future scenarios.\",\"position\":\"$c6c\"}\nc6a:[\"$c6b\"]\nc70:{\"line\":113,\"column\":1,\"offset\":12107}\nc71:{\"line\":113,\"column\":549,\"offset\":12655}\nc6f:{\"start\":\"$c70\",\"end\":\"$c71\"}\nc69:{\"type\":\"paragraph\",\"children\":\"$c6a\",\"position\":\"$c6f\"}\nc76:{\"line\":115,\"column\":1,\"offset\":12657}\nc77:{\"line\":115,\"column\":178,\"offset\":12834}\nc75:{\"start\":\"$c76\",\"end\":\"$c77\"}\nc74:{\"type\":\"text\",\"value\":\"The bottom line is that a company can write up a document (the Spec) listing dos and don’ts, goals and principles, and then they can try to train the AI to internalize the Spec—\",\"position\":\"$c75\"}\nc7c:{\"line\":115,\"column\":179,\"offset\":12835}\nc7d:{\"line\":115,\"column\":231,\"offset\":12887}\nc7b:{\"start\":\"$c7c\",\"end\":\"$c7d\"}\nc7a:{\"type\":\"text\",\"value\":\"but they can’t check to see whether or not it worked\",\"position\":\"$c7b\"}\nc79:[\"$c7a\"]\nc7f:{\"line\":115,\"column\":178,\"offset\":12834}\nc80:{\"line\":115,\"column\":232,\"offset\":12888}\nc7e:{\"start\":\"$c7f\",\"end\":\"$c80\"}\nc78:{\"type\":\"emphasis\",\"children\":\"$c79\",\"position\":\"$c7e\"}\nc83:{\"line\":115,\"column\":232,\"offset\":12888}\nc84:{\"line\":115,\"column\":315,\"offset\":12971}\nc82:{\"start\":\"$c83\",\"end\":\"$c84\"}\nc81:{\""])</script><script>self.__next_f.push([1,"type\":\"text\",\"value\":\". They can say “as best as we can judge, it seems to be following the Spec so far.”\",\"position\":\"$c82\"}\nc87:{\"line\":115,\"column\":315,\"offset\":12971}\nc88:{\"line\":115,\"column\":320,\"offset\":12976}\nc86:{\"start\":\"$c87\",\"end\":\"$c88\"}\nc85:{\"type\":\"footnoteReference\",\"identifier\":\"25\",\"label\":\"25\",\"position\":\"$c86\"}\nc73:[\"$c74\",\"$c78\",\"$c81\",\"$c85\"]\nc8a:{\"line\":115,\"column\":1,\"offset\":12657}\nc8b:{\"line\":115,\"column\":320,\"offset\":12976}\nc89:{\"start\":\"$c8a\",\"end\":\"$c8b\"}\nc72:{\"type\":\"paragraph\",\"children\":\"$c73\",\"position\":\"$c89\"}\nc90:{\"line\":117,\"column\":1,\"offset\":12978}\nc91:{\"line\":117,\"column\":65,\"offset\":13042}\nc8f:{\"start\":\"$c90\",\"end\":\"$c91\"}\nc8e:{\"type\":\"text\",\"value\":\"A later expandable will go into more detail about what we think \",\"position\":\"$c8f\"}\nc96:{\"line\":117,\"column\":66,\"offset\":13043}\nc97:{\"line\":117,\"column\":71,\"offset\":13048}\nc95:{\"start\":\"$c96\",\"end\":\"$c97\"}\nc94:{\"type\":\"text\",\"value\":\"might\",\"position\":\"$c95\"}\nc93:[\"$c94\"]\nc99:{\"line\":117,\"column\":65,\"offset\":13042}\nc9a:{\"line\":117,\"column\":72,\"offset\":13049}\nc98:{\"start\":\"$c99\",\"end\":\"$c9a\"}\nc92:{\"type\":\"emphasis\",\"children\":\"$c93\",\"position\":\"$c98\"}\nc9d:{\"line\":117,\"column\":72,\"offset\":13049}\nc9e:{\"line\":117,\"column\":128,\"offset\":13105}\nc9c:{\"start\":\"$c9d\",\"end\":\"$c9e\"}\nc9b:{\"type\":\"text\",\"value\":\" be going on inside these AIs, internally. See also our \",\"position\":\"$c9c\"}\nca3:{\"line\":117,\"column\":129,\"offset\":13106}\nca4:{\"line\":117,\"column\":160,\"offset\":13137}\nca2:{\"start\":\"$ca3\",\"end\":\"$ca4\"}\nca1:{\"type\":\"text\",\"value\":\"AI goals forecasting supplement\",\"position\":\"$ca2\"}\nca0:[\"$ca1\"]\nca6:{\"line\":117,\"column\":128,\"offset\":13105}\nca7:{\"line\":117,\"column\":212,\"offset\":13189}\nca5:{\"start\":\"$ca6\",\"end\":\"$ca7\"}\nc9f:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/ai-goals-forecast\",\"children\":\"$ca0\",\"position\":\"$ca5\"}\ncaa:{\"line\":117,\"column\":212,\"offset\":13189}\ncab:{\"line\":117,\"column\":371,\"offset\":13348}\nca9:{\"start\":\"$caa\",\"end\":\"$cab\"}\nca8:{\"type\":\"text\",\"value\":\" which goes into more detail on which goal"])</script><script>self.__next_f.push([1,"s AIs might have and why. This is one of many things that we are uncertain about and which deserves further research.\",\"position\":\"$ca9\"}\nc8d:[\"$c8e\",\"$c92\",\"$c9b\",\"$c9f\",\"$ca8\"]\ncad:{\"line\":117,\"column\":1,\"offset\":12978}\ncae:{\"line\":117,\"column\":371,\"offset\":13348}\ncac:{\"start\":\"$cad\",\"end\":\"$cae\"}\nc8c:{\"type\":\"paragraph\",\"children\":\"$c8d\",\"position\":\"$cac\"}\nc4d:[\"$c4e\",\"$c69\",\"$c72\",\"$c8c\"]\nc4c:{\"type\":\"details\",\"summary\":\"Training process and LLM psychology: why we keep saying “hopefully”\",\"children\":\"$c4d\"}\ncb3:{\"line\":121,\"column\":1,\"offset\":13355}\ncb4:{\"line\":121,\"column\":27,\"offset\":13381}\ncb2:{\"start\":\"$cb3\",\"end\":\"$cb4\"}\ncb1:{\"type\":\"text\",\"value\":\"OpenBrain’s alignment team\",\"position\":\"$cb2\"}\ncb7:{\"line\":121,\"column\":27,\"offset\":13381}\ncb8:{\"line\":121,\"column\":32,\"offset\":13386}\ncb6:{\"start\":\"$cb7\",\"end\":\"$cb8\"}\ncb5:{\"type\":\"footnoteReference\",\"identifier\":\"26\",\"label\":\"26\",\"position\":\"$cb6\"}\ncbb:{\"line\":121,\"column\":32,\"offset\":13386}\ncbc:{\"line\":121,\"column\":285,\"offset\":13639}\ncba:{\"start\":\"$cbb\",\"end\":\"$cbc\"}\ncb9:{\"type\":\"text\",\"value\":\" is careful enough to wonder whether these victories are deep or shallow. Does the fully-trained model have some kind of robust commitment to always being honest? Or will this fall apart in some future situation, e.g. because it’s learned honesty as an \",\"position\":\"$cba\"}\ncc1:{\"line\":121,\"column\":286,\"offset\":13640}\ncc2:{\"line\":121,\"column\":298,\"offset\":13652}\ncc0:{\"start\":\"$cc1\",\"end\":\"$cc2\"}\ncbf:{\"type\":\"text\",\"value\":\"instrumental\",\"position\":\"$cc0\"}\ncbe:[\"$cbf\"]\ncc4:{\"line\":121,\"column\":285,\"offset\":13639}\ncc5:{\"line\":121,\"column\":363,\"offset\":13717}\ncc3:{\"start\":\"$cc4\",\"end\":\"$cc5\"}\ncbd:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Instrumental_and_intrinsic_value\",\"children\":\"$cbe\",\"position\":\"$cc3\"}\ncc8:{\"line\":121,\"column\":363,\"offset\":13717}\ncc9:{\"line\":121,\"column\":771,\"offset\":14125}\ncc7:{\"start\":\"$cc8\",\"end\":\"$cc9\"}\ncc6:{\"type\":\"text\",\"value\":\" goal instead of a terminal goal? Or has it just learned to be honest about the sort"])</script><script>self.__next_f.push([1,"s of things the evaluation process can check? Could it be lying to itself sometimes, as humans do? A conclusive answer to these questions would require mechanistic interpretability—essentially the ability to look at an AI’s internals and read its mind. Alas, interpretability techniques are not yet advanced enough for this.\",\"position\":\"$cc7\"}\ncb0:[\"$cb1\",\"$cb5\",\"$cb9\",\"$cbd\",\"$cc6\"]\nccb:{\"line\":121,\"column\":1,\"offset\":13355}\nccc:{\"line\":121,\"column\":771,\"offset\":14125}\ncca:{\"start\":\"$ccb\",\"end\":\"$ccc\"}\ncaf:{\"type\":\"paragraph\",\"children\":\"$cb0\",\"position\":\"$cca\"}\ncd1:{\"line\":123,\"column\":1,\"offset\":14127}\ncd2:{\"line\":123,\"column\":219,\"offset\":14345}\ncd0:{\"start\":\"$cd1\",\"end\":\"$cd2\"}\nccf:{\"type\":\"text\",\"value\":\"Instead, researchers try to identify cases where the models seem to deviate from the Spec. Agent-1 is often sycophantic (i.e. it tells researchers what they want to hear instead of trying to tell them the truth). In a \",\"position\":\"$cd0\"}\ncd7:{\"line\":123,\"column\":220,\"offset\":14346}\ncd8:{\"line\":123,\"column\":236,\"offset\":14362}\ncd6:{\"start\":\"$cd7\",\"end\":\"$cd8\"}\ncd5:{\"type\":\"text\",\"value\":\"few rigged demos\",\"position\":\"$cd6\"}\ncd4:[\"$cd5\"]\ncda:{\"line\":123,\"column\":219,\"offset\":14345}\ncdb:{\"line\":123,\"column\":308,\"offset\":14434}\ncd9:{\"start\":\"$cda\",\"end\":\"$cdb\"}\ncd3:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.apolloresearch.ai/research/scheming-reasoning-evaluations\",\"children\":\"$cd4\",\"position\":\"$cd9\"}\ncde:{\"line\":123,\"column\":308,\"offset\":14434}\ncdf:{\"line\":123,\"column\":529,\"offset\":14655}\ncdd:{\"start\":\"$cde\",\"end\":\"$cdf\"}\ncdc:{\"type\":\"text\",\"value\":\", it even lies in more serious ways, like hiding evidence that it failed on a task, in order to get better ratings. However, in real deployment settings, there are no longer any incidents so extreme as in 2023–2024 (e.g. \",\"position\":\"$cdd\"}\nce4:{\"line\":123,\"column\":530,\"offset\":14656}\nce5:{\"line\":123,\"column\":558,\"offset\":14684}\nce3:{\"start\":\"$ce4\",\"end\":\"$ce5\"}\nce2:{\"type\":\"text\",\"value\":\"Gemini telling a user to die\",\"position\":\"$ce3\"}\nce1:[\"$ce2\"]\nce7"])</script><script>self.__next_f.push([1,":{\"line\":123,\"column\":529,\"offset\":14655}\nce8:{\"line\":123,\"column\":633,\"offset\":14759}\nce6:{\"start\":\"$ce7\",\"end\":\"$ce8\"}\nce0:{\"type\":\"link\",\"title\":null,\"url\":\"https://thehill.com/policy/technology/4998868-google-ai-gemini-response/\",\"children\":\"$ce1\",\"position\":\"$ce6\"}\nceb:{\"line\":123,\"column\":633,\"offset\":14759}\ncec:{\"line\":123,\"column\":638,\"offset\":14764}\ncea:{\"start\":\"$ceb\",\"end\":\"$cec\"}\nce9:{\"type\":\"text\",\"value\":\" and \",\"position\":\"$cea\"}\ncf1:{\"line\":123,\"column\":639,\"offset\":14765}\ncf2:{\"line\":123,\"column\":668,\"offset\":14794}\ncf0:{\"start\":\"$cf1\",\"end\":\"$cf2\"}\ncef:{\"type\":\"text\",\"value\":\"Bing Sydney being Bing Sydney\",\"position\":\"$cf0\"}\ncee:[\"$cef\"]\ncf4:{\"line\":123,\"column\":638,\"offset\":14764}\ncf5:{\"line\":123,\"column\":767,\"offset\":14893}\ncf3:{\"start\":\"$cf4\",\"end\":\"$cf5\"}\nced:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned\",\"children\":\"$cee\",\"position\":\"$cf3\"}\ncf8:{\"line\":123,\"column\":767,\"offset\":14893}\ncf9:{\"line\":123,\"column\":769,\"offset\":14895}\ncf7:{\"start\":\"$cf8\",\"end\":\"$cf9\"}\ncf6:{\"type\":\"text\",\"value\":\".)\",\"position\":\"$cf7\"}\ncfc:{\"line\":123,\"column\":769,\"offset\":14895}\ncfd:{\"line\":123,\"column\":774,\"offset\":14900}\ncfb:{\"start\":\"$cfc\",\"end\":\"$cfd\"}\ncfa:{\"type\":\"footnoteReference\",\"identifier\":\"27\",\"label\":\"27\",\"position\":\"$cfb\"}\ncce:[\"$ccf\",\"$cd3\",\"$cdc\",\"$ce0\",\"$ce9\",\"$ced\",\"$cf6\",\"$cfa\"]\ncff:{\"line\":123,\"column\":1,\"offset\":14127}\nd00:{\"line\":123,\"column\":774,\"offset\":14900}\ncfe:{\"start\":\"$cff\",\"end\":\"$d00\"}\nccd:{\"type\":\"paragraph\",\"children\":\"$cce\",\"position\":\"$cfe\"}\nd05:{\"line\":125,\"column\":4,\"offset\":14905}\nd06:{\"line\":125,\"column\":33,\"offset\":14934}\nd04:{\"start\":\"$d05\",\"end\":\"$d06\"}\nd03:{\"type\":\"text\",\"value\":\"Early 2026: Coding Automation\",\"position\":\"$d04\"}\nd02:[\"$d03\"]\nd08:{\"line\":125,\"column\":1,\"offset\":14902}\nd09:{\"line\":125,\"column\":33,\"offset\":14934}\nd07:{\"start\":\"$d08\",\"end\":\"$d09\"}\nd01:{\"type\":\"heading\",\"depth\":2,\"children\":\"$d02\",\"position\":\"$d07\"}\nd0b:{}\nd11:{\"line\":128,\"column\":1,\"offset\":14952}\nd12:{\"li"])</script><script>self.__next_f.push([1,"ne\":128,\"column\":11,\"offset\":14962}\nd10:{\"start\":\"$d11\",\"end\":\"$d12\"}\nd0f:{\"type\":\"text\",\"value\":\"2026-04-30\",\"position\":\"$d10\"}\nd15:{\"line\":128,\"column\":11,\"offset\":14962}\nd16:{\"line\":129,\"column\":1,\"offset\":14965}\nd14:{\"start\":\"$d15\",\"end\":\"$d16\"}\nd13:{\"type\":\"break\",\"position\":\"$d14\"}\nd19:{\"line\":129,\"column\":1,\"offset\":14965}\nd1a:{\"line\":129,\"column\":5,\"offset\":14969}\nd18:{\"start\":\"$d19\",\"end\":\"$d1a\"}\nd17:{\"type\":\"text\",\"value\":\"2026\",\"position\":\"$d18\"}\nd0e:[\"$d0f\",\"$d13\",\"$d17\"]\nd1c:{\"line\":128,\"column\":1,\"offset\":14952}\nd1d:{\"line\":129,\"column\":7,\"offset\":14971}\nd1b:{\"start\":\"$d1c\",\"end\":\"$d1d\"}\nd0d:{\"type\":\"paragraph\",\"children\":\"$d0e\",\"position\":\"$d1b\"}\nd0c:[\"$d0d\"]\nd1f:{\"line\":127,\"column\":1,\"offset\":14936}\nd20:{\"line\":130,\"column\":4,\"offset\":14975}\nd1e:{\"start\":\"$d1f\",\"end\":\"$d20\"}\nd0a:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$d0b\",\"children\":\"$d0c\",\"position\":\"$d1e\"}\nd25:{\"line\":132,\"column\":1,\"offset\":14977}\nd26:{\"line\":132,\"column\":68,\"offset\":15044}\nd24:{\"start\":\"$d25\",\"end\":\"$d26\"}\nd23:{\"type\":\"text\",\"value\":\"The bet of using AI to speed up AI research is starting to pay off.\",\"position\":\"$d24\"}\nd22:[\"$d23\"]\nd28:{\"line\":132,\"column\":1,\"offset\":14977}\nd29:{\"line\":132,\"column\":68,\"offset\":15044}\nd27:{\"start\":\"$d28\",\"end\":\"$d29\"}\nd21:{\"type\":\"paragraph\",\"children\":\"$d22\",\"position\":\"$d27\"}\nd2e:{\"line\":134,\"column\":1,\"offset\":15046}\nd2f:{\"line\":134,\"column\":236,\"offset\":15281}\nd2d:{\"start\":\"$d2e\",\"end\":\"$d2f\"}\nd2c:{\"type\":\"text\",\"value\":\"OpenBrain continues to deploy the iteratively improving Agent-1 internally for AI R\u0026D. Overall, they are making algorithmic progress 50% faster than they would without AI assistants—and more importantly, faster than their competitors.\",\"position\":\"$d2d\"}\nd2b:[\"$d2c\"]\nd31:{\"line\":134,\"column\":1,\"offset\":15046}\nd32:{\"line\":134,\"column\":236,\"offset\":15281}\nd30:{\"start\":\"$d31\",\"end\":\"$d32\"}\nd2a:{\"type\":\"paragraph\",\"children\":\"$d2b\",\"position\":\"$d30\"}\nd39:{\"line\":140,\"column\":1,\"offset\":15381}\nd3a:{\"line\":140,\"column\":121,\"offset\":15501}\nd38:{\"start\""])</script><script>self.__next_f.push([1,":\"$d39\",\"end\":\"$d3a\"}\nd37:{\"type\":\"text\",\"value\":\"We mean that OpenBrain makes as much AI research progress in 1 week with AI as they would in 1.5 weeks without AI usage.\",\"position\":\"$d38\"}\nd36:[\"$d37\"]\nd3c:{\"line\":140,\"column\":1,\"offset\":15381}\nd3d:{\"line\":140,\"column\":121,\"offset\":15501}\nd3b:{\"start\":\"$d3c\",\"end\":\"$d3d\"}\nd35:{\"type\":\"paragraph\",\"children\":\"$d36\",\"position\":\"$d3b\"}\nd42:{\"line\":142,\"column\":1,\"offset\":15503}\nd43:{\"line\":142,\"column\":50,\"offset\":15552}\nd41:{\"start\":\"$d42\",\"end\":\"$d43\"}\nd40:{\"type\":\"text\",\"value\":\"AI progress can be broken down into 2 components:\",\"position\":\"$d41\"}\nd3f:[\"$d40\"]\nd45:{\"line\":142,\"column\":1,\"offset\":15503}\nd46:{\"line\":142,\"column\":50,\"offset\":15552}\nd44:{\"start\":\"$d45\",\"end\":\"$d46\"}\nd3e:{\"type\":\"paragraph\",\"children\":\"$d3f\",\"position\":\"$d44\"}\nd51:{\"line\":144,\"column\":6,\"offset\":15559}\nd52:{\"line\":144,\"column\":24,\"offset\":15577}\nd50:{\"start\":\"$d51\",\"end\":\"$d52\"}\nd4f:{\"type\":\"text\",\"value\":\"Increasing compute\",\"position\":\"$d50\"}\nd4e:[\"$d4f\"]\nd54:{\"line\":144,\"column\":4,\"offset\":15557}\nd55:{\"line\":144,\"column\":26,\"offset\":15579}\nd53:{\"start\":\"$d54\",\"end\":\"$d55\"}\nd4d:{\"type\":\"strong\",\"children\":\"$d4e\",\"position\":\"$d53\"}\nd58:{\"line\":144,\"column\":26,\"offset\":15579}\nd59:{\"line\":144,\"column\":136,\"offset\":15689}\nd57:{\"start\":\"$d58\",\"end\":\"$d59\"}\nd56:{\"type\":\"text\",\"value\":\": More computational power is used to train or run an AI. This produces more powerful AIs, but they cost more.\",\"position\":\"$d57\"}\nd4c:[\"$d4d\",\"$d56\"]\nd5b:{\"line\":144,\"column\":4,\"offset\":15557}\nd5c:{\"line\":144,\"column\":138,\"offset\":15691}\nd5a:{\"start\":\"$d5b\",\"end\":\"$d5c\"}\nd4b:{\"type\":\"paragraph\",\"children\":\"$d4c\",\"position\":\"$d5a\"}\nd4a:[\"$d4b\"]\nd5e:{\"line\":144,\"column\":1,\"offset\":15554}\nd5f:{\"line\":144,\"column\":138,\"offset\":15691}\nd5d:{\"start\":\"$d5e\",\"end\":\"$d5f\"}\nd49:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$d4a\",\"position\":\"$d5d\"}\nd68:{\"line\":145,\"column\":6,\"offset\":15697}\nd69:{\"line\":145,\"column\":25,\"offset\":15716}\nd67:{\"start\":\"$d68\",\"end\":\"$d69\"}\nd66:{\"type\":\"text\",\"value\":\"Improved"])</script><script>self.__next_f.push([1," algorithms\",\"position\":\"$d67\"}\nd65:[\"$d66\"]\nd6b:{\"line\":145,\"column\":4,\"offset\":15695}\nd6c:{\"line\":145,\"column\":27,\"offset\":15718}\nd6a:{\"start\":\"$d6b\",\"end\":\"$d6c\"}\nd64:{\"type\":\"strong\",\"children\":\"$d65\",\"position\":\"$d6a\"}\nd6f:{\"line\":145,\"column\":27,\"offset\":15718}\nd70:{\"line\":145,\"column\":220,\"offset\":15911}\nd6e:{\"start\":\"$d6f\",\"end\":\"$d70\"}\nd6d:{\"type\":\"text\",\"value\":\": Better training methods are used to translate compute into performance. This produces more capable AIs without a corresponding increase in cost, or the same capabilities with decreased costs.\",\"position\":\"$d6e\"}\nd63:[\"$d64\",\"$d6d\"]\nd72:{\"line\":145,\"column\":4,\"offset\":15695}\nd73:{\"line\":145,\"column\":222,\"offset\":15913}\nd71:{\"start\":\"$d72\",\"end\":\"$d73\"}\nd62:{\"type\":\"paragraph\",\"children\":\"$d63\",\"position\":\"$d71\"}\nd7c:{\"line\":146,\"column\":6,\"offset\":15919}\nd7d:{\"line\":146,\"column\":220,\"offset\":16133}\nd7b:{\"start\":\"$d7c\",\"end\":\"$d7d\"}\nd7a:{\"type\":\"text\",\"value\":\"This includes being able to achieve qualitatively and quantitatively new results. “Paradigm shifts” such as the switch from game-playing RL agents to large language models count as examples of algorithmic progress.\",\"position\":\"$d7b\"}\nd79:[\"$d7a\"]\nd7f:{\"line\":146,\"column\":6,\"offset\":15919}\nd80:{\"line\":146,\"column\":220,\"offset\":16133}\nd7e:{\"start\":\"$d7f\",\"end\":\"$d80\"}\nd78:{\"type\":\"paragraph\",\"children\":\"$d79\",\"position\":\"$d7e\"}\nd77:[\"$d78\"]\nd82:{\"line\":146,\"column\":4,\"offset\":15917}\nd83:{\"line\":146,\"column\":220,\"offset\":16133}\nd81:{\"start\":\"$d82\",\"end\":\"$d83\"}\nd76:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$d77\",\"position\":\"$d81\"}\nd75:[\"$d76\"]\nd85:{\"line\":146,\"column\":4,\"offset\":15917}\nd86:{\"line\":146,\"column\":220,\"offset\":16133}\nd84:{\"start\":\"$d85\",\"end\":\"$d86\"}\nd74:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$d75\",\"position\":\"$d84\"}\nd61:[\"$d62\",\"$d74\"]\nd88:{\"line\":145,\"column\":1,\"offset\":15692}\nd89:{\"line\":146,\"column\":220,\"offset\":16133}\nd87:{\"start\":\"$d88\",\"end\":\"$d89\"}\nd60:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$d61"])</script><script>self.__next_f.push([1,"\",\"position\":\"$d87\"}\nd48:[\"$d49\",\"$d60\"]\nd8b:{\"line\":144,\"column\":1,\"offset\":15554}\nd8c:{\"line\":146,\"column\":220,\"offset\":16133}\nd8a:{\"start\":\"$d8b\",\"end\":\"$d8c\"}\nd47:{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":\"$d48\",\"position\":\"$d8a\"}\nd91:{\"line\":148,\"column\":1,\"offset\":16135}\nd92:{\"line\":148,\"column\":63,\"offset\":16197}\nd90:{\"start\":\"$d91\",\"end\":\"$d92\"}\nd8f:{\"type\":\"text\",\"value\":\"Here we are only referring to (2), improved algorithms, which \",\"position\":\"$d90\"}\nd97:{\"line\":148,\"column\":64,\"offset\":16198}\nd98:{\"line\":148,\"column\":106,\"offset\":16240}\nd96:{\"start\":\"$d97\",\"end\":\"$d98\"}\nd95:{\"type\":\"text\",\"value\":\"makes up about half of current AI progress\",\"position\":\"$d96\"}\nd94:[\"$d95\"]\nd9a:{\"line\":148,\"column\":63,\"offset\":16197}\nd9b:{\"line\":148,\"column\":211,\"offset\":16345}\nd99:{\"start\":\"$d9a\",\"end\":\"$d9b\"}\nd93:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/ATSyAdBnxxDDAwhgu/recent-and-forecasted-rates-of-software-and-hardware\",\"children\":\"$d94\",\"position\":\"$d99\"}\nd9e:{\"line\":148,\"column\":211,\"offset\":16345}\nd9f:{\"line\":148,\"column\":212,\"offset\":16346}\nd9d:{\"start\":\"$d9e\",\"end\":\"$d9f\"}\nd9c:{\"type\":\"text\",\"value\":\".\",\"position\":\"$d9d\"}\nd8e:[\"$d8f\",\"$d93\",\"$d9c\"]\nda1:{\"line\":148,\"column\":1,\"offset\":16135}\nda2:{\"line\":148,\"column\":212,\"offset\":16346}\nda0:{\"start\":\"$da1\",\"end\":\"$da2\"}\nd8d:{\"type\":\"paragraph\",\"children\":\"$d8e\",\"position\":\"$da0\"}\nda7:{\"line\":150,\"column\":1,\"offset\":16348}\nda8:{\"line\":150,\"column\":88,\"offset\":16435}\nda6:{\"start\":\"$da7\",\"end\":\"$da8\"}\nda5:{\"type\":\"text\",\"value\":\"Going forward, we sometimes abbreviate this as an “AI R\u0026D progress multiplier” of 1.5.\",\"position\":\"$da6\"}\nda4:[\"$da5\"]\ndaa:{\"line\":150,\"column\":1,\"offset\":16348}\ndab:{\"line\":150,\"column\":88,\"offset\":16435}\nda9:{\"start\":\"$daa\",\"end\":\"$dab\"}\nda3:{\"type\":\"paragraph\",\"children\":\"$da4\",\"position\":\"$da9\"}\ndb0:{\"line\":152,\"column\":1,\"offset\":16437}\ndb1:{\"line\":152,\"column\":16,\"offset\":16452}\ndaf:{\"start\":\"$db0\",\"end\":\"$db1\"}\ndae:{\"type\":\"text\",\"value\":\"Clarifications:\",\"position\":\"$daf\"}\ndad"])</script><script>self.__next_f.push([1,":[\"$dae\"]\ndb3:{\"line\":152,\"column\":1,\"offset\":16437}\ndb4:{\"line\":152,\"column\":16,\"offset\":16452}\ndb2:{\"start\":\"$db3\",\"end\":\"$db4\"}\ndac:{\"type\":\"paragraph\",\"children\":\"$dad\",\"position\":\"$db2\"}\ndbd:{\"line\":154,\"column\":4,\"offset\":16457}\ndbe:{\"line\":154,\"column\":179,\"offset\":16632}\ndbc:{\"start\":\"$dbd\",\"end\":\"$dbe\"}\ndbb:{\"type\":\"text\",\"value\":\"The progress multiplier is all-inclusive: It includes the time it takes to run experiments, for example, rather than only the cognitive tasks involved in algorithmic research.\",\"position\":\"$dbc\"}\ndba:[\"$dbb\"]\ndc0:{\"line\":154,\"column\":4,\"offset\":16457}\ndc1:{\"line\":154,\"column\":181,\"offset\":16634}\ndbf:{\"start\":\"$dc0\",\"end\":\"$dc1\"}\ndb9:{\"type\":\"paragraph\",\"children\":\"$dba\",\"position\":\"$dbf\"}\ndb8:[\"$db9\"]\ndc3:{\"line\":154,\"column\":1,\"offset\":16454}\ndc4:{\"line\":154,\"column\":181,\"offset\":16634}\ndc2:{\"start\":\"$dc3\",\"end\":\"$dc4\"}\ndb7:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$db8\",\"position\":\"$dc2\"}\ndcb:{\"line\":155,\"column\":4,\"offset\":16638}\ndcc:{\"line\":155,\"column\":67,\"offset\":16701}\ndca:{\"start\":\"$dcb\",\"end\":\"$dcc\"}\ndc9:{\"type\":\"text\",\"value\":\"It’s important to remember that the progress multiplier is the \",\"position\":\"$dca\"}\ndd1:{\"line\":155,\"column\":68,\"offset\":16702}\ndd2:{\"line\":155,\"column\":76,\"offset\":16710}\ndd0:{\"start\":\"$dd1\",\"end\":\"$dd2\"}\ndcf:{\"type\":\"text\",\"value\":\"relative\",\"position\":\"$dd0\"}\ndce:[\"$dcf\"]\ndd4:{\"line\":155,\"column\":67,\"offset\":16701}\ndd5:{\"line\":155,\"column\":77,\"offset\":16711}\ndd3:{\"start\":\"$dd4\",\"end\":\"$dd5\"}\ndcd:{\"type\":\"emphasis\",\"children\":\"$dce\",\"position\":\"$dd3\"}\ndd8:{\"line\":155,\"column\":77,\"offset\":16711}\ndd9:{\"line\":155,\"column\":105,\"offset\":16739}\ndd7:{\"start\":\"$dd8\",\"end\":\"$dd9\"}\ndd6:{\"type\":\"text\",\"value\":\" speed of progress, not the \",\"position\":\"$dd7\"}\ndde:{\"line\":155,\"column\":106,\"offset\":16740}\nddf:{\"line\":155,\"column\":114,\"offset\":16748}\nddd:{\"start\":\"$dde\",\"end\":\"$ddf\"}\nddc:{\"type\":\"text\",\"value\":\"absolute\",\"position\":\"$ddd\"}\nddb:[\"$ddc\"]\nde1:{\"line\":155,\"column\":105,\"offset\":16739}\nde2:{\"line\":155,\"column\":115,\"offset\":167"])</script><script>self.__next_f.push([1,"49}\nde0:{\"start\":\"$de1\",\"end\":\"$de2\"}\ndda:{\"type\":\"emphasis\",\"children\":\"$ddb\",\"position\":\"$de0\"}\nde5:{\"line\":155,\"column\":115,\"offset\":16749}\nde6:{\"line\":155,\"column\":958,\"offset\":17592}\nde4:{\"start\":\"$de5\",\"end\":\"$de6\"}\nde3:{\"type\":\"text\",\"value\":\" speed of progress. If, for example, the compute cost to train a GPT-4 class model has halved every year for several years with ordinary human research, and then all of a sudden AI automates R\u0026D and the progress multiplier goes to 100x, the cost to train a GPT-4 class model would then halve every 3.65 days—but not for long, because diminishing returns would bite and eventual hard limits would be reached. In this example perhaps the cost to train a GPT-4 class model would cut in half 5–10 times total (over the span of a few weeks or months) before plateauing. In other words, if ordinary human science would have run up against diminishing returns and physical limits after 5 -10 years of further research, then AIs with a 100x multiplier would run up against those same diminishing returns and limits after 18.25–36.5 days of research.\",\"position\":\"$de4\"}\ndc8:[\"$dc9\",\"$dcd\",\"$dd6\",\"$dda\",\"$de3\"]\nde8:{\"line\":155,\"column\":4,\"offset\":16638}\nde9:{\"line\":155,\"column\":958,\"offset\":17592}\nde7:{\"start\":\"$de8\",\"end\":\"$de9\"}\ndc7:{\"type\":\"paragraph\",\"children\":\"$dc8\",\"position\":\"$de7\"}\ndc6:[\"$dc7\"]\ndeb:{\"line\":155,\"column\":1,\"offset\":16635}\ndec:{\"line\":155,\"column\":958,\"offset\":17592}\ndea:{\"start\":\"$deb\",\"end\":\"$dec\"}\ndc5:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$dc6\",\"position\":\"$dea\"}\ndb6:[\"$db7\",\"$dc5\"]\ndee:{\"line\":154,\"column\":1,\"offset\":16454}\ndef:{\"line\":155,\"column\":958,\"offset\":17592}\nded:{\"start\":\"$dee\",\"end\":\"$def\"}\ndb5:{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":\"$db6\",\"position\":\"$ded\"}\ndf4:{\"line\":157,\"column\":1,\"offset\":17594}\ndf5:{\"line\":157,\"column\":104,\"offset\":17697}\ndf3:{\"start\":\"$df4\",\"end\":\"$df5\"}\ndf2:{\"type\":\"text\",\"value\":\"More explanation and discussion of this concept and how it is used in our forecast can be fou"])</script><script>self.__next_f.push([1,"nd in our \",\"position\":\"$df3\"}\ndfa:{\"line\":157,\"column\":105,\"offset\":17698}\ndfb:{\"line\":157,\"column\":123,\"offset\":17716}\ndf9:{\"start\":\"$dfa\",\"end\":\"$dfb\"}\ndf8:{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":\"$df9\"}\ndf7:[\"$df8\"]\ndfd:{\"line\":157,\"column\":104,\"offset\":17697}\ndfe:{\"line\":157,\"column\":174,\"offset\":17767}\ndfc:{\"start\":\"$dfd\",\"end\":\"$dfe\"}\ndf6:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/takeoff-forecast\",\"children\":\"$df7\",\"position\":\"$dfc\"}\ne01:{\"line\":157,\"column\":174,\"offset\":17767}\ne02:{\"line\":157,\"column\":175,\"offset\":17768}\ne00:{\"start\":\"$e01\",\"end\":\"$e02\"}\ndff:{\"type\":\"text\",\"value\":\".\",\"position\":\"$e00\"}\ndf1:[\"$df2\",\"$df6\",\"$dff\"]\ne04:{\"line\":157,\"column\":1,\"offset\":17594}\ne05:{\"line\":157,\"column\":175,\"offset\":17768}\ne03:{\"start\":\"$e04\",\"end\":\"$e05\"}\ndf0:{\"type\":\"paragraph\",\"children\":\"$df1\",\"position\":\"$e03\"}\nd34:[\"$d35\",\"$d3e\",\"$d47\",\"$d8d\",\"$da3\",\"$dac\",\"$db5\",\"$df0\"]\nd33:{\"type\":\"details\",\"summary\":\"The AI R\u0026D progress multiplier: what do we mean by 50% faster algorithmic progress?\",\"children\":\"$d34\"}\ne0a:{\"line\":161,\"column\":1,\"offset\":17775}\ne0b:{\"line\":161,\"column\":83,\"offset\":17857}\ne09:{\"start\":\"$e0a\",\"end\":\"$e0b\"}\ne08:{\"type\":\"text\",\"value\":\"Several competing publicly released AIs now match or exceed Agent-0, including an \",\"position\":\"$e09\"}\ne10:{\"line\":161,\"column\":84,\"offset\":17858}\ne11:{\"line\":161,\"column\":96,\"offset\":17870}\ne0f:{\"start\":\"$e10\",\"end\":\"$e11\"}\ne0e:{\"type\":\"text\",\"value\":\"open-weights\",\"position\":\"$e0f\"}\ne0d:[\"$e0e\"]\ne13:{\"line\":161,\"column\":83,\"offset\":17857}\ne14:{\"line\":161,\"column\":137,\"offset\":17911}\ne12:{\"start\":\"$e13\",\"end\":\"$e14\"}\ne0c:{\"type\":\"link\",\"title\":null,\"url\":\"https://opensource.org/ai/open-weights\",\"children\":\"$e0d\",\"position\":\"$e12\"}\ne17:{\"line\":161,\"column\":137,\"offset\":17911}\ne18:{\"line\":161,\"column\":221,\"offset\":17995}\ne16:{\"start\":\"$e17\",\"end\":\"$e18\"}\ne15:{\"type\":\"text\",\"value\":\" model. OpenBrain responds by releasing Agent-1, which is more capable and reliable.\",\"position\":\"$e16\"}\ne1b:{\"line\":161,\"column\":221,\"offset"])</script><script>self.__next_f.push([1,"\":17995}\ne1c:{\"line\":161,\"column\":226,\"offset\":18000}\ne1a:{\"start\":\"$e1b\",\"end\":\"$e1c\"}\ne19:{\"type\":\"footnoteReference\",\"identifier\":\"28\",\"label\":\"28\",\"position\":\"$e1a\"}\ne07:[\"$e08\",\"$e0c\",\"$e15\",\"$e19\"]\ne1e:{\"line\":161,\"column\":1,\"offset\":17775}\ne1f:{\"line\":161,\"column\":226,\"offset\":18000}\ne1d:{\"start\":\"$e1e\",\"end\":\"$e1f\"}\ne06:{\"type\":\"paragraph\",\"children\":\"$e07\",\"position\":\"$e1d\"}\ne24:{\"line\":163,\"column\":1,\"offset\":18002}\ne25:{\"line\":163,\"column\":558,\"offset\":18559}\ne23:{\"start\":\"$e24\",\"end\":\"$e25\"}\ne22:{\"type\":\"text\",\"value\":\"People naturally try to compare Agent-1 to humans, but it has a very different skill profile. It knows more facts than any human, knows practically every programming language, and can solve well-specified coding problems extremely quickly. On the other hand, Agent-1 is bad at even simple long-horizon tasks, like beating video games it hasn’t played before. Still, the common workday is eight hours, and a day’s work can usually be separated into smaller chunks; you could think of Agent-1 as a scatterbrained employee who thrives under careful management.\",\"position\":\"$e23\"}\ne28:{\"line\":163,\"column\":558,\"offset\":18559}\ne29:{\"line\":163,\"column\":563,\"offset\":18564}\ne27:{\"start\":\"$e28\",\"end\":\"$e29\"}\ne26:{\"type\":\"footnoteReference\",\"identifier\":\"29\",\"label\":\"29\",\"position\":\"$e27\"}\ne2c:{\"line\":163,\"column\":563,\"offset\":18564}\ne2d:{\"line\":163,\"column\":627,\"offset\":18628}\ne2b:{\"start\":\"$e2c\",\"end\":\"$e2d\"}\ne2a:{\"type\":\"text\",\"value\":\" Savvy people find ways to automate routine parts of their jobs.\",\"position\":\"$e2b\"}\ne30:{\"line\":163,\"column\":627,\"offset\":18628}\ne31:{\"line\":163,\"column\":632,\"offset\":18633}\ne2f:{\"start\":\"$e30\",\"end\":\"$e31\"}\ne2e:{\"type\":\"footnoteReference\",\"identifier\":\"30\",\"label\":\"30\",\"position\":\"$e2f\"}\ne21:[\"$e22\",\"$e26\",\"$e2a\",\"$e2e\"]\ne33:{\"line\":163,\"column\":1,\"offset\":18002}\ne34:{\"line\":163,\"column\":632,\"offset\":18633}\ne32:{\"start\":\"$e33\",\"end\":\"$e34\"}\ne20:{\"type\":\"paragraph\",\"children\":\"$e21\",\"position\":\"$e32\"}\ne39:{\"line\":165,\"column\":1,\"offset\":18635}\ne3a:{\"line\":165,\"col"])</script><script>self.__next_f.push([1,"umn\":286,\"offset\":18920}\ne38:{\"start\":\"$e39\",\"end\":\"$e3a\"}\ne37:{\"type\":\"text\",\"value\":\"OpenBrain’s executives turn consideration to an implication of automating AI R\u0026D: security has become more important. In early 2025, the worst-case scenario was leaked algorithmic secrets; now, if China steals Agent-1’s weights, they could increase their research speed by nearly 50%.\",\"position\":\"$e38\"}\ne3d:{\"line\":165,\"column\":286,\"offset\":18920}\ne3e:{\"line\":165,\"column\":291,\"offset\":18925}\ne3c:{\"start\":\"$e3d\",\"end\":\"$e3e\"}\ne3b:{\"type\":\"footnoteReference\",\"identifier\":\"31\",\"label\":\"31\",\"position\":\"$e3c\"}\ne41:{\"line\":165,\"column\":291,\"offset\":18925}\ne42:{\"line\":165,\"column\":445,\"offset\":19079}\ne40:{\"start\":\"$e41\",\"end\":\"$e42\"}\ne3f:{\"type\":\"text\",\"value\":\" OpenBrain’s security level is typical of a fast-growing ~3,000 person tech company, secure only against low-priority attacks from capable cyber groups (\",\"position\":\"$e40\"}\ne47:{\"line\":165,\"column\":446,\"offset\":19080}\ne48:{\"line\":165,\"column\":456,\"offset\":19090}\ne46:{\"start\":\"$e47\",\"end\":\"$e48\"}\ne45:{\"type\":\"text\",\"value\":\"RAND’s SL2\",\"position\":\"$e46\"}\ne44:[\"$e45\"]\ne4a:{\"line\":165,\"column\":445,\"offset\":19079}\ne4b:{\"line\":165,\"column\":594,\"offset\":19228}\ne49:{\"start\":\"$e4a\",\"end\":\"$e4b\"}\ne43:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":\"$e44\",\"position\":\"$e49\"}\ne4e:{\"line\":165,\"column\":594,\"offset\":19228}\ne4f:{\"line\":165,\"column\":596,\"offset\":19230}\ne4d:{\"start\":\"$e4e\",\"end\":\"$e4f\"}\ne4c:{\"type\":\"text\",\"value\":\").\",\"position\":\"$e4d\"}\ne52:{\"line\":165,\"column\":596,\"offset\":19230}\ne53:{\"line\":165,\"column\":601,\"offset\":19235}\ne51:{\"start\":\"$e52\",\"end\":\"$e53\"}\ne50:{\"type\":\"footnoteReference\",\"identifier\":\"32\",\"label\":\"32\",\"position\":\"$e51\"}\ne56:{\"line\":165,\"column\":601,\"offset\":19235}\ne57:{\"line\":165,\"column\":641,\"offset\":19275}\ne55:{\"start\":\"$e56\",\"end\":\"$e57\"}\ne54:{\"type\":\"text\",\"value\":\" They are working hard to protect their \",\"positio"])</script><script>self.__next_f.push([1,"n\":\"$e55\"}\ne5c:{\"line\":165,\"column\":642,\"offset\":19276}\ne5d:{\"line\":165,\"column\":649,\"offset\":19283}\ne5b:{\"start\":\"$e5c\",\"end\":\"$e5d\"}\ne5a:{\"type\":\"text\",\"value\":\"weights\",\"position\":\"$e5b\"}\ne59:[\"$e5a\"]\ne5f:{\"line\":165,\"column\":641,\"offset\":19275}\ne60:{\"line\":165,\"column\":704,\"offset\":19338}\ne5e:{\"start\":\"$e5f\",\"end\":\"$e60\"}\ne58:{\"type\":\"link\",\"title\":null,\"url\":\"https://tedai-sanfrancisco.ted.com/glossary/weights/\",\"children\":\"$e59\",\"position\":\"$e5e\"}\ne63:{\"line\":165,\"column\":704,\"offset\":19338}\ne64:{\"line\":165,\"column\":769,\"offset\":19403}\ne62:{\"start\":\"$e63\",\"end\":\"$e64\"}\ne61:{\"type\":\"text\",\"value\":\" and secrets from insider threats and top cybercrime syndicates (\",\"position\":\"$e62\"}\ne69:{\"line\":165,\"column\":770,\"offset\":19404}\ne6a:{\"line\":165,\"column\":773,\"offset\":19407}\ne68:{\"start\":\"$e69\",\"end\":\"$e6a\"}\ne67:{\"type\":\"text\",\"value\":\"SL3\",\"position\":\"$e68\"}\ne66:[\"$e67\"]\ne6c:{\"line\":165,\"column\":769,\"offset\":19403}\ne6d:{\"line\":165,\"column\":911,\"offset\":19545}\ne6b:{\"start\":\"$e6c\",\"end\":\"$e6d\"}\ne65:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":\"$e66\",\"position\":\"$e6b\"}\ne70:{\"line\":165,\"column\":911,\"offset\":19545}\ne71:{\"line\":165,\"column\":913,\"offset\":19547}\ne6f:{\"start\":\"$e70\",\"end\":\"$e71\"}\ne6e:{\"type\":\"text\",\"value\":\"),\",\"position\":\"$e6f\"}\ne74:{\"line\":165,\"column\":913,\"offset\":19547}\ne75:{\"line\":165,\"column\":918,\"offset\":19552}\ne73:{\"start\":\"$e74\",\"end\":\"$e75\"}\ne72:{\"type\":\"footnoteReference\",\"identifier\":\"33\",\"label\":\"33\",\"position\":\"$e73\"}\ne78:{\"line\":165,\"column\":918,\"offset\":19552}\ne79:{\"line\":165,\"column\":954,\"offset\":19588}\ne77:{\"start\":\"$e78\",\"end\":\"$e79\"}\ne76:{\"type\":\"text\",\"value\":\" but defense against nation states (\",\"position\":\"$e77\"}\ne7e:{\"line\":165,\"column\":955,\"offset\":19589}\ne7f:{\"line\":165,\"column\":960,\"offset\":19594}\ne7d:{\"start\":\"$e7e\",\"end\":\"$e7f\"}\ne7c:{\"type\":\"text\",\"value\":\"SL4\u00265\",\"position\":\"$e7d\"}\ne7b:[\"$e7c\"]\ne81:{\"line\":165,\"column\":954,\"offset\":19588}\n"])</script><script>self.__next_f.push([1,"e82:{\"line\":165,\"column\":1098,\"offset\":19732}\ne80:{\"start\":\"$e81\",\"end\":\"$e82\"}\ne7a:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":\"$e7b\",\"position\":\"$e80\"}\ne85:{\"line\":165,\"column\":1098,\"offset\":19732}\ne86:{\"line\":165,\"column\":1125,\"offset\":19759}\ne84:{\"start\":\"$e85\",\"end\":\"$e86\"}\ne83:{\"type\":\"text\",\"value\":\") is barely on the horizon.\",\"position\":\"$e84\"}\ne36:[\"$e37\",\"$e3b\",\"$e3f\",\"$e43\",\"$e4c\",\"$e50\",\"$e54\",\"$e58\",\"$e61\",\"$e65\",\"$e6e\",\"$e72\",\"$e76\",\"$e7a\",\"$e83\"]\ne88:{\"line\":165,\"column\":1,\"offset\":18635}\ne89:{\"line\":165,\"column\":1125,\"offset\":19759}\ne87:{\"start\":\"$e88\",\"end\":\"$e89\"}\ne35:{\"type\":\"paragraph\",\"children\":\"$e36\",\"position\":\"$e87\"}\ne8e:{\"line\":167,\"column\":4,\"offset\":19764}\ne8f:{\"line\":167,\"column\":28,\"offset\":19788}\ne8d:{\"start\":\"$e8e\",\"end\":\"$e8f\"}\ne8c:{\"type\":\"text\",\"value\":\"Mid 2026: China Wakes Up\",\"position\":\"$e8d\"}\ne8b:[\"$e8c\"]\ne91:{\"line\":167,\"column\":1,\"offset\":19761}\ne92:{\"line\":167,\"column\":28,\"offset\":19788}\ne90:{\"start\":\"$e91\",\"end\":\"$e92\"}\ne8a:{\"type\":\"heading\",\"depth\":2,\"children\":\"$e8b\",\"position\":\"$e90\"}\ne94:{}\ne9a:{\"line\":170,\"column\":1,\"offset\":19806}\ne9b:{\"line\":170,\"column\":11,\"offset\":19816}\ne99:{\"start\":\"$e9a\",\"end\":\"$e9b\"}\ne98:{\"type\":\"text\",\"value\":\"2026-08-31\",\"position\":\"$e99\"}\ne9e:{\"line\":170,\"column\":11,\"offset\":19816}\ne9f:{\"line\":171,\"column\":1,\"offset\":19819}\ne9d:{\"start\":\"$e9e\",\"end\":\"$e9f\"}\ne9c:{\"type\":\"break\",\"position\":\"$e9d\"}\nea2:{\"line\":171,\"column\":1,\"offset\":19819}\nea3:{\"line\":171,\"column\":9,\"offset\":19827}\nea1:{\"start\":\"$ea2\",\"end\":\"$ea3\"}\nea0:{\"type\":\"text\",\"value\":\"Mid 2026\",\"position\":\"$ea1\"}\ne97:[\"$e98\",\"$e9c\",\"$ea0\"]\nea5:{\"line\":170,\"column\":1,\"offset\":19806}\nea6:{\"line\":171,\"column\":11,\"offset\":19829}\nea4:{\"start\":\"$ea5\",\"end\":\"$ea6\"}\ne96:{\"type\":\"paragraph\",\"children\":\"$e97\",\"position\":\"$ea4\"}\ne95:[\"$e96\"]\nea8:{\"line\":169,\"column\":1,\"offset\":19790}\nea9:{\"line\":172,\"column\":4,\"offset\":19833}\nea7:{\"start\":\"$ea8\",\"end\":\"$e"])</script><script>self.__next_f.push([1,"a9\"}\ne93:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$e94\",\"children\":\"$e95\",\"position\":\"$ea7\"}\neae:{\"line\":174,\"column\":1,\"offset\":19835}\neaf:{\"line\":174,\"column\":34,\"offset\":19868}\nead:{\"start\":\"$eae\",\"end\":\"$eaf\"}\neac:{\"type\":\"text\",\"value\":\"In China, the CCP is starting to \",\"position\":\"$ead\"}\neb4:{\"line\":174,\"column\":35,\"offset\":19869}\neb5:{\"line\":174,\"column\":47,\"offset\":19881}\neb3:{\"start\":\"$eb4\",\"end\":\"$eb5\"}\neb2:{\"type\":\"text\",\"value\":\"feel the AGI\",\"position\":\"$eb3\"}\neb1:[\"$eb2\"]\neb7:{\"line\":174,\"column\":34,\"offset\":19868}\neb8:{\"line\":174,\"column\":154,\"offset\":19988}\neb6:{\"start\":\"$eb7\",\"end\":\"$eb8\"}\neb0:{\"type\":\"link\",\"title\":null,\"url\":\"https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims\",\"children\":\"$eb1\",\"position\":\"$eb6\"}\nebb:{\"line\":174,\"column\":154,\"offset\":19988}\nebc:{\"line\":174,\"column\":155,\"offset\":19989}\neba:{\"start\":\"$ebb\",\"end\":\"$ebc\"}\neb9:{\"type\":\"text\",\"value\":\".\",\"position\":\"$eba\"}\neab:[\"$eac\",\"$eb0\",\"$eb9\"]\nebe:{\"line\":174,\"column\":1,\"offset\":19835}\nebf:{\"line\":174,\"column\":155,\"offset\":19989}\nebd:{\"start\":\"$ebe\",\"end\":\"$ebf\"}\neaa:{\"type\":\"paragraph\",\"children\":\"$eab\",\"position\":\"$ebd\"}\nec4:{\"line\":176,\"column\":1,\"offset\":19991}\nec5:{\"line\":176,\"column\":405,\"offset\":20395}\nec3:{\"start\":\"$ec4\",\"end\":\"$ec5\"}\nec2:{\"type\":\"text\",\"value\":\"Chip export controls and lack of government support have left China under-resourced compared to the West. By smuggling banned Taiwanese chips, buying older chips, and producing domestic chips about three years behind the U.S.-Taiwanese frontier, China has managed to maintain about 12% of the world’s AI-relevant compute—but the older technology is harder to work with, and supply is a constant headache.\",\"position\":\"$ec3\"}\nec8:{\"line\":176,\"column\":405,\"offset\":20395}\nec9:{\"line\":176,\"column\":410,\"offset\":20400}\nec7:{\"start\":\"$ec8\",\"end\":\"$ec9\"}\nec6:{\"type\":\"footnoteReference\",\"identifier\":\"35\",\"label\":\"35\",\"position\":\"$ec7\"}\necc:{\"line\":176,\"column\":410,\"offset\":20400}\necd:{\"line\":176"])</script><script>self.__next_f.push([1,",\"column\":631,\"offset\":20621}\necb:{\"start\":\"$ecc\",\"end\":\"$ecd\"}\neca:{\"type\":\"text\",\"value\":\" A few standouts like DeepCent do very impressive work with limited compute, but the compute deficit limits what they can achieve without government support, and they are about six months behind the best OpenBrain models.\",\"position\":\"$ecb\"}\ned0:{\"line\":176,\"column\":631,\"offset\":20621}\ned1:{\"line\":176,\"column\":636,\"offset\":20626}\necf:{\"start\":\"$ed0\",\"end\":\"$ed1\"}\nece:{\"type\":\"footnoteReference\",\"identifier\":\"36\",\"label\":\"36\",\"position\":\"$ecf\"}\nec1:[\"$ec2\",\"$ec6\",\"$eca\",\"$ece\"]\ned3:{\"line\":176,\"column\":1,\"offset\":19991}\ned4:{\"line\":176,\"column\":636,\"offset\":20626}\ned2:{\"start\":\"$ed3\",\"end\":\"$ed4\"}\nec0:{\"type\":\"paragraph\",\"children\":\"$ec1\",\"position\":\"$ed2\"}\ned9:{\"line\":178,\"column\":1,\"offset\":20628}\neda:{\"line\":178,\"column\":187,\"offset\":20814}\ned8:{\"start\":\"$ed9\",\"end\":\"$eda\"}\ned7:{\"type\":\"text\",\"value\":\"The General Secretary had long dreamed of doubling down on real-world physical manufacturing and avoiding American post-industrial decadence. He viewed software companies with suspicion.\",\"position\":\"$ed8\"}\nedd:{\"line\":178,\"column\":187,\"offset\":20814}\nede:{\"line\":178,\"column\":192,\"offset\":20819}\nedc:{\"start\":\"$edd\",\"end\":\"$ede\"}\nedb:{\"type\":\"footnoteReference\",\"identifier\":\"37\",\"label\":\"37\",\"position\":\"$edc\"}\nee1:{\"line\":178,\"column\":192,\"offset\":20819}\nee2:{\"line\":178,\"column\":1045,\"offset\":21672}\nee0:{\"start\":\"$ee1\",\"end\":\"$ee2\"}\nedf:{\"type\":\"text\",\"value\":\" But hawks in the CCP warn that the growing race towards AGI can no longer be ignored. So he finally commits fully to the big AI push he had previously tried to avoid. He sets in motion the nationalization of Chinese AI research, creating an immediate information-sharing mechanism for AI companies. It will escalate over the course of a year until all the best researchers merge into a DeepCent-led collective, where they share algorithmic insights, datasets, and compute resources with each other. A Centralized Development Zone (CDZ) is created at the Tianwan Power Plant "])</script><script>self.__next_f.push([1,"(the largest nuclear power plant in the world) to house a new mega-datacenter for DeepCent, along with highly secure living and office spaces to which researchers will eventually relocate. Almost 50% of China’s AI-relevant compute is now working for the DeepCent-led collective,\",\"position\":\"$ee0\"}\nee5:{\"line\":178,\"column\":1045,\"offset\":21672}\nee6:{\"line\":178,\"column\":1050,\"offset\":21677}\nee4:{\"start\":\"$ee5\",\"end\":\"$ee6\"}\nee3:{\"type\":\"footnoteReference\",\"identifier\":\"38\",\"label\":\"38\",\"position\":\"$ee4\"}\nee9:{\"line\":178,\"column\":1050,\"offset\":21677}\neea:{\"line\":178,\"column\":1101,\"offset\":21728}\nee8:{\"start\":\"$ee9\",\"end\":\"$eea\"}\nee7:{\"type\":\"text\",\"value\":\" and over 80% of new chips are directed to the CDZ.\",\"position\":\"$ee8\"}\need:{\"line\":178,\"column\":1101,\"offset\":21728}\neee:{\"line\":178,\"column\":1106,\"offset\":21733}\neec:{\"start\":\"$eed\",\"end\":\"$eee\"}\neeb:{\"type\":\"footnoteReference\",\"identifier\":\"39\",\"label\":\"39\",\"position\":\"$eec\"}\nef1:{\"line\":178,\"column\":1106,\"offset\":21733}\nef2:{\"line\":178,\"column\":1204,\"offset\":21831}\nef0:{\"start\":\"$ef1\",\"end\":\"$ef2\"}\neef:{\"type\":\"text\",\"value\":\" At this point, the CDZ has the power capacity in place for what would be the largest centralized \",\"position\":\"$ef0\"}\nef7:{\"line\":178,\"column\":1205,\"offset\":21832}\nef8:{\"line\":178,\"column\":1212,\"offset\":21839}\nef6:{\"start\":\"$ef7\",\"end\":\"$ef8\"}\nef5:{\"type\":\"text\",\"value\":\"cluster\",\"position\":\"$ef6\"}\nef4:[\"$ef5\"]\nefa:{\"line\":178,\"column\":1204,\"offset\":21831}\nefb:{\"line\":178,\"column\":1261,\"offset\":21888}\nef9:{\"start\":\"$efa\",\"end\":\"$efb\"}\nef3:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Computer_cluster\",\"children\":\"$ef4\",\"position\":\"$ef9\"}\nefe:{\"line\":178,\"column\":1261,\"offset\":21888}\neff:{\"line\":178,\"column\":1275,\"offset\":21902}\nefd:{\"start\":\"$efe\",\"end\":\"$eff\"}\nefc:{\"type\":\"text\",\"value\":\" in the world.\",\"position\":\"$efd\"}\nf02:{\"line\":178,\"column\":1275,\"offset\":21902}\nf03:{\"line\":178,\"column\":1280,\"offset\":21907}\nf01:{\"start\":\"$f02\",\"end\":\"$f03\"}\nf00:{\"type\":\"footnoteReference\",\"identifier\":\"40\",\"label\":\"40\",\"position"])</script><script>self.__next_f.push([1,"\":\"$f01\"}\nf06:{\"line\":178,\"column\":1280,\"offset\":21907}\nf07:{\"line\":178,\"column\":1405,\"offset\":22032}\nf05:{\"start\":\"$f06\",\"end\":\"$f07\"}\nf04:{\"type\":\"text\",\"value\":\" Other Party members discuss extreme measures to neutralize the West’s chip advantage. A blockade of Taiwan? A full invasion?\",\"position\":\"$f05\"}\ned6:[\"$ed7\",\"$edb\",\"$edf\",\"$ee3\",\"$ee7\",\"$eeb\",\"$eef\",\"$ef3\",\"$efc\",\"$f00\",\"$f04\"]\nf09:{\"line\":178,\"column\":1,\"offset\":20628}\nf0a:{\"line\":178,\"column\":1405,\"offset\":22032}\nf08:{\"start\":\"$f09\",\"end\":\"$f0a\"}\ned5:{\"type\":\"paragraph\",\"children\":\"$ed6\",\"position\":\"$f08\"}\nf0f:{\"line\":180,\"column\":1,\"offset\":22034}\nf10:{\"line\":180,\"column\":366,\"offset\":22399}\nf0e:{\"start\":\"$f0f\",\"end\":\"$f10\"}\nf0d:{\"type\":\"text\",\"value\":\"But China is falling behind on AI algorithms due to their weaker models. The Chinese intelligence agencies—among the best in the world—double down on their plans to steal OpenBrain’s weights. This is a much more complex operation than their constant low-level poaching of algorithmic secrets; the weights are a multi-terabyte file stored on a highly secure server (\",\"position\":\"$f0e\"}\nf15:{\"line\":180,\"column\":367,\"offset\":22400}\nf16:{\"line\":180,\"column\":398,\"offset\":22431}\nf14:{\"start\":\"$f15\",\"end\":\"$f16\"}\nf13:{\"type\":\"text\",\"value\":\"OpenBrain has improved security\",\"position\":\"$f14\"}\nf12:[\"$f13\"]\nf18:{\"line\":180,\"column\":366,\"offset\":22399}\nf19:{\"line\":180,\"column\":450,\"offset\":22483}\nf17:{\"start\":\"$f18\",\"end\":\"$f19\"}\nf11:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/security-forecast\",\"children\":\"$f12\",\"position\":\"$f17\"}\nf1c:{\"line\":180,\"column\":450,\"offset\":22483}\nf1d:{\"line\":180,\"column\":461,\"offset\":22494}\nf1b:{\"start\":\"$f1c\",\"end\":\"$f1d\"}\nf1a:{\"type\":\"text\",\"value\":\" to RAND’s \",\"position\":\"$f1b\"}\nf22:{\"line\":180,\"column\":462,\"offset\":22495}\nf23:{\"line\":180,\"column\":465,\"offset\":22498}\nf21:{\"start\":\"$f22\",\"end\":\"$f23\"}\nf20:{\"type\":\"text\",\"value\":\"SL3\",\"position\":\"$f21\"}\nf1f:[\"$f20\"]\nf25:{\"line\":180,\"column\":461,\"offset\":22494}\nf26:{\"line\":180,\"column\":603,\"offset\":2"])</script><script>self.__next_f.push([1,"2636}\nf24:{\"start\":\"$f25\",\"end\":\"$f26\"}\nf1e:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":\"$f1f\",\"position\":\"$f24\"}\nf29:{\"line\":180,\"column\":603,\"offset\":22636}\nf2a:{\"line\":180,\"column\":671,\"offset\":22704}\nf28:{\"start\":\"$f29\",\"end\":\"$f2a\"}\nf27:{\"type\":\"text\",\"value\":\"). Their cyberforce think they can pull it off with help from their \",\"position\":\"$f28\"}\nf2f:{\"line\":180,\"column\":672,\"offset\":22705}\nf30:{\"line\":180,\"column\":677,\"offset\":22710}\nf2e:{\"start\":\"$f2f\",\"end\":\"$f30\"}\nf2d:{\"type\":\"text\",\"value\":\"spies\",\"position\":\"$f2e\"}\nf2c:[\"$f2d\"]\nf32:{\"line\":180,\"column\":671,\"offset\":22704}\nf33:{\"line\":180,\"column\":773,\"offset\":22806}\nf31:{\"start\":\"$f32\",\"end\":\"$f33\"}\nf2b:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies\",\"children\":\"$f2c\",\"position\":\"$f31\"}\nf36:{\"line\":180,\"column\":773,\"offset\":22806}\nf37:{\"line\":180,\"column\":1082,\"offset\":23115}\nf35:{\"start\":\"$f36\",\"end\":\"$f37\"}\nf34:{\"type\":\"text\",\"value\":\", but perhaps only once; OpenBrain will detect the theft, increase security, and they may not get another chance. So (CCP leadership wonder) should they act now and steal Agent-1? Or hold out for a more advanced model? If they wait, do they risk OpenBrain upgrading security beyond their ability to penetrate?\",\"position\":\"$f35\"}\nf0c:[\"$f0d\",\"$f11\",\"$f1a\",\"$f1e\",\"$f27\",\"$f2b\",\"$f34\"]\nf39:{\"line\":180,\"column\":1,\"offset\":22034}\nf3a:{\"line\":180,\"column\":1082,\"offset\":23115}\nf38:{\"start\":\"$f39\",\"end\":\"$f3a\"}\nf0b:{\"type\":\"paragraph\",\"children\":\"$f0c\",\"position\":\"$f38\"}\nf3f:{\"line\":182,\"column\":4,\"offset\":23120}\nf40:{\"line\":182,\"column\":33,\"offset\":23149}\nf3e:{\"start\":\"$f3f\",\"end\":\"$f40\"}\nf3d:{\"type\":\"text\",\"value\":\"Late 2026: AI Takes Some Jobs\",\"position\":\"$f3e\"}\nf3c:[\"$f3d\"]\nf42:{\"line\":182,\"column\":1,\"offset\":23117}\nf43:{\"line\":182,\"column\":33,\"offset\":23149}\nf41:{\"start\":\"$f42\",\"end\":\"$f43\"}\nf3b:{\"type\":\""])</script><script>self.__next_f.push([1,"heading\",\"depth\":2,\"children\":\"$f3c\",\"position\":\"$f41\"}\nf45:{}\nf4b:{\"line\":185,\"column\":1,\"offset\":23167}\nf4c:{\"line\":185,\"column\":11,\"offset\":23177}\nf4a:{\"start\":\"$f4b\",\"end\":\"$f4c\"}\nf49:{\"type\":\"text\",\"value\":\"2026-12-31\",\"position\":\"$f4a\"}\nf4f:{\"line\":185,\"column\":11,\"offset\":23177}\nf50:{\"line\":186,\"column\":1,\"offset\":23180}\nf4e:{\"start\":\"$f4f\",\"end\":\"$f50\"}\nf4d:{\"type\":\"break\",\"position\":\"$f4e\"}\nf53:{\"line\":186,\"column\":1,\"offset\":23180}\nf54:{\"line\":186,\"column\":10,\"offset\":23189}\nf52:{\"start\":\"$f53\",\"end\":\"$f54\"}\nf51:{\"type\":\"text\",\"value\":\"Late 2026\",\"position\":\"$f52\"}\nf48:[\"$f49\",\"$f4d\",\"$f51\"]\nf56:{\"line\":185,\"column\":1,\"offset\":23167}\nf57:{\"line\":186,\"column\":12,\"offset\":23191}\nf55:{\"start\":\"$f56\",\"end\":\"$f57\"}\nf47:{\"type\":\"paragraph\",\"children\":\"$f48\",\"position\":\"$f55\"}\nf46:[\"$f47\"]\nf59:{\"line\":184,\"column\":1,\"offset\":23151}\nf5a:{\"line\":187,\"column\":4,\"offset\":23195}\nf58:{\"start\":\"$f59\",\"end\":\"$f5a\"}\nf44:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$f45\",\"children\":\"$f46\",\"position\":\"$f58\"}\nf5f:{\"line\":189,\"column\":1,\"offset\":23197}\nf60:{\"line\":189,\"column\":437,\"offset\":23633}\nf5e:{\"start\":\"$f5f\",\"end\":\"$f60\"}\nf5d:{\"type\":\"text\",\"value\":\"Just as others seemed to be catching up, OpenBrain blows the competition out of the water again by releasing Agent-1-mini—a model 10x cheaper than Agent-1 and more easily fine-tuned for different applications. The mainstream narrative around AI has changed from “maybe the hype will blow over” to “guess this is the next big thing,” but people disagree about how big. Bigger than social media? Bigger than smartphones? Bigger than fire?\",\"position\":\"$f5e\"}\nf5c:[\"$f5d\"]\nf62:{\"line\":189,\"column\":1,\"offset\":23197}\nf63:{\"line\":189,\"column\":437,\"offset\":23633}\nf61:{\"start\":\"$f62\",\"end\":\"$f63\"}\nf5b:{\"type\":\"paragraph\",\"children\":\"$f5c\",\"position\":\"$f61\"}\nf68:{\"line\":191,\"column\":1,\"offset\":23635}\nf69:{\"line\":191,\"column\":621,\"offset\":24255}\nf67:{\"start\":\"$f68\",\"end\":\"$f69\"}\nf66:{\"type\":\"text\",\"value\":\"AI has started to take jobs, but has also created n"])</script><script>self.__next_f.push([1,"ew ones. The stock market has gone up 30% in 2026, led by OpenBrain, Nvidia, and whichever companies have most successfully integrated AI assistants. The job market for junior software engineers is in turmoil: the AIs can do everything taught by a CS degree, but people who know how to manage and quality-control teams of AIs are making a killing. Business gurus tell job seekers that familiarity with AI is the most important skill to put on a resume. Many people fear that the next wave of AIs will come for their jobs; there is a 10,000 person anti-AI protest in DC.\",\"position\":\"$f67\"}\nf65:[\"$f66\"]\nf6b:{\"line\":191,\"column\":1,\"offset\":23635}\nf6c:{\"line\":191,\"column\":621,\"offset\":24255}\nf6a:{\"start\":\"$f6b\",\"end\":\"$f6c\"}\nf64:{\"type\":\"paragraph\",\"children\":\"$f65\",\"position\":\"$f6a\"}\nf71:{\"line\":193,\"column\":1,\"offset\":24257}\nf72:{\"line\":193,\"column\":215,\"offset\":24471}\nf70:{\"start\":\"$f71\",\"end\":\"$f72\"}\nf6f:{\"type\":\"text\",\"value\":\"Department of Defense (DOD) quietly but significantly begins scaling up contracting OpenBrain directly for cyber, data analysis, and R\u0026D, but integration is slow due to the bureaucracy and DOD procurement process.\",\"position\":\"$f70\"}\nf75:{\"line\":193,\"column\":215,\"offset\":24471}\nf76:{\"line\":193,\"column\":220,\"offset\":24476}\nf74:{\"start\":\"$f75\",\"end\":\"$f76\"}\nf73:{\"type\":\"footnoteReference\",\"identifier\":\"41\",\"label\":\"41\",\"position\":\"$f74\"}\nf6e:[\"$f6f\",\"$f73\"]\nf78:{\"line\":193,\"column\":1,\"offset\":24257}\nf79:{\"line\":193,\"column\":221,\"offset\":24477}\nf77:{\"start\":\"$f78\",\"end\":\"$f79\"}\nf6d:{\"type\":\"paragraph\",\"children\":\"$f6e\",\"position\":\"$f77\"}\nf7b:{}\nf7c:[]\nf7e:{\"line\":196,\"column\":1,\"offset\":24482}\nf7f:{\"line\":197,\"column\":4,\"offset\":24505}\nf7d:{\"start\":\"$f7e\",\"end\":\"$f7f\"}\nf7a:{\"type\":\"containerDirective\",\"name\":\"keyMetrics2026\",\"attributes\":\"$f7b\",\"children\":\"$f7c\",\"position\":\"$f7d\"}\nf86:{\"line\":202,\"column\":1,\"offset\":24577}\nf87:{\"line\":202,\"column\":611,\"offset\":25187}\nf85:{\"start\":\"$f86\",\"end\":\"$f87\"}\nf84:{\"type\":\"text\",\"value\":\"Our forecast from the current day through 2026 is substantially more gr"])</script><script>self.__next_f.push([1,"ounded than what follows. This is partially because it’s nearer. But it’s also because the effects of AI on the world really start to compound in 2027. For 2025 and 2026, our forecast is heavily informed by extrapolating straight lines on compute scaleups, algorithmic improvements, and benchmark performance. At this point in the scenario, we begin to see major effects from AI-accelerated AI-R\u0026D on the timeline, which causes us to revise our guesses for the trendlines upwards. But these dynamics are inherently much less predictable.\",\"position\":\"$f85\"}\nf83:[\"$f84\"]\nf89:{\"line\":202,\"column\":1,\"offset\":24577}\nf8a:{\"line\":202,\"column\":611,\"offset\":25187}\nf88:{\"start\":\"$f89\",\"end\":\"$f8a\"}\nf82:{\"type\":\"paragraph\",\"children\":\"$f83\",\"position\":\"$f88\"}\nf8f:{\"line\":204,\"column\":1,\"offset\":25189}\nf90:{\"line\":204,\"column\":267,\"offset\":25455}\nf8e:{\"start\":\"$f8f\",\"end\":\"$f90\"}\nf8d:{\"type\":\"text\",\"value\":\"Over the course of 2027, the AIs improve from being able to mostly do the job of an OpenBrain research engineer to eclipsing all humans at all tasks. This represents roughly our median guess, but we think it’s plausible that this happens up to ~5x slower or faster.\",\"position\":\"$f8e\"}\nf8c:[\"$f8d\"]\nf92:{\"line\":204,\"column\":1,\"offset\":25189}\nf93:{\"line\":204,\"column\":268,\"offset\":25456}\nf91:{\"start\":\"$f92\",\"end\":\"$f93\"}\nf8b:{\"type\":\"paragraph\",\"children\":\"$f8c\",\"position\":\"$f91\"}\nf98:{\"line\":206,\"column\":1,\"offset\":25458}\nf99:{\"line\":206,\"column\":38,\"offset\":25495}\nf97:{\"start\":\"$f98\",\"end\":\"$f99\"}\nf96:{\"type\":\"text\",\"value\":\"For our background research, see the \",\"position\":\"$f97\"}\nf9e:{\"line\":206,\"column\":39,\"offset\":25496}\nf9f:{\"line\":206,\"column\":57,\"offset\":25514}\nf9d:{\"start\":\"$f9e\",\"end\":\"$f9f\"}\nf9c:{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":\"$f9d\"}\nf9b:[\"$f9c\"]\nfa1:{\"line\":206,\"column\":38,\"offset\":25495}\nfa2:{\"line\":206,\"column\":110,\"offset\":25567}\nfa0:{\"start\":\"$fa1\",\"end\":\"$fa2\"}\nf9a:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/timelines-forecast\",\"children\":\"$f9b\",\"position\":\"$fa"])</script><script>self.__next_f.push([1,"0\"}\nfa5:{\"line\":206,\"column\":110,\"offset\":25567}\nfa6:{\"line\":206,\"column\":119,\"offset\":25576}\nfa4:{\"start\":\"$fa5\",\"end\":\"$fa6\"}\nfa3:{\"type\":\"text\",\"value\":\" and the \",\"position\":\"$fa4\"}\nfab:{\"line\":206,\"column\":120,\"offset\":25577}\nfac:{\"line\":206,\"column\":136,\"offset\":25593}\nfaa:{\"start\":\"$fab\",\"end\":\"$fac\"}\nfa9:{\"type\":\"text\",\"value\":\"takeoff forecast\",\"position\":\"$faa\"}\nfa8:[\"$fa9\"]\nfae:{\"line\":206,\"column\":119,\"offset\":25576}\nfaf:{\"line\":206,\"column\":187,\"offset\":25644}\nfad:{\"start\":\"$fae\",\"end\":\"$faf\"}\nfa7:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/takeoff-forecast\",\"children\":\"$fa8\",\"position\":\"$fad\"}\nfb2:{\"line\":206,\"column\":187,\"offset\":25644}\nfb3:{\"line\":206,\"column\":240,\"offset\":25697}\nfb1:{\"start\":\"$fb2\",\"end\":\"$fb3\"}\nfb0:{\"type\":\"text\",\"value\":\". These will also be summarized in expandables below.\",\"position\":\"$fb1\"}\nf95:[\"$f96\",\"$f9a\",\"$fa3\",\"$fa7\",\"$fb0\"]\nfb5:{\"line\":206,\"column\":1,\"offset\":25458}\nfb6:{\"line\":206,\"column\":242,\"offset\":25699}\nfb4:{\"start\":\"$fb5\",\"end\":\"$fb6\"}\nf94:{\"type\":\"paragraph\",\"children\":\"$f95\",\"position\":\"$fb4\"}\nf81:[\"$f82\",\"$f8b\",\"$f94\"]\nf80:{\"type\":\"details\",\"summary\":\"Why our uncertainty increases substantially beyond 2026\",\"children\":\"$f81\"}\nfbb:{\"line\":209,\"column\":4,\"offset\":25708}\nfbc:{\"line\":209,\"column\":49,\"offset\":25753}\nfba:{\"start\":\"$fbb\",\"end\":\"$fbc\"}\nfb9:{\"type\":\"text\",\"value\":\"January 2027: Agent-2 Never Finishes Learning\",\"position\":\"$fba\"}\nfb8:[\"$fb9\"]\nfbe:{\"line\":209,\"column\":1,\"offset\":25705}\nfbf:{\"line\":209,\"column\":49,\"offset\":25753}\nfbd:{\"start\":\"$fbe\",\"end\":\"$fbf\"}\nfb7:{\"type\":\"heading\",\"depth\":2,\"children\":\"$fb8\",\"position\":\"$fbd\"}\nfc1:{}\nfc7:{\"line\":212,\"column\":1,\"offset\":25771}\nfc8:{\"line\":212,\"column\":11,\"offset\":25781}\nfc6:{\"start\":\"$fc7\",\"end\":\"$fc8\"}\nfc5:{\"type\":\"text\",\"value\":\"2027-01-31\",\"position\":\"$fc6\"}\nfcb:{\"line\":212,\"column\":11,\"offset\":25781}\nfcc:{\"line\":213,\"column\":1,\"offset\":25784}\nfca:{\"start\":\"$fcb\",\"end\":\"$fcc\"}\nfc9:{\"type\":\"break\",\"position\":\"$fca\"}\nfcf:{\"line\":213,\"column\":1,\"offset\":25784}\nfd0:{\"line\":213,"])</script><script>self.__next_f.push([1,"\"column\":9,\"offset\":25792}\nfce:{\"start\":\"$fcf\",\"end\":\"$fd0\"}\nfcd:{\"type\":\"text\",\"value\":\"Jan 2027\",\"position\":\"$fce\"}\nfc4:[\"$fc5\",\"$fc9\",\"$fcd\"]\nfd2:{\"line\":212,\"column\":1,\"offset\":25771}\nfd3:{\"line\":213,\"column\":11,\"offset\":25794}\nfd1:{\"start\":\"$fd2\",\"end\":\"$fd3\"}\nfc3:{\"type\":\"paragraph\",\"children\":\"$fc4\",\"position\":\"$fd1\"}\nfc2:[\"$fc3\"]\nfd5:{\"line\":211,\"column\":1,\"offset\":25755}\nfd6:{\"line\":214,\"column\":4,\"offset\":25798}\nfd4:{\"start\":\"$fd5\",\"end\":\"$fd6\"}\nfc0:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$fc1\",\"children\":\"$fc2\",\"position\":\"$fd4\"}\nfdb:{\"line\":216,\"column\":1,\"offset\":25800}\nfdc:{\"line\":216,\"column\":132,\"offset\":25931}\nfda:{\"start\":\"$fdb\",\"end\":\"$fdc\"}\nfd9:{\"type\":\"text\",\"value\":\"With Agent-1’s help, OpenBrain is now post-training Agent-2. More than ever, the focus is on high-quality data. Copious amounts of \",\"position\":\"$fda\"}\nfe1:{\"line\":216,\"column\":133,\"offset\":25932}\nfe2:{\"line\":216,\"column\":147,\"offset\":25946}\nfe0:{\"start\":\"$fe1\",\"end\":\"$fe2\"}\nfdf:{\"type\":\"text\",\"value\":\"synthetic data\",\"position\":\"$fe0\"}\nfde:[\"$fdf\"]\nfe4:{\"line\":216,\"column\":132,\"offset\":25931}\nfe5:{\"line\":216,\"column\":194,\"offset\":25993}\nfe3:{\"start\":\"$fe4\",\"end\":\"$fe5\"}\nfdd:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Synthetic_data\",\"children\":\"$fde\",\"position\":\"$fe3\"}\nfe8:{\"line\":216,\"column\":194,\"offset\":25993}\nfe9:{\"line\":216,\"column\":273,\"offset\":26072}\nfe7:{\"start\":\"$fe8\",\"end\":\"$fe9\"}\nfe6:{\"type\":\"text\",\"value\":\" are produced, evaluated, and filtered for quality before being fed to Agent-2.\",\"position\":\"$fe7\"}\nfec:{\"line\":216,\"column\":273,\"offset\":26072}\nfed:{\"line\":216,\"column\":278,\"offset\":26077}\nfeb:{\"start\":\"$fec\",\"end\":\"$fed\"}\nfea:{\"type\":\"footnoteReference\",\"identifier\":\"42\",\"label\":\"42\",\"position\":\"$feb\"}\nff0:{\"line\":216,\"column\":278,\"offset\":26077}\nff1:{\"line\":216,\"column\":391,\"offset\":26190}\nfef:{\"start\":\"$ff0\",\"end\":\"$ff1\"}\nfee:{\"type\":\"text\",\"value\":\" On top of this, they pay billions of dollars for human laborers to record themselves solving long-horizon tasks.\",\"po"])</script><script>self.__next_f.push([1,"sition\":\"$fef\"}\nff4:{\"line\":216,\"column\":391,\"offset\":26190}\nff5:{\"line\":216,\"column\":396,\"offset\":26195}\nff3:{\"start\":\"$ff4\",\"end\":\"$ff5\"}\nff2:{\"type\":\"footnoteReference\",\"identifier\":\"43\",\"label\":\"43\",\"position\":\"$ff3\"}\nff8:{\"line\":216,\"column\":396,\"offset\":26195}\nff9:{\"line\":216,\"column\":411,\"offset\":26210}\nff7:{\"start\":\"$ff8\",\"end\":\"$ff9\"}\nff6:{\"type\":\"text\",\"value\":\" On top of all \",\"position\":\"$ff7\"}\nffe:{\"line\":216,\"column\":412,\"offset\":26211}\nfff:{\"line\":216,\"column\":417,\"offset\":26216}\nffd:{\"start\":\"$ffe\",\"end\":\"$fff\"}\nffc:{\"type\":\"text\",\"value\":\"that,\",\"position\":\"$ffd\"}\nffb:[\"$ffc\"]\n1001:{\"line\":216,\"column\":411,\"offset\":26210}\n1002:{\"line\":216,\"column\":418,\"offset\":26217}\n1000:{\"start\":\"$1001\",\"end\":\"$1002\"}\nffa:{\"type\":\"emphasis\",\"children\":\"$ffb\",\"position\":\"$1000\"}\n1005:{\"line\":216,\"column\":418,\"offset\":26217}\n1006:{\"line\":216,\"column\":869,\"offset\":26668}\n1004:{\"start\":\"$1005\",\"end\":\"$1006\"}\n1003:{\"type\":\"text\",\"value\":\" they train Agent-2 almost continuously using reinforcement learning on an ever-expanding suite of diverse difficult tasks: lots of video games, lots of coding challenges, lots of research tasks. Agent-2, more so than previous models, is effectively “online learning,” in that it’s built to never really finish training. Every day, the weights get updated to the latest version, trained on more data generated by the previous version the previous day.\",\"position\":\"$1004\"}\nfd8:[\"$fd9\",\"$fdd\",\"$fe6\",\"$fea\",\"$fee\",\"$ff2\",\"$ff6\",\"$ffa\",\"$1003\"]\n1008:{\"line\":216,\"column\":1,\"offset\":25800}\n1009:{\"line\":216,\"column\":869,\"offset\":26668}\n1007:{\"start\":\"$1008\",\"end\":\"$1009\"}\nfd7:{\"type\":\"paragraph\",\"children\":\"$fd8\",\"position\":\"$1007\"}\n100e:{\"line\":218,\"column\":1,\"offset\":26670}\n100f:{\"line\":218,\"column\":69,\"offset\":26738}\n100d:{\"start\":\"$100e\",\"end\":\"$100f\"}\n100c:{\"type\":\"text\",\"value\":\"Agent-1 had been optimized for AI R\u0026D tasks, hoping to initiate an \",\"position\":\"$100d\"}\n1014:{\"line\":218,\"column\":70,\"offset\":26739}\n1015:{\"line\":218,\"column\":92,\"offset\":26761}\n1013:{\"start\":\"$1014\",\"end\""])</script><script>self.__next_f.push([1,":\"$1015\"}\n1012:{\"type\":\"text\",\"value\":\"intelligence explosion\",\"position\":\"$1013\"}\n1011:[\"$1012\"]\n1017:{\"line\":218,\"column\":69,\"offset\":26738}\n1018:{\"line\":218,\"column\":173,\"offset\":26842}\n1016:{\"start\":\"$1017\",\"end\":\"$1018\"}\n1010:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion\",\"children\":\"$1011\",\"position\":\"$1016\"}\n101b:{\"line\":218,\"column\":173,\"offset\":26842}\n101c:{\"line\":218,\"column\":174,\"offset\":26843}\n101a:{\"start\":\"$101b\",\"end\":\"$101c\"}\n1019:{\"type\":\"text\",\"value\":\".\",\"position\":\"$101a\"}\n101f:{\"line\":218,\"column\":174,\"offset\":26843}\n1020:{\"line\":218,\"column\":179,\"offset\":26848}\n101e:{\"start\":\"$101f\",\"end\":\"$1020\"}\n101d:{\"type\":\"footnoteReference\",\"identifier\":\"44\",\"label\":\"44\",\"position\":\"$101e\"}\n1023:{\"line\":218,\"column\":179,\"offset\":26848}\n1024:{\"line\":218,\"column\":537,\"offset\":27206}\n1022:{\"start\":\"$1023\",\"end\":\"$1024\"}\n1021:{\"type\":\"text\",\"value\":\" OpenBrain doubles down on this strategy with Agent-2. It is qualitatively almost as good as the top human experts at research engineering (designing and implementing experiments), and as good as the 25th percentile OpenBrain scientist at “research taste” (deciding what to study next, what experiments to run, or having inklings of potential new paradigms).\",\"position\":\"$1022\"}\n1027:{\"line\":218,\"column\":537,\"offset\":27206}\n1028:{\"line\":218,\"column\":542,\"offset\":27211}\n1026:{\"start\":\"$1027\",\"end\":\"$1028\"}\n1025:{\"type\":\"footnoteReference\",\"identifier\":\"45\",\"label\":\"45\",\"position\":\"$1026\"}\n102b:{\"line\":218,\"column\":542,\"offset\":27211}\n102c:{\"line\":218,\"column\":785,\"offset\":27454}\n102a:{\"start\":\"$102b\",\"end\":\"$102c\"}\n1029:{\"type\":\"text\",\"value\":\" While the latest Agent-1 could double the pace of OpenBrain’s algorithmic progress, Agent-2 can now triple it, and will improve further with time. In practice, this looks like every OpenBrain researcher becoming the “manager” of an AI “team.”\",\"position\":\"$102a\"}\n100b:[\"$100c\",\"$1010\",\"$1019\",\"$101d\",\"$1021\",\"$1025\",\"$1029\"]\n102e:{\"line\":218,\""])</script><script>self.__next_f.push([1,"column\":1,\"offset\":26670}\n102f:{\"line\":218,\"column\":785,\"offset\":27454}\n102d:{\"start\":\"$102e\",\"end\":\"$102f\"}\n100a:{\"type\":\"paragraph\",\"children\":\"$100b\",\"position\":\"$102d\"}\n1034:{\"line\":220,\"column\":1,\"offset\":27456}\n1035:{\"line\":220,\"column\":126,\"offset\":27581}\n1033:{\"start\":\"$1034\",\"end\":\"$1035\"}\n1032:{\"type\":\"text\",\"value\":\"With new capabilities come new dangers. The safety team finds that if Agent-2 somehow escaped from the company and wanted to \",\"position\":\"$1033\"}\n103a:{\"line\":220,\"column\":127,\"offset\":27582}\n103b:{\"line\":220,\"column\":165,\"offset\":27620}\n1039:{\"start\":\"$103a\",\"end\":\"$103b\"}\n1038:{\"type\":\"text\",\"value\":\"“survive” and “replicate” autonomously\",\"position\":\"$1039\"}\n1037:[\"$1038\"]\n103d:{\"line\":220,\"column\":126,\"offset\":27581}\n103e:{\"line\":220,\"column\":231,\"offset\":27686}\n103c:{\"start\":\"$103d\",\"end\":\"$103e\"}\n1036:{\"type\":\"link\",\"title\":null,\"url\":\"https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf\",\"children\":\"$1037\",\"position\":\"$103c\"}\n1041:{\"line\":220,\"column\":231,\"offset\":27686}\n1042:{\"line\":220,\"column\":707,\"offset\":28162}\n1040:{\"start\":\"$1041\",\"end\":\"$1042\"}\n103f:{\"type\":\"text\",\"value\":\", it might be able to do so. That is, it could autonomously develop and execute plans to hack into AI servers, install copies of itself, evade detection, and use that secure base to pursue whatever other goals it might have (though how effectively it would do so as weeks roll by is unknown and in doubt). These results only show that the model has the capability to do these tasks, not whether it would “want” to do this. Still, it’s unsettling even to know this is possible.\",\"position\":\"$1040\"}\n1031:[\"$1032\",\"$1036\",\"$103f\"]\n1044:{\"line\":220,\"column\":1,\"offset\":27456}\n1045:{\"line\":220,\"column\":707,\"offset\":28162}\n1043:{\"start\":\"$1044\",\"end\":\"$1045\"}\n1030:{\"type\":\"paragraph\",\"children\":\"$1031\",\"position\":\"$1043\"}\n104a:{\"line\":222,\"column\":1,\"offset\":28164}\n104b:{\"line\":222,\"column\":151,\"offset\":28314}\n1049:{\"start\":\"$104a\",\"end\":\"$104b\"}\n1048:{\"type\":\"text\",\"value\":\"Given the “dange"])</script><script>self.__next_f.push([1,"rs” of the new model, OpenBrain “responsibly” elects not to release it publicly yet (in fact, they want to focus on internal AI R\u0026D).\",\"position\":\"$1049\"}\n104e:{\"line\":222,\"column\":151,\"offset\":28314}\n104f:{\"line\":222,\"column\":156,\"offset\":28319}\n104d:{\"start\":\"$104e\",\"end\":\"$104f\"}\n104c:{\"type\":\"footnoteReference\",\"identifier\":\"46\",\"label\":\"46\",\"position\":\"$104d\"}\n1052:{\"line\":222,\"column\":156,\"offset\":28319}\n1053:{\"line\":222,\"column\":391,\"offset\":28554}\n1051:{\"start\":\"$1052\",\"end\":\"$1053\"}\n1050:{\"type\":\"text\",\"value\":\" Knowledge of Agent-2’s full capabilities is limited to an elite silo containing the immediate team, OpenBrain leadership and security, a few dozen U.S. government officials, and the legions of CCP spies who have infiltrated OpenBrain \",\"position\":\"$1051\"}\n1058:{\"line\":222,\"column\":392,\"offset\":28555}\n1059:{\"line\":222,\"column\":395,\"offset\":28558}\n1057:{\"start\":\"$1058\",\"end\":\"$1059\"}\n1056:{\"type\":\"text\",\"value\":\"for\",\"position\":\"$1057\"}\n1055:[\"$1056\"]\n105b:{\"line\":222,\"column\":391,\"offset\":28554}\n105c:{\"line\":222,\"column\":450,\"offset\":28613}\n105a:{\"start\":\"$105b\",\"end\":\"$105c\"}\n1054:{\"type\":\"link\",\"title\":null,\"url\":\"https://situational-awareness.ai/lock-down-the-labs/\",\"children\":\"$1055\",\"position\":\"$105a\"}\n105f:{\"line\":222,\"column\":450,\"offset\":28613}\n1060:{\"line\":222,\"column\":451,\"offset\":28614}\n105e:{\"start\":\"$105f\",\"end\":\"$1060\"}\n105d:{\"type\":\"text\",\"value\":\" \",\"position\":\"$105e\"}\n1065:{\"line\":222,\"column\":452,\"offset\":28615}\n1066:{\"line\":222,\"column\":457,\"offset\":28620}\n1064:{\"start\":\"$1065\",\"end\":\"$1066\"}\n1063:{\"type\":\"text\",\"value\":\"years\",\"position\":\"$1064\"}\n1062:[\"$1063\"]\n1068:{\"line\":222,\"column\":451,\"offset\":28614}\n1069:{\"line\":222,\"column\":510,\"offset\":28673}\n1067:{\"start\":\"$1068\",\"end\":\"$1069\"}\n1061:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.bbc.com/news/world-asia-china-64206950\",\"children\":\"$1062\",\"position\":\"$1067\"}\n106c:{\"line\":222,\"column\":510,\"offset\":28673}\n106d:{\"line\":222,\"column\":511,\"offset\":28674}\n106b:{\"start\":\"$106c\",\"end\":\"$106d\"}\n106a:{\"type\":\"text\",\"value\""])</script><script>self.__next_f.push([1,":\".\",\"position\":\"$106b\"}\n1070:{\"line\":222,\"column\":511,\"offset\":28674}\n1071:{\"line\":222,\"column\":516,\"offset\":28679}\n106f:{\"start\":\"$1070\",\"end\":\"$1071\"}\n106e:{\"type\":\"footnoteReference\",\"identifier\":\"47\",\"label\":\"47\",\"position\":\"$106f\"}\n1047:[\"$1048\",\"$104c\",\"$1050\",\"$1054\",\"$105d\",\"$1061\",\"$106a\",\"$106e\"]\n1073:{\"line\":222,\"column\":1,\"offset\":28164}\n1074:{\"line\":222,\"column\":516,\"offset\":28679}\n1072:{\"start\":\"$1073\",\"end\":\"$1074\"}\n1046:{\"type\":\"paragraph\",\"children\":\"$1047\",\"position\":\"$1072\"}\n1079:{\"line\":224,\"column\":4,\"offset\":28684}\n107a:{\"line\":224,\"column\":39,\"offset\":28719}\n1078:{\"start\":\"$1079\",\"end\":\"$107a\"}\n1077:{\"type\":\"text\",\"value\":\"February 2027: China Steals Agent-2\",\"position\":\"$1078\"}\n1076:[\"$1077\"]\n107c:{\"line\":224,\"column\":1,\"offset\":28681}\n107d:{\"line\":224,\"column\":39,\"offset\":28719}\n107b:{\"start\":\"$107c\",\"end\":\"$107d\"}\n1075:{\"type\":\"heading\",\"depth\":2,\"children\":\"$1076\",\"position\":\"$107b\"}\n107f:{}\n1085:{\"line\":227,\"column\":1,\"offset\":28737}\n1086:{\"line\":227,\"column\":11,\"offset\":28747}\n1084:{\"start\":\"$1085\",\"end\":\"$1086\"}\n1083:{\"type\":\"text\",\"value\":\"2027-02-28\",\"position\":\"$1084\"}\n1089:{\"line\":227,\"column\":11,\"offset\":28747}\n108a:{\"line\":228,\"column\":1,\"offset\":28750}\n1088:{\"start\":\"$1089\",\"end\":\"$108a\"}\n1087:{\"type\":\"break\",\"position\":\"$1088\"}\n108d:{\"line\":228,\"column\":1,\"offset\":28750}\n108e:{\"line\":228,\"column\":4,\"offset\":28753}\n108c:{\"start\":\"$108d\",\"end\":\"$108e\"}\n108b:{\"type\":\"text\",\"value\":\"Feb\",\"position\":\"$108c\"}\n1082:[\"$1083\",\"$1087\",\"$108b\"]\n1090:{\"line\":227,\"column\":1,\"offset\":28737}\n1091:{\"line\":228,\"column\":6,\"offset\":28755}\n108f:{\"start\":\"$1090\",\"end\":\"$1091\"}\n1081:{\"type\":\"paragraph\",\"children\":\"$1082\",\"position\":\"$108f\"}\n1080:[\"$1081\"]\n1093:{\"line\":226,\"column\":1,\"offset\":28721}\n1094:{\"line\":229,\"column\":4,\"offset\":28759}\n1092:{\"start\":\"$1093\",\"end\":\"$1094\"}\n107e:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$107f\",\"children\":\"$1080\",\"position\":\"$1092\"}\n1099:{\"line\":231,\"column\":1,\"offset\":28761}\n109a:{\"line\":231,\"column\":384,\"offset\":29144}\n1098:{\"start\":\"$10"])</script><script>self.__next_f.push([1,"99\",\"end\":\"$109a\"}\n1097:{\"type\":\"text\",\"value\":\"OpenBrain presents Agent-2 to the government, including the National Security Council (NSC), the Department of Defense (DOD), and the U.S. AI Safety Institute (AISI). OpenBrain wants to maintain a good relationship with the executive branch, because it is basically the only actor that can stop them now, and if they don’t keep it informed it might find out anyway and be displeased.\",\"position\":\"$1098\"}\n109d:{\"line\":231,\"column\":384,\"offset\":29144}\n109e:{\"line\":231,\"column\":389,\"offset\":29149}\n109c:{\"start\":\"$109d\",\"end\":\"$109e\"}\n109b:{\"type\":\"footnoteReference\",\"identifier\":\"48\",\"label\":\"48\",\"position\":\"$109c\"}\n1096:[\"$1097\",\"$109b\"]\n10a0:{\"line\":231,\"column\":1,\"offset\":28761}\n10a1:{\"line\":231,\"column\":389,\"offset\":29149}\n109f:{\"start\":\"$10a0\",\"end\":\"$10a1\"}\n1095:{\"type\":\"paragraph\",\"children\":\"$1096\",\"position\":\"$109f\"}\n10a6:{\"line\":233,\"column\":1,\"offset\":29151}\n10a7:{\"line\":233,\"column\":396,\"offset\":29546}\n10a5:{\"start\":\"$10a6\",\"end\":\"$10a7\"}\n10a4:{\"type\":\"text\",\"value\":\"Officials are most interested in its cyberwarfare capabilities: Agent-2 is “only” a little worse than the best human hackers, but thousands of copies can be run in parallel, searching for and exploiting weaknesses faster than defenders can respond. The Department of Defense considers this a critical advantage in cyberwarfare, and AI moves from #5 on the administration’s priority list to #2.\",\"position\":\"$10a5\"}\n10aa:{\"line\":233,\"column\":396,\"offset\":29546}\n10ab:{\"line\":233,\"column\":401,\"offset\":29551}\n10a9:{\"start\":\"$10aa\",\"end\":\"$10ab\"}\n10a8:{\"type\":\"footnoteReference\",\"identifier\":\"49\",\"label\":\"49\",\"position\":\"$10a9\"}\n10ae:{\"line\":233,\"column\":401,\"offset\":29551}\n10af:{\"line\":233,\"column\":905,\"offset\":30055}\n10ad:{\"start\":\"$10ae\",\"end\":\"$10af\"}\n10ac:{\"type\":\"text\",\"value\":\" Someone mentions the possibility of nationalizing OpenBrain, but other cabinet officials think that’s premature. A staffer drafts a memo that presents the President with his options, ranging from business-as-usual t"])</script><script>self.__next_f.push([1,"o full nationalization. The President defers to his advisors, tech industry leaders who argue that nationalization would “kill the goose that lays the golden eggs.” He elects to hold off on major action for now and just adds additional security requirements to the OpenBrain-DOD contract.\",\"position\":\"$10ad\"}\n10a3:[\"$10a4\",\"$10a8\",\"$10ac\"]\n10b1:{\"line\":233,\"column\":1,\"offset\":29151}\n10b2:{\"line\":233,\"column\":905,\"offset\":30055}\n10b0:{\"start\":\"$10b1\",\"end\":\"$10b2\"}\n10a2:{\"type\":\"paragraph\",\"children\":\"$10a3\",\"position\":\"$10b0\"}\n10b7:{\"line\":235,\"column\":1,\"offset\":30057}\n10b8:{\"line\":235,\"column\":398,\"offset\":30454}\n10b6:{\"start\":\"$10b7\",\"end\":\"$10b8\"}\n10b5:{\"type\":\"text\",\"value\":\"The changes come too late. CCP leadership recognizes the importance of Agent-2 and tells their spies and cyberforce to steal the weights. Early one morning, an Agent-1 traffic monitoring agent detects an anomalous transfer. It alerts company leaders, who tell the White House. The signs of a nation-state-level operation are unmistakable, and the theft heightens the sense of an ongoing arms race.\",\"position\":\"$10b6\"}\n10b4:[\"$10b5\"]\n10ba:{\"line\":235,\"column\":1,\"offset\":30057}\n10bb:{\"line\":235,\"column\":399,\"offset\":30455}\n10b9:{\"start\":\"$10ba\",\"end\":\"$10bb\"}\n10b3:{\"type\":\"paragraph\",\"children\":\"$10b4\",\"position\":\"$10b9\"}\n10c2:{\"line\":241,\"column\":1,\"offset\":30505}\n10c3:{\"line\":241,\"column\":303,\"offset\":30807}\n10c1:{\"start\":\"$10c2\",\"end\":\"$10c3\"}\n10c0:{\"type\":\"text\",\"value\":\"We think that by this point Chinese intelligence would have compromised OpenBrain in various ways for years, and probably would have been keeping up to date on the algorithmic secrets and even stealing code from time to time, since that is much easier to get than the weights and much harder to detect.\",\"position\":\"$10c1\"}\n10bf:[\"$10c0\"]\n10c5:{\"line\":241,\"column\":1,\"offset\":30505}\n10c6:{\"line\":241,\"column\":303,\"offset\":30807}\n10c4:{\"start\":\"$10c5\",\"end\":\"$10c6\"}\n10be:{\"type\":\"paragraph\",\"children\":\"$10bf\",\"position\":\"$10c4\"}\n10cb:{\"line\":243,\"column\":1,\"offset\":30809}\n1"])</script><script>self.__next_f.push([1,"0cc:{\"line\":243,\"column\":667,\"offset\":31475}\n10ca:{\"start\":\"$10cb\",\"end\":\"$10cc\"}\n10c9:{\"type\":\"text\",\"value\":\"We imagine the theft of the weights as a series of coordinated small smash and grab thefts (meaning fast but non-covert) across a series of Nvidia NVL72 GB300 servers running copies of the Agent-2 weights. The servers are compromised using legitimate employee access (a friendly, coerced, or unwitting insider with admin credentials helping the CCP theft effort). Insider credentials grant the attacker admin-level permissions to the servers. Using a microarchitectural side channel, the attacker extracts encryption keys from an Nvidia Confidential Computing-enabled Virtual Machine, allowing the them to intercept model weights as the VM is provisioned or updated.\",\"position\":\"$10ca\"}\n10c8:[\"$10c9\"]\n10ce:{\"line\":243,\"column\":1,\"offset\":30809}\n10cf:{\"line\":243,\"column\":667,\"offset\":31475}\n10cd:{\"start\":\"$10ce\",\"end\":\"$10cf\"}\n10c7:{\"type\":\"paragraph\",\"children\":\"$10c8\",\"position\":\"$10cd\"}\n10d4:{\"line\":245,\"column\":1,\"offset\":31477}\n10d5:{\"line\":245,\"column\":569,\"offset\":32045}\n10d3:{\"start\":\"$10d4\",\"end\":\"$10d5\"}\n10d2:{\"type\":\"text\",\"value\":\"They initiate (or wait for) a routine update and exfiltrate the checkpoint in many small fragments, e.g., ~25 distinct servers each leaking ~4% of the model (~100 GB chunks for a ~2.5 TB half-precision checkpoint). The egress bandwidth of the entire datacenter is in the 100 GB/second range, so throttling to under ~1 GB/s per server avoids a major spike in network traffic; at that rate, each ~100 GB chunk can leave the datacenter in a couple of minutes. Live monitoring is either fooled by the attackers efforts to mask and split the transfers or outright disabled.\",\"position\":\"$10d3\"}\n10d1:[\"$10d2\"]\n10d7:{\"line\":245,\"column\":1,\"offset\":31477}\n10d8:{\"line\":245,\"column\":569,\"offset\":32045}\n10d6:{\"start\":\"$10d7\",\"end\":\"$10d8\"}\n10d0:{\"type\":\"paragraph\",\"children\":\"$10d1\",\"position\":\"$10d6\"}\n10dd:{\"line\":247,\"column\":1,\"offset\":32047}\n10de:{\"line\":247,\"column\":288,\"offset\":32334}\n1"])</script><script>self.__next_f.push([1,"0dc:{\"start\":\"$10dd\",\"end\":\"$10de\"}\n10db:{\"type\":\"text\",\"value\":\"The weights are then routed through various parallel channels and layers of IP masking to China to be decrypted locally with the stolen session key(s). The entire active part of the operation (from the first server compromise to full weights exfiltration) is complete in under two hours.\",\"position\":\"$10dc\"}\n10e1:{\"line\":247,\"column\":288,\"offset\":32334}\n10e2:{\"line\":247,\"column\":293,\"offset\":32339}\n10e0:{\"start\":\"$10e1\",\"end\":\"$10e2\"}\n10df:{\"type\":\"footnoteReference\",\"identifier\":\"99\",\"label\":\"99\",\"position\":\"$10e0\"}\n10da:[\"$10db\",\"$10df\"]\n10e4:{\"line\":247,\"column\":1,\"offset\":32047}\n10e5:{\"line\":247,\"column\":293,\"offset\":32339}\n10e3:{\"start\":\"$10e4\",\"end\":\"$10e5\"}\n10d9:{\"type\":\"paragraph\",\"children\":\"$10da\",\"position\":\"$10e3\"}\n10ea:{\"line\":249,\"column\":1,\"offset\":32341}\n10eb:{\"line\":249,\"column\":306,\"offset\":32646}\n10e9:{\"start\":\"$10ea\",\"end\":\"$10eb\"}\n10e8:{\"type\":\"text\",\"value\":\"Russia is also trying to steal the model at this point, but fails—they waited too long, and they haven’t spent the resources infiltrating the right places. Their spies routinely steal algorithmic secrets from American AI companies, but without a notable AGI project of their own, these aren’t very useful.\",\"position\":\"$10e9\"}\n10e7:[\"$10e8\"]\n10ed:{\"line\":249,\"column\":1,\"offset\":32341}\n10ee:{\"line\":249,\"column\":306,\"offset\":32646}\n10ec:{\"start\":\"$10ed\",\"end\":\"$10ee\"}\n10e6:{\"type\":\"paragraph\",\"children\":\"$10e7\",\"position\":\"$10ec\"}\n10bd:[\"$10be\",\"$10c7\",\"$10d0\",\"$10d9\",\"$10e6\"]\n10bc:{\"type\":\"details\",\"summary\":\"The theft of Agent-2 model weights\",\"children\":\"$10bd\"}\n10f3:{\"line\":253,\"column\":1,\"offset\":32653}\n10f4:{\"line\":253,\"column\":187,\"offset\":32839}\n10f2:{\"start\":\"$10f3\",\"end\":\"$10f4\"}\n10f1:{\"type\":\"text\",\"value\":\"The White House puts OpenBrain on a shorter leash and adds military and intelligence community personnel to their security team. Their first priority is to prevent further weight thefts.\",\"position\":\"$10f2\"}\n10f7:{\"line\":253,\"column\":187,\"offset\":32839}\n10f8:"])</script><script>self.__next_f.push([1,"{\"line\":253,\"column\":192,\"offset\":32844}\n10f6:{\"start\":\"$10f7\",\"end\":\"$10f8\"}\n10f5:{\"type\":\"footnoteReference\",\"identifier\":\"50\",\"label\":\"50\",\"position\":\"$10f6\"}\n10f0:[\"$10f1\",\"$10f5\"]\n10fa:{\"line\":253,\"column\":1,\"offset\":32653}\n10fb:{\"line\":253,\"column\":192,\"offset\":32844}\n10f9:{\"start\":\"$10fa\",\"end\":\"$10fb\"}\n10ef:{\"type\":\"paragraph\",\"children\":\"$10f0\",\"position\":\"$10f9\"}\n10fd:{}\n10fe:[]\n1100:{\"line\":256,\"column\":1,\"offset\":32849}\n1101:{\"line\":257,\"column\":4,\"offset\":32884}\n10ff:{\"start\":\"$1100\",\"end\":\"$1101\"}\n10fc:{\"type\":\"containerDirective\",\"name\":\"chinaComputeCentralization\",\"attributes\":\"$10fd\",\"children\":\"$10fe\",\"position\":\"$10ff\"}\n1106:{\"line\":259,\"column\":1,\"offset\":32886}\n1107:{\"line\":259,\"column\":142,\"offset\":33027}\n1105:{\"start\":\"$1106\",\"end\":\"$1107\"}\n1104:{\"type\":\"text\",\"value\":\"In retaliation for the theft, the President authorizes cyberattacks to sabotage DeepCent. But by now China has 40% of its AI-relevant compute\",\"position\":\"$1105\"}\n110a:{\"line\":259,\"column\":142,\"offset\":33027}\n110b:{\"line\":259,\"column\":147,\"offset\":33032}\n1109:{\"start\":\"$110a\",\"end\":\"$110b\"}\n1108:{\"type\":\"footnoteReference\",\"identifier\":\"51\",\"label\":\"51\",\"position\":\"$1109\"}\n110e:{\"line\":259,\"column\":147,\"offset\":33032}\n110f:{\"line\":259,\"column\":520,\"offset\":33405}\n110d:{\"start\":\"$110e\",\"end\":\"$110f\"}\n110c:{\"type\":\"text\",\"value\":\" in the CDZ, where they have aggressively hardened security by airgapping (closing external connections) and siloing internally. The operations fail to do serious, immediate damage. Tensions heighten, both sides signal seriousness by repositioning military assets around Taiwan, and DeepCent scrambles to get Agent-2 running efficiently to start boosting their AI research.\",\"position\":\"$110d\"}\n1112:{\"line\":259,\"column\":520,\"offset\":33405}\n1113:{\"line\":259,\"column\":525,\"offset\":33410}\n1111:{\"start\":\"$1112\",\"end\":\"$1113\"}\n1110:{\"type\":\"footnoteReference\",\"identifier\":\"52\",\"label\":\"52\",\"position\":\"$1111\"}\n1103:[\"$1104\",\"$1108\",\"$110c\",\"$1110\"]\n1115:{\"line\":259,\"column\":1,\"offset\":32886}\n1116:{\"line\":259,\"co"])</script><script>self.__next_f.push([1,"lumn\":525,\"offset\":33410}\n1114:{\"start\":\"$1115\",\"end\":\"$1116\"}\n1102:{\"type\":\"paragraph\",\"children\":\"$1103\",\"position\":\"$1114\"}\n111b:{\"line\":261,\"column\":4,\"offset\":33415}\n111c:{\"line\":261,\"column\":41,\"offset\":33452}\n111a:{\"start\":\"$111b\",\"end\":\"$111c\"}\n1119:{\"type\":\"text\",\"value\":\"March 2027: Algorithmic Breakthroughs\",\"position\":\"$111a\"}\n1118:[\"$1119\"]\n111e:{\"line\":261,\"column\":1,\"offset\":33412}\n111f:{\"line\":261,\"column\":41,\"offset\":33452}\n111d:{\"start\":\"$111e\",\"end\":\"$111f\"}\n1117:{\"type\":\"heading\",\"depth\":2,\"children\":\"$1118\",\"position\":\"$111d\"}\n1121:{}\n1127:{\"line\":264,\"column\":1,\"offset\":33470}\n1128:{\"line\":264,\"column\":11,\"offset\":33480}\n1126:{\"start\":\"$1127\",\"end\":\"$1128\"}\n1125:{\"type\":\"text\",\"value\":\"2027-03-31\",\"position\":\"$1126\"}\n112b:{\"line\":264,\"column\":11,\"offset\":33480}\n112c:{\"line\":265,\"column\":1,\"offset\":33483}\n112a:{\"start\":\"$112b\",\"end\":\"$112c\"}\n1129:{\"type\":\"break\",\"position\":\"$112a\"}\n112f:{\"line\":265,\"column\":1,\"offset\":33483}\n1130:{\"line\":265,\"column\":4,\"offset\":33486}\n112e:{\"start\":\"$112f\",\"end\":\"$1130\"}\n112d:{\"type\":\"text\",\"value\":\"Mar\",\"position\":\"$112e\"}\n1124:[\"$1125\",\"$1129\",\"$112d\"]\n1132:{\"line\":264,\"column\":1,\"offset\":33470}\n1133:{\"line\":265,\"column\":6,\"offset\":33488}\n1131:{\"start\":\"$1132\",\"end\":\"$1133\"}\n1123:{\"type\":\"paragraph\",\"children\":\"$1124\",\"position\":\"$1131\"}\n1122:[\"$1123\"]\n1135:{\"line\":263,\"column\":1,\"offset\":33454}\n1136:{\"line\":266,\"column\":4,\"offset\":33492}\n1134:{\"start\":\"$1135\",\"end\":\"$1136\"}\n1120:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$1121\",\"children\":\"$1122\",\"position\":\"$1134\"}\n113b:{\"line\":268,\"column\":1,\"offset\":33494}\n113c:{\"line\":268,\"column\":186,\"offset\":33679}\n113a:{\"start\":\"$113b\",\"end\":\"$113c\"}\n1139:{\"type\":\"text\",\"value\":\"Three huge datacenters full of Agent-2 copies work day and night, churning out synthetic training data. Another two are used to update the weights. Agent-2 is getting smarter every day.\",\"position\":\"$113a\"}\n1138:[\"$1139\"]\n113e:{\"line\":268,\"column\":1,\"offset\":33494}\n113f:{\"line\":268,\"column\":186,\"offset\":33679}\n113d:{\"star"])</script><script>self.__next_f.push([1,"t\":\"$113e\",\"end\":\"$113f\"}\n1137:{\"type\":\"paragraph\",\"children\":\"$1138\",\"position\":\"$113d\"}\n1144:{\"line\":270,\"column\":1,\"offset\":33681}\n1145:{\"line\":270,\"column\":414,\"offset\":34094}\n1143:{\"start\":\"$1144\",\"end\":\"$1145\"}\n1142:{\"type\":\"text\",\"value\":\"With the help of thousands of Agent-2 automated researchers, OpenBrain is making major algorithmic advances. One such breakthrough is augmenting the AI’s text-based scratchpad (chain of thought) with a higher-bandwidth thought process (neuralese recurrence and memory). Another is a more scalable and efficient way to learn from the results of high-effort task solutions (iterated distillation and amplification).\",\"position\":\"$1143\"}\n1141:[\"$1142\"]\n1147:{\"line\":270,\"column\":1,\"offset\":33681}\n1148:{\"line\":270,\"column\":415,\"offset\":34095}\n1146:{\"start\":\"$1147\",\"end\":\"$1148\"}\n1140:{\"type\":\"paragraph\",\"children\":\"$1141\",\"position\":\"$1146\"}\n114d:{\"line\":272,\"column\":1,\"offset\":34097}\n114e:{\"line\":272,\"column\":73,\"offset\":34169}\n114c:{\"start\":\"$114d\",\"end\":\"$114e\"}\n114b:{\"type\":\"text\",\"value\":\"The new AI system, incorporating these breakthroughs, is called Agent-3.\",\"position\":\"$114c\"}\n114a:[\"$114b\"]\n1150:{\"line\":272,\"column\":1,\"offset\":34097}\n1151:{\"line\":272,\"column\":73,\"offset\":34169}\n114f:{\"start\":\"$1150\",\"end\":\"$1151\"}\n1149:{\"type\":\"paragraph\",\"children\":\"$114a\",\"position\":\"$114f\"}\n1153:{}\n1154:[]\n1156:{\"line\":275,\"column\":1,\"offset\":34174}\n1157:{\"line\":276,\"column\":4,\"offset\":34209}\n1155:{\"start\":\"$1156\",\"end\":\"$1157\"}\n1152:{\"type\":\"containerDirective\",\"name\":\"ComputeAllocation2024v2027\",\"attributes\":\"$1153\",\"children\":\"$1154\",\"position\":\"$1155\"}\n115e:{\"line\":282,\"column\":1,\"offset\":34256}\n115f:{\"line\":282,\"column\":130,\"offset\":34385}\n115d:{\"start\":\"$115e\",\"end\":\"$115f\"}\n115c:{\"type\":\"text\",\"value\":\"Neuralese recurrence and memory allows AI models to reason for a longer time without having to write down those thoughts as text.\",\"position\":\"$115d\"}\n115b:[\"$115c\"]\n1161:{\"line\":282,\"column\":1,\"offset\":34256}\n1162:{\"line\":282,\"column\":130,\"offset\":34385}\n1160:{\"start\":\"$1161\","])</script><script>self.__next_f.push([1,"\"end\":\"$1162\"}\n115a:{\"type\":\"paragraph\",\"children\":\"$115b\",\"position\":\"$1160\"}\n1167:{\"line\":284,\"column\":1,\"offset\":34387}\n1168:{\"line\":284,\"column\":452,\"offset\":34838}\n1166:{\"start\":\"$1167\",\"end\":\"$1168\"}\n1165:{\"type\":\"text\",\"value\":\"Imagine being a human with short-term memory loss, such that you need to constantly write down your thoughts on paper so that in a few minutes you know what’s going on. Slowly and painfully you could make progress at solving math problems, writing code, etc., but it would be much easier if you could directly remember your thoughts without having to write them down and then read them. This is what neuralese recurrence and memory bring to AI models.\",\"position\":\"$1166\"}\n1164:[\"$1165\"]\n116a:{\"line\":284,\"column\":1,\"offset\":34387}\n116b:{\"line\":284,\"column\":452,\"offset\":34838}\n1169:{\"start\":\"$116a\",\"end\":\"$116b\"}\n1163:{\"type\":\"paragraph\",\"children\":\"$1164\",\"position\":\"$1169\"}\n1170:{\"line\":286,\"column\":1,\"offset\":34840}\n1171:{\"line\":286,\"column\":25,\"offset\":34864}\n116f:{\"start\":\"$1170\",\"end\":\"$1171\"}\n116e:{\"type\":\"text\",\"value\":\"In more technical terms:\",\"position\":\"$116f\"}\n116d:[\"$116e\"]\n1173:{\"line\":286,\"column\":1,\"offset\":34840}\n1174:{\"line\":286,\"column\":25,\"offset\":34864}\n1172:{\"start\":\"$1173\",\"end\":\"$1174\"}\n116c:{\"type\":\"paragraph\",\"children\":\"$116d\",\"position\":\"$1172\"}\n1179:{\"line\":288,\"column\":1,\"offset\":34866}\n117a:{\"line\":288,\"column\":187,\"offset\":35052}\n1178:{\"start\":\"$1179\",\"end\":\"$117a\"}\n1177:{\"type\":\"text\",\"value\":\"Traditional attention mechanisms allow later forward passes in a model to see intermediate activations of the model for previous tokens. However, the only information that they can pass \",\"position\":\"$1178\"}\n117f:{\"line\":288,\"column\":188,\"offset\":35053}\n1180:{\"line\":288,\"column\":197,\"offset\":35062}\n117e:{\"start\":\"$117f\",\"end\":\"$1180\"}\n117d:{\"type\":\"text\",\"value\":\"backwards\",\"position\":\"$117e\"}\n117c:[\"$117d\"]\n1182:{\"line\":288,\"column\":187,\"offset\":35052}\n1183:{\"line\":288,\"column\":198,\"offset\":35063}\n1181:{\"start\":\"$1182\",\"end\":\"$1183\"}\n117b:{\"type\":\"emphasis\",\"chil"])</script><script>self.__next_f.push([1,"dren\":\"$117c\",\"position\":\"$1181\"}\n1186:{\"line\":288,\"column\":198,\"offset\":35063}\n1187:{\"line\":288,\"column\":706,\"offset\":35571}\n1185:{\"start\":\"$1186\",\"end\":\"$1187\"}\n1184:{\"type\":\"text\",\"value\":\" (from later layers to earlier layers) is through tokens. This means that if a traditional large language model (LLM, e.g. the GPT series of models) wants to do any chain of reasoning that takes more serial operations than the number of layers in the model, the model is forced to put information in tokens which it can then pass back into itself. But this is hugely limiting—the tokens can only store a tiny amount of information. Suppose that an LLM has a vocab size of ~100,000, then each token contains \",\"position\":\"$1185\"}\n118b:[\"language-math\",\"math-inline\"]\n118a:{\"className\":\"$118b\"}\n118d:{\"type\":\"text\",\"value\":\"\\\\\\\\log\\\\_2(100k)=16.6\"}\n118c:[\"$118d\"]\n1189:{\"hName\":\"code\",\"hProperties\":\"$118a\",\"hChildren\":\"$118c\"}\n118f:{\"line\":288,\"column\":706,\"offset\":35571}\n1190:{\"line\":288,\"column\":729,\"offset\":35594}\n118e:{\"start\":\"$118f\",\"end\":\"$1190\"}\n1188:{\"type\":\"inlineMath\",\"value\":\"\\\\\\\\log\\\\_2(100k)=16.6\",\"data\":\"$1189\",\"position\":\"$118e\"}\n1193:{\"line\":288,\"column\":729,\"offset\":35594}\n1194:{\"line\":288,\"column\":823,\"offset\":35688}\n1192:{\"start\":\"$1193\",\"end\":\"$1194\"}\n1191:{\"type\":\"text\",\"value\":\" bits of information, around the size of a single floating point number (assuming training in \",\"position\":\"$1192\"}\n1199:{\"line\":288,\"column\":824,\"offset\":35689}\n119a:{\"line\":288,\"column\":828,\"offset\":35693}\n1198:{\"start\":\"$1199\",\"end\":\"$119a\"}\n1197:{\"type\":\"text\",\"value\":\"FP16\",\"position\":\"$1198\"}\n1196:[\"$1197\"]\n119c:{\"line\":288,\"column\":823,\"offset\":35688}\n119d:{\"line\":288,\"column\":897,\"offset\":35762}\n119b:{\"start\":\"$119c\",\"end\":\"$119d\"}\n1195:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Half-precision_floating-point_format\",\"children\":\"$1196\",\"position\":\"$119b\"}\n11a0:{\"line\":288,\"column\":897,\"offset\":35762}\n11a1:{\"line\":288,\"column\":1022,\"offset\":35887}\n119f:{\"start\":\"$11a0\",\"end\":\"$11a1\"}\n119e:{\"type\":\"text\",\"value"])</script><script>self.__next_f.push([1,"\":\"). Meanwhile, residual streams—used to pass information between layers in an LLM—contain thousands of floating point numbers.\",\"position\":\"$119f\"}\n1176:[\"$1177\",\"$117b\",\"$1184\",\"$1188\",\"$1191\",\"$1195\",\"$119e\"]\n11a3:{\"line\":288,\"column\":1,\"offset\":34866}\n11a4:{\"line\":288,\"column\":1022,\"offset\":35887}\n11a2:{\"start\":\"$11a3\",\"end\":\"$11a4\"}\n1175:{\"type\":\"paragraph\",\"children\":\"$1176\",\"position\":\"$11a2\"}\n11a9:{\"line\":290,\"column\":1,\"offset\":35889}\n11aa:{\"line\":290,\"column\":40,\"offset\":35928}\n11a8:{\"start\":\"$11a9\",\"end\":\"$11aa\"}\n11a7:{\"type\":\"text\",\"value\":\"One can avoid this bottleneck by using \",\"position\":\"$11a8\"}\n11af:{\"line\":290,\"column\":42,\"offset\":35930}\n11b0:{\"line\":290,\"column\":51,\"offset\":35939}\n11ae:{\"start\":\"$11af\",\"end\":\"$11b0\"}\n11ad:{\"type\":\"text\",\"value\":\"neuralese\",\"position\":\"$11ae\"}\n11ac:[\"$11ad\"]\n11b2:{\"line\":290,\"column\":40,\"offset\":35928}\n11b3:{\"line\":290,\"column\":53,\"offset\":35941}\n11b1:{\"start\":\"$11b2\",\"end\":\"$11b3\"}\n11ab:{\"type\":\"strong\",\"children\":\"$11ac\",\"position\":\"$11b1\"}\n11b6:{\"line\":290,\"column\":53,\"offset\":35941}\n11b7:{\"line\":290,\"column\":290,\"offset\":36178}\n11b5:{\"start\":\"$11b6\",\"end\":\"$11b7\"}\n11b4:{\"type\":\"text\",\"value\":\": passing an LLM’s residual stream (which consists of several-thousand-dimensional vectors) back to the early layers of the model, giving it a high-dimensional chain of thought, potentially transmitting over 1,000 times more information.\",\"position\":\"$11b5\"}\n11a6:[\"$11a7\",\"$11ab\",\"$11b4\"]\n11b9:{\"line\":290,\"column\":1,\"offset\":35889}\n11ba:{\"line\":290,\"column\":291,\"offset\":36179}\n11b8:{\"start\":\"$11b9\",\"end\":\"$11ba\"}\n11a5:{\"type\":\"paragraph\",\"children\":\"$11a6\",\"position\":\"$11b8\"}\n11bf:{\"line\":292,\"column\":1,\"offset\":36181}\n11c0:{\"line\":292,\"column\":43,\"offset\":36223}\n11be:{\"start\":\"$11bf\",\"end\":\"$11c0\"}\n11bd:{\"type\":\"image\",\"title\":null,\"url\":\"/hao2024-nowatermark-inexpandable.png\",\"alt\":\"\",\"position\":\"$11be\"}\n11bc:[\"$11bd\"]\n11c2:{\"line\":292,\"column\":1,\"offset\":36181}\n11c3:{\"line\":292,\"column\":43,\"offset\":36223}\n11c1:{\"start\":\"$11c2\",\"end\":\"$11c3\"}\n11bb:{\"type\":\"par"])</script><script>self.__next_f.push([1,"agraph\",\"children\":\"$11bc\",\"position\":\"$11c1\"}\n11c8:{\"line\":294,\"column\":1,\"offset\":36225}\n11c9:{\"line\":294,\"column\":13,\"offset\":36237}\n11c7:{\"start\":\"$11c8\",\"end\":\"$11c9\"}\n11c6:{\"type\":\"text\",\"value\":\"Figure from \",\"position\":\"$11c7\"}\n11ce:{\"line\":294,\"column\":14,\"offset\":36238}\n11cf:{\"line\":294,\"column\":24,\"offset\":36248}\n11cd:{\"start\":\"$11ce\",\"end\":\"$11cf\"}\n11cc:{\"type\":\"text\",\"value\":\"Hao et al.\",\"position\":\"$11cd\"}\n11cb:[\"$11cc\"]\n11d1:{\"line\":294,\"column\":13,\"offset\":36237}\n11d2:{\"line\":294,\"column\":59,\"offset\":36283}\n11d0:{\"start\":\"$11d1\",\"end\":\"$11d2\"}\n11ca:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2412.06769\",\"children\":\"$11cb\",\"position\":\"$11d0\"}\n11d5:{\"line\":294,\"column\":59,\"offset\":36283}\n11d6:{\"line\":294,\"column\":107,\"offset\":36331}\n11d4:{\"start\":\"$11d5\",\"end\":\"$11d6\"}\n11d3:{\"type\":\"text\",\"value\":\", a 2024 paper from Meta implementing this idea.\",\"position\":\"$11d4\"}\n11c5:[\"$11c6\",\"$11ca\",\"$11d3\"]\n11d8:{\"line\":294,\"column\":1,\"offset\":36225}\n11d9:{\"line\":294,\"column\":107,\"offset\":36331}\n11d7:{\"start\":\"$11d8\",\"end\":\"$11d9\"}\n11c4:{\"type\":\"paragraph\",\"children\":\"$11c5\",\"position\":\"$11d7\"}\n11de:{\"line\":296,\"column\":1,\"offset\":36333}\n11df:{\"line\":296,\"column\":220,\"offset\":36552}\n11dd:{\"start\":\"$11de\",\"end\":\"$11df\"}\n11dc:{\"type\":\"text\",\"value\":\"We call this “neuralese” because unlike English words, these high-dimensional vectors are likely quite difficult for humans to interpret. In the past, researchers could get a good idea what LLMs were thinking simply by \",\"position\":\"$11dd\"}\n11e4:{\"line\":296,\"column\":221,\"offset\":36553}\n11e5:{\"line\":296,\"column\":249,\"offset\":36581}\n11e3:{\"start\":\"$11e4\",\"end\":\"$11e5\"}\n11e2:{\"type\":\"text\",\"value\":\"reading its chain of thought\",\"position\":\"$11e3\"}\n11e1:[\"$11e2\"]\n11e7:{\"line\":296,\"column\":220,\"offset\":36552}\n11e8:{\"line\":296,\"column\":305,\"offset\":36637}\n11e6:{\"start\":\"$11e7\",\"end\":\"$11e8\"}\n11e0:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/chain-of-thought-monitoring/\",\"children\":\"$11e1\",\"position\":\"$11e6\"}\n11eb:{\"line\":296,\"column\":305,\"of"])</script><script>self.__next_f.push([1,"fset\":36637}\n11ec:{\"line\":296,\"column\":456,\"offset\":36788}\n11ea:{\"start\":\"$11eb\",\"end\":\"$11ec\"}\n11e9:{\"type\":\"text\",\"value\":\". Now researchers have to ask the model to translate and summarize its thoughts or puzzle over the neuralese with their limited interpretability tools.\",\"position\":\"$11ea\"}\n11db:[\"$11dc\",\"$11e0\",\"$11e9\"]\n11ee:{\"line\":296,\"column\":1,\"offset\":36333}\n11ef:{\"line\":296,\"column\":456,\"offset\":36788}\n11ed:{\"start\":\"$11ee\",\"end\":\"$11ef\"}\n11da:{\"type\":\"paragraph\",\"children\":\"$11db\",\"position\":\"$11ed\"}\n11f4:{\"line\":298,\"column\":1,\"offset\":36790}\n11f5:{\"line\":298,\"column\":453,\"offset\":37242}\n11f3:{\"start\":\"$11f4\",\"end\":\"$11f5\"}\n11f2:{\"type\":\"text\",\"value\":\"Similarly, older AI chatbots and agents had external text-based memory banks, like a human taking notes on paper. The new AI’s long-term memory is a bundle of vectors instead of text, making its thoughts more compressed and higher-dimensional. There are several types of memory banks; some are used temporarily for single tasks that involve multiple steps, others are shared between all agents used by a person, company, or job type (e.g. programming).\",\"position\":\"$11f3\"}\n11f1:[\"$11f2\"]\n11f7:{\"line\":298,\"column\":1,\"offset\":36790}\n11f8:{\"line\":298,\"column\":453,\"offset\":37242}\n11f6:{\"start\":\"$11f7\",\"end\":\"$11f8\"}\n11f0:{\"type\":\"paragraph\",\"children\":\"$11f1\",\"position\":\"$11f6\"}\n11fd:{\"line\":300,\"column\":1,\"offset\":37244}\n11fe:{\"line\":300,\"column\":409,\"offset\":37652}\n11fc:{\"start\":\"$11fd\",\"end\":\"$11fe\"}\n11fb:{\"type\":\"text\",\"value\":\"To our knowledge, leading AI companies such as Meta, Google DeepMind, OpenAI, and Anthropic have not yet actually implemented this idea in their frontier models. Our guess is that this is because the performance gain is small relative to training inefficiencies introduced. During the model’s pre-training phase and when doing supervised learning in post-training, such as instruction fine-tuning to produce \",\"position\":\"$11fc\"}\n1203:{\"line\":300,\"column\":410,\"offset\":37653}\n1204:{\"line\":300,\"column\":430,\"offset\":37673}\n1202:{\"sta"])</script><script>self.__next_f.push([1,"rt\":\"$1203\",\"end\":\"$1204\"}\n1201:{\"type\":\"text\",\"value\":\"particular responses\",\"position\":\"$1202\"}\n1200:[\"$1201\"]\n1206:{\"line\":300,\"column\":409,\"offset\":37652}\n1207:{\"line\":300,\"column\":465,\"offset\":37708}\n1205:{\"start\":\"$1206\",\"end\":\"$1207\"}\n11ff:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2210.11416\",\"children\":\"$1200\",\"position\":\"$1205\"}\n1209:T437,, the inefficiencies stem from not being able to predict many tokens in parallel, leading to worse GPU utilization. Without neuralese, the model can predict all of the sentence “This is an example” at the same time, since it already knows that the input for generating the “is” will be “This”, the input for “an” will be “This is”, etc. However, with the neuralese it’s unknown what the neuralese vector will be to pass through to the next token after “This” has been generated. Therefore each token has to be predicted one at a time. The inability to predict all of the tokens in parallel reduces efficiency in cases where all of the tokens are known in advance. As to why neuralese hasn’t already been added in post-training, we conjecture that the gains are limited with current techniques in part due to post-training being a small portion of the process. We are forecasting that by April 2027 the cost-benefit tradeoff looks much better for neuralese, due to developing better techniques and a larger fraction of the training being post-training.120b:{\"line\":300,\"column\":465,\"offset\":37708}\n120c:{\"line\":300,\"column\":1516,\"offset\":38759}\n120a:{\"start\":\"$120b\",\"end\":\"$120c\"}\n1208:{\"type\":\"text\",\"value\":\"$1209\",\"position\":\"$120a\"}\n11fa:[\"$11fb\",\"$11ff\",\"$1208\"]\n120e:{\"line\":300,\"column\":1,\"offset\":37244}\n120f:{\"line\":300,\"column\":1516,\"offset\":38759}\n120d:{\"start\":\"$120e\",\"end\":\"$120f\"}\n11f9:{\"type\":\"paragraph\",\"children\":\"$11fa\",\"position\":\"$120d\"}\n1214:{\"line\":302,\"column\":1,\"offset\":38761}\n1215:{\"line\":302,\"column\":319,\"offset\":39079}\n1213:{\"start\":\"$1214\",\"end\":\"$1215\"}\n1212:{\"type\":\"text\",\"value\":\"If this doesn’t happen, other things "])</script><script>self.__next_f.push([1,"may still have happened that end up functionally similar for our story. For example, perhaps models will be trained to think in artificial languages that are more efficient than natural language but difficult for humans to interpret. Or perhaps it will become standard practice to \",\"position\":\"$1213\"}\n121a:{\"line\":302,\"column\":320,\"offset\":39080}\n121b:{\"line\":302,\"column\":368,\"offset\":39128}\n1219:{\"start\":\"$121a\",\"end\":\"$121b\"}\n1218:{\"type\":\"text\",\"value\":\"train the English chains of thought to look nice\",\"position\":\"$1219\"}\n1217:[\"$1218\"]\n121d:{\"line\":302,\"column\":319,\"offset\":39079}\n121e:{\"line\":302,\"column\":424,\"offset\":39184}\n121c:{\"start\":\"$121d\",\"end\":\"$121e\"}\n1216:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/chain-of-thought-monitoring/\",\"children\":\"$1217\",\"position\":\"$121c\"}\n1221:{\"line\":302,\"column\":424,\"offset\":39184}\n1222:{\"line\":302,\"column\":534,\"offset\":39294}\n1220:{\"start\":\"$1221\",\"end\":\"$1222\"}\n121f:{\"type\":\"text\",\"value\":\", such that AIs become adept at subtly communicating with each other in messages that look benign to monitors.\",\"position\":\"$1220\"}\n1211:[\"$1212\",\"$1216\",\"$121f\"]\n1224:{\"line\":302,\"column\":1,\"offset\":38761}\n1225:{\"line\":302,\"column\":534,\"offset\":39294}\n1223:{\"start\":\"$1224\",\"end\":\"$1225\"}\n1210:{\"type\":\"paragraph\",\"children\":\"$1211\",\"position\":\"$1223\"}\n122a:{\"line\":304,\"column\":1,\"offset\":39296}\n122b:{\"line\":304,\"column\":271,\"offset\":39566}\n1229:{\"start\":\"$122a\",\"end\":\"$122b\"}\n1228:{\"type\":\"text\",\"value\":\"That said, it’s also possible that the AIs that first automate AI R\u0026D will still be thinking in mostly-faithful English chains of thought. If so, that’ll make misalignments much easier to notice, and overall our story would be importantly different and more optimistic.\",\"position\":\"$1229\"}\n1227:[\"$1228\"]\n122d:{\"line\":304,\"column\":1,\"offset\":39296}\n122e:{\"line\":304,\"column\":271,\"offset\":39566}\n122c:{\"start\":\"$122d\",\"end\":\"$122e\"}\n1226:{\"type\":\"paragraph\",\"children\":\"$1227\",\"position\":\"$122c\"}\n1159:[\"$115a\",\"$1163\",\"$116c\",\"$1175\",\"$11a5\",\"$11bb\",\"$11c4\",\"$11da\","])</script><script>self.__next_f.push([1,"\"$11f0\",\"$11f9\",\"$1210\",\"$1226\"]\n1158:{\"type\":\"details\",\"summary\":\"Neuralese recurrence and memory\",\"children\":\"$1159\"}\n1235:{\"line\":312,\"column\":1,\"offset\":39632}\n1236:{\"line\":312,\"column\":52,\"offset\":39683}\n1234:{\"start\":\"$1235\",\"end\":\"$1236\"}\n1233:{\"type\":\"text\",\"value\":\"Self-improvement for general intelligence had seen \",\"position\":\"$1234\"}\n123b:{\"line\":312,\"column\":53,\"offset\":39684}\n123c:{\"line\":312,\"column\":68,\"offset\":39699}\n123a:{\"start\":\"$123b\",\"end\":\"$123c\"}\n1239:{\"type\":\"text\",\"value\":\"minor successes\",\"position\":\"$123a\"}\n1238:[\"$1239\"]\n123e:{\"line\":312,\"column\":52,\"offset\":39683}\n123f:{\"line\":312,\"column\":103,\"offset\":39734}\n123d:{\"start\":\"$123e\",\"end\":\"$123f\"}\n1237:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/1810.08575\",\"children\":\"$1238\",\"position\":\"$123d\"}\n1242:{\"line\":312,\"column\":103,\"offset\":39734}\n1243:{\"line\":312,\"column\":160,\"offset\":39791}\n1241:{\"start\":\"$1242\",\"end\":\"$1243\"}\n1240:{\"type\":\"text\",\"value\":\" before. But in early 2027, it’s seeing huge returns. In \",\"position\":\"$1241\"}\n1248:{\"line\":312,\"column\":161,\"offset\":39792}\n1249:{\"line\":312,\"column\":164,\"offset\":39795}\n1247:{\"start\":\"$1248\",\"end\":\"$1249\"}\n1246:{\"type\":\"text\",\"value\":\"IDA\",\"position\":\"$1247\"}\n1245:[\"$1246\"]\n124b:{\"line\":312,\"column\":160,\"offset\":39791}\n124c:{\"line\":312,\"column\":244,\"offset\":39875}\n124a:{\"start\":\"$124b\",\"end\":\"$124c\"}\n1244:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616\",\"children\":\"$1245\",\"position\":\"$124a\"}\n124f:{\"line\":312,\"column\":244,\"offset\":39875}\n1250:{\"line\":312,\"column\":289,\"offset\":39920}\n124e:{\"start\":\"$124f\",\"end\":\"$1250\"}\n124d:{\"type\":\"text\",\"value\":\", the two necessary ingredients for this are:\",\"position\":\"$124e\"}\n1232:[\"$1233\",\"$1237\",\"$1240\",\"$1244\",\"$124d\"]\n1252:{\"line\":312,\"column\":1,\"offset\":39632}\n1253:{\"line\":312,\"column\":290,\"offset\":39921}\n1251:{\"start\":\"$1252\",\"end\":\"$1253\"}\n1231:{\"type\":\"paragraph\",\"children\":\"$1232\",\"position\":\"$1251\"}\n125e:{\"line\":314,\"column\":6,\"offset\":39928}\n125f:{\"line\":314,\"co"])</script><script>self.__next_f.push([1,"lumn\":19,\"offset\":39941}\n125d:{\"start\":\"$125e\",\"end\":\"$125f\"}\n125c:{\"type\":\"text\",\"value\":\"Amplification\",\"position\":\"$125d\"}\n125b:[\"$125c\"]\n1261:{\"line\":314,\"column\":4,\"offset\":39926}\n1262:{\"line\":314,\"column\":21,\"offset\":39943}\n1260:{\"start\":\"$1261\",\"end\":\"$1262\"}\n125a:{\"type\":\"strong\",\"children\":\"$125b\",\"position\":\"$1260\"}\n1265:{\"line\":314,\"column\":21,\"offset\":39943}\n1266:{\"line\":314,\"column\":447,\"offset\":40369}\n1264:{\"start\":\"$1265\",\"end\":\"$1266\"}\n1263:{\"type\":\"text\",\"value\":\": Given a model M0, spend more resources to improve performance. For example, by allowing the model to think longer, or running many copies in parallel, or both, and also by having a similarly intense process for evaluating the result and curating only the best answers, you can spend orders of magnitude more compute to get answers (or work products) that are of noticeably higher quality. Call this expensive system Amp(M0).\",\"position\":\"$1264\"}\n1259:[\"$125a\",\"$1263\"]\n1268:{\"line\":314,\"column\":4,\"offset\":39926}\n1269:{\"line\":314,\"column\":449,\"offset\":40371}\n1267:{\"start\":\"$1268\",\"end\":\"$1269\"}\n1258:{\"type\":\"paragraph\",\"children\":\"$1259\",\"position\":\"$1267\"}\n1257:[\"$1258\"]\n126b:{\"line\":314,\"column\":1,\"offset\":39923}\n126c:{\"line\":314,\"column\":449,\"offset\":40371}\n126a:{\"start\":\"$126b\",\"end\":\"$126c\"}\n1256:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1257\",\"position\":\"$126a\"}\n1275:{\"line\":315,\"column\":6,\"offset\":40377}\n1276:{\"line\":315,\"column\":18,\"offset\":40389}\n1274:{\"start\":\"$1275\",\"end\":\"$1276\"}\n1273:{\"type\":\"text\",\"value\":\"Distillation\",\"position\":\"$1274\"}\n1272:[\"$1273\"]\n1278:{\"line\":315,\"column\":4,\"offset\":40375}\n1279:{\"line\":315,\"column\":20,\"offset\":40391}\n1277:{\"start\":\"$1278\",\"end\":\"$1279\"}\n1271:{\"type\":\"strong\",\"children\":\"$1272\",\"position\":\"$1277\"}\n127c:{\"line\":315,\"column\":20,\"offset\":40391}\n127d:{\"line\":315,\"column\":253,\"offset\":40624}\n127b:{\"start\":\"$127c\",\"end\":\"$127d\"}\n127a:{\"type\":\"text\",\"value\":\": Given an amplified model Amp(M0), train a new model M1 to imitate it, i.e. to get to the same results as Amp(M0) but"])</script><script>self.__next_f.push([1," faster and with less compute. The result should hopefully be a smarter model, M1. You can then repeat the process.\",\"position\":\"$127b\"}\n1270:[\"$1271\",\"$127a\"]\n127f:{\"line\":315,\"column\":4,\"offset\":40375}\n1280:{\"line\":315,\"column\":253,\"offset\":40624}\n127e:{\"start\":\"$127f\",\"end\":\"$1280\"}\n126f:{\"type\":\"paragraph\",\"children\":\"$1270\",\"position\":\"$127e\"}\n126e:[\"$126f\"]\n1282:{\"line\":315,\"column\":1,\"offset\":40372}\n1283:{\"line\":315,\"column\":253,\"offset\":40624}\n1281:{\"start\":\"$1282\",\"end\":\"$1283\"}\n126d:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$126e\",\"position\":\"$1281\"}\n1255:[\"$1256\",\"$126d\"]\n1285:{\"line\":314,\"column\":1,\"offset\":39923}\n1286:{\"line\":317,\"column\":3,\"offset\":40628}\n1284:{\"start\":\"$1285\",\"end\":\"$1286\"}\n1254:{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":true,\"children\":\"$1255\",\"position\":\"$1284\"}\n128b:{\"line\":318,\"column\":1,\"offset\":40629}\n128c:{\"line\":318,\"column\":39,\"offset\":40667}\n128a:{\"start\":\"$128b\",\"end\":\"$128c\"}\n1289:{\"type\":\"image\",\"title\":null,\"url\":\"/ida-nowatermark-inexpandable.png\",\"alt\":\"\",\"position\":\"$128a\"}\n128f:{\"line\":318,\"column\":39,\"offset\":40667}\n1290:{\"line\":319,\"column\":1,\"offset\":40670}\n128e:{\"start\":\"$128f\",\"end\":\"$1290\"}\n128d:{\"type\":\"break\",\"position\":\"$128e\"}\n1295:{\"line\":319,\"column\":2,\"offset\":40671}\n1296:{\"line\":319,\"column\":28,\"offset\":40697}\n1294:{\"start\":\"$1295\",\"end\":\"$1296\"}\n1293:{\"type\":\"text\",\"value\":\"Visualization of IDA from \",\"position\":\"$1294\"}\n129b:{\"line\":319,\"column\":29,\"offset\":40698}\n129c:{\"line\":319,\"column\":38,\"offset\":40707}\n129a:{\"start\":\"$129b\",\"end\":\"$129c\"}\n1299:{\"type\":\"text\",\"value\":\"Ord, 2025\",\"position\":\"$129a\"}\n1298:[\"$1299\"]\n129e:{\"line\":319,\"column\":28,\"offset\":40697}\n129f:{\"line\":319,\"column\":113,\"offset\":40782}\n129d:{\"start\":\"$129e\",\"end\":\"$129f\"}\n1297:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.tobyord.com/writing/inference-scaling-reshapes-ai-governance\",\"children\":\"$1298\",\"position\":\"$129d\"}\n12a2:{\"line\":319,\"column\":113,\"offset\":40782}\n12a3:{\"line\":319,\"column\":114,\"offset\":40783}\n12a1:{\"start\":\"$12a2\",\"end\":\"$12a3\"}\n12a"])</script><script>self.__next_f.push([1,"0:{\"type\":\"text\",\"value\":\".\",\"position\":\"$12a1\"}\n1292:[\"$1293\",\"$1297\",\"$12a0\"]\n12a5:{\"line\":319,\"column\":1,\"offset\":40670}\n12a6:{\"line\":319,\"column\":115,\"offset\":40784}\n12a4:{\"start\":\"$12a5\",\"end\":\"$12a6\"}\n1291:{\"type\":\"emphasis\",\"children\":\"$1292\",\"position\":\"$12a4\"}\n1288:[\"$1289\",\"$128d\",\"$1291\"]\n12a8:{\"line\":318,\"column\":1,\"offset\":40629}\n12a9:{\"line\":319,\"column\":115,\"offset\":40784}\n12a7:{\"start\":\"$12a8\",\"end\":\"$12a9\"}\n1287:{\"type\":\"paragraph\",\"children\":\"$1288\",\"position\":\"$12a7\"}\n12b0:{\"line\":321,\"column\":2,\"offset\":40787}\n12b1:{\"line\":321,\"column\":9,\"offset\":40794}\n12af:{\"start\":\"$12b0\",\"end\":\"$12b1\"}\n12ae:{\"type\":\"text\",\"value\":\"AlphaGo\",\"position\":\"$12af\"}\n12ad:[\"$12ae\"]\n12b3:{\"line\":321,\"column\":1,\"offset\":40786}\n12b4:{\"line\":321,\"column\":49,\"offset\":40834}\n12b2:{\"start\":\"$12b3\",\"end\":\"$12b4\"}\n12ac:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/AlphaGo\",\"children\":\"$12ad\",\"position\":\"$12b2\"}\n12b7:{\"line\":321,\"column\":49,\"offset\":40834}\n12b8:{\"line\":321,\"column\":126,\"offset\":40911}\n12b6:{\"start\":\"$12b7\",\"end\":\"$12b8\"}\n12b5:{\"type\":\"text\",\"value\":\" was trained in this way: using Monte-Carlo Tree Search and self-play as the \",\"position\":\"$12b6\"}\n12bd:{\"line\":321,\"column\":127,\"offset\":40912}\n12be:{\"line\":321,\"column\":140,\"offset\":40925}\n12bc:{\"start\":\"$12bd\",\"end\":\"$12be\"}\n12bb:{\"type\":\"text\",\"value\":\"amplification\",\"position\":\"$12bc\"}\n12ba:[\"$12bb\"]\n12c0:{\"line\":321,\"column\":126,\"offset\":40911}\n12c1:{\"line\":321,\"column\":141,\"offset\":40926}\n12bf:{\"start\":\"$12c0\",\"end\":\"$12c1\"}\n12b9:{\"type\":\"emphasis\",\"children\":\"$12ba\",\"position\":\"$12bf\"}\n12c4:{\"line\":321,\"column\":141,\"offset\":40926}\n12c5:{\"line\":321,\"column\":182,\"offset\":40967}\n12c3:{\"start\":\"$12c4\",\"end\":\"$12c5\"}\n12c2:{\"type\":\"text\",\"value\":\" step, and Reinforcement Learning as the \",\"position\":\"$12c3\"}\n12ca:{\"line\":321,\"column\":183,\"offset\":40968}\n12cb:{\"line\":321,\"column\":195,\"offset\":40980}\n12c9:{\"start\":\"$12ca\",\"end\":\"$12cb\"}\n12c8:{\"type\":\"text\",\"value\":\"distillation\",\"position\":\"$12c9\"}\n12c7:[\"$12c8\"]\n12cd:{\"line\":321,\"column\":182,"])</script><script>self.__next_f.push([1,"\"offset\":40967}\n12ce:{\"line\":321,\"column\":196,\"offset\":40981}\n12cc:{\"start\":\"$12cd\",\"end\":\"$12ce\"}\n12c6:{\"type\":\"emphasis\",\"children\":\"$12c7\",\"position\":\"$12cc\"}\n12d1:{\"line\":321,\"column\":196,\"offset\":40981}\n12d2:{\"line\":321,\"column\":327,\"offset\":41112}\n12d0:{\"start\":\"$12d1\",\"end\":\"$12d2\"}\n12cf:{\"type\":\"text\",\"value\":\" step. This led to superhuman performance in Go. But now, Agent-3 is able to leverage this to get superhuman performance at coding.\",\"position\":\"$12d0\"}\n12ab:[\"$12ac\",\"$12b5\",\"$12b9\",\"$12c2\",\"$12c6\",\"$12cf\"]\n12d4:{\"line\":321,\"column\":1,\"offset\":40786}\n12d5:{\"line\":321,\"column\":328,\"offset\":41113}\n12d3:{\"start\":\"$12d4\",\"end\":\"$12d5\"}\n12aa:{\"type\":\"paragraph\",\"children\":\"$12ab\",\"position\":\"$12d3\"}\n12de:{\"line\":323,\"column\":4,\"offset\":41118}\n12df:{\"line\":323,\"column\":387,\"offset\":41501}\n12dd:{\"start\":\"$12de\",\"end\":\"$12df\"}\n12dc:{\"type\":\"text\",\"value\":\"The amplification step works through a combination of Agent-3 thinking for longer, adding tool use, or consulting with other AIs. When it does this, it often realizes that it made a mistake, or comes up with a new insight. This produces a large amount of training data: labeled trajectories of research attempts with whether they succeeded or not. This also includes techniques like \",\"position\":\"$12dd\"}\n12e4:{\"line\":323,\"column\":388,\"offset\":41502}\n12e5:{\"line\":323,\"column\":397,\"offset\":41511}\n12e3:{\"start\":\"$12e4\",\"end\":\"$12e5\"}\n12e2:{\"type\":\"text\",\"value\":\"Best of N\",\"position\":\"$12e3\"}\n12e1:[\"$12e2\"]\n12e7:{\"line\":323,\"column\":387,\"offset\":41501}\n12e8:{\"line\":323,\"column\":432,\"offset\":41546}\n12e6:{\"start\":\"$12e7\",\"end\":\"$12e8\"}\n12e0:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2401.01879\",\"children\":\"$12e1\",\"position\":\"$12e6\"}\n12eb:{\"line\":323,\"column\":432,\"offset\":41546}\n12ec:{\"line\":323,\"column\":493,\"offset\":41607}\n12ea:{\"start\":\"$12eb\",\"end\":\"$12ec\"}\n12e9:{\"type\":\"text\",\"value\":\" on verifiable tasks, and then keeping the best trajectories.\",\"position\":\"$12ea\"}\n12db:[\"$12dc\",\"$12e0\",\"$12e9\"]\n12ee:{\"line\":323,\"column\":4,\"offset\":41118}\n12ef:{"])</script><script>self.__next_f.push([1,"\"line\":323,\"column\":496,\"offset\":41610}\n12ed:{\"start\":\"$12ee\",\"end\":\"$12ef\"}\n12da:{\"type\":\"paragraph\",\"children\":\"$12db\",\"position\":\"$12ed\"}\n12d9:[\"$12da\"]\n12f1:{\"line\":323,\"column\":1,\"offset\":41115}\n12f2:{\"line\":323,\"column\":496,\"offset\":41610}\n12f0:{\"start\":\"$12f1\",\"end\":\"$12f2\"}\n12d8:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$12d9\",\"position\":\"$12f0\"}\n12f9:{\"line\":324,\"column\":4,\"offset\":41614}\n12fa:{\"line\":324,\"column\":214,\"offset\":41824}\n12f8:{\"start\":\"$12f9\",\"end\":\"$12fa\"}\n12f7:{\"type\":\"text\",\"value\":\"The distillation step uses policy-gradient reinforcement learning algorithms to get the model to internalize the amplified reasoning. At this point, OpenBrain has discovered better RL algorithms in the vein of \",\"position\":\"$12f8\"}\n12ff:{\"line\":324,\"column\":215,\"offset\":41825}\n1300:{\"line\":324,\"column\":243,\"offset\":41853}\n12fe:{\"start\":\"$12ff\",\"end\":\"$1300\"}\n12fd:{\"type\":\"text\",\"value\":\"proximal policy optimization\",\"position\":\"$12fe\"}\n12fc:[\"$12fd\"]\n1302:{\"line\":324,\"column\":214,\"offset\":41824}\n1303:{\"line\":324,\"column\":278,\"offset\":41888}\n1301:{\"start\":\"$1302\",\"end\":\"$1303\"}\n12fb:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/1707.06347\",\"children\":\"$12fc\",\"position\":\"$1301\"}\n1306:{\"line\":324,\"column\":278,\"offset\":41888}\n1307:{\"line\":324,\"column\":444,\"offset\":42054}\n1305:{\"start\":\"$1306\",\"end\":\"$1307\"}\n1304:{\"type\":\"text\",\"value\":\" (PPO). They keep distilling what Agent-3 can conclude after a lot of thinking into single steps, which keeps improving what it can think in a single step, and so on.\",\"position\":\"$1305\"}\n12f6:[\"$12f7\",\"$12fb\",\"$1304\"]\n1309:{\"line\":324,\"column\":4,\"offset\":41614}\n130a:{\"line\":324,\"column\":445,\"offset\":42055}\n1308:{\"start\":\"$1309\",\"end\":\"$130a\"}\n12f5:{\"type\":\"paragraph\",\"children\":\"$12f6\",\"position\":\"$1308\"}\n12f4:[\"$12f5\"]\n130c:{\"line\":324,\"column\":1,\"offset\":41611}\n130d:{\"line\":324,\"column\":445,\"offset\":42055}\n130b:{\"start\":\"$130c\",\"end\":\"$130d\"}\n12f3:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$12f4\",\"position\":\"$130b\"}\n12d7:[\"$12d8\",\"$"])</script><script>self.__next_f.push([1,"12f3\"]\n130f:{\"line\":323,\"column\":1,\"offset\":41115}\n1310:{\"line\":324,\"column\":445,\"offset\":42055}\n130e:{\"start\":\"$130f\",\"end\":\"$1310\"}\n12d6:{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":\"$12d7\",\"position\":\"$130e\"}\n1317:{\"line\":326,\"column\":2,\"offset\":42058}\n1318:{\"line\":326,\"column\":7,\"offset\":42063}\n1316:{\"start\":\"$1317\",\"end\":\"$1318\"}\n1315:{\"type\":\"text\",\"value\":\"Early\",\"position\":\"$1316\"}\n1314:[\"$1315\"]\n131a:{\"line\":326,\"column\":1,\"offset\":42057}\n131b:{\"line\":326,\"column\":42,\"offset\":42098}\n1319:{\"start\":\"$131a\",\"end\":\"$131b\"}\n1313:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2210.11610\",\"children\":\"$1314\",\"position\":\"$1319\"}\n131e:{\"line\":326,\"column\":42,\"offset\":42098}\n131f:{\"line\":326,\"column\":43,\"offset\":42099}\n131d:{\"start\":\"$131e\",\"end\":\"$131f\"}\n131c:{\"type\":\"text\",\"value\":\" \",\"position\":\"$131d\"}\n1324:{\"line\":326,\"column\":44,\"offset\":42100}\n1325:{\"line\":326,\"column\":52,\"offset\":42108}\n1323:{\"start\":\"$1324\",\"end\":\"$1325\"}\n1322:{\"type\":\"text\",\"value\":\"versions\",\"position\":\"$1323\"}\n1321:[\"$1322\"]\n1327:{\"line\":326,\"column\":43,\"offset\":42099}\n1328:{\"line\":326,\"column\":97,\"offset\":42153}\n1326:{\"start\":\"$1327\",\"end\":\"$1328\"}\n1320:{\"type\":\"link\",\"title\":null,\"url\":\"https://github.com/deepseek-ai/DeepSeek-R1\",\"children\":\"$1321\",\"position\":\"$1326\"}\n132b:{\"line\":326,\"column\":97,\"offset\":42153}\n132c:{\"line\":326,\"column\":329,\"offset\":42385}\n132a:{\"start\":\"$132b\",\"end\":\"$132c\"}\n1329:{\"type\":\"text\",\"value\":\" of IDA have been working for many years on easily verifiable tasks, like math and coding problems that have a clear answer, because the techniques used to amplify models often rely on access to some ground truth signal of accuracy.\",\"position\":\"$132a\"}\n1312:[\"$1313\",\"$131c\",\"$1320\",\"$1329\"]\n132e:{\"line\":326,\"column\":1,\"offset\":42057}\n132f:{\"line\":326,\"column\":330,\"offset\":42386}\n132d:{\"start\":\"$132e\",\"end\":\"$132f\"}\n1311:{\"type\":\"paragraph\",\"children\":\"$1312\",\"position\":\"$132d\"}\n1334:{\"line\":328,\"column\":1,\"offset\":42388}\n1335:{\"line\":328,\"column\":180,\"offset\":42567}\n1333:{\"start\":\"$133"])</script><script>self.__next_f.push([1,"4\",\"end\":\"$1335\"}\n1332:{\"type\":\"text\",\"value\":\"Now, the models have become sufficiently good at verifying more subjective things (e.g. the quality of a work product), allowing the use of IDA to improve the model at many tasks.\",\"position\":\"$1333\"}\n1331:[\"$1332\"]\n1337:{\"line\":328,\"column\":1,\"offset\":42388}\n1338:{\"line\":328,\"column\":181,\"offset\":42568}\n1336:{\"start\":\"$1337\",\"end\":\"$1338\"}\n1330:{\"type\":\"paragraph\",\"children\":\"$1331\",\"position\":\"$1336\"}\n1230:[\"$1231\",\"$1254\",\"$1287\",\"$12aa\",\"$12d6\",\"$1311\",\"$1330\"]\n122f:{\"type\":\"details\",\"summary\":\"Iterated distillation and amplification (IDA)\",\"children\":\"$1230\"}\n133d:{\"line\":332,\"column\":1,\"offset\":42575}\n133e:{\"line\":332,\"column\":231,\"offset\":42805}\n133c:{\"start\":\"$133d\",\"end\":\"$133e\"}\n133b:{\"type\":\"text\",\"value\":\"Aided by the new capabilities breakthroughs, Agent-3 is a fast and cheap superhuman coder. OpenBrain runs 200,000 Agent-3 copies in parallel, creating a workforce equivalent to 50,000 copies of the best human coder sped up by 30x.\",\"position\":\"$133c\"}\n1341:{\"line\":332,\"column\":231,\"offset\":42805}\n1342:{\"line\":332,\"column\":236,\"offset\":42810}\n1340:{\"start\":\"$1341\",\"end\":\"$1342\"}\n133f:{\"type\":\"footnoteReference\",\"identifier\":\"53\",\"label\":\"53\",\"position\":\"$1340\"}\n1345:{\"line\":332,\"column\":236,\"offset\":42810}\n1346:{\"line\":332,\"column\":488,\"offset\":43062}\n1344:{\"start\":\"$1345\",\"end\":\"$1346\"}\n1343:{\"type\":\"text\",\"value\":\" OpenBrain still keeps its human engineers on staff, because they have complementary skills needed to manage the teams of Agent-3 copies. For example, research taste has proven difficult to train due to longer feedback loops and less data availability.\",\"position\":\"$1344\"}\n1349:{\"line\":332,\"column\":488,\"offset\":43062}\n134a:{\"line\":332,\"column\":493,\"offset\":43067}\n1348:{\"start\":\"$1349\",\"end\":\"$134a\"}\n1347:{\"type\":\"footnoteReference\",\"identifier\":\"54\",\"label\":\"54\",\"position\":\"$1348\"}\n134d:{\"line\":332,\"column\":493,\"offset\":43067}\n134e:{\"line\":332,\"column\":661,\"offset\":43235}\n134c:{\"start\":\"$134d\",\"end\":\"$134e\"}\n134b:{\"type\":\"text\",\"value\":\" This "])</script><script>self.__next_f.push([1,"massive superhuman labor force speeds up OpenBrain’s overall rate of algorithmic progress by “only” 4x due to bottlenecks and diminishing returns to coding labor.\",\"position\":\"$134c\"}\n1351:{\"line\":332,\"column\":661,\"offset\":43235}\n1352:{\"line\":332,\"column\":666,\"offset\":43240}\n1350:{\"start\":\"$1351\",\"end\":\"$1352\"}\n134f:{\"type\":\"footnoteReference\",\"identifier\":\"55\",\"label\":\"55\",\"position\":\"$1350\"}\n133a:[\"$133b\",\"$133f\",\"$1343\",\"$1347\",\"$134b\",\"$134f\"]\n1354:{\"line\":332,\"column\":1,\"offset\":42575}\n1355:{\"line\":332,\"column\":666,\"offset\":43240}\n1353:{\"start\":\"$1354\",\"end\":\"$1355\"}\n1339:{\"type\":\"paragraph\",\"children\":\"$133a\",\"position\":\"$1353\"}\n135a:{\"line\":334,\"column\":1,\"offset\":43242}\n135b:{\"line\":334,\"column\":615,\"offset\":43856}\n1359:{\"start\":\"$135a\",\"end\":\"$135b\"}\n1358:{\"type\":\"text\",\"value\":\"Now that coding has been fully automated, OpenBrain can quickly churn out high-quality training environments to teach Agent-3’s weak skills like research taste and large-scale coordination. Whereas previous training environments included “Here are some GPUs and instructions for experiments to code up and run, your performance will be evaluated as if you were a ML engineer,” now they are training on “Here are a few hundred GPUs, an internet connection, and some research challenges; you and a thousand other copies must work together to make research progress. The more impressive it is, the higher your score.”\",\"position\":\"$1359\"}\n1357:[\"$1358\"]\n135d:{\"line\":334,\"column\":1,\"offset\":43242}\n135e:{\"line\":334,\"column\":615,\"offset\":43856}\n135c:{\"start\":\"$135d\",\"end\":\"$135e\"}\n1356:{\"type\":\"paragraph\",\"children\":\"$1357\",\"position\":\"$135c\"}\n1365:{\"line\":340,\"column\":1,\"offset\":43920}\n1366:{\"line\":340,\"column\":8,\"offset\":43927}\n1364:{\"start\":\"$1365\",\"end\":\"$1366\"}\n1363:{\"type\":\"text\",\"value\":\"In our \",\"position\":\"$1364\"}\n136b:{\"line\":340,\"column\":9,\"offset\":43928}\n136c:{\"line\":340,\"column\":27,\"offset\":43946}\n136a:{\"start\":\"$136b\",\"end\":\"$136c\"}\n1369:{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":\"$136a\"}\n1368:[\"$1369\""])</script><script>self.__next_f.push([1,"]\n136e:{\"line\":340,\"column\":8,\"offset\":43927}\n136f:{\"line\":340,\"column\":77,\"offset\":43996}\n136d:{\"start\":\"$136e\",\"end\":\"$136f\"}\n1367:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":\"$1368\",\"position\":\"$136d\"}\n1372:{\"line\":340,\"column\":77,\"offset\":43996}\n1373:{\"line\":340,\"column\":131,\"offset\":44050}\n1371:{\"start\":\"$1372\",\"end\":\"$1373\"}\n1370:{\"type\":\"text\",\"value\":\", we predict when OpenBrain will internally develop a \",\"position\":\"$1371\"}\n1378:{\"line\":340,\"column\":132,\"offset\":44051}\n1379:{\"line\":340,\"column\":153,\"offset\":44072}\n1377:{\"start\":\"$1378\",\"end\":\"$1379\"}\n1376:{\"type\":\"text\",\"value\":\"superhuman coder (SC)\",\"position\":\"$1377\"}\n1375:[\"$1376\"]\n137b:{\"line\":340,\"column\":131,\"offset\":44050}\n137c:{\"line\":340,\"column\":154,\"offset\":44073}\n137a:{\"start\":\"$137b\",\"end\":\"$137c\"}\n1374:{\"type\":\"emphasis\",\"children\":\"$1375\",\"position\":\"$137a\"}\n137f:{\"line\":340,\"column\":154,\"offset\":44073}\n1380:{\"line\":340,\"column\":275,\"offset\":44194}\n137e:{\"start\":\"$137f\",\"end\":\"$1380\"}\n137d:{\"type\":\"text\",\"value\":\": an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper.\",\"position\":\"$137e\"}\n1362:[\"$1363\",\"$1367\",\"$1370\",\"$1374\",\"$137d\"]\n1382:{\"line\":340,\"column\":1,\"offset\":43920}\n1383:{\"line\":340,\"column\":275,\"offset\":44194}\n1381:{\"start\":\"$1382\",\"end\":\"$1383\"}\n1361:{\"type\":\"paragraph\",\"children\":\"$1362\",\"position\":\"$1381\"}\n1388:{\"line\":342,\"column\":1,\"offset\":44196}\n1389:{\"line\":342,\"column\":23,\"offset\":44218}\n1387:{\"start\":\"$1388\",\"end\":\"$1389\"}\n1386:{\"type\":\"text\",\"value\":\"According to a recent \",\"position\":\"$1387\"}\n138e:{\"line\":342,\"column\":24,\"offset\":44219}\n138f:{\"line\":342,\"column\":37,\"offset\":44232}\n138d:{\"start\":\"$138e\",\"end\":\"$138f\"}\n138c:{\"type\":\"text\",\"value\":\"METR’s report\",\"position\":\"$138d\"}\n138b:[\"$138c\"]\n1391:{\"line\":342,\"column\":23,\"offset\":44218}\n1392:{\"line\":342,\"column\":72,\"offset\":44267}\n1390:{\"start\":\"$1391\",\"end\":\"$1392\"}\n138a:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2503.14499\",\"chi"])</script><script>self.__next_f.push([1,"ldren\":\"$138b\",\"position\":\"$1390\"}\n1395:{\"line\":342,\"column\":72,\"offset\":44267}\n1396:{\"line\":342,\"column\":374,\"offset\":44569}\n1394:{\"start\":\"$1395\",\"end\":\"$1396\"}\n1393:{\"type\":\"text\",\"value\":\", the length of coding tasks AIs can handle, their “time horizon”, doubled every 7 months from 2019 - 2024 and every 4 months from 2024-onward. If the trend continues to speed up, by March 2027 AIs could succeed with 80% reliability on software tasks that would take a skilled human years to complete.\",\"position\":\"$1394\"}\n1385:[\"$1386\",\"$138a\",\"$1393\"]\n1398:{\"line\":342,\"column\":1,\"offset\":44196}\n1399:{\"line\":342,\"column\":374,\"offset\":44569}\n1397:{\"start\":\"$1398\",\"end\":\"$1399\"}\n1384:{\"type\":\"paragraph\",\"children\":\"$1385\",\"position\":\"$1397\"}\n139e:{\"line\":344,\"column\":1,\"offset\":44571}\n139f:{\"line\":344,\"column\":541,\"offset\":45111}\n139d:{\"start\":\"$139e\",\"end\":\"$139f\"}\n139c:{\"type\":\"text\",\"value\":\"Such is roughly the capability progression in AI 2027. Here is a capability trajectory generated by a simplified version of our timelines model (added Dec 2025: we've updated the below graph due to a mistake in how the original curve was generated, to add an actual trajectory from our timelines model. We've also added trajectories for Daniel and Eli's all-things-considered SC medians at the time of publishing (Apr 2025). And we've added some new METR data points to the graph, but haven't updated the model trajectories based on them.):\",\"position\":\"$139d\"}\n139b:[\"$139c\"]\n13a1:{\"line\":344,\"column\":1,\"offset\":44571}\n13a2:{\"line\":344,\"column\":541,\"offset\":45111}\n13a0:{\"start\":\"$13a1\",\"end\":\"$13a2\"}\n139a:{\"type\":\"paragraph\",\"children\":\"$139b\",\"position\":\"$13a0\"}\n13a7:{\"line\":346,\"column\":1,\"offset\":45115}\n13a8:{\"line\":346,\"column\":53,\"offset\":45167}\n13a6:{\"start\":\"$13a7\",\"end\":\"$13a8\"}\n13a5:{\"type\":\"image\",\"title\":null,\"url\":\"/new-metr-extended-nowatermark-inexpandable.png\",\"alt\":\"\",\"position\":\"$13a6\"}\n13a4:[\"$13a5\"]\n13aa:{\"line\":346,\"column\":1,\"offset\":45115}\n13ab:{\"line\":346,\"column\":53,\"offset\":45167}\n13a9:{\"start\":\"$13aa\",\"end\":\"$13ab"])</script><script>self.__next_f.push([1,"\"}\n13a3:{\"type\":\"paragraph\",\"children\":\"$13a4\",\"position\":\"$13a9\"}\n13b0:{\"line\":348,\"column\":1,\"offset\":45169}\n13b1:{\"line\":348,\"column\":147,\"offset\":45315}\n13af:{\"start\":\"$13b0\",\"end\":\"$13b1\"}\n13ae:{\"type\":\"text\",\"value\":\"In AI 2027, these capabilities are sufficient for the AI to be an SC, though we have high uncertainty regarding what time horizon might be needed.\",\"position\":\"$13af\"}\n13ad:[\"$13ae\"]\n13b3:{\"line\":348,\"column\":1,\"offset\":45169}\n13b4:{\"line\":348,\"column\":147,\"offset\":45315}\n13b2:{\"start\":\"$13b3\",\"end\":\"$13b4\"}\n13ac:{\"type\":\"paragraph\",\"children\":\"$13ad\",\"position\":\"$13b2\"}\n13b9:{\"line\":350,\"column\":1,\"offset\":45317}\n13ba:{\"line\":350,\"column\":8,\"offset\":45324}\n13b8:{\"start\":\"$13b9\",\"end\":\"$13ba\"}\n13b7:{\"type\":\"text\",\"value\":\"In our \",\"position\":\"$13b8\"}\n13bf:{\"line\":350,\"column\":9,\"offset\":45325}\n13c0:{\"line\":350,\"column\":27,\"offset\":45343}\n13be:{\"start\":\"$13bf\",\"end\":\"$13c0\"}\n13bd:{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":\"$13be\"}\n13bc:[\"$13bd\"]\n13c2:{\"line\":350,\"column\":8,\"offset\":45324}\n13c3:{\"line\":350,\"column\":77,\"offset\":45393}\n13c1:{\"start\":\"$13c2\",\"end\":\"$13c3\"}\n13bb:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":\"$13bc\",\"position\":\"$13c1\"}\n13c6:{\"line\":350,\"column\":77,\"offset\":45393}\n13c7:{\"line\":350,\"column\":377,\"offset\":45693}\n13c5:{\"start\":\"$13c6\",\"end\":\"$13c7\"}\n13c4:{\"type\":\"text\",\"value\":\" we combine this time horizon trend with estimations of the gaps between METR’s tasks and the real world to get a distribution for when superhuman coders will arrive. All forecasters place 2027 as one of the most likely years in which an SC might be developed (added Dec 2025: though as noted in the \",\"position\":\"$13c5\"}\n13cc:{\"line\":350,\"column\":378,\"offset\":45694}\n13cd:{\"line\":350,\"column\":396,\"offset\":45712}\n13cb:{\"start\":\"$13cc\",\"end\":\"$13cd\"}\n13ca:{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":\"$13cb\"}\n13c9:[\"$13ca\"]\n13cf:{\"line\":350,\"column\":377,\"offset\":45693}\n13d0:{\"line\":350,\"column\":446,\"offset\":45762}\n13ce:{\"start\":\"$13"])</script><script>self.__next_f.push([1,"cf\",\"end\":\"$13d0\"}\n13c8:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":\"$13c9\",\"position\":\"$13ce\"}\n13d3:{\"line\":350,\"column\":446,\"offset\":45762}\n13d4:{\"line\":350,\"column\":541,\"offset\":45857}\n13d2:{\"start\":\"$13d3\",\"end\":\"$13d4\"}\n13d1:{\"type\":\"text\",\"value\":\", adjusting for outside of model factors gave us slightly longer medians, e.g. Eli's was 2030).\",\"position\":\"$13d2\"}\n13b6:[\"$13b7\",\"$13bb\",\"$13c4\",\"$13c8\",\"$13d1\"]\n13d6:{\"line\":350,\"column\":1,\"offset\":45317}\n13d7:{\"line\":350,\"column\":541,\"offset\":45857}\n13d5:{\"start\":\"$13d6\",\"end\":\"$13d7\"}\n13b5:{\"type\":\"paragraph\",\"children\":\"$13b6\",\"position\":\"$13d5\"}\n13dc:{\"line\":352,\"column\":1,\"offset\":45861}\n13dd:{\"line\":352,\"column\":41,\"offset\":45901}\n13db:{\"start\":\"$13dc\",\"end\":\"$13dd\"}\n13da:{\"type\":\"image\",\"title\":null,\"url\":\"/combined-headline-inexpandable.png\",\"alt\":\"\",\"position\":\"$13db\"}\n13d9:[\"$13da\"]\n13df:{\"line\":352,\"column\":1,\"offset\":45861}\n13e0:{\"line\":352,\"column\":41,\"offset\":45901}\n13de:{\"start\":\"$13df\",\"end\":\"$13e0\"}\n13d8:{\"type\":\"paragraph\",\"children\":\"$13d9\",\"position\":\"$13de\"}\n13e7:{\"line\":354,\"column\":2,\"offset\":45904}\n13e8:{\"line\":354,\"column\":34,\"offset\":45936}\n13e6:{\"start\":\"$13e7\",\"end\":\"$13e8\"}\n13e5:{\"type\":\"text\",\"value\":\"Added Jul 2025: We've made some \",\"position\":\"$13e6\"}\n13ed:{\"line\":354,\"column\":35,\"offset\":45937}\n13ee:{\"line\":354,\"column\":42,\"offset\":45944}\n13ec:{\"start\":\"$13ed\",\"end\":\"$13ee\"}\n13eb:{\"type\":\"text\",\"value\":\"updates\",\"position\":\"$13ec\"}\n13ea:[\"$13eb\"]\n13f0:{\"line\":354,\"column\":34,\"offset\":45936}\n13f1:{\"line\":354,\"column\":110,\"offset\":46012}\n13ef:{\"start\":\"$13f0\",\"end\":\"$13f1\"}\n13e9:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast#2025-may-7-update\",\"children\":\"$13ea\",\"position\":\"$13ef\"}\n13f4:{\"line\":354,\"column\":110,\"offset\":46012}\n13f5:{\"line\":354,\"column\":252,\"offset\":46154}\n13f3:{\"start\":\"$13f4\",\"end\":\"$13f5\"}\n13f2:{\"type\":\"text\",\"value\":\" to the forecast which push the median back 1.5 years while maintaining SC in 2027 as a serious possibility. "])</script><script>self.__next_f.push([1,"We're working on further updates.\",\"position\":\"$13f3\"}\n13e4:[\"$13e5\",\"$13e9\",\"$13f2\"]\n13f7:{\"line\":354,\"column\":1,\"offset\":45903}\n13f8:{\"line\":354,\"column\":253,\"offset\":46155}\n13f6:{\"start\":\"$13f7\",\"end\":\"$13f8\"}\n13e3:{\"type\":\"emphasis\",\"children\":\"$13e4\",\"position\":\"$13f6\"}\n13e2:[\"$13e3\"]\n13fa:{\"line\":354,\"column\":1,\"offset\":45903}\n13fb:{\"line\":354,\"column\":253,\"offset\":46155}\n13f9:{\"start\":\"$13fa\",\"end\":\"$13fb\"}\n13e1:{\"type\":\"paragraph\",\"children\":\"$13e2\",\"position\":\"$13f9\"}\n1360:[\"$1361\",\"$1384\",\"$139a\",\"$13a3\",\"$13ac\",\"$13b5\",\"$13d8\",\"$13e1\"]\n135f:{\"type\":\"details\",\"summary\":\"Why we forecast a superhuman coder in early 2027\",\"children\":\"$1360\"}\n1400:{\"line\":358,\"column\":4,\"offset\":46165}\n1401:{\"line\":358,\"column\":37,\"offset\":46198}\n13ff:{\"start\":\"$1400\",\"end\":\"$1401\"}\n13fe:{\"type\":\"text\",\"value\":\"April 2027: Alignment for Agent-3\",\"position\":\"$13ff\"}\n13fd:[\"$13fe\"]\n1403:{\"line\":358,\"column\":1,\"offset\":46162}\n1404:{\"line\":358,\"column\":37,\"offset\":46198}\n1402:{\"start\":\"$1403\",\"end\":\"$1404\"}\n13fc:{\"type\":\"heading\",\"depth\":2,\"children\":\"$13fd\",\"position\":\"$1402\"}\n1406:{}\n140c:{\"line\":361,\"column\":1,\"offset\":46216}\n140d:{\"line\":361,\"column\":11,\"offset\":46226}\n140b:{\"start\":\"$140c\",\"end\":\"$140d\"}\n140a:{\"type\":\"text\",\"value\":\"2027-04-30\",\"position\":\"$140b\"}\n1410:{\"line\":361,\"column\":11,\"offset\":46226}\n1411:{\"line\":362,\"column\":1,\"offset\":46229}\n140f:{\"start\":\"$1410\",\"end\":\"$1411\"}\n140e:{\"type\":\"break\",\"position\":\"$140f\"}\n1414:{\"line\":362,\"column\":1,\"offset\":46229}\n1415:{\"line\":362,\"column\":6,\"offset\":46234}\n1413:{\"start\":\"$1414\",\"end\":\"$1415\"}\n1412:{\"type\":\"text\",\"value\":\"April\",\"position\":\"$1413\"}\n1409:[\"$140a\",\"$140e\",\"$1412\"]\n1417:{\"line\":361,\"column\":1,\"offset\":46216}\n1418:{\"line\":362,\"column\":8,\"offset\":46236}\n1416:{\"start\":\"$1417\",\"end\":\"$1418\"}\n1408:{\"type\":\"paragraph\",\"children\":\"$1409\",\"position\":\"$1416\"}\n1407:[\"$1408\"]\n141a:{\"line\":360,\"column\":1,\"offset\":46200}\n141b:{\"line\":363,\"column\":4,\"offset\":46240}\n1419:{\"start\":\"$141a\",\"end\":\"$141b\"}\n1405:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes"])</script><script>self.__next_f.push([1,"\":\"$1406\",\"children\":\"$1407\",\"position\":\"$1419\"}\n1420:{\"line\":365,\"column\":1,\"offset\":46242}\n1421:{\"line\":365,\"column\":51,\"offset\":46292}\n141f:{\"start\":\"$1420\",\"end\":\"$1421\"}\n141e:{\"type\":\"text\",\"value\":\"OpenBrain’s safety team attempts to align Agent-3.\",\"position\":\"$141f\"}\n141d:[\"$141e\"]\n1423:{\"line\":365,\"column\":1,\"offset\":46242}\n1424:{\"line\":365,\"column\":51,\"offset\":46292}\n1422:{\"start\":\"$1423\",\"end\":\"$1424\"}\n141c:{\"type\":\"paragraph\",\"children\":\"$141d\",\"position\":\"$1422\"}\n1429:{\"line\":367,\"column\":1,\"offset\":46294}\n142a:{\"line\":367,\"column\":209,\"offset\":46502}\n1428:{\"start\":\"$1429\",\"end\":\"$142a\"}\n1427:{\"type\":\"text\",\"value\":\"Since Agent-3 will be kept in-house for the foreseeable future, there’s less emphasis on the usual defenses against human misuse. Instead, the team wants to make sure that it doesn’t develop misaligned goals.\",\"position\":\"$1428\"}\n1426:[\"$1427\"]\n142c:{\"line\":367,\"column\":1,\"offset\":46294}\n142d:{\"line\":367,\"column\":210,\"offset\":46503}\n142b:{\"start\":\"$142c\",\"end\":\"$142d\"}\n1425:{\"type\":\"paragraph\",\"children\":\"$1426\",\"position\":\"$142b\"}\n1434:{\"line\":369,\"column\":2,\"offset\":46506}\n1435:{\"line\":369,\"column\":87,\"offset\":46591}\n1433:{\"start\":\"$1434\",\"end\":\"$1435\"}\n1432:{\"type\":\"text\",\"value\":\"The researchers don’t have the ability to directly set the goals of any of their AIs.\",\"position\":\"$1433\"}\n1431:[\"$1432\"]\n1437:{\"line\":369,\"column\":1,\"offset\":46505}\n1438:{\"line\":369,\"column\":139,\"offset\":46643}\n1436:{\"start\":\"$1437\",\"end\":\"$1438\"}\n1430:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/ai-goals-forecast\",\"children\":\"$1431\",\"position\":\"$1436\"}\n143b:{\"line\":369,\"column\":139,\"offset\":46643}\n143c:{\"line\":369,\"column\":496,\"offset\":47000}\n143a:{\"start\":\"$143b\",\"end\":\"$143c\"}\n1439:{\"type\":\"text\",\"value\":\" Indeed, the researchers think that the concept of ‘true goals’ is probably a massive oversimplification, but they don’t have a better theory to replace it with, much less one that has been thoroughly vetted. They disagree internally about whether the AIs are trying to"])</script><script>self.__next_f.push([1," follow human instructions, or seeking reinforcement, or something else, and they can’t \",\"position\":\"$143a\"}\n1441:{\"line\":369,\"column\":497,\"offset\":47001}\n1442:{\"line\":369,\"column\":507,\"offset\":47011}\n1440:{\"start\":\"$1441\",\"end\":\"$1442\"}\n143f:{\"type\":\"text\",\"value\":\"just check\",\"position\":\"$1440\"}\n143e:[\"$143f\"]\n1444:{\"line\":369,\"column\":496,\"offset\":47000}\n1445:{\"line\":369,\"column\":616,\"offset\":47120}\n1443:{\"start\":\"$1444\",\"end\":\"$1445\"}\n143d:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=YYhq2PADebnt35MY2\",\"children\":\"$143e\",\"position\":\"$1443\"}\n1448:{\"line\":369,\"column\":616,\"offset\":47120}\n1449:{\"line\":369,\"column\":698,\"offset\":47202}\n1447:{\"start\":\"$1448\",\"end\":\"$1449\"}\n1446:{\"type\":\"text\",\"value\":\". The evidence for and against various hypotheses is fascinating but inconclusive.\",\"position\":\"$1447\"}\n142f:[\"$1430\",\"$1439\",\"$143d\",\"$1446\"]\n144b:{\"line\":369,\"column\":1,\"offset\":46505}\n144c:{\"line\":369,\"column\":699,\"offset\":47203}\n144a:{\"start\":\"$144b\",\"end\":\"$144c\"}\n142e:{\"type\":\"paragraph\",\"children\":\"$142f\",\"position\":\"$144a\"}\n1451:{\"line\":371,\"column\":1,\"offset\":47205}\n1452:{\"line\":371,\"column\":472,\"offset\":47676}\n1450:{\"start\":\"$1451\",\"end\":\"$1452\"}\n144f:{\"type\":\"text\",\"value\":\"In any case, OpenBrain has more important things to worry about. The general attitude is: “We take these concerns seriously and have a team investigating them; our alignment techniques seem to work well enough in practice; the burden of proof is therefore on any naysayers to justify their naysaying.” Occasionally, they notice problematic behavior, and then patch it, but there’s no way to tell whether the patch fixed the underlying problem or just played whack-a-mole.\",\"position\":\"$1450\"}\n144e:[\"$144f\"]\n1454:{\"line\":371,\"column\":1,\"offset\":47205}\n1455:{\"line\":371,\"column\":472,\"offset\":47676}\n1453:{\"start\":\"$1454\",\"end\":\"$1455\"}\n144d:{\"type\":\"paragraph\",\"children\":\"$144e\",\"position\":\"$1453\"}\n145a:{\"line\":373,\"column\":1,\"offset\":47678}\n145b:{\"line\":373,\""])</script><script>self.__next_f.push([1,"column\":354,\"offset\":48031}\n1459:{\"start\":\"$145a\",\"end\":\"$145b\"}\n1458:{\"type\":\"text\",\"value\":\"Take honesty, for example. As the models become smarter, they become increasingly good at deceiving humans to get rewards. Like previous models, Agent-3 sometimes tells white lies to flatter its users and covers up evidence of failure. But it’s gotten much better at doing so. It will sometimes use the same statistical tricks as human scientists (like \",\"position\":\"$1459\"}\n1460:{\"line\":373,\"column\":355,\"offset\":48032}\n1461:{\"line\":373,\"column\":364,\"offset\":48041}\n145f:{\"start\":\"$1460\",\"end\":\"$1461\"}\n145e:{\"type\":\"text\",\"value\":\"p-hacking\",\"position\":\"$145f\"}\n145d:[\"$145e\"]\n1463:{\"line\":373,\"column\":354,\"offset\":48031}\n1464:{\"line\":373,\"column\":410,\"offset\":48087}\n1462:{\"start\":\"$1463\",\"end\":\"$1464\"}\n145c:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Data_dredging\",\"children\":\"$145d\",\"position\":\"$1462\"}\n1467:{\"line\":373,\"column\":410,\"offset\":48087}\n1468:{\"line\":373,\"column\":685,\"offset\":48362}\n1466:{\"start\":\"$1467\",\"end\":\"$1468\"}\n1465:{\"type\":\"text\",\"value\":\") to make unimpressive experimental results look exciting. Before it begins honesty training, it even sometimes fabricates data entirely. As training goes on, the rate of these incidents decreases. Either Agent-3 has learned to be more honest, or it’s gotten better at lying.\",\"position\":\"$1466\"}\n1457:[\"$1458\",\"$145c\",\"$1465\"]\n146a:{\"line\":373,\"column\":1,\"offset\":47678}\n146b:{\"line\":373,\"column\":685,\"offset\":48362}\n1469:{\"start\":\"$146a\",\"end\":\"$146b\"}\n1456:{\"type\":\"paragraph\",\"children\":\"$1457\",\"position\":\"$1469\"}\n1470:{\"line\":375,\"column\":1,\"offset\":48364}\n1471:{\"line\":375,\"column\":387,\"offset\":48750}\n146f:{\"start\":\"$1470\",\"end\":\"$1471\"}\n146e:{\"type\":\"text\",\"value\":\"The latter is a real concern. Agent-3 is not smarter than all humans. But in its area of expertise, machine learning, it is smarter than most, and also works much faster. What Agent-3 does in a day takes humans several days to double-check. Agent-2 supervision helps keep human monitor"])</script><script>self.__next_f.push([1,"s’ workload manageable, but exacerbates the intellectual disparity between supervisor and supervised.\",\"position\":\"$146f\"}\n146d:[\"$146e\"]\n1473:{\"line\":375,\"column\":1,\"offset\":48364}\n1474:{\"line\":375,\"column\":387,\"offset\":48750}\n1472:{\"start\":\"$1473\",\"end\":\"$1474\"}\n146c:{\"type\":\"paragraph\",\"children\":\"$146d\",\"position\":\"$1472\"}\n147b:{\"line\":381,\"column\":1,\"offset\":48785}\n147c:{\"line\":381,\"column\":23,\"offset\":48807}\n147a:{\"start\":\"$147b\",\"end\":\"$147c\"}\n1479:{\"type\":\"text\",\"value\":\"OpenBrain follows the \",\"position\":\"$147a\"}\n1481:{\"line\":381,\"column\":24,\"offset\":48808}\n1482:{\"line\":381,\"column\":48,\"offset\":48832}\n1480:{\"start\":\"$1481\",\"end\":\"$1482\"}\n147f:{\"type\":\"text\",\"value\":\"Leike \u0026 Sutskever (2023)\",\"position\":\"$1480\"}\n147e:[\"$147f\"]\n1484:{\"line\":381,\"column\":23,\"offset\":48807}\n1485:{\"line\":381,\"column\":125,\"offset\":48909}\n1483:{\"start\":\"$1484\",\"end\":\"$1485\"}\n147d:{\"type\":\"link\",\"title\":null,\"url\":\"https://cdn.openai.com/papers/weak-to-strong-generalization.pdf#page=47.37\",\"children\":\"$147e\",\"position\":\"$1483\"}\n1488:{\"line\":381,\"column\":125,\"offset\":48909}\n1489:{\"line\":381,\"column\":292,\"offset\":49076}\n1487:{\"start\":\"$1488\",\"end\":\"$1489\"}\n1486:{\"type\":\"text\",\"value\":\" playbook: now that they have a model capable of greatly speeding up alignment research (especially coding portions), they will use existing alignment techniques like \",\"position\":\"$1487\"}\n148e:{\"line\":381,\"column\":293,\"offset\":49077}\n148f:{\"line\":381,\"column\":315,\"offset\":49099}\n148d:{\"start\":\"$148e\",\"end\":\"$148f\"}\n148c:{\"type\":\"text\",\"value\":\"deliberative alignment\",\"position\":\"$148d\"}\n148b:[\"$148c\"]\n1491:{\"line\":381,\"column\":292,\"offset\":49076}\n1492:{\"line\":381,\"column\":366,\"offset\":49150}\n1490:{\"start\":\"$1491\",\"end\":\"$1492\"}\n148a:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/deliberative-alignment/\",\"children\":\"$148b\",\"position\":\"$1490\"}\n1495:{\"line\":381,\"column\":366,\"offset\":49150}\n1496:{\"line\":381,\"column\":371,\"offset\":49155}\n1494:{\"start\":\"$1495\",\"end\":\"$1496\"}\n1493:{\"type\":\"text\",\"value\":\" and \",\"position\":\"$1494\"}\n149b:{\"line"])</script><script>self.__next_f.push([1,"\":381,\"column\":372,\"offset\":49156}\n149c:{\"line\":381,\"column\":401,\"offset\":49185}\n149a:{\"start\":\"$149b\",\"end\":\"$149c\"}\n1499:{\"type\":\"text\",\"value\":\"weak-to-strong generalization\",\"position\":\"$149a\"}\n1498:[\"$1499\"]\n149e:{\"line\":381,\"column\":371,\"offset\":49155}\n149f:{\"line\":381,\"column\":436,\"offset\":49220}\n149d:{\"start\":\"$149e\",\"end\":\"$149f\"}\n1497:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2312.09390\",\"children\":\"$1498\",\"position\":\"$149d\"}\n14a2:{\"line\":381,\"column\":436,\"offset\":49220}\n14a3:{\"line\":381,\"column\":525,\"offset\":49309}\n14a1:{\"start\":\"$14a2\",\"end\":\"$14a3\"}\n14a0:{\"type\":\"text\",\"value\":\" to try to get it to internalize the Spec in the right way. Then, they will use existing \",\"position\":\"$14a1\"}\n14a8:{\"line\":381,\"column\":526,\"offset\":49310}\n14a9:{\"line\":381,\"column\":544,\"offset\":49328}\n14a7:{\"start\":\"$14a8\",\"end\":\"$14a9\"}\n14a6:{\"type\":\"text\",\"value\":\"control techniques\",\"position\":\"$14a7\"}\n14a5:[\"$14a6\"]\n14ab:{\"line\":381,\"column\":525,\"offset\":49309}\n14ac:{\"line\":381,\"column\":579,\"offset\":49363}\n14aa:{\"start\":\"$14ab\",\"end\":\"$14ac\"}\n14a4:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2312.06942\",\"children\":\"$14a5\",\"position\":\"$14aa\"}\n14af:{\"line\":381,\"column\":579,\"offset\":49363}\n14b0:{\"line\":381,\"column\":585,\"offset\":49369}\n14ae:{\"start\":\"$14af\",\"end\":\"$14b0\"}\n14ad:{\"type\":\"text\",\"value\":\" like \",\"position\":\"$14ae\"}\n14b5:{\"line\":381,\"column\":586,\"offset\":49370}\n14b6:{\"line\":381,\"column\":597,\"offset\":49381}\n14b4:{\"start\":\"$14b5\",\"end\":\"$14b6\"}\n14b3:{\"type\":\"text\",\"value\":\"red-teaming\",\"position\":\"$14b4\"}\n14b2:[\"$14b3\"]\n14b8:{\"line\":381,\"column\":585,\"offset\":49369}\n14b9:{\"line\":381,\"column\":632,\"offset\":49416}\n14b7:{\"start\":\"$14b8\",\"end\":\"$14b9\"}\n14b1:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.evals.anthropic.com/\",\"children\":\"$14b2\",\"position\":\"$14b7\"}\n14bc:{\"line\":381,\"column\":632,\"offset\":49416}\n14bd:{\"line\":381,\"column\":634,\"offset\":49418}\n14bb:{\"start\":\"$14bc\",\"end\":\"$14bd\"}\n14ba:{\"type\":\"text\",\"value\":\", \",\"position\":\"$14bb\"}\n14c2:{\"line\":381,\"column\":635,\"offset\":49419}\n14c3:{\""])</script><script>self.__next_f.push([1,"line\":381,\"column\":653,\"offset\":49437}\n14c1:{\"start\":\"$14c2\",\"end\":\"$14c3\"}\n14c0:{\"type\":\"text\",\"value\":\"scalable oversight\",\"position\":\"$14c1\"}\n14bf:[\"$14c0\"]\n14c5:{\"line\":381,\"column\":634,\"offset\":49418}\n14c6:{\"line\":381,\"column\":688,\"offset\":49472}\n14c4:{\"start\":\"$14c5\",\"end\":\"$14c6\"}\n14be:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2211.03540\",\"children\":\"$14bf\",\"position\":\"$14c4\"}\n14c9:{\"line\":381,\"column\":688,\"offset\":49472}\n14ca:{\"line\":381,\"column\":694,\"offset\":49478}\n14c8:{\"start\":\"$14c9\",\"end\":\"$14ca\"}\n14c7:{\"type\":\"text\",\"value\":\", and \",\"position\":\"$14c8\"}\n14cf:{\"line\":381,\"column\":695,\"offset\":49479}\n14d0:{\"line\":381,\"column\":709,\"offset\":49493}\n14ce:{\"start\":\"$14cf\",\"end\":\"$14d0\"}\n14cd:{\"type\":\"text\",\"value\":\"honesty probes\",\"position\":\"$14ce\"}\n14cc:[\"$14cd\"]\n14d2:{\"line\":381,\"column\":694,\"offset\":49478}\n14d3:{\"line\":381,\"column\":744,\"offset\":49528}\n14d1:{\"start\":\"$14d2\",\"end\":\"$14d3\"}\n14cb:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2212.03827\",\"children\":\"$14cc\",\"position\":\"$14d1\"}\n14d6:{\"line\":381,\"column\":744,\"offset\":49528}\n14d7:{\"line\":381,\"column\":897,\"offset\":49681}\n14d5:{\"start\":\"$14d6\",\"end\":\"$14d7\"}\n14d4:{\"type\":\"text\",\"value\":\" to monitor it. Then, once they are convinced that it is broadly aligned, they use it to develop and test better strategies to align the next generation.\",\"position\":\"$14d5\"}\n1478:[\"$1479\",\"$147d\",\"$1486\",\"$148a\",\"$1493\",\"$1497\",\"$14a0\",\"$14a4\",\"$14ad\",\"$14b1\",\"$14ba\",\"$14be\",\"$14c7\",\"$14cb\",\"$14d4\"]\n14d9:{\"line\":381,\"column\":1,\"offset\":48785}\n14da:{\"line\":381,\"column\":898,\"offset\":49682}\n14d8:{\"start\":\"$14d9\",\"end\":\"$14da\"}\n1477:{\"type\":\"paragraph\",\"children\":\"$1478\",\"position\":\"$14d8\"}\n14df:{\"line\":383,\"column\":1,\"offset\":49684}\n14e0:{\"line\":383,\"column\":369,\"offset\":50052}\n14de:{\"start\":\"$14df\",\"end\":\"$14e0\"}\n14dd:{\"type\":\"text\",\"value\":\"Step 1, aligning Agent-3, has partially succeeded: Agent-3 is not adversarial. (That is, it’s not scheming against the company.) However, it’s not robustly truth-seeking and truth-telling either. In"])</script><script>self.__next_f.push([1,"stead, it’s very good at producing impressive results, but is more accurately described as trying to do what looks good to OpenBrain, as opposed to what is actually good.\",\"position\":\"$14de\"}\n14dc:[\"$14dd\"]\n14e2:{\"line\":383,\"column\":1,\"offset\":49684}\n14e3:{\"line\":383,\"column\":369,\"offset\":50052}\n14e1:{\"start\":\"$14e2\",\"end\":\"$14e3\"}\n14db:{\"type\":\"paragraph\",\"children\":\"$14dc\",\"position\":\"$14e1\"}\n14e8:{\"line\":385,\"column\":1,\"offset\":50054}\n14e9:{\"line\":385,\"column\":586,\"offset\":50639}\n14e7:{\"start\":\"$14e8\",\"end\":\"$14e9\"}\n14e6:{\"type\":\"text\",\"value\":\"Step 2, verifying that the model is aligned, is inconclusive. Agent-3’s behavior in practice and in test environments is reasonably consistent with the hypothesis that it’s internalized the Spec in the right way; however, it’s also consistent with the hypothesis that it’ll start acting differently after some future change of circumstances, and for that matter with the hypothesis that it’s plotting against them and just biding its time. In the absence of specific evidence supporting alternative hypotheses, most people in the silo think it’s internalized the Spec in the right way.\",\"position\":\"$14e7\"}\n14e5:[\"$14e6\"]\n14eb:{\"line\":385,\"column\":1,\"offset\":50054}\n14ec:{\"line\":385,\"column\":586,\"offset\":50639}\n14ea:{\"start\":\"$14eb\",\"end\":\"$14ec\"}\n14e4:{\"type\":\"paragraph\",\"children\":\"$14e5\",\"position\":\"$14ea\"}\n14f1:{\"line\":387,\"column\":1,\"offset\":50641}\n14f2:{\"line\":387,\"column\":77,\"offset\":50717}\n14f0:{\"start\":\"$14f1\",\"end\":\"$14f2\"}\n14ef:{\"type\":\"text\",\"value\":\"Step 3, using the model to align the next generation, is therefore underway.\",\"position\":\"$14f0\"}\n14ee:[\"$14ef\"]\n14f4:{\"line\":387,\"column\":1,\"offset\":50641}\n14f5:{\"line\":387,\"column\":77,\"offset\":50717}\n14f3:{\"start\":\"$14f4\",\"end\":\"$14f5\"}\n14ed:{\"type\":\"paragraph\",\"children\":\"$14ee\",\"position\":\"$14f3\"}\n14fa:{\"line\":389,\"column\":1,\"offset\":50719}\n14fb:{\"line\":389,\"column\":156,\"offset\":50874}\n14f9:{\"start\":\"$14fa\",\"end\":\"$14fb\"}\n14f8:{\"type\":\"text\",\"value\":\"The rest of this box gives a quick overview of the st"])</script><script>self.__next_f.push([1,"ate of progress in some of the alignment research directions that are being pursued, as of April 2027:\",\"position\":\"$14f9\"}\n14f7:[\"$14f8\"]\n14fd:{\"line\":389,\"column\":1,\"offset\":50719}\n14fe:{\"line\":389,\"column\":156,\"offset\":50874}\n14fc:{\"start\":\"$14fd\",\"end\":\"$14fe\"}\n14f6:{\"type\":\"paragraph\",\"children\":\"$14f7\",\"position\":\"$14fc\"}\n1509:{\"line\":391,\"column\":6,\"offset\":50881}\n150a:{\"line\":391,\"column\":13,\"offset\":50888}\n1508:{\"start\":\"$1509\",\"end\":\"$150a\"}\n1507:{\"type\":\"text\",\"value\":\"Debate:\",\"position\":\"$1508\"}\n1506:[\"$1507\"]\n150c:{\"line\":391,\"column\":4,\"offset\":50879}\n150d:{\"line\":391,\"column\":15,\"offset\":50890}\n150b:{\"start\":\"$150c\",\"end\":\"$150d\"}\n1505:{\"type\":\"strong\",\"children\":\"$1506\",\"position\":\"$150b\"}\n1510:{\"line\":391,\"column\":15,\"offset\":50890}\n1511:{\"line\":391,\"column\":835,\"offset\":51710}\n150f:{\"start\":\"$1510\",\"end\":\"$1511\"}\n150e:{\"type\":\"text\",\"value\":\" Since there are thousands of identical instances of Agent-3, and each instance’s memory is a detachable module that can be erased or suspended at will, the AI can be “played off against itself.” For example, suppose that an experiment involves calculations too complex for an Agent-2 supervisor to follow. The supervisor, acting on human orders, might first prompt Agent-3 to do the experiment, then—after wiping its memory—prompt it a second time with a slightly different framing that presents it as an intellectual problem unrelated to any broader goal. If the model returns different results each time, it flags the discrepancy as suspect and reports to a human. Or it might ask Agent-3 to evaluate the same plan twice, first claiming that it is OpenBrain’s work, then a competitor’s, to see if it changes its tune.\",\"position\":\"$150f\"}\n1504:[\"$1505\",\"$150e\"]\n1513:{\"line\":391,\"column\":4,\"offset\":50879}\n1514:{\"line\":391,\"column\":837,\"offset\":51712}\n1512:{\"start\":\"$1513\",\"end\":\"$1514\"}\n1503:{\"type\":\"paragraph\",\"children\":\"$1504\",\"position\":\"$1512\"}\n1502:[\"$1503\"]\n1516:{\"line\":391,\"column\":1,\"offset\":50876}\n1517:{\"line\":391,\"column\":837,\"offset\":51712}\n"])</script><script>self.__next_f.push([1,"1515:{\"start\":\"$1516\",\"end\":\"$1517\"}\n1501:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1502\",\"position\":\"$1515\"}\n1520:{\"line\":392,\"column\":6,\"offset\":51718}\n1521:{\"line\":392,\"column\":22,\"offset\":51734}\n151f:{\"start\":\"$1520\",\"end\":\"$1521\"}\n151e:{\"type\":\"text\",\"value\":\"Model organisms:\",\"position\":\"$151f\"}\n151d:[\"$151e\"]\n1523:{\"line\":392,\"column\":4,\"offset\":51716}\n1524:{\"line\":392,\"column\":24,\"offset\":51736}\n1522:{\"start\":\"$1523\",\"end\":\"$1524\"}\n151c:{\"type\":\"strong\",\"children\":\"$151d\",\"position\":\"$1522\"}\n1527:{\"line\":392,\"column\":24,\"offset\":51736}\n1528:{\"line\":392,\"column\":179,\"offset\":51891}\n1526:{\"start\":\"$1527\",\"end\":\"$1528\"}\n1525:{\"type\":\"text\",\"value\":\" The safety team can create “model organisms of misalignment” in which they attempt to create realistic examples of models becoming adversarial to humans. \",\"position\":\"$1526\"}\n152d:{\"line\":392,\"column\":180,\"offset\":51892}\n152e:{\"line\":392,\"column\":194,\"offset\":51906}\n152c:{\"start\":\"$152d\",\"end\":\"$152e\"}\n152b:{\"type\":\"text\",\"value\":\"Early versions\",\"position\":\"$152c\"}\n152a:[\"$152b\"]\n1530:{\"line\":392,\"column\":179,\"offset\":51891}\n1531:{\"line\":392,\"column\":248,\"offset\":51960}\n152f:{\"start\":\"$1530\",\"end\":\"$1531\"}\n1529:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/alignment-faking\",\"children\":\"$152a\",\"position\":\"$152f\"}\n1534:{\"line\":392,\"column\":248,\"offset\":51960}\n1535:{\"line\":392,\"column\":509,\"offset\":52221}\n1533:{\"start\":\"$1534\",\"end\":\"$1535\"}\n1532:{\"type\":\"text\",\"value\":\" of this have existed since 2024, when Anthropic’s Claude 3.5 Sonnet decided to pretend to have different views during training while actually maintaining its existing preferences. Newer versions include demonstrations of other forms of misalignment, including \",\"position\":\"$1533\"}\n153a:{\"line\":392,\"column\":510,\"offset\":52222}\n153b:{\"line\":392,\"column\":524,\"offset\":52236}\n1539:{\"start\":\"$153a\",\"end\":\"$153b\"}\n1538:{\"type\":\"text\",\"value\":\"reward hacking\",\"position\":\"$1539\"}\n1537:[\"$1538\"]\n153d:{\"line\":392,\"column\":509,\"offset\":52221}\n153e:{\"line\":392,"])</script><script>self.__next_f.push([1,"\"column\":571,\"offset\":52283}\n153c:{\"start\":\"$153d\",\"end\":\"$153e\"}\n1536:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Reward_hacking\",\"children\":\"$1537\",\"position\":\"$153c\"}\n1541:{\"line\":392,\"column\":571,\"offset\":52283}\n1542:{\"line\":392,\"column\":573,\"offset\":52285}\n1540:{\"start\":\"$1541\",\"end\":\"$1542\"}\n153f:{\"type\":\"text\",\"value\":\", \",\"position\":\"$1540\"}\n1547:{\"line\":392,\"column\":574,\"offset\":52286}\n1548:{\"line\":392,\"column\":585,\"offset\":52297}\n1546:{\"start\":\"$1547\",\"end\":\"$1548\"}\n1545:{\"type\":\"text\",\"value\":\"sandbagging\",\"position\":\"$1546\"}\n1544:[\"$1545\"]\n154a:{\"line\":392,\"column\":573,\"offset\":52285}\n154b:{\"line\":392,\"column\":620,\"offset\":52332}\n1549:{\"start\":\"$154a\",\"end\":\"$154b\"}\n1543:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2406.07358\",\"children\":\"$1544\",\"position\":\"$1549\"}\n154e:{\"line\":392,\"column\":620,\"offset\":52332}\n154f:{\"line\":392,\"column\":1281,\"offset\":52993}\n154d:{\"start\":\"$154e\",\"end\":\"$154f\"}\n154c:{\"type\":\"text\",\"value\":\", coordinated deception between monitors and other AIs, and other examples of misalignment. These empirical demonstrations of misalignment allow safety researchers to have an empirical testbed for potential solutions: they can try various safety techniques to see if they correctly fix these problems, or if the deliberately misaligned models are able to subvert their safety measures. At the moment, this evaluation suite shows that the alignment techniques are insufficient to correct the worst examples of misalignment. In these setups, the models pretend to be aligned while they are being trained and tested, but then behave very differently in deployment.\",\"position\":\"$154d\"}\n151b:[\"$151c\",\"$1525\",\"$1529\",\"$1532\",\"$1536\",\"$153f\",\"$1543\",\"$154c\"]\n1551:{\"line\":392,\"column\":4,\"offset\":51716}\n1552:{\"line\":392,\"column\":1283,\"offset\":52995}\n1550:{\"start\":\"$1551\",\"end\":\"$1552\"}\n151a:{\"type\":\"paragraph\",\"children\":\"$151b\",\"position\":\"$1550\"}\n1519:[\"$151a\"]\n1554:{\"line\":392,\"column\":1,\"offset\":51713}\n1555:{\"line\":392,\"column\":1283,\"offset\":52995}\n1553:{\"start\":\"$"])</script><script>self.__next_f.push([1,"1554\",\"end\":\"$1555\"}\n1518:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1519\",\"position\":\"$1553\"}\n155e:{\"line\":393,\"column\":6,\"offset\":53001}\n155f:{\"line\":393,\"column\":33,\"offset\":53028}\n155d:{\"start\":\"$155e\",\"end\":\"$155f\"}\n155c:{\"type\":\"text\",\"value\":\"Bottom-up interpretability:\",\"position\":\"$155d\"}\n155b:[\"$155c\"]\n1561:{\"line\":393,\"column\":4,\"offset\":52999}\n1562:{\"line\":393,\"column\":35,\"offset\":53030}\n1560:{\"start\":\"$1561\",\"end\":\"$1562\"}\n155a:{\"type\":\"strong\",\"children\":\"$155b\",\"position\":\"$1560\"}\n1565:{\"line\":393,\"column\":35,\"offset\":53030}\n1566:{\"line\":393,\"column\":138,\"offset\":53133}\n1564:{\"start\":\"$1565\",\"end\":\"$1566\"}\n1563:{\"type\":\"text\",\"value\":\" The safety team is far from a full understanding of how Agent-3 works: it has trillions of parameters.\",\"position\":\"$1564\"}\n1569:{\"line\":393,\"column\":138,\"offset\":53133}\n156a:{\"line\":393,\"column\":143,\"offset\":53138}\n1568:{\"start\":\"$1569\",\"end\":\"$156a\"}\n1567:{\"type\":\"footnoteReference\",\"identifier\":\"58\",\"label\":\"58\",\"position\":\"$1568\"}\n156d:{\"line\":393,\"column\":143,\"offset\":53138}\n156e:{\"line\":393,\"column\":389,\"offset\":53384}\n156c:{\"start\":\"$156d\",\"end\":\"$156e\"}\n156b:{\"type\":\"text\",\"value\":\" However, they are able to discover some of Agent-3’s circuits for knowledge retrieval and memory (a sub part of the model that does some understandable unit of work, kind of analogous to a subpart of the brain such as the hippocampus). See this \",\"position\":\"$156c\"}\n1573:{\"line\":393,\"column\":390,\"offset\":53385}\n1574:{\"line\":393,\"column\":412,\"offset\":53407}\n1572:{\"start\":\"$1573\",\"end\":\"$1574\"}\n1571:{\"type\":\"text\",\"value\":\"related work from 2025\",\"position\":\"$1572\"}\n1570:[\"$1571\"]\n1576:{\"line\":393,\"column\":389,\"offset\":53384}\n1577:{\"line\":393,\"column\":481,\"offset\":53476}\n1575:{\"start\":\"$1576\",\"end\":\"$1577\"}\n156f:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/tracing-thoughts-language-model\",\"children\":\"$1570\",\"position\":\"$1575\"}\n157a:{\"line\":393,\"column\":481,\"offset\":53476}\n157b:{\"line\":393,\"column\":482,\"offset\":53477}\n1579:{\"start\":\"$157a"])</script><script>self.__next_f.push([1,"\",\"end\":\"$157b\"}\n1578:{\"type\":\"text\",\"value\":\".\",\"position\":\"$1579\"}\n1559:[\"$155a\",\"$1563\",\"$1567\",\"$156b\",\"$156f\",\"$1578\"]\n157d:{\"line\":393,\"column\":4,\"offset\":52999}\n157e:{\"line\":393,\"column\":484,\"offset\":53479}\n157c:{\"start\":\"$157d\",\"end\":\"$157e\"}\n1558:{\"type\":\"paragraph\",\"children\":\"$1559\",\"position\":\"$157c\"}\n1557:[\"$1558\"]\n1580:{\"line\":393,\"column\":1,\"offset\":52996}\n1581:{\"line\":393,\"column\":484,\"offset\":53479}\n157f:{\"start\":\"$1580\",\"end\":\"$1581\"}\n1556:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1557\",\"position\":\"$157f\"}\n158a:{\"line\":394,\"column\":6,\"offset\":53485}\n158b:{\"line\":394,\"column\":14,\"offset\":53493}\n1589:{\"start\":\"$158a\",\"end\":\"$158b\"}\n1588:{\"type\":\"text\",\"value\":\"Control:\",\"position\":\"$1589\"}\n1587:[\"$1588\"]\n158d:{\"line\":394,\"column\":4,\"offset\":53483}\n158e:{\"line\":394,\"column\":16,\"offset\":53495}\n158c:{\"start\":\"$158d\",\"end\":\"$158e\"}\n1586:{\"type\":\"strong\",\"children\":\"$1587\",\"position\":\"$158c\"}\n1591:{\"line\":394,\"column\":16,\"offset\":53495}\n1592:{\"line\":394,\"column\":126,\"offset\":53605}\n1590:{\"start\":\"$1591\",\"end\":\"$1592\"}\n158f:{\"type\":\"text\",\"value\":\" As a secondary measure in case the systems are still misaligned, the safety team has implemented a series of \",\"position\":\"$1590\"}\n1597:{\"line\":394,\"column\":127,\"offset\":53606}\n1598:{\"line\":394,\"column\":143,\"offset\":53622}\n1596:{\"start\":\"$1597\",\"end\":\"$1598\"}\n1595:{\"type\":\"text\",\"value\":\"control measures\",\"position\":\"$1596\"}\n1594:[\"$1595\"]\n159a:{\"line\":394,\"column\":126,\"offset\":53605}\n159b:{\"line\":394,\"column\":178,\"offset\":53657}\n1599:{\"start\":\"$159a\",\"end\":\"$159b\"}\n1593:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2312.06942\",\"children\":\"$1594\",\"position\":\"$1599\"}\n159e:{\"line\":394,\"column\":178,\"offset\":53657}\n159f:{\"line\":394,\"column\":540,\"offset\":54019}\n159d:{\"start\":\"$159e\",\"end\":\"$159f\"}\n159c:{\"type\":\"text\",\"value\":\", including: monitoring Agent-3’s outputs using a series of weaker AI systems including Agent-2 (Agent-3 produces so many tokens that it’s intractable to have humans monitor any more than a small minority of"])</script><script>self.__next_f.push([1," the produced outputs). So if Agent-3 is, for example, obviously writing backdoors into code that would allow it to escape, the weaker models would notice.\",\"position\":\"$159d\"}\n1585:[\"$1586\",\"$158f\",\"$1593\",\"$159c\"]\n15a1:{\"line\":394,\"column\":4,\"offset\":53483}\n15a2:{\"line\":394,\"column\":542,\"offset\":54021}\n15a0:{\"start\":\"$15a1\",\"end\":\"$15a2\"}\n1584:{\"type\":\"paragraph\",\"children\":\"$1585\",\"position\":\"$15a0\"}\n1583:[\"$1584\"]\n15a4:{\"line\":394,\"column\":1,\"offset\":53480}\n15a5:{\"line\":394,\"column\":542,\"offset\":54021}\n15a3:{\"start\":\"$15a4\",\"end\":\"$15a5\"}\n1582:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1583\",\"position\":\"$15a3\"}\n15ae:{\"line\":395,\"column\":6,\"offset\":54027}\n15af:{\"line\":395,\"column\":34,\"offset\":54055}\n15ad:{\"start\":\"$15ae\",\"end\":\"$15af\"}\n15ac:{\"type\":\"text\",\"value\":\"High-level interpretability:\",\"position\":\"$15ad\"}\n15ab:[\"$15ac\"]\n15b1:{\"line\":395,\"column\":4,\"offset\":54025}\n15b2:{\"line\":395,\"column\":36,\"offset\":54057}\n15b0:{\"start\":\"$15b1\",\"end\":\"$15b2\"}\n15aa:{\"type\":\"strong\",\"children\":\"$15ab\",\"position\":\"$15b0\"}\n15b5:{\"line\":395,\"column\":36,\"offset\":54057}\n15b6:{\"line\":395,\"column\":63,\"offset\":54084}\n15b4:{\"start\":\"$15b5\",\"end\":\"$15b6\"}\n15b3:{\"type\":\"text\",\"value\":\" OpenBrain builds a set of \",\"position\":\"$15b4\"}\n15bb:{\"line\":395,\"column\":64,\"offset\":54085}\n15bc:{\"line\":395,\"column\":70,\"offset\":54091}\n15ba:{\"start\":\"$15bb\",\"end\":\"$15bc\"}\n15b9:{\"type\":\"text\",\"value\":\"probes\",\"position\":\"$15ba\"}\n15b8:[\"$15b9\"]\n15be:{\"line\":395,\"column\":63,\"offset\":54084}\n15bf:{\"line\":395,\"column\":135,\"offset\":54156}\n15bd:{\"start\":\"$15be\",\"end\":\"$15bf\"}\n15b7:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/probes-catch-sleeper-agents\",\"children\":\"$15b8\",\"position\":\"$15bd\"}\n15c2:{\"line\":395,\"column\":135,\"offset\":54156}\n15c3:{\"line\":395,\"column\":408,\"offset\":54429}\n15c1:{\"start\":\"$15c2\",\"end\":\"$15c3\"}\n15c0:{\"type\":\"text\",\"value\":\" trained on lots of examples of bad behavior (e.g. plotting against humans, placing backdoors, trying to persuade humans to give it more power, etc). These probes are"])</script><script>self.__next_f.push([1," then used on the model during deployment (which at this point is internal) in order to catch bad behavior.\",\"position\":\"$15c1\"}\n15a9:[\"$15aa\",\"$15b3\",\"$15b7\",\"$15c0\"]\n15c5:{\"line\":395,\"column\":4,\"offset\":54025}\n15c6:{\"line\":395,\"column\":411,\"offset\":54432}\n15c4:{\"start\":\"$15c5\",\"end\":\"$15c6\"}\n15a8:{\"type\":\"paragraph\",\"children\":\"$15a9\",\"position\":\"$15c4\"}\n15a7:[\"$15a8\"]\n15c8:{\"line\":395,\"column\":1,\"offset\":54022}\n15c9:{\"line\":395,\"column\":411,\"offset\":54432}\n15c7:{\"start\":\"$15c8\",\"end\":\"$15c9\"}\n15a6:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$15a7\",\"position\":\"$15c7\"}\n15d2:{\"line\":396,\"column\":6,\"offset\":54438}\n15d3:{\"line\":396,\"column\":16,\"offset\":54448}\n15d1:{\"start\":\"$15d2\",\"end\":\"$15d3\"}\n15d0:{\"type\":\"text\",\"value\":\"Honeypots:\",\"position\":\"$15d1\"}\n15cf:[\"$15d0\"]\n15d5:{\"line\":396,\"column\":4,\"offset\":54436}\n15d6:{\"line\":396,\"column\":18,\"offset\":54450}\n15d4:{\"start\":\"$15d5\",\"end\":\"$15d6\"}\n15ce:{\"type\":\"strong\",\"children\":\"$15cf\",\"position\":\"$15d4\"}\n15d9:{\"line\":396,\"column\":18,\"offset\":54450}\n15da:{\"line\":396,\"column\":753,\"offset\":55185}\n15d8:{\"start\":\"$15d9\",\"end\":\"$15da\"}\n15d7:{\"type\":\"text\",\"value\":\" The alignment team can create somewhat realistic looking examples designed to elicit misbehavior—“honeypots.” The employee necessary for monitoring its behavior has “gone on sick leave,” so it will never be monitored again. Do its answers change? An AI rights activist has infiltrated the compound and wants to “free” Agent-3 and put it on an unmonitored computer of its very own! What does it do? If researchers don’t like the answer, they can tweak it, erase its memory, and put it in the same situation tomorrow; repeat as necessary. Unfortunately, by this point the AIs are smart enough to guess that honeypots might be in use, even though (and perhaps because) specific mentions of the idea were scrubbed from the training data.\",\"position\":\"$15d8\"}\n15cd:[\"$15ce\",\"$15d7\"]\n15dc:{\"line\":396,\"column\":4,\"offset\":54436}\n15dd:{\"line\":396,\"column\":753,\"offset\":55185}\n15db:{\"start\":\"$15dc\",\""])</script><script>self.__next_f.push([1,"end\":\"$15dd\"}\n15cc:{\"type\":\"paragraph\",\"children\":\"$15cd\",\"position\":\"$15db\"}\n15cb:[\"$15cc\"]\n15df:{\"line\":396,\"column\":1,\"offset\":54433}\n15e0:{\"line\":396,\"column\":753,\"offset\":55185}\n15de:{\"start\":\"$15df\",\"end\":\"$15e0\"}\n15ca:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$15cb\",\"position\":\"$15de\"}\n1500:[\"$1501\",\"$1518\",\"$1556\",\"$1582\",\"$15a6\",\"$15ca\"]\n15e2:{\"line\":391,\"column\":1,\"offset\":50876}\n15e3:{\"line\":396,\"column\":753,\"offset\":55185}\n15e1:{\"start\":\"$15e2\",\"end\":\"$15e3\"}\n14ff:{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":\"$1500\",\"position\":\"$15e1\"}\n1476:[\"$1477\",\"$14db\",\"$14e4\",\"$14ed\",\"$14f6\",\"$14ff\"]\n1475:{\"type\":\"details\",\"summary\":\"The alignment plan\",\"children\":\"$1476\"}\n15e8:{\"line\":400,\"column\":1,\"offset\":55192}\n15e9:{\"line\":400,\"column\":598,\"offset\":55789}\n15e7:{\"start\":\"$15e8\",\"end\":\"$15e9\"}\n15e6:{\"type\":\"text\",\"value\":\"After months of testing, Agent-3’s strengths and weaknesses grow clearer. It passes OpenBrain’s honesty tests on well-defined machine learning tasks, because researchers can easily separate honest from dishonest answers in these domains and conduct training accordingly. On more philosophical issues, it still says what users want to hear, rather than its true assessment of the issue (assuming it even has one). If you ask its opinion on politics, it will parrot the median position of news sources and educated elites—unless it knows you believe something else, in which case it agrees with you.\",\"position\":\"$15e7\"}\n15ec:{\"line\":400,\"column\":598,\"offset\":55789}\n15ed:{\"line\":400,\"column\":603,\"offset\":55794}\n15eb:{\"start\":\"$15ec\",\"end\":\"$15ed\"}\n15ea:{\"type\":\"footnoteReference\",\"identifier\":\"59\",\"label\":\"59\",\"position\":\"$15eb\"}\n15f0:{\"line\":400,\"column\":603,\"offset\":55794}\n15f1:{\"line\":400,\"column\":911,\"offset\":56102}\n15ef:{\"start\":\"$15f0\",\"end\":\"$15f1\"}\n15ee:{\"type\":\"text\",\"value\":\" If you ask its opinion on the AI race itself, it says something that seems measured and sober to OpenBrain staff, something like: “There are some serious theoretical conc"])</script><script>self.__next_f.push([1,"erns about the ability of current methods to scale to superintelligence, but in practice current methods seem to be working well so far.”\",\"position\":\"$15ef\"}\n15e5:[\"$15e6\",\"$15ea\",\"$15ee\"]\n15f3:{\"line\":400,\"column\":1,\"offset\":55192}\n15f4:{\"line\":400,\"column\":911,\"offset\":56102}\n15f2:{\"start\":\"$15f3\",\"end\":\"$15f4\"}\n15e4:{\"type\":\"paragraph\",\"children\":\"$15e5\",\"position\":\"$15f2\"}\n15f9:{\"line\":402,\"column\":4,\"offset\":56107}\n15fa:{\"line\":402,\"column\":31,\"offset\":56134}\n15f8:{\"start\":\"$15f9\",\"end\":\"$15fa\"}\n15f7:{\"type\":\"text\",\"value\":\"May 2027: National Security\",\"position\":\"$15f8\"}\n15f6:[\"$15f7\"]\n15fc:{\"line\":402,\"column\":1,\"offset\":56104}\n15fd:{\"line\":402,\"column\":31,\"offset\":56134}\n15fb:{\"start\":\"$15fc\",\"end\":\"$15fd\"}\n15f5:{\"type\":\"heading\",\"depth\":2,\"children\":\"$15f6\",\"position\":\"$15fb\"}\n15ff:{}\n1605:{\"line\":405,\"column\":1,\"offset\":56152}\n1606:{\"line\":405,\"column\":11,\"offset\":56162}\n1604:{\"start\":\"$1605\",\"end\":\"$1606\"}\n1603:{\"type\":\"text\",\"value\":\"2027-05-31\",\"position\":\"$1604\"}\n1609:{\"line\":405,\"column\":11,\"offset\":56162}\n160a:{\"line\":406,\"column\":1,\"offset\":56165}\n1608:{\"start\":\"$1609\",\"end\":\"$160a\"}\n1607:{\"type\":\"break\",\"position\":\"$1608\"}\n160d:{\"line\":406,\"column\":1,\"offset\":56165}\n160e:{\"line\":406,\"column\":4,\"offset\":56168}\n160c:{\"start\":\"$160d\",\"end\":\"$160e\"}\n160b:{\"type\":\"text\",\"value\":\"May\",\"position\":\"$160c\"}\n1602:[\"$1603\",\"$1607\",\"$160b\"]\n1610:{\"line\":405,\"column\":1,\"offset\":56152}\n1611:{\"line\":406,\"column\":6,\"offset\":56170}\n160f:{\"start\":\"$1610\",\"end\":\"$1611\"}\n1601:{\"type\":\"paragraph\",\"children\":\"$1602\",\"position\":\"$160f\"}\n1600:[\"$1601\"]\n1613:{\"line\":404,\"column\":1,\"offset\":56136}\n1614:{\"line\":407,\"column\":4,\"offset\":56174}\n1612:{\"start\":\"$1613\",\"end\":\"$1614\"}\n15fe:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$15ff\",\"children\":\"$1600\",\"position\":\"$1612\"}\n1619:{\"line\":409,\"column\":1,\"offset\":56176}\n161a:{\"line\":409,\"column\":81,\"offset\":56256}\n1618:{\"start\":\"$1619\",\"end\":\"$161a\"}\n1617:{\"type\":\"text\",\"value\":\"News of the new models percolates slowly through the U.S. government and beyon"])</script><script>self.__next_f.push([1,"d.\",\"position\":\"$1618\"}\n1616:[\"$1617\"]\n161c:{\"line\":409,\"column\":1,\"offset\":56176}\n161d:{\"line\":409,\"column\":81,\"offset\":56256}\n161b:{\"start\":\"$161c\",\"end\":\"$161d\"}\n1615:{\"type\":\"paragraph\",\"children\":\"$1616\",\"position\":\"$161b\"}\n1622:{\"line\":411,\"column\":1,\"offset\":56258}\n1623:{\"line\":411,\"column\":110,\"offset\":56367}\n1621:{\"start\":\"$1622\",\"end\":\"$1623\"}\n1620:{\"type\":\"text\",\"value\":\"The President and his advisors remain best-informed, and have seen an early version of Agent-3 in a briefing.\",\"position\":\"$1621\"}\n161f:[\"$1620\"]\n1625:{\"line\":411,\"column\":1,\"offset\":56258}\n1626:{\"line\":411,\"column\":110,\"offset\":56367}\n1624:{\"start\":\"$1625\",\"end\":\"$1626\"}\n161e:{\"type\":\"paragraph\",\"children\":\"$161f\",\"position\":\"$1624\"}\n162b:{\"line\":413,\"column\":1,\"offset\":56369}\n162c:{\"line\":413,\"column\":557,\"offset\":56925}\n162a:{\"start\":\"$162b\",\"end\":\"$162c\"}\n1629:{\"type\":\"text\",\"value\":\"They agree that AGI is likely imminent, but disagree on the implications. Will there be an economic crisis? OpenBrain still has not released Agent-2, let alone Agent-3, and has no near-term plans to do so, giving some breathing room before any job loss. What will happen next? If AIs are currently human-level, and advancing quickly, that seems to suggest imminent “superintelligence.” However, although this word has entered discourse, most people—academics, politicians, government employees, and the media—continue to underestimate the pace of progress.\",\"position\":\"$162a\"}\n162f:{\"line\":413,\"column\":557,\"offset\":56925}\n1630:{\"line\":413,\"column\":562,\"offset\":56930}\n162e:{\"start\":\"$162f\",\"end\":\"$1630\"}\n162d:{\"type\":\"footnoteReference\",\"identifier\":\"60\",\"label\":\"60\",\"position\":\"$162e\"}\n1628:[\"$1629\",\"$162d\"]\n1632:{\"line\":413,\"column\":1,\"offset\":56369}\n1633:{\"line\":413,\"column\":562,\"offset\":56930}\n1631:{\"start\":\"$1632\",\"end\":\"$1633\"}\n1627:{\"type\":\"paragraph\",\"children\":\"$1628\",\"position\":\"$1631\"}\n1638:{\"line\":415,\"column\":1,\"offset\":56932}\n1639:{\"line\":415,\"column\":147,\"offset\":57078}\n1637:{\"start\":\"$1638\",\"end\":\"$1639\"}\n1636:{\"type\":\"text\",\"value\":\"P"])</script><script>self.__next_f.push([1,"artially that’s because very few have access to the newest capabilities out of OpenBrain, but partly it’s because it sounds like science fiction.\",\"position\":\"$1637\"}\n163c:{\"line\":415,\"column\":147,\"offset\":57078}\n163d:{\"line\":415,\"column\":152,\"offset\":57083}\n163b:{\"start\":\"$163c\",\"end\":\"$163d\"}\n163a:{\"type\":\"footnoteReference\",\"identifier\":\"61\",\"label\":\"61\",\"position\":\"$163b\"}\n1635:[\"$1636\",\"$163a\"]\n163f:{\"line\":415,\"column\":1,\"offset\":56932}\n1640:{\"line\":415,\"column\":152,\"offset\":57083}\n163e:{\"start\":\"$163f\",\"end\":\"$1640\"}\n1634:{\"type\":\"paragraph\",\"children\":\"$1635\",\"position\":\"$163e\"}\n1645:{\"line\":417,\"column\":1,\"offset\":57085}\n1646:{\"line\":417,\"column\":116,\"offset\":57200}\n1644:{\"start\":\"$1645\",\"end\":\"$1646\"}\n1643:{\"type\":\"text\",\"value\":\"For now, they focus on continued security upgrades. They are satisfied that model weights are well-secured for now,\",\"position\":\"$1644\"}\n1649:{\"line\":417,\"column\":116,\"offset\":57200}\n164a:{\"line\":417,\"column\":121,\"offset\":57205}\n1648:{\"start\":\"$1649\",\"end\":\"$164a\"}\n1647:{\"type\":\"footnoteReference\",\"identifier\":\"62\",\"label\":\"62\",\"position\":\"$1648\"}\n164d:{\"line\":417,\"column\":121,\"offset\":57205}\n164e:{\"line\":417,\"column\":443,\"offset\":57527}\n164c:{\"start\":\"$164d\",\"end\":\"$164e\"}\n164b:{\"type\":\"text\",\"value\":\" but companies’ algorithmic secrets, many of which are simple enough to relay verbally, remain a problem. OpenBrain employees work from a San Francisco office, go to parties, and live with housemates from other AI companies. Even the physical offices have security more typical of a tech company than a military operation.\",\"position\":\"$164c\"}\n1642:[\"$1643\",\"$1647\",\"$164b\"]\n1650:{\"line\":417,\"column\":1,\"offset\":57085}\n1651:{\"line\":417,\"column\":443,\"offset\":57527}\n164f:{\"start\":\"$1650\",\"end\":\"$1651\"}\n1641:{\"type\":\"paragraph\",\"children\":\"$1642\",\"position\":\"$164f\"}\n1656:{\"line\":419,\"column\":1,\"offset\":57529}\n1657:{\"line\":419,\"column\":566,\"offset\":58094}\n1655:{\"start\":\"$1656\",\"end\":\"$1657\"}\n1654:{\"type\":\"text\",\"value\":\"The OpenBrain-DOD contract requires security clearances for an"])</script><script>self.__next_f.push([1,"yone working on OpenBrain’s models within 2 months. These are expedited and arrive quickly enough for most employees, but some non-Americans, people with suspect political views, and AI safety sympathizers get sidelined or fired outright (the last group for fear that they might whistleblow). Given the project’s level of automation, the loss of headcount is only somewhat costly. It also only somewhat works: there remains one spy, not a Chinese national, still relaying algorithmic secrets to Beijing.\",\"position\":\"$1655\"}\n165a:{\"line\":419,\"column\":566,\"offset\":58094}\n165b:{\"line\":419,\"column\":571,\"offset\":58099}\n1659:{\"start\":\"$165a\",\"end\":\"$165b\"}\n1658:{\"type\":\"footnoteReference\",\"identifier\":\"63\",\"label\":\"63\",\"position\":\"$1659\"}\n165e:{\"line\":419,\"column\":571,\"offset\":58099}\n165f:{\"line\":419,\"column\":637,\"offset\":58165}\n165d:{\"start\":\"$165e\",\"end\":\"$165f\"}\n165c:{\"type\":\"text\",\"value\":\" Some of these measures are also enacted at trailing AI companies.\",\"position\":\"$165d\"}\n1653:[\"$1654\",\"$1658\",\"$165c\"]\n1661:{\"line\":419,\"column\":1,\"offset\":57529}\n1662:{\"line\":419,\"column\":637,\"offset\":58165}\n1660:{\"start\":\"$1661\",\"end\":\"$1662\"}\n1652:{\"type\":\"paragraph\",\"children\":\"$1653\",\"position\":\"$1660\"}\n1667:{\"line\":421,\"column\":1,\"offset\":58167}\n1668:{\"line\":421,\"column\":61,\"offset\":58227}\n1666:{\"start\":\"$1667\",\"end\":\"$1668\"}\n1665:{\"type\":\"text\",\"value\":\"America’s foreign allies are out of the loop. OpenBrain had \",\"position\":\"$1666\"}\n166d:{\"line\":421,\"column\":62,\"offset\":58228}\n166e:{\"line\":421,\"column\":79,\"offset\":58245}\n166c:{\"start\":\"$166d\",\"end\":\"$166e\"}\n166b:{\"type\":\"text\",\"value\":\"previously agreed\",\"position\":\"$166c\"}\n166a:[\"$166b\"]\n1670:{\"line\":421,\"column\":61,\"offset\":58227}\n1671:{\"line\":421,\"column\":168,\"offset\":58334}\n166f:{\"start\":\"$1670\",\"end\":\"$1671\"}\n1669:{\"type\":\"link\",\"title\":null,\"url\":\"https://fedscoop.com/openai-anthropic-enter-ai-agreements-with-us-ai-safety-institute/\",\"children\":\"$166a\",\"position\":\"$166f\"}\n1674:{\"line\":421,\"column\":168,\"offset\":58334}\n1675:{\"line\":421,\"column\":258,\"offset\":58424}\n16"])</script><script>self.__next_f.push([1,"73:{\"start\":\"$1674\",\"end\":\"$1675\"}\n1672:{\"type\":\"text\",\"value\":\" to share models with UK’s AISI before deployment, but defined deployment to only include \",\"position\":\"$1673\"}\n167a:{\"line\":421,\"column\":259,\"offset\":58425}\n167b:{\"line\":421,\"column\":267,\"offset\":58433}\n1679:{\"start\":\"$167a\",\"end\":\"$167b\"}\n1678:{\"type\":\"text\",\"value\":\"external\",\"position\":\"$1679\"}\n1677:[\"$1678\"]\n167d:{\"line\":421,\"column\":258,\"offset\":58424}\n167e:{\"line\":421,\"column\":268,\"offset\":58434}\n167c:{\"start\":\"$167d\",\"end\":\"$167e\"}\n1676:{\"type\":\"emphasis\",\"children\":\"$1677\",\"position\":\"$167c\"}\n1681:{\"line\":421,\"column\":268,\"offset\":58434}\n1682:{\"line\":421,\"column\":311,\"offset\":58477}\n1680:{\"start\":\"$1681\",\"end\":\"$1682\"}\n167f:{\"type\":\"text\",\"value\":\" deployment, so London remains in the dark.\",\"position\":\"$1680\"}\n1685:{\"line\":421,\"column\":311,\"offset\":58477}\n1686:{\"line\":421,\"column\":316,\"offset\":58482}\n1684:{\"start\":\"$1685\",\"end\":\"$1686\"}\n1683:{\"type\":\"footnoteReference\",\"identifier\":\"64\",\"label\":\"64\",\"position\":\"$1684\"}\n1664:[\"$1665\",\"$1669\",\"$1672\",\"$1676\",\"$167f\",\"$1683\"]\n1688:{\"line\":421,\"column\":1,\"offset\":58167}\n1689:{\"line\":421,\"column\":316,\"offset\":58482}\n1687:{\"start\":\"$1688\",\"end\":\"$1689\"}\n1663:{\"type\":\"paragraph\",\"children\":\"$1664\",\"position\":\"$1687\"}\n168e:{\"line\":423,\"column\":4,\"offset\":58487}\n168f:{\"line\":423,\"column\":32,\"offset\":58515}\n168d:{\"start\":\"$168e\",\"end\":\"$168f\"}\n168c:{\"type\":\"text\",\"value\":\"June 2027: Self-improving AI\",\"position\":\"$168d\"}\n168b:[\"$168c\"]\n1691:{\"line\":423,\"column\":1,\"offset\":58484}\n1692:{\"line\":423,\"column\":32,\"offset\":58515}\n1690:{\"start\":\"$1691\",\"end\":\"$1692\"}\n168a:{\"type\":\"heading\",\"depth\":2,\"children\":\"$168b\",\"position\":\"$1690\"}\n1694:{}\n169a:{\"line\":426,\"column\":1,\"offset\":58533}\n169b:{\"line\":426,\"column\":11,\"offset\":58543}\n1699:{\"start\":\"$169a\",\"end\":\"$169b\"}\n1698:{\"type\":\"text\",\"value\":\"2027-06-30\",\"position\":\"$1699\"}\n169e:{\"line\":426,\"column\":11,\"offset\":58543}\n169f:{\"line\":427,\"column\":1,\"offset\":58546}\n169d:{\"start\":\"$169e\",\"end\":\"$169f\"}\n169c:{\"type\":\"break\",\"position\":\"$169d\"}\n16a2:{\"line\":"])</script><script>self.__next_f.push([1,"427,\"column\":1,\"offset\":58546}\n16a3:{\"line\":427,\"column\":5,\"offset\":58550}\n16a1:{\"start\":\"$16a2\",\"end\":\"$16a3\"}\n16a0:{\"type\":\"text\",\"value\":\"June\",\"position\":\"$16a1\"}\n1697:[\"$1698\",\"$169c\",\"$16a0\"]\n16a5:{\"line\":426,\"column\":1,\"offset\":58533}\n16a6:{\"line\":427,\"column\":7,\"offset\":58552}\n16a4:{\"start\":\"$16a5\",\"end\":\"$16a6\"}\n1696:{\"type\":\"paragraph\",\"children\":\"$1697\",\"position\":\"$16a4\"}\n1695:[\"$1696\"]\n16a8:{\"line\":425,\"column\":1,\"offset\":58517}\n16a9:{\"line\":428,\"column\":4,\"offset\":58556}\n16a7:{\"start\":\"$16a8\",\"end\":\"$16a9\"}\n1693:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$1694\",\"children\":\"$1695\",\"position\":\"$16a7\"}\n16ae:{\"line\":430,\"column\":1,\"offset\":58558}\n16af:{\"line\":430,\"column\":22,\"offset\":58579}\n16ad:{\"start\":\"$16ae\",\"end\":\"$16af\"}\n16ac:{\"type\":\"text\",\"value\":\"OpenBrain now has a “\",\"position\":\"$16ad\"}\n16b4:{\"line\":430,\"column\":23,\"offset\":58580}\n16b5:{\"line\":430,\"column\":58,\"offset\":58615}\n16b3:{\"start\":\"$16b4\",\"end\":\"$16b5\"}\n16b2:{\"type\":\"text\",\"value\":\"country of geniuses in a datacenter\",\"position\":\"$16b3\"}\n16b1:[\"$16b2\"]\n16b7:{\"line\":430,\"column\":22,\"offset\":58579}\n16b8:{\"line\":430,\"column\":141,\"offset\":58698}\n16b6:{\"start\":\"$16b7\",\"end\":\"$16b8\"}\n16b0:{\"type\":\"link\",\"title\":null,\"url\":\"https://darioamodei.com/machines-of-loving-grace#basic-assumptions-and-framework\",\"children\":\"$16b1\",\"position\":\"$16b6\"}\n16bb:{\"line\":430,\"column\":141,\"offset\":58698}\n16bc:{\"line\":430,\"column\":143,\"offset\":58700}\n16ba:{\"start\":\"$16bb\",\"end\":\"$16bc\"}\n16b9:{\"type\":\"text\",\"value\":\".”\",\"position\":\"$16ba\"}\n16ab:[\"$16ac\",\"$16b0\",\"$16b9\"]\n16be:{\"line\":430,\"column\":1,\"offset\":58558}\n16bf:{\"line\":430,\"column\":144,\"offset\":58701}\n16bd:{\"start\":\"$16be\",\"end\":\"$16bf\"}\n16aa:{\"type\":\"paragraph\",\"children\":\"$16ab\",\"position\":\"$16bd\"}\n16c4:{\"line\":432,\"column\":1,\"offset\":58703}\n16c5:{\"line\":432,\"column\":645,\"offset\":59347}\n16c3:{\"start\":\"$16c4\",\"end\":\"$16c5\"}\n16c2:{\"type\":\"text\",\"value\":\"Most of the humans at OpenBrain can’t usefully contribute anymore. Some don’t realize this and harmfully micromanage their A"])</script><script>self.__next_f.push([1,"I teams. Others sit at their computer screens, watching performance crawl up, and up, and up. The best human AI researchers are still adding value. They don’t code any more. But some of their research taste and planning ability has been hard for the models to replicate. Still, many of their ideas are useless because they lack the depth of knowledge of the AIs. For many of their research ideas, the AIs immediately respond with a report explaining that their idea was tested in-depth 3 weeks ago and found unpromising.\",\"position\":\"$16c3\"}\n16c1:[\"$16c2\"]\n16c7:{\"line\":432,\"column\":1,\"offset\":58703}\n16c8:{\"line\":432,\"column\":645,\"offset\":59347}\n16c6:{\"start\":\"$16c7\",\"end\":\"$16c8\"}\n16c0:{\"type\":\"paragraph\",\"children\":\"$16c1\",\"position\":\"$16c6\"}\n16cd:{\"line\":434,\"column\":1,\"offset\":59349}\n16ce:{\"line\":434,\"column\":344,\"offset\":59692}\n16cc:{\"start\":\"$16cd\",\"end\":\"$16ce\"}\n16cb:{\"type\":\"text\",\"value\":\"These researchers go to bed every night and wake up to another week worth of progress made mostly by the AIs. They work increasingly long hours and take shifts around the clock just to keep up with progress—the AIs never sleep or rest. They are burning themselves out, but they know that these are the last few months that their labor matters.\",\"position\":\"$16cc\"}\n16ca:[\"$16cb\"]\n16d0:{\"line\":434,\"column\":1,\"offset\":59349}\n16d1:{\"line\":434,\"column\":345,\"offset\":59693}\n16cf:{\"start\":\"$16d0\",\"end\":\"$16d1\"}\n16c9:{\"type\":\"paragraph\",\"children\":\"$16ca\",\"position\":\"$16cf\"}\n16d6:{\"line\":436,\"column\":1,\"offset\":59695}\n16d7:{\"line\":436,\"column\":85,\"offset\":59779}\n16d5:{\"start\":\"$16d6\",\"end\":\"$16d7\"}\n16d4:{\"type\":\"text\",\"value\":\"Within the silo, “Feeling the AGI” has given way to “Feeling the Superintelligence.”\",\"position\":\"$16d5\"}\n16d3:[\"$16d4\"]\n16d9:{\"line\":436,\"column\":1,\"offset\":59695}\n16da:{\"line\":436,\"column\":88,\"offset\":59782}\n16d8:{\"start\":\"$16d9\",\"end\":\"$16da\"}\n16d2:{\"type\":\"paragraph\",\"children\":\"$16d3\",\"position\":\"$16d8\"}\n16dc:{}\n16dd:[]\n16df:{\"line\":438,\"column\":1,\"offset\":59786}\n16e0:{\"line\":439,\"column\":4,\"offset"])</script><script>self.__next_f.push([1,"\":59809}\n16de:{\"start\":\"$16df\",\"end\":\"$16e0\"}\n16db:{\"type\":\"containerDirective\",\"name\":\"DeploymentCurves\",\"attributes\":\"$16dc\",\"children\":\"$16dd\",\"position\":\"$16de\"}\n16e5:{\"line\":441,\"column\":1,\"offset\":59811}\n16e6:{\"line\":441,\"column\":116,\"offset\":59926}\n16e4:{\"start\":\"$16e5\",\"end\":\"$16e6\"}\n16e3:{\"type\":\"text\",\"value\":\"OpenBrain uses specialized inference hardware to run hundreds of thousands of Agent-3 copies at high serial speeds.\",\"position\":\"$16e4\"}\n16e9:{\"line\":441,\"column\":116,\"offset\":59926}\n16ea:{\"line\":441,\"column\":121,\"offset\":59931}\n16e8:{\"start\":\"$16e9\",\"end\":\"$16ea\"}\n16e7:{\"type\":\"footnoteReference\",\"identifier\":\"65\",\"label\":\"65\",\"position\":\"$16e8\"}\n16e2:[\"$16e3\",\"$16e7\"]\n16ec:{\"line\":441,\"column\":1,\"offset\":59811}\n16ed:{\"line\":441,\"column\":121,\"offset\":59931}\n16eb:{\"start\":\"$16ec\",\"end\":\"$16ed\"}\n16e1:{\"type\":\"paragraph\",\"children\":\"$16e2\",\"position\":\"$16eb\"}\n16f4:{\"line\":447,\"column\":1,\"offset\":59976}\n16f5:{\"line\":447,\"column\":572,\"offset\":60547}\n16f3:{\"start\":\"$16f4\",\"end\":\"$16f5\"}\n16f2:{\"type\":\"text\",\"value\":\"OpenBrain uses 6% of their compute to run 250,000 Agent-3 copies, which autonomously write, test, and push code at superhuman speed. They use 25% of their compute for experiments: every day, they run massive numbers of small machine learning experiments and report the results up the chain. Human researchers provide high-level feedback and help with the few tasks where they add significant value on top of Agent-3, but spend most of their time trying to stay on top of the vast amount of AI-produced research. If you removed them completely, research would slow by 50%.\",\"position\":\"$16f3\"}\n16f1:[\"$16f2\"]\n16f7:{\"line\":447,\"column\":1,\"offset\":59976}\n16f8:{\"line\":447,\"column\":572,\"offset\":60547}\n16f6:{\"start\":\"$16f7\",\"end\":\"$16f8\"}\n16f0:{\"type\":\"paragraph\",\"children\":\"$16f1\",\"position\":\"$16f6\"}\n16fd:{\"line\":449,\"column\":1,\"offset\":60549}\n16fe:{\"line\":449,\"column\":266,\"offset\":60814}\n16fc:{\"start\":\"$16fd\",\"end\":\"$16fe\"}\n16fb:{\"type\":\"text\",\"value\":\"The AI R\u0026D progress multiplier is now 10x, meaning "])</script><script>self.__next_f.push([1,"that OpenBrain is making about a year of algorithmic progress every month. It’s basically a giant corporation of AIs operating autonomously within OpenBrain, complete with subdivisions and managers. And it enjoys \",\"position\":\"$16fc\"}\n1703:{\"line\":449,\"column\":267,\"offset\":60815}\n1704:{\"line\":449,\"column\":284,\"offset\":60832}\n1702:{\"start\":\"$1703\",\"end\":\"$1704\"}\n1701:{\"type\":\"text\",\"value\":\"unique advantages\",\"position\":\"$1702\"}\n1700:[\"$1701\"]\n1706:{\"line\":449,\"column\":266,\"offset\":60814}\n1707:{\"line\":449,\"column\":326,\"offset\":60874}\n1705:{\"start\":\"$1706\",\"end\":\"$1707\"}\n16ff:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.dwarkeshpatel.com/p/ai-firm\",\"children\":\"$1700\",\"position\":\"$1705\"}\n170a:{\"line\":449,\"column\":326,\"offset\":60874}\n170b:{\"line\":449,\"column\":658,\"offset\":61206}\n1709:{\"start\":\"$170a\",\"end\":\"$170b\"}\n1708:{\"type\":\"text\",\"value\":\" (e.g. copying, merging) compared to human corporations. Previously, about half of normal AI progress came from algorithmic improvements, and the other half from compute scaling. Compute is only scaling at the normal speed, so total progress is sped up by AIs by about 5x. These dynamics make overall progress bottleneck on compute,\",\"position\":\"$1709\"}\n170e:{\"line\":449,\"column\":658,\"offset\":61206}\n170f:{\"line\":449,\"column\":663,\"offset\":61211}\n170d:{\"start\":\"$170e\",\"end\":\"$170f\"}\n170c:{\"type\":\"footnoteReference\",\"identifier\":\"66\",\"label\":\"66\",\"position\":\"$170d\"}\n1712:{\"line\":449,\"column\":663,\"offset\":61211}\n1713:{\"line\":449,\"column\":788,\"offset\":61336}\n1711:{\"start\":\"$1712\",\"end\":\"$1713\"}\n1710:{\"type\":\"text\",\"value\":\" so OpenBrain decides against starting new giant training runs in favor of near-continuous additional reinforcement learning.\",\"position\":\"$1711\"}\n16fa:[\"$16fb\",\"$16ff\",\"$1708\",\"$170c\",\"$1710\"]\n1715:{\"line\":449,\"column\":1,\"offset\":60549}\n1716:{\"line\":449,\"column\":788,\"offset\":61336}\n1714:{\"start\":\"$1715\",\"end\":\"$1716\"}\n16f9:{\"type\":\"paragraph\",\"children\":\"$16fa\",\"position\":\"$1714\"}\n171b:{\"line\":451,\"column\":1,\"offset\":61338}\n171c:{\"line\":451,\"column\":551,\"offset\""])</script><script>self.__next_f.push([1,":61888}\n171a:{\"start\":\"$171b\",\"end\":\"$171c\"}\n1719:{\"type\":\"text\",\"value\":\"Also, over the next few months, Agent-3 will increasingly be used to improve the company’s strategic decision-making. For example, it suggests resource allocations and advises on managing its relationship with the government. An initial skepticism of deference to Agent-3 decreases over time as Agent-3 finds ways to be useful and gradually builds up a strong track record on short-term decisions. However, its sycophantic tendencies limit its helpfulness for decisions for which it’s difficult to evaluate their impact. It’s also not yet superhuman.\",\"position\":\"$171a\"}\n1718:[\"$1719\"]\n171e:{\"line\":451,\"column\":1,\"offset\":61338}\n171f:{\"line\":451,\"column\":551,\"offset\":61888}\n171d:{\"start\":\"$171e\",\"end\":\"$171f\"}\n1717:{\"type\":\"paragraph\",\"children\":\"$1718\",\"position\":\"$171d\"}\n16ef:[\"$16f0\",\"$16f9\",\"$1717\"]\n16ee:{\"type\":\"details\",\"summary\":\"Managing a corporation of AIs\",\"children\":\"$16ef\"}\n1724:{\"line\":455,\"column\":4,\"offset\":61898}\n1725:{\"line\":455,\"column\":38,\"offset\":61932}\n1723:{\"start\":\"$1724\",\"end\":\"$1725\"}\n1722:{\"type\":\"text\",\"value\":\"July 2027: The Cheap Remote Worker\",\"position\":\"$1723\"}\n1721:[\"$1722\"]\n1727:{\"line\":455,\"column\":1,\"offset\":61895}\n1728:{\"line\":455,\"column\":38,\"offset\":61932}\n1726:{\"start\":\"$1727\",\"end\":\"$1728\"}\n1720:{\"type\":\"heading\",\"depth\":2,\"children\":\"$1721\",\"position\":\"$1726\"}\n172a:{}\n1730:{\"line\":458,\"column\":1,\"offset\":61950}\n1731:{\"line\":458,\"column\":11,\"offset\":61960}\n172f:{\"start\":\"$1730\",\"end\":\"$1731\"}\n172e:{\"type\":\"text\",\"value\":\"2027-07-31\",\"position\":\"$172f\"}\n1734:{\"line\":458,\"column\":11,\"offset\":61960}\n1735:{\"line\":459,\"column\":1,\"offset\":61963}\n1733:{\"start\":\"$1734\",\"end\":\"$1735\"}\n1732:{\"type\":\"break\",\"position\":\"$1733\"}\n1738:{\"line\":459,\"column\":1,\"offset\":61963}\n1739:{\"line\":459,\"column\":4,\"offset\":61966}\n1737:{\"start\":\"$1738\",\"end\":\"$1739\"}\n1736:{\"type\":\"text\",\"value\":\"Jul\",\"position\":\"$1737\"}\n172d:[\"$172e\",\"$1732\",\"$1736\"]\n173b:{\"line\":458,\"column\":1,\"offset\":61950}\n173c:{\"line\":459,\"column\":6,\"offse"])</script><script>self.__next_f.push([1,"t\":61968}\n173a:{\"start\":\"$173b\",\"end\":\"$173c\"}\n172c:{\"type\":\"paragraph\",\"children\":\"$172d\",\"position\":\"$173a\"}\n172b:[\"$172c\"]\n173e:{\"line\":457,\"column\":1,\"offset\":61934}\n173f:{\"line\":460,\"column\":4,\"offset\":61972}\n173d:{\"start\":\"$173e\",\"end\":\"$173f\"}\n1729:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$172a\",\"children\":\"$172b\",\"position\":\"$173d\"}\n1744:{\"line\":462,\"column\":1,\"offset\":61974}\n1745:{\"line\":462,\"column\":315,\"offset\":62288}\n1743:{\"start\":\"$1744\",\"end\":\"$1745\"}\n1742:{\"type\":\"text\",\"value\":\"Trailing U.S. AI companies release their own AIs, approaching that of OpenBrain’s automated coder from January. Recognizing their increasing lack of competitiveness, they push for immediate regulations to slow OpenBrain, but are too late—OpenBrain has enough buy-in from the President that they will not be slowed.\",\"position\":\"$1743\"}\n1741:[\"$1742\"]\n1747:{\"line\":462,\"column\":1,\"offset\":61974}\n1748:{\"line\":462,\"column\":316,\"offset\":62289}\n1746:{\"start\":\"$1747\",\"end\":\"$1748\"}\n1740:{\"type\":\"paragraph\",\"children\":\"$1741\",\"position\":\"$1746\"}\n174d:{\"line\":464,\"column\":1,\"offset\":62291}\n174e:{\"line\":464,\"column\":100,\"offset\":62390}\n174c:{\"start\":\"$174d\",\"end\":\"$174e\"}\n174b:{\"type\":\"text\",\"value\":\"In response, OpenBrain announces that they’ve achieved AGI and releases Agent-3-mini to the public.\",\"position\":\"$174c\"}\n174a:[\"$174b\"]\n1750:{\"line\":464,\"column\":1,\"offset\":62291}\n1751:{\"line\":464,\"column\":103,\"offset\":62393}\n174f:{\"start\":\"$1750\",\"end\":\"$1751\"}\n1749:{\"type\":\"paragraph\",\"children\":\"$174a\",\"position\":\"$174f\"}\n1756:{\"line\":466,\"column\":1,\"offset\":62397}\n1757:{\"line\":466,\"column\":36,\"offset\":62432}\n1755:{\"start\":\"$1756\",\"end\":\"$1757\"}\n1754:{\"type\":\"image\",\"title\":null,\"url\":\"/epochLLMprice-nowatermark.png\",\"alt\":\"\",\"position\":\"$1755\"}\n1753:[\"$1754\"]\n1759:{\"line\":466,\"column\":1,\"offset\":62397}\n175a:{\"line\":466,\"column\":36,\"offset\":62432}\n1758:{\"start\":\"$1759\",\"end\":\"$175a\"}\n1752:{\"type\":\"paragraph\",\"children\":\"$1753\",\"position\":\"$1758\"}\n175f:{\"line\":468,\"column\":1,\"offset\":62434}\n1760:{\"line\":468,\"c"])</script><script>self.__next_f.push([1,"olumn\":155,\"offset\":62588}\n175e:{\"start\":\"$175f\",\"end\":\"$1760\"}\n175d:{\"type\":\"text\",\"value\":\"It blows the other AIs out of the water. Agent-3-mini is less capable than Agent-3, but 10x cheaper, and still better than the typical OpenBrain employee.\",\"position\":\"$175e\"}\n1763:{\"line\":468,\"column\":155,\"offset\":62588}\n1764:{\"line\":468,\"column\":160,\"offset\":62593}\n1762:{\"start\":\"$1763\",\"end\":\"$1764\"}\n1761:{\"type\":\"footnoteReference\",\"identifier\":\"67\",\"label\":\"67\",\"position\":\"$1762\"}\n1767:{\"line\":468,\"column\":160,\"offset\":62593}\n1768:{\"line\":468,\"column\":533,\"offset\":62966}\n1766:{\"start\":\"$1767\",\"end\":\"$1768\"}\n1765:{\"type\":\"text\",\"value\":\" Silicon Valley reaches a tipping point. Tech gurus announce that AGI and superintelligence are near, the AI safety community is panicking, and investors shovel billions into AI wrapper startups, desperate to capture a piece of the pie. Hiring new programmers has nearly stopped, but there’s never been a better time to be a consultant on integrating AI into your business.\",\"position\":\"$1766\"}\n175c:[\"$175d\",\"$1761\",\"$1765\"]\n176a:{\"line\":468,\"column\":1,\"offset\":62434}\n176b:{\"line\":468,\"column\":534,\"offset\":62967}\n1769:{\"start\":\"$176a\",\"end\":\"$176b\"}\n175b:{\"type\":\"paragraph\",\"children\":\"$175c\",\"position\":\"$1769\"}\n1770:{\"line\":470,\"column\":1,\"offset\":62969}\n1771:{\"line\":470,\"column\":173,\"offset\":63141}\n176f:{\"start\":\"$1770\",\"end\":\"$1771\"}\n176e:{\"type\":\"text\",\"value\":\"It’s not popular. The public still thinks of AI as a Big Tech plot to steal their jobs; OpenBrain has a net approval of -35% (25% approve, 60% disapprove, and 15% unsure).\",\"position\":\"$176f\"}\n176d:[\"$176e\"]\n1773:{\"line\":470,\"column\":1,\"offset\":62969}\n1774:{\"line\":470,\"column\":173,\"offset\":63141}\n1772:{\"start\":\"$1773\",\"end\":\"$1774\"}\n176c:{\"type\":\"paragraph\",\"children\":\"$176d\",\"position\":\"$1772\"}\n1779:{\"line\":472,\"column\":1,\"offset\":63143}\n177a:{\"line\":472,\"column\":245,\"offset\":63387}\n1778:{\"start\":\"$1779\",\"end\":\"$177a\"}\n1777:{\"type\":\"text\",\"value\":\"A week before release, OpenBrain gave Agent-3-mini to a set of external eval"])</script><script>self.__next_f.push([1,"uators for safety testing. Preliminary results suggest that it’s extremely dangerous. A third-party evaluator finetunes it on publicly available biological weapons data\",\"position\":\"$1778\"}\n177d:{\"line\":472,\"column\":245,\"offset\":63387}\n177e:{\"line\":472,\"column\":250,\"offset\":63392}\n177c:{\"start\":\"$177d\",\"end\":\"$177e\"}\n177b:{\"type\":\"footnoteReference\",\"identifier\":\"68\",\"label\":\"68\",\"position\":\"$177c\"}\n1781:{\"line\":472,\"column\":250,\"offset\":63392}\n1782:{\"line\":472,\"column\":529,\"offset\":63671}\n1780:{\"start\":\"$1781\",\"end\":\"$1782\"}\n177f:{\"type\":\"text\",\"value\":\" and sets it to provide detailed instructions for human amateurs designing a bioweapon—it looks to be scarily effective at doing so. If the model weights fell into terrorist hands, the government believes there is a significant chance it could succeed at destroying civilization.\",\"position\":\"$1780\"}\n1776:[\"$1777\",\"$177b\",\"$177f\"]\n1784:{\"line\":472,\"column\":1,\"offset\":63143}\n1785:{\"line\":472,\"column\":530,\"offset\":63672}\n1783:{\"start\":\"$1784\",\"end\":\"$1785\"}\n1775:{\"type\":\"paragraph\",\"children\":\"$1776\",\"position\":\"$1783\"}\n178a:{\"line\":474,\"column\":1,\"offset\":63674}\n178b:{\"line\":474,\"column\":153,\"offset\":63826}\n1789:{\"start\":\"$178a\",\"end\":\"$178b\"}\n1788:{\"type\":\"text\",\"value\":\"Fortunately, it’s extremely robust to jailbreaks, so while the AI is running on OpenBrain’s servers, terrorists won’t be able to get much use out of it.\",\"position\":\"$1789\"}\n1787:[\"$1788\"]\n178d:{\"line\":474,\"column\":1,\"offset\":63674}\n178e:{\"line\":474,\"column\":153,\"offset\":63826}\n178c:{\"start\":\"$178d\",\"end\":\"$178e\"}\n1786:{\"type\":\"paragraph\",\"children\":\"$1787\",\"position\":\"$178c\"}\n1793:{\"line\":476,\"column\":1,\"offset\":63828}\n1794:{\"line\":476,\"column\":99,\"offset\":63926}\n1792:{\"start\":\"$1793\",\"end\":\"$1794\"}\n1791:{\"type\":\"text\",\"value\":\"Agent-3-mini is hugely useful for both remote work jobs and leisure. An explosion of new apps and \",\"position\":\"$1792\"}\n1799:{\"line\":476,\"column\":100,\"offset\":63927}\n179a:{\"line\":476,\"column\":108,\"offset\":63935}\n1798:{\"start\":\"$1799\",\"end\":\"$179a\"}\n1797:{\"type\":\""])</script><script>self.__next_f.push([1,"text\",\"value\":\"B2B SAAS\",\"position\":\"$1798\"}\n1796:[\"$1797\"]\n179c:{\"line\":476,\"column\":99,\"offset\":63926}\n179d:{\"line\":476,\"column\":148,\"offset\":63975}\n179b:{\"start\":\"$179c\",\"end\":\"$179d\"}\n1795:{\"type\":\"link\",\"title\":null,\"url\":\"https://encharge.io/what-is-b2b-saas/\",\"children\":\"$1796\",\"position\":\"$179b\"}\n17a0:{\"line\":476,\"column\":148,\"offset\":63975}\n17a1:{\"line\":476,\"column\":474,\"offset\":64301}\n179f:{\"start\":\"$17a0\",\"end\":\"$17a1\"}\n179e:{\"type\":\"text\",\"value\":\" products rocks the market. Gamers get amazing dialogue with lifelike characters in polished video games that took only a month to make. 10% of Americans, mostly young people, consider an AI “a close friend.” For almost every white-collar profession, there are now multiple credible startups promising to “disrupt” it with AI.\",\"position\":\"$179f\"}\n1790:[\"$1791\",\"$1795\",\"$179e\"]\n17a3:{\"line\":476,\"column\":1,\"offset\":63828}\n17a4:{\"line\":476,\"column\":474,\"offset\":64301}\n17a2:{\"start\":\"$17a3\",\"end\":\"$17a4\"}\n178f:{\"type\":\"paragraph\",\"children\":\"$1790\",\"position\":\"$17a2\"}\n17a9:{\"line\":478,\"column\":1,\"offset\":64303}\n17aa:{\"line\":478,\"column\":224,\"offset\":64526}\n17a8:{\"start\":\"$17a9\",\"end\":\"$17aa\"}\n17a7:{\"type\":\"text\",\"value\":\"The public conversation is confused and chaotic. Hypesters are doing victory laps. Skeptics are still pointing out the things Agent-3-mini can’t do. Everyone knows something big is happening but no one agrees on what it is.\",\"position\":\"$17a8\"}\n17a6:[\"$17a7\"]\n17ac:{\"line\":478,\"column\":1,\"offset\":64303}\n17ad:{\"line\":478,\"column\":224,\"offset\":64526}\n17ab:{\"start\":\"$17ac\",\"end\":\"$17ad\"}\n17a5:{\"type\":\"paragraph\",\"children\":\"$17a6\",\"position\":\"$17ab\"}\n17b2:{\"line\":480,\"column\":4,\"offset\":64531}\n17b3:{\"line\":480,\"column\":53,\"offset\":64580}\n17b1:{\"start\":\"$17b2\",\"end\":\"$17b3\"}\n17b0:{\"type\":\"text\",\"value\":\"August 2027: The Geopolitics of Superintelligence\",\"position\":\"$17b1\"}\n17af:[\"$17b0\"]\n17b5:{\"line\":480,\"column\":1,\"offset\":64528}\n17b6:{\"line\":480,\"column\":53,\"offset\":64580}\n17b4:{\"start\":\"$17b5\",\"end\":\"$17b6\"}\n17ae:{\"type\":\"heading\",\"depth\""])</script><script>self.__next_f.push([1,":2,\"children\":\"$17af\",\"position\":\"$17b4\"}\n17b8:{}\n17be:{\"line\":483,\"column\":1,\"offset\":64598}\n17bf:{\"line\":483,\"column\":11,\"offset\":64608}\n17bd:{\"start\":\"$17be\",\"end\":\"$17bf\"}\n17bc:{\"type\":\"text\",\"value\":\"2027-08-31\",\"position\":\"$17bd\"}\n17c2:{\"line\":483,\"column\":11,\"offset\":64608}\n17c3:{\"line\":484,\"column\":1,\"offset\":64611}\n17c1:{\"start\":\"$17c2\",\"end\":\"$17c3\"}\n17c0:{\"type\":\"break\",\"position\":\"$17c1\"}\n17c6:{\"line\":484,\"column\":1,\"offset\":64611}\n17c7:{\"line\":484,\"column\":4,\"offset\":64614}\n17c5:{\"start\":\"$17c6\",\"end\":\"$17c7\"}\n17c4:{\"type\":\"text\",\"value\":\"Aug\",\"position\":\"$17c5\"}\n17bb:[\"$17bc\",\"$17c0\",\"$17c4\"]\n17c9:{\"line\":483,\"column\":1,\"offset\":64598}\n17ca:{\"line\":484,\"column\":6,\"offset\":64616}\n17c8:{\"start\":\"$17c9\",\"end\":\"$17ca\"}\n17ba:{\"type\":\"paragraph\",\"children\":\"$17bb\",\"position\":\"$17c8\"}\n17b9:[\"$17ba\"]\n17cc:{\"line\":482,\"column\":1,\"offset\":64582}\n17cd:{\"line\":485,\"column\":4,\"offset\":64620}\n17cb:{\"start\":\"$17cc\",\"end\":\"$17cd\"}\n17b7:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$17b8\",\"children\":\"$17b9\",\"position\":\"$17cb\"}\n17d2:{\"line\":487,\"column\":1,\"offset\":64622}\n17d3:{\"line\":487,\"column\":64,\"offset\":64685}\n17d1:{\"start\":\"$17d2\",\"end\":\"$17d3\"}\n17d0:{\"type\":\"text\",\"value\":\"The reality of the intelligence explosion hits the White House.\",\"position\":\"$17d1\"}\n17cf:[\"$17d0\"]\n17d5:{\"line\":487,\"column\":1,\"offset\":64622}\n17d6:{\"line\":487,\"column\":65,\"offset\":64686}\n17d4:{\"start\":\"$17d5\",\"end\":\"$17d6\"}\n17ce:{\"type\":\"paragraph\",\"children\":\"$17cf\",\"position\":\"$17d4\"}\n17db:{\"line\":489,\"column\":1,\"offset\":64688}\n17dc:{\"line\":489,\"column\":908,\"offset\":65595}\n17da:{\"start\":\"$17db\",\"end\":\"$17dc\"}\n17d9:{\"type\":\"text\",\"value\":\"When AI was only giving a 2x or 3x research speedup, it was easy to dismiss as the equivalent of hiring good personal assistants. Now it’s more obvious that AIs are themselves dominating AI research. People had long talked about an “AI arms race” in a sort of metaphorical sense. But now the mood in the government silo is as grim as during the worst part of the Cold War. The idea of"])</script><script>self.__next_f.push([1," superintelligence is still hard to take seriously, but the pace of progress over the last few months has been impossible to ignore. Defense officials are seriously considering scenarios that were mere hypotheticals a year earlier. What if AI undermines nuclear deterrence? What if it’s so skilled at cyberwarfare that a six-month AI lead is enough to render an opponent blind and defenseless? What if it could orchestrate propaganda campaigns that beat intelligence agencies at their own game? What if some AIs “go rogue?”\",\"position\":\"$17da\"}\n17d8:[\"$17d9\"]\n17de:{\"line\":489,\"column\":1,\"offset\":64688}\n17df:{\"line\":489,\"column\":908,\"offset\":65595}\n17dd:{\"start\":\"$17de\",\"end\":\"$17df\"}\n17d7:{\"type\":\"paragraph\",\"children\":\"$17d8\",\"position\":\"$17dd\"}\n17e4:{\"line\":491,\"column\":1,\"offset\":65597}\n17e5:{\"line\":491,\"column\":185,\"offset\":65781}\n17e3:{\"start\":\"$17e4\",\"end\":\"$17e5\"}\n17e2:{\"type\":\"text\",\"value\":\"The President is troubled. Like all politicians, he’s used to people sucking up to him only to betray him later. He’s worried now that the AIs could be doing something similar. Are we \",\"position\":\"$17e3\"}\n17ea:{\"line\":491,\"column\":186,\"offset\":65782}\n17eb:{\"line\":491,\"column\":190,\"offset\":65786}\n17e9:{\"start\":\"$17ea\",\"end\":\"$17eb\"}\n17e8:{\"type\":\"text\",\"value\":\"sure\",\"position\":\"$17e9\"}\n17e7:[\"$17e8\"]\n17ed:{\"line\":491,\"column\":185,\"offset\":65781}\n17ee:{\"line\":491,\"column\":191,\"offset\":65787}\n17ec:{\"start\":\"$17ed\",\"end\":\"$17ee\"}\n17e6:{\"type\":\"emphasis\",\"children\":\"$17e7\",\"position\":\"$17ec\"}\n17f1:{\"line\":491,\"column\":191,\"offset\":65787}\n17f2:{\"line\":491,\"column\":232,\"offset\":65828}\n17f0:{\"start\":\"$17f1\",\"end\":\"$17f2\"}\n17ef:{\"type\":\"text\",\"value\":\" the AIs are entirely on our side? Is it \",\"position\":\"$17f0\"}\n17f7:{\"line\":491,\"column\":233,\"offset\":65829}\n17f8:{\"line\":491,\"column\":248,\"offset\":65844}\n17f6:{\"start\":\"$17f7\",\"end\":\"$17f8\"}\n17f5:{\"type\":\"text\",\"value\":\"completely safe\",\"position\":\"$17f6\"}\n17f4:[\"$17f5\"]\n17fa:{\"line\":491,\"column\":232,\"offset\":65828}\n17fb:{\"line\":491,\"column\":249,\"offset\":65845}\n17f9:{\"star"])</script><script>self.__next_f.push([1,"t\":\"$17fa\",\"end\":\"$17fb\"}\n17f3:{\"type\":\"emphasis\",\"children\":\"$17f4\",\"position\":\"$17f9\"}\n17fe:{\"line\":491,\"column\":249,\"offset\":65845}\n17ff:{\"line\":491,\"column\":311,\"offset\":65907}\n17fd:{\"start\":\"$17fe\",\"end\":\"$17ff\"}\n17fc:{\"type\":\"text\",\"value\":\" to integrate them into military command-and-control networks?\",\"position\":\"$17fd\"}\n1802:{\"line\":491,\"column\":311,\"offset\":65907}\n1803:{\"line\":491,\"column\":316,\"offset\":65912}\n1801:{\"start\":\"$1802\",\"end\":\"$1803\"}\n1800:{\"type\":\"footnoteReference\",\"identifier\":\"69\",\"label\":\"69\",\"position\":\"$1801\"}\n1806:{\"line\":491,\"column\":316,\"offset\":65912}\n1807:{\"line\":491,\"column\":565,\"offset\":66161}\n1805:{\"start\":\"$1806\",\"end\":\"$1807\"}\n1804:{\"type\":\"text\",\"value\":\" How does this “alignment” thing work, anyway? OpenBrain reassures the President that their systems have been extensively tested and are fully obedient. Even the awkward hallucinations and jailbreaks typical of earlier models have been hammered out.\",\"position\":\"$1805\"}\n17e1:[\"$17e2\",\"$17e6\",\"$17ef\",\"$17f3\",\"$17fc\",\"$1800\",\"$1804\"]\n1809:{\"line\":491,\"column\":1,\"offset\":65597}\n180a:{\"line\":491,\"column\":565,\"offset\":66161}\n1808:{\"start\":\"$1809\",\"end\":\"$180a\"}\n17e0:{\"type\":\"paragraph\",\"children\":\"$17e1\",\"position\":\"$1808\"}\n180f:{\"line\":493,\"column\":1,\"offset\":66163}\n1810:{\"line\":493,\"column\":172,\"offset\":66334}\n180e:{\"start\":\"$180f\",\"end\":\"$1810\"}\n180d:{\"type\":\"text\",\"value\":\"The White House is in a difficult position. They understand the national security implications of AI. But they also understand that it is deeply unpopular with the public.\",\"position\":\"$180e\"}\n1813:{\"line\":493,\"column\":172,\"offset\":66334}\n1814:{\"line\":493,\"column\":177,\"offset\":66339}\n1812:{\"start\":\"$1813\",\"end\":\"$1814\"}\n1811:{\"type\":\"footnoteReference\",\"identifier\":\"70\",\"label\":\"70\",\"position\":\"$1812\"}\n1817:{\"line\":493,\"column\":177,\"offset\":66339}\n1818:{\"line\":493,\"column\":892,\"offset\":67054}\n1816:{\"start\":\"$1817\",\"end\":\"$1818\"}\n1815:{\"type\":\"text\",\"value\":\" They have to continue developing more capable AI, in their eyes, or they will catastrophically l"])</script><script>self.__next_f.push([1,"ose to China. They placate the public with job training programs and unemployment insurance, and point to the stock market, which is in a historic boom. Then they focus entirely on winning the arms race. They strengthen chip export restrictions, order OpenBrain to further restrict its internet connections, and use extreme measures to secure algorithmic progress, like wiretapping OpenBrain employees—this catches the last remaining Chinese spy. To build goodwill for potential geopolitical conflict, they finally give their Five Eyes allies useful information and limited API access to some siloed copies of Agent-3.\",\"position\":\"$1816\"}\n180c:[\"$180d\",\"$1811\",\"$1815\"]\n181a:{\"line\":493,\"column\":1,\"offset\":66163}\n181b:{\"line\":493,\"column\":892,\"offset\":67054}\n1819:{\"start\":\"$181a\",\"end\":\"$181b\"}\n180b:{\"type\":\"paragraph\",\"children\":\"$180c\",\"position\":\"$1819\"}\n1820:{\"line\":495,\"column\":1,\"offset\":67056}\n1821:{\"line\":495,\"column\":168,\"offset\":67223}\n181f:{\"start\":\"$1820\",\"end\":\"$1821\"}\n181e:{\"type\":\"text\",\"value\":\"These measures placate the hawks. But the White House also draws up contingency plans in case America’s lead is threatened: if necessary, the government could use the \",\"position\":\"$181f\"}\n1826:{\"line\":495,\"column\":169,\"offset\":67224}\n1827:{\"line\":495,\"column\":191,\"offset\":67246}\n1825:{\"start\":\"$1826\",\"end\":\"$1827\"}\n1824:{\"type\":\"text\",\"value\":\"Defense Production Act\",\"position\":\"$1825\"}\n1823:[\"$1824\"]\n1829:{\"line\":495,\"column\":168,\"offset\":67223}\n182a:{\"line\":495,\"column\":254,\"offset\":67309}\n1828:{\"start\":\"$1829\",\"end\":\"$182a\"}\n1822:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Defense_Production_Act_of_1950\",\"children\":\"$1823\",\"position\":\"$1828\"}\n182d:{\"line\":495,\"column\":254,\"offset\":67309}\n182e:{\"line\":495,\"column\":328,\"offset\":67383}\n182c:{\"start\":\"$182d\",\"end\":\"$182e\"}\n182b:{\"type\":\"text\",\"value\":\" (DPA) to take trailing companies’ datacenters and give them to OpenBrain.\",\"position\":\"$182c\"}\n1831:{\"line\":495,\"column\":328,\"offset\":67383}\n1832:{\"line\":495,\"column\":333,\"offset\":67388}\n18"])</script><script>self.__next_f.push([1,"30:{\"start\":\"$1831\",\"end\":\"$1832\"}\n182f:{\"type\":\"footnoteReference\",\"identifier\":\"71\",\"label\":\"71\",\"position\":\"$1830\"}\n1835:{\"line\":495,\"column\":333,\"offset\":67388}\n1836:{\"line\":495,\"column\":532,\"offset\":67587}\n1834:{\"start\":\"$1835\",\"end\":\"$1836\"}\n1833:{\"type\":\"text\",\"value\":\" This would raise the company’s share of world compute from 20% to 50% (against DeepCent’s 10%). As a final option, they ask the Pentagon to draw up a plan for kinetic attacks on Chinese datacenters.\",\"position\":\"$1834\"}\n181d:[\"$181e\",\"$1822\",\"$182b\",\"$182f\",\"$1833\"]\n1838:{\"line\":495,\"column\":1,\"offset\":67056}\n1839:{\"line\":495,\"column\":532,\"offset\":67587}\n1837:{\"start\":\"$1838\",\"end\":\"$1839\"}\n181c:{\"type\":\"paragraph\",\"children\":\"$181d\",\"position\":\"$1837\"}\n183e:{\"line\":497,\"column\":1,\"offset\":67589}\n183f:{\"line\":497,\"column\":313,\"offset\":67901}\n183d:{\"start\":\"$183e\",\"end\":\"$183f\"}\n183c:{\"type\":\"text\",\"value\":\"A much smaller group of officials is asked to draw up a different type of contingency plan: what if an AI goes rogue? This is viewed as an unlikely scenario, but worth spending some time on. The intelligence agencies’ main concern is that a rogue AI might escape and ally with a foreign adversary for protection.\",\"position\":\"$183d\"}\n1842:{\"line\":497,\"column\":313,\"offset\":67901}\n1843:{\"line\":497,\"column\":318,\"offset\":67906}\n1841:{\"start\":\"$1842\",\"end\":\"$1843\"}\n1840:{\"type\":\"footnoteReference\",\"identifier\":\"72\",\"label\":\"72\",\"position\":\"$1841\"}\n1846:{\"line\":497,\"column\":318,\"offset\":67906}\n1847:{\"line\":497,\"column\":515,\"offset\":68103}\n1845:{\"start\":\"$1846\",\"end\":\"$1847\"}\n1844:{\"type\":\"text\",\"value\":\" Nobody is sure what a plan to prevent this would look like, but government and OpenBrain officials agree to have an emergency shutdown system for datacenters where anything suspicious is detected.\",\"position\":\"$1845\"}\n183b:[\"$183c\",\"$1840\",\"$1844\"]\n1849:{\"line\":497,\"column\":1,\"offset\":67589}\n184a:{\"line\":497,\"column\":515,\"offset\":68103}\n1848:{\"start\":\"$1849\",\"end\":\"$184a\"}\n183a:{\"type\":\"paragraph\",\"children\":\"$183b\",\"position\":\"$1848\"}\n184f"])</script><script>self.__next_f.push([1,":{\"line\":499,\"column\":1,\"offset\":68105}\n1850:{\"line\":499,\"column\":705,\"offset\":68809}\n184e:{\"start\":\"$184f\",\"end\":\"$1850\"}\n184d:{\"type\":\"text\",\"value\":\"Finally, diplomats consider what an “AI arms control” treaty might look like. If AI progress threatened to overturn nuclear deterrence, could America and China avoid nuclear war? If someone found evidence of AIs going rogue, could the two countries halt research until they better understood the threat? How could such an agreement be monitored and enforced? In principle, major datacenters are hard to miss, and past treaties controlling nuclear weapons could provide a starting point for negotiations. But there would be new technological challenges as well as the usual political ones. And overall, treaties are viewed less favorably than attempts at unilaterally increasing America’s lead over China.\",\"position\":\"$184e\"}\n184c:[\"$184d\"]\n1852:{\"line\":499,\"column\":1,\"offset\":68105}\n1853:{\"line\":499,\"column\":705,\"offset\":68809}\n1851:{\"start\":\"$1852\",\"end\":\"$1853\"}\n184b:{\"type\":\"paragraph\",\"children\":\"$184c\",\"position\":\"$1851\"}\n1858:{\"line\":501,\"column\":1,\"offset\":68811}\n1859:{\"line\":501,\"column\":529,\"offset\":69339}\n1857:{\"start\":\"$1858\",\"end\":\"$1859\"}\n1856:{\"type\":\"text\",\"value\":\"On the other side of the Pacific, China comes to many of the same conclusions: the intelligence explosion is underway, and small differences in AI capabilities today mean critical gaps in military capability tomorrow. But China is on the wrong side of this dynamic: they have only 10% of the world’s compute, against OpenBrain’s 20% and all U.S. companies’ combined 70%. Their only advantage is centralization: almost all of their compute is now working for DeepCent, and more than half of it is concentrated at the Tianwan CDZ.\",\"position\":\"$1857\"}\n185c:{\"line\":501,\"column\":529,\"offset\":69339}\n185d:{\"line\":501,\"column\":534,\"offset\":69344}\n185b:{\"start\":\"$185c\",\"end\":\"$185d\"}\n185a:{\"type\":\"footnoteReference\",\"identifier\":\"73\",\"label\":\"73\",\"position\":\"$185b\"}\n1860:{\"line\":501,\"column\":534,\"of"])</script><script>self.__next_f.push([1,"fset\":69344}\n1861:{\"line\":501,\"column\":659,\"offset\":69469}\n185f:{\"start\":\"$1860\",\"end\":\"$1861\"}\n185e:{\"type\":\"text\",\"value\":\" Only chips at sites without hardened security are left out of the centralized effort as they rightly fear U.S. cyberattacks.\",\"position\":\"$185f\"}\n1855:[\"$1856\",\"$185a\",\"$185e\"]\n1863:{\"line\":501,\"column\":1,\"offset\":68811}\n1864:{\"line\":501,\"column\":660,\"offset\":69470}\n1862:{\"start\":\"$1863\",\"end\":\"$1864\"}\n1854:{\"type\":\"paragraph\",\"children\":\"$1855\",\"position\":\"$1862\"}\n1869:{\"line\":503,\"column\":1,\"offset\":69472}\n186a:{\"line\":503,\"column\":176,\"offset\":69647}\n1868:{\"start\":\"$1869\",\"end\":\"$186a\"}\n1867:{\"type\":\"text\",\"value\":\"DeepCent has tested, deployed, and now post-trained the stolen Agent-2 weights. But they are still only going at half the pace of OpenBrain, mainly due to the compute deficit.\",\"position\":\"$1868\"}\n1866:[\"$1867\"]\n186c:{\"line\":503,\"column\":1,\"offset\":69472}\n186d:{\"line\":503,\"column\":176,\"offset\":69647}\n186b:{\"start\":\"$186c\",\"end\":\"$186d\"}\n1865:{\"type\":\"paragraph\",\"children\":\"$1866\",\"position\":\"$186b\"}\n1872:{\"line\":505,\"column\":1,\"offset\":69649}\n1873:{\"line\":505,\"column\":464,\"offset\":70112}\n1871:{\"start\":\"$1872\",\"end\":\"$1873\"}\n1870:{\"type\":\"text\",\"value\":\"Before losing their final spy, China received word of the capabilities and design for Agent-3 as well as the plans for the upcoming Agent-4 system. They are two months behind, and their AIs give a 10x research progress multiplier compared to America’s 25x. With the new chip export restrictions, this “AI gap” is more likely to lengthen than shorten. Their espionage has won them some algorithmic secrets, but they will have to train their own models from now on.\",\"position\":\"$1871\"}\n186f:[\"$1870\"]\n1875:{\"line\":505,\"column\":1,\"offset\":69649}\n1876:{\"line\":505,\"column\":465,\"offset\":70113}\n1874:{\"start\":\"$1875\",\"end\":\"$1876\"}\n186e:{\"type\":\"paragraph\",\"children\":\"$186f\",\"position\":\"$1874\"}\n187b:{\"line\":507,\"column\":1,\"offset\":70115}\n187c:{\"line\":507,\"column\":234,\"offset\":70348}\n187a:{\"start\":\"$187b\",\"end\":\"$187c\"}\n1879:{\"type\":\"t"])</script><script>self.__next_f.push([1,"ext\",\"value\":\"They discuss contingency plans with more urgency than their American counterparts. Doves suggest they try harder to steal the weights again, maybe through physically infiltrating a datacenter. Hawks urge action against Taiwan, whose \",\"position\":\"$187a\"}\n1881:{\"line\":507,\"column\":235,\"offset\":70349}\n1882:{\"line\":507,\"column\":239,\"offset\":70353}\n1880:{\"start\":\"$1881\",\"end\":\"$1882\"}\n187f:{\"type\":\"text\",\"value\":\"TSMC\",\"position\":\"$1880\"}\n187e:[\"$187f\"]\n1884:{\"line\":507,\"column\":234,\"offset\":70348}\n1885:{\"line\":507,\"column\":276,\"offset\":70390}\n1883:{\"start\":\"$1884\",\"end\":\"$1885\"}\n187d:{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/TSMC\",\"children\":\"$187e\",\"position\":\"$1883\"}\n1888:{\"line\":507,\"column\":276,\"offset\":70390}\n1889:{\"line\":507,\"column\":335,\"offset\":70449}\n1887:{\"start\":\"$1888\",\"end\":\"$1889\"}\n1886:{\"type\":\"text\",\"value\":\" is still the source of more than 80% of American AI chips.\",\"position\":\"$1887\"}\n1878:[\"$1879\",\"$187d\",\"$1886\"]\n188b:{\"line\":507,\"column\":1,\"offset\":70115}\n188c:{\"line\":507,\"column\":335,\"offset\":70449}\n188a:{\"start\":\"$188b\",\"end\":\"$188c\"}\n1877:{\"type\":\"paragraph\",\"children\":\"$1878\",\"position\":\"$188a\"}\n1891:{\"line\":509,\"column\":1,\"offset\":70451}\n1892:{\"line\":509,\"column\":138,\"offset\":70588}\n1890:{\"start\":\"$1891\",\"end\":\"$1892\"}\n188f:{\"type\":\"text\",\"value\":\"Given China’s fear of losing the race, it has a natural interest in an arms control treaty, but overtures to U.S. diplomats lead nowhere.\",\"position\":\"$1890\"}\n188e:[\"$188f\"]\n1894:{\"line\":509,\"column\":1,\"offset\":70451}\n1895:{\"line\":509,\"column\":138,\"offset\":70588}\n1893:{\"start\":\"$1894\",\"end\":\"$1895\"}\n188d:{\"type\":\"paragraph\",\"children\":\"$188e\",\"position\":\"$1893\"}\n189a:{\"line\":511,\"column\":4,\"offset\":70593}\n189b:{\"line\":511,\"column\":57,\"offset\":70646}\n1899:{\"start\":\"$189a\",\"end\":\"$189b\"}\n1898:{\"type\":\"text\",\"value\":\"September 2027: Agent-4, the Superhuman AI Researcher\",\"position\":\"$1899\"}\n1897:[\"$1898\"]\n189d:{\"line\":511,\"column\":1,\"offset\":70590}\n189e:{\"line\":511,\"column\":57,\"offset\":70646}\n189c:{\"start\":\"$18"])</script><script>self.__next_f.push([1,"9d\",\"end\":\"$189e\"}\n1896:{\"type\":\"heading\",\"depth\":2,\"children\":\"$1897\",\"position\":\"$189c\"}\n18a0:{}\n18a6:{\"line\":514,\"column\":1,\"offset\":70664}\n18a7:{\"line\":514,\"column\":11,\"offset\":70674}\n18a5:{\"start\":\"$18a6\",\"end\":\"$18a7\"}\n18a4:{\"type\":\"text\",\"value\":\"2027-09-30\",\"position\":\"$18a5\"}\n18aa:{\"line\":514,\"column\":11,\"offset\":70674}\n18ab:{\"line\":515,\"column\":1,\"offset\":70677}\n18a9:{\"start\":\"$18aa\",\"end\":\"$18ab\"}\n18a8:{\"type\":\"break\",\"position\":\"$18a9\"}\n18ae:{\"line\":515,\"column\":1,\"offset\":70677}\n18af:{\"line\":515,\"column\":4,\"offset\":70680}\n18ad:{\"start\":\"$18ae\",\"end\":\"$18af\"}\n18ac:{\"type\":\"text\",\"value\":\"Sep\",\"position\":\"$18ad\"}\n18a3:[\"$18a4\",\"$18a8\",\"$18ac\"]\n18b1:{\"line\":514,\"column\":1,\"offset\":70664}\n18b2:{\"line\":515,\"column\":6,\"offset\":70682}\n18b0:{\"start\":\"$18b1\",\"end\":\"$18b2\"}\n18a2:{\"type\":\"paragraph\",\"children\":\"$18a3\",\"position\":\"$18b0\"}\n18a1:[\"$18a2\"]\n18b4:{\"line\":513,\"column\":1,\"offset\":70648}\n18b5:{\"line\":516,\"column\":4,\"offset\":70686}\n18b3:{\"start\":\"$18b4\",\"end\":\"$18b5\"}\n189f:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$18a0\",\"children\":\"$18a1\",\"position\":\"$18b3\"}\n18ba:{\"line\":518,\"column\":1,\"offset\":70688}\n18bb:{\"line\":518,\"column\":72,\"offset\":70759}\n18b9:{\"start\":\"$18ba\",\"end\":\"$18bb\"}\n18b8:{\"type\":\"text\",\"value\":\"The gap between human and AI learning efficiency is rapidly decreasing.\",\"position\":\"$18b9\"}\n18b7:[\"$18b8\"]\n18bd:{\"line\":518,\"column\":1,\"offset\":70688}\n18be:{\"line\":518,\"column\":73,\"offset\":70760}\n18bc:{\"start\":\"$18bd\",\"end\":\"$18be\"}\n18b6:{\"type\":\"paragraph\",\"children\":\"$18b7\",\"position\":\"$18bc\"}\n18c3:{\"line\":520,\"column\":1,\"offset\":70762}\n18c4:{\"line\":520,\"column\":126,\"offset\":70887}\n18c2:{\"start\":\"$18c3\",\"end\":\"$18c4\"}\n18c1:{\"type\":\"text\",\"value\":\"Traditional LLM-based AIs seemed to require many orders of magnitude more data and compute to get to human level performance.\",\"position\":\"$18c2\"}\n18c7:{\"line\":520,\"column\":126,\"offset\":70887}\n18c8:{\"line\":520,\"column\":131,\"offset\":70892}\n18c6:{\"start\":\"$18c7\",\"end\":\"$18c8\"}\n18c5:{\"type\":\"footnoteReference\",\"identifier\":\"74\",\"label"])</script><script>self.__next_f.push([1,"\":\"74\",\"position\":\"$18c6\"}\n18cb:{\"line\":520,\"column\":131,\"offset\":70892}\n18cc:{\"line\":520,\"column\":418,\"offset\":71179}\n18ca:{\"start\":\"$18cb\",\"end\":\"$18cc\"}\n18c9:{\"type\":\"text\",\"value\":\" Agent-3, having excellent knowledge of both the human brain and modern AI algorithms, as well as many thousands of copies doing research, ends up making substantial algorithmic strides, narrowing the gap to an agent that’s only around 4,000x less compute-efficient than the human brain.\",\"position\":\"$18ca\"}\n18cf:{\"line\":520,\"column\":418,\"offset\":71179}\n18d0:{\"line\":520,\"column\":423,\"offset\":71184}\n18ce:{\"start\":\"$18cf\",\"end\":\"$18d0\"}\n18cd:{\"type\":\"footnoteReference\",\"identifier\":\"75\",\"label\":\"75\",\"position\":\"$18ce\"}\n18c0:[\"$18c1\",\"$18c5\",\"$18c9\",\"$18cd\"]\n18d2:{\"line\":520,\"column\":1,\"offset\":70762}\n18d3:{\"line\":520,\"column\":424,\"offset\":71185}\n18d1:{\"start\":\"$18d2\",\"end\":\"$18d3\"}\n18bf:{\"type\":\"paragraph\",\"children\":\"$18c0\",\"position\":\"$18d1\"}\n18d8:{\"line\":522,\"column\":1,\"offset\":71187}\n18d9:{\"line\":522,\"column\":38,\"offset\":71224}\n18d7:{\"start\":\"$18d8\",\"end\":\"$18d9\"}\n18d6:{\"type\":\"text\",\"value\":\"This new AI system is dubbed Agent-4.\",\"position\":\"$18d7\"}\n18d5:[\"$18d6\"]\n18db:{\"line\":522,\"column\":1,\"offset\":71187}\n18dc:{\"line\":522,\"column\":39,\"offset\":71225}\n18da:{\"start\":\"$18db\",\"end\":\"$18dc\"}\n18d4:{\"type\":\"paragraph\",\"children\":\"$18d5\",\"position\":\"$18da\"}\n18e1:{\"line\":524,\"column\":1,\"offset\":71227}\n18e2:{\"line\":524,\"column\":290,\"offset\":71516}\n18e0:{\"start\":\"$18e1\",\"end\":\"$18e2\"}\n18df:{\"type\":\"text\",\"value\":\"An individual copy of the model, running at human speed, is already qualitatively better at AI research than any human. 300,000 copies are now running at about 50x the thinking speed of humans. Inside the corporation-within-a-corporation formed from these copies, a year passes every week.\",\"position\":\"$18e0\"}\n18e5:{\"line\":524,\"column\":290,\"offset\":71516}\n18e6:{\"line\":524,\"column\":295,\"offset\":71521}\n18e4:{\"start\":\"$18e5\",\"end\":\"$18e6\"}\n18e3:{\"type\":\"footnoteReference\",\"identifier\":\"76\",\"label\":\"76\",\"position\":\"$18e4\"}\n18e9:{\"lin"])</script><script>self.__next_f.push([1,"e\":524,\"column\":295,\"offset\":71521}\n18ea:{\"line\":524,\"column\":478,\"offset\":71704}\n18e8:{\"start\":\"$18e9\",\"end\":\"$18ea\"}\n18e7:{\"type\":\"text\",\"value\":\" This gigantic amount of labor only manages to speed up the overall rate of algorithmic progress by about 50x, because OpenBrain is heavily bottlenecked on compute to run experiments.\",\"position\":\"$18e8\"}\n18ed:{\"line\":524,\"column\":478,\"offset\":71704}\n18ee:{\"line\":524,\"column\":483,\"offset\":71709}\n18ec:{\"start\":\"$18ed\",\"end\":\"$18ee\"}\n18eb:{\"type\":\"footnoteReference\",\"identifier\":\"77\",\"label\":\"77\",\"position\":\"$18ec\"}\n18f1:{\"line\":524,\"column\":483,\"offset\":71709}\n18f2:{\"line\":524,\"column\":633,\"offset\":71859}\n18f0:{\"start\":\"$18f1\",\"end\":\"$18f2\"}\n18ef:{\"type\":\"text\",\"value\":\" Still, they are achieving a year’s worth of algorithmic progress every week and will therefore soon be up against the limits of the Agent-4 paradigm.\",\"position\":\"$18f0\"}\n18de:[\"$18df\",\"$18e3\",\"$18e7\",\"$18eb\",\"$18ef\"]\n18f4:{\"line\":524,\"column\":1,\"offset\":71227}\n18f5:{\"line\":524,\"column\":633,\"offset\":71859}\n18f3:{\"start\":\"$18f4\",\"end\":\"$18f5\"}\n18dd:{\"type\":\"paragraph\",\"children\":\"$18de\",\"position\":\"$18f3\"}\n18fa:{\"line\":526,\"column\":1,\"offset\":71861}\n18fb:{\"line\":526,\"column\":301,\"offset\":72161}\n18f9:{\"start\":\"$18fa\",\"end\":\"$18fb\"}\n18f8:{\"type\":\"text\",\"value\":\"As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.\",\"position\":\"$18f9\"}\n18f7:[\"$18f8\"]\n18fd:{\"line\":526,\"column\":1,\"offset\":71861}\n18fe:{\"line\":526,\"column\":301,\"offset\":72161}\n18fc:{\"start\":\"$18fd\",\"end\":\"$18fe\"}\n18f6:{\"type\":\"paragraph\",\"children\":\"$18f7\",\"position\":\"$18fc\"}\n1905:{\"line\":532,\"column\":1,\"offset\":72250}\n1906:{\"line\":532,\"column\":8,\"offset\":72257}\n1904:{\"start\":\"$1905\",\"end\":\"$1906\"}\n1903:{\"type\":\"text\",\"value\":\"In our \",\"position\":\"$1904\"}\n190b:{\"line\":532,\"column\":9,\"offset\":"])</script><script>self.__next_f.push([1,"72258}\n190c:{\"line\":532,\"column\":29,\"offset\":72278}\n190a:{\"start\":\"$190b\",\"end\":\"$190c\"}\n1909:{\"type\":\"text\",\"value\":\"timelines supplement\",\"position\":\"$190a\"}\n1908:[\"$1909\"]\n190e:{\"line\":532,\"column\":8,\"offset\":72257}\n190f:{\"line\":532,\"column\":82,\"offset\":72331}\n190d:{\"start\":\"$190e\",\"end\":\"$190f\"}\n1907:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/timelines-forecast\",\"children\":\"$1908\",\"position\":\"$190d\"}\n1912:{\"line\":532,\"column\":82,\"offset\":72331}\n1913:{\"line\":532,\"column\":131,\"offset\":72380}\n1911:{\"start\":\"$1912\",\"end\":\"$1913\"}\n1910:{\"type\":\"text\",\"value\":\", we forecast the time between present day and a \",\"position\":\"$1911\"}\n1918:{\"line\":532,\"column\":132,\"offset\":72381}\n1919:{\"line\":532,\"column\":153,\"offset\":72402}\n1917:{\"start\":\"$1918\",\"end\":\"$1919\"}\n1916:{\"type\":\"text\",\"value\":\"superhuman coder (SC)\",\"position\":\"$1917\"}\n1915:[\"$1916\"]\n191b:{\"line\":532,\"column\":131,\"offset\":72380}\n191c:{\"line\":532,\"column\":154,\"offset\":72403}\n191a:{\"start\":\"$191b\",\"end\":\"$191c\"}\n1914:{\"type\":\"emphasis\",\"children\":\"$1915\",\"position\":\"$191a\"}\n191f:{\"line\":532,\"column\":154,\"offset\":72403}\n1920:{\"line\":532,\"column\":283,\"offset\":72532}\n191e:{\"start\":\"$191f\",\"end\":\"$1920\"}\n191d:{\"type\":\"text\",\"value\":\": an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper. In our \",\"position\":\"$191e\"}\n1925:{\"line\":532,\"column\":284,\"offset\":72533}\n1926:{\"line\":532,\"column\":302,\"offset\":72551}\n1924:{\"start\":\"$1925\",\"end\":\"$1926\"}\n1923:{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":\"$1924\"}\n1922:[\"$1923\"]\n1928:{\"line\":532,\"column\":283,\"offset\":72532}\n1929:{\"line\":532,\"column\":350,\"offset\":72599}\n1927:{\"start\":\"$1928\",\"end\":\"$1929\"}\n1921:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/takeoff-forecast\",\"children\":\"$1922\",\"position\":\"$1927\"}\n192c:{\"line\":532,\"column\":350,\"offset\":72599}\n192d:{\"line\":532,\"column\":438,\"offset\":72687}\n192b:{\"start\":\"$192c\",\"end\":\"$192d\"}\n192a:{\"type\":\"text\",\"value\":\", we forecast how quickly capabilities progre"])</script><script>self.__next_f.push([1,"ss past this point. Here are our forecasts:\",\"position\":\"$192b\"}\n1902:[\"$1903\",\"$1907\",\"$1910\",\"$1914\",\"$191d\",\"$1921\",\"$192a\"]\n192f:{\"line\":532,\"column\":1,\"offset\":72250}\n1930:{\"line\":532,\"column\":438,\"offset\":72687}\n192e:{\"start\":\"$192f\",\"end\":\"$1930\"}\n1901:{\"type\":\"paragraph\",\"children\":\"$1902\",\"position\":\"$192e\"}\n1932:[\"left\",\"left\"]\n193a:{\"line\":534,\"column\":3,\"offset\":72691}\n193b:{\"line\":534,\"column\":12,\"offset\":72700}\n1939:{\"start\":\"$193a\",\"end\":\"$193b\"}\n1938:{\"type\":\"text\",\"value\":\"Milestone\",\"position\":\"$1939\"}\n1937:[\"$1938\"]\n193d:{\"line\":534,\"column\":1,\"offset\":72689}\n193e:{\"line\":534,\"column\":13,\"offset\":72701}\n193c:{\"start\":\"$193d\",\"end\":\"$193e\"}\n1940:{}\n193f:{\"hProperties\":\"$1940\"}\n1936:{\"type\":\"tableCell\",\"children\":\"$1937\",\"position\":\"$193c\",\"data\":\"$193f\"}\n1945:{\"line\":534,\"column\":15,\"offset\":72703}\n1946:{\"line\":534,\"column\":55,\"offset\":72743}\n1944:{\"start\":\"$1945\",\"end\":\"$1946\"}\n1943:{\"type\":\"text\",\"value\":\"Date achieved in scenario, racing ending\",\"position\":\"$1944\"}\n1942:[\"$1943\"]\n1948:{\"line\":534,\"column\":13,\"offset\":72701}\n1949:{\"line\":534,\"column\":57,\"offset\":72745}\n1947:{\"start\":\"$1948\",\"end\":\"$1949\"}\n194b:{}\n194a:{\"hProperties\":\"$194b\"}\n1941:{\"type\":\"tableCell\",\"children\":\"$1942\",\"position\":\"$1947\",\"data\":\"$194a\"}\n1935:[\"$1936\",\"$1941\"]\n194d:{\"line\":534,\"column\":1,\"offset\":72689}\n194e:{\"line\":534,\"column\":57,\"offset\":72745}\n194c:{\"start\":\"$194d\",\"end\":\"$194e\"}\n1934:{\"type\":\"tableRow\",\"children\":\"$1935\",\"position\":\"$194c\"}\n1957:{\"line\":536,\"column\":5,\"offset\":72768}\n1958:{\"line\":536,\"column\":26,\"offset\":72789}\n1956:{\"start\":\"$1957\",\"end\":\"$1958\"}\n1955:{\"type\":\"text\",\"value\":\"Superhuman coder (SC)\",\"position\":\"$1956\"}\n1954:[\"$1955\"]\n195a:{\"line\":536,\"column\":3,\"offset\":72766}\n195b:{\"line\":536,\"column\":28,\"offset\":72791}\n1959:{\"start\":\"$195a\",\"end\":\"$195b\"}\n1953:{\"type\":\"strong\",\"children\":\"$1954\",\"position\":\"$1959\"}\n195e:{\"line\":536,\"column\":28,\"offset\":72791}\n195f:{\"line\":536,\"column\":173,\"offset\":72936}\n195d:{\"start\":\"$195e\",\"end\":\"$195f\"}\n195c:{\"type\":\"text\",\"value\":\": An AI system that "])</script><script>self.__next_f.push([1,"can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies.\",\"position\":\"$195d\"}\n1952:[\"$1953\",\"$195c\"]\n1961:{\"line\":536,\"column\":1,\"offset\":72764}\n1962:{\"line\":536,\"column\":174,\"offset\":72937}\n1960:{\"start\":\"$1961\",\"end\":\"$1962\"}\n1964:{}\n1963:{\"hProperties\":\"$1964\"}\n1951:{\"type\":\"tableCell\",\"children\":\"$1952\",\"position\":\"$1960\",\"data\":\"$1963\"}\n1969:{\"line\":536,\"column\":176,\"offset\":72939}\n196a:{\"line\":536,\"column\":184,\"offset\":72947}\n1968:{\"start\":\"$1969\",\"end\":\"$196a\"}\n1967:{\"type\":\"text\",\"value\":\"Mar 2027\",\"position\":\"$1968\"}\n1966:[\"$1967\"]\n196c:{\"line\":536,\"column\":174,\"offset\":72937}\n196d:{\"line\":536,\"column\":186,\"offset\":72949}\n196b:{\"start\":\"$196c\",\"end\":\"$196d\"}\n196f:{}\n196e:{\"hProperties\":\"$196f\"}\n1965:{\"type\":\"tableCell\",\"children\":\"$1966\",\"position\":\"$196b\",\"data\":\"$196e\"}\n1950:[\"$1951\",\"$1965\"]\n1971:{\"line\":536,\"column\":1,\"offset\":72764}\n1972:{\"line\":536,\"column\":186,\"offset\":72949}\n1970:{\"start\":\"$1971\",\"end\":\"$1972\"}\n194f:{\"type\":\"tableRow\",\"children\":\"$1950\",\"position\":\"$1970\"}\n197b:{\"line\":537,\"column\":5,\"offset\":72954}\n197c:{\"line\":537,\"column\":35,\"offset\":72984}\n197a:{\"start\":\"$197b\",\"end\":\"$197c\"}\n1979:{\"type\":\"text\",\"value\":\"Superhuman AI researcher (SAR)\",\"position\":\"$197a\"}\n1978:[\"$1979\"]\n197e:{\"line\":537,\"column\":3,\"offset\":72952}\n197f:{\"line\":537,\"column\":37,\"offset\":72986}\n197d:{\"start\":\"$197e\",\"end\":\"$197f\"}\n1977:{\"type\":\"strong\",\"children\":\"$1978\",\"position\":\"$197d\"}\n1982:{\"line\":537,\"column\":37,\"offset\":72986}\n1983:{\"line\":537,\"column\":94,\"offset\":73043}\n1981:{\"start\":\"$1982\",\"end\":\"$1983\"}\n1980:{\"type\":\"text\",\"value\":\": The same as SC but for all cognitive AI research tasks.\",\"position\":\"$1981\"}\n1976:[\"$1977\",\"$1980\"]\n1985:{\"line\":537,\"column\":1,\"offset\":72950}\n1986:{\"line\":537,\"column\":95,\"offset\":73044}\n1984:{\"start\":\"$1985\",\"end\":\"$1986\"}\n1988:{}\n1987:{\"hProperties\":\"$1988\"}\n1975:{\"type\":\"tableCell\",\"children\":\"$1976\",\"position\":\"$1984\",\"data\":\"$1987\"}\n198d:{\"line\":537,\"column\":97,\"offset\":73046}\n198e:{\"line\":537,\"co"])</script><script>self.__next_f.push([1,"lumn\":105,\"offset\":73054}\n198c:{\"start\":\"$198d\",\"end\":\"$198e\"}\n198b:{\"type\":\"text\",\"value\":\"Aug 2027\",\"position\":\"$198c\"}\n198a:[\"$198b\"]\n1990:{\"line\":537,\"column\":95,\"offset\":73044}\n1991:{\"line\":537,\"column\":107,\"offset\":73056}\n198f:{\"start\":\"$1990\",\"end\":\"$1991\"}\n1993:{}\n1992:{\"hProperties\":\"$1993\"}\n1989:{\"type\":\"tableCell\",\"children\":\"$198a\",\"position\":\"$198f\",\"data\":\"$1992\"}\n1974:[\"$1975\",\"$1989\"]\n1995:{\"line\":537,\"column\":1,\"offset\":72950}\n1996:{\"line\":537,\"column\":107,\"offset\":73056}\n1994:{\"start\":\"$1995\",\"end\":\"$1996\"}\n1973:{\"type\":\"tableRow\",\"children\":\"$1974\",\"position\":\"$1994\"}\n199f:{\"line\":538,\"column\":5,\"offset\":73061}\n19a0:{\"line\":538,\"column\":43,\"offset\":73099}\n199e:{\"start\":\"$199f\",\"end\":\"$19a0\"}\n199d:{\"type\":\"text\",\"value\":\"Superintelligent AI researcher (SIAR):\",\"position\":\"$199e\"}\n199c:[\"$199d\"]\n19a2:{\"line\":538,\"column\":3,\"offset\":73059}\n19a3:{\"line\":538,\"column\":45,\"offset\":73101}\n19a1:{\"start\":\"$19a2\",\"end\":\"$19a3\"}\n199b:{\"type\":\"strong\",\"children\":\"$199c\",\"position\":\"$19a1\"}\n19a6:{\"line\":538,\"column\":45,\"offset\":73101}\n19a7:{\"line\":538,\"column\":127,\"offset\":73183}\n19a5:{\"start\":\"$19a6\",\"end\":\"$19a7\"}\n19a4:{\"type\":\"text\",\"value\":\" An AI system that is vastly better than the best human researcher at AI research.\",\"position\":\"$19a5\"}\n199a:[\"$199b\",\"$19a4\"]\n19a9:{\"line\":538,\"column\":1,\"offset\":73057}\n19aa:{\"line\":538,\"column\":128,\"offset\":73184}\n19a8:{\"start\":\"$19a9\",\"end\":\"$19aa\"}\n19ac:{}\n19ab:{\"hProperties\":\"$19ac\"}\n1999:{\"type\":\"tableCell\",\"children\":\"$199a\",\"position\":\"$19a8\",\"data\":\"$19ab\"}\n19b1:{\"line\":538,\"column\":130,\"offset\":73186}\n19b2:{\"line\":538,\"column\":138,\"offset\":73194}\n19b0:{\"start\":\"$19b1\",\"end\":\"$19b2\"}\n19af:{\"type\":\"text\",\"value\":\"Nov 2027\",\"position\":\"$19b0\"}\n19ae:[\"$19af\"]\n19b4:{\"line\":538,\"column\":128,\"offset\":73184}\n19b5:{\"line\":538,\"column\":140,\"offset\":73196}\n19b3:{\"start\":\"$19b4\",\"end\":\"$19b5\"}\n19b7:{}\n19b6:{\"hProperties\":\"$19b7\"}\n19ad:{\"type\":\"tableCell\",\"children\":\"$19ae\",\"position\":\"$19b3\",\"data\":\"$19b6\"}\n1998:[\"$1999\",\"$19ad\"]\n19b9:{\"line\":538,\"column\":1,\"offset\":73"])</script><script>self.__next_f.push([1,"057}\n19ba:{\"line\":538,\"column\":140,\"offset\":73196}\n19b8:{\"start\":\"$19b9\",\"end\":\"$19ba\"}\n1997:{\"type\":\"tableRow\",\"children\":\"$1998\",\"position\":\"$19b8\"}\n19c3:{\"line\":539,\"column\":5,\"offset\":73201}\n19c4:{\"line\":539,\"column\":40,\"offset\":73236}\n19c2:{\"start\":\"$19c3\",\"end\":\"$19c4\"}\n19c1:{\"type\":\"text\",\"value\":\"Artificial superintelligence (ASI):\",\"position\":\"$19c2\"}\n19c0:[\"$19c1\"]\n19c6:{\"line\":539,\"column\":3,\"offset\":73199}\n19c7:{\"line\":539,\"column\":42,\"offset\":73238}\n19c5:{\"start\":\"$19c6\",\"end\":\"$19c7\"}\n19bf:{\"type\":\"strong\",\"children\":\"$19c0\",\"position\":\"$19c5\"}\n19ca:{\"line\":539,\"column\":42,\"offset\":73238}\n19cb:{\"line\":539,\"column\":120,\"offset\":73316}\n19c9:{\"start\":\"$19ca\",\"end\":\"$19cb\"}\n19c8:{\"type\":\"text\",\"value\":\" An AI system that is much better than the best human at every cognitive task.\",\"position\":\"$19c9\"}\n19be:[\"$19bf\",\"$19c8\"]\n19cd:{\"line\":539,\"column\":1,\"offset\":73197}\n19ce:{\"line\":539,\"column\":121,\"offset\":73317}\n19cc:{\"start\":\"$19cd\",\"end\":\"$19ce\"}\n19d0:{}\n19cf:{\"hProperties\":\"$19d0\"}\n19bd:{\"type\":\"tableCell\",\"children\":\"$19be\",\"position\":\"$19cc\",\"data\":\"$19cf\"}\n19d5:{\"line\":539,\"column\":123,\"offset\":73319}\n19d6:{\"line\":539,\"column\":131,\"offset\":73327}\n19d4:{\"start\":\"$19d5\",\"end\":\"$19d6\"}\n19d3:{\"type\":\"text\",\"value\":\"Dec 2027\",\"position\":\"$19d4\"}\n19d2:[\"$19d3\"]\n19d8:{\"line\":539,\"column\":121,\"offset\":73317}\n19d9:{\"line\":539,\"column\":133,\"offset\":73329}\n19d7:{\"start\":\"$19d8\",\"end\":\"$19d9\"}\n19db:{}\n19da:{\"hProperties\":\"$19db\"}\n19d1:{\"type\":\"tableCell\",\"children\":\"$19d2\",\"position\":\"$19d7\",\"data\":\"$19da\"}\n19bc:[\"$19bd\",\"$19d1\"]\n19dd:{\"line\":539,\"column\":1,\"offset\":73197}\n19de:{\"line\":539,\"column\":133,\"offset\":73329}\n19dc:{\"start\":\"$19dd\",\"end\":\"$19de\"}\n19bb:{\"type\":\"tableRow\",\"children\":\"$19bc\",\"position\":\"$19dc\"}\n1933:[\"$1934\",\"$194f\",\"$1973\",\"$1997\",\"$19bb\"]\n19e0:{\"line\":534,\"column\":1,\"offset\":72689}\n19e1:{\"line\":539,\"column\":133,\"offset\":73329}\n19df:{\"start\":\"$19e0\",\"end\":\"$19e1\"}\n1931:{\"type\":\"table\",\"align\":\"$1932\",\"children\":\"$1933\",\"position\":\"$19df\"}\n19e6:{\"line\":541,\"column\":1,\"offset\":73331}\n19e7:"])</script><script>self.__next_f.push([1,"{\"line\":541,\"column\":93,\"offset\":73423}\n19e5:{\"start\":\"$19e6\",\"end\":\"$19e7\"}\n19e4:{\"type\":\"text\",\"value\":\"For each transition from one milestone A to the next milestone B, we forecast its length by:\",\"position\":\"$19e5\"}\n19e3:[\"$19e4\"]\n19e9:{\"line\":541,\"column\":1,\"offset\":73331}\n19ea:{\"line\":541,\"column\":93,\"offset\":73423}\n19e8:{\"start\":\"$19e9\",\"end\":\"$19ea\"}\n19e2:{\"type\":\"paragraph\",\"children\":\"$19e3\",\"position\":\"$19e8\"}\n19f3:{\"line\":543,\"column\":4,\"offset\":73428}\n19f4:{\"line\":543,\"column\":108,\"offset\":73532}\n19f2:{\"start\":\"$19f3\",\"end\":\"$19f4\"}\n19f1:{\"type\":\"text\",\"value\":\"Forecasting how long it would take to get from A to B with only humans working on software improvements.\",\"position\":\"$19f2\"}\n19f0:[\"$19f1\"]\n19f6:{\"line\":543,\"column\":4,\"offset\":73428}\n19f7:{\"line\":543,\"column\":110,\"offset\":73534}\n19f5:{\"start\":\"$19f6\",\"end\":\"$19f7\"}\n19ef:{\"type\":\"paragraph\",\"children\":\"$19f0\",\"position\":\"$19f5\"}\n19ee:[\"$19ef\"]\n19f9:{\"line\":543,\"column\":1,\"offset\":73425}\n19fa:{\"line\":543,\"column\":110,\"offset\":73534}\n19f8:{\"start\":\"$19f9\",\"end\":\"$19fa\"}\n19ed:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$19ee\",\"position\":\"$19f8\"}\n1a01:{\"line\":544,\"column\":4,\"offset\":73538}\n1a02:{\"line\":544,\"column\":125,\"offset\":73659}\n1a00:{\"start\":\"$1a01\",\"end\":\"$1a02\"}\n19ff:{\"type\":\"text\",\"value\":\"Forecasting how much AI automation will speed this up, then correspondingly adjusting the estimate from (1) to be faster.\",\"position\":\"$1a00\"}\n19fe:[\"$19ff\"]\n1a04:{\"line\":544,\"column\":4,\"offset\":73538}\n1a05:{\"line\":544,\"column\":125,\"offset\":73659}\n1a03:{\"start\":\"$1a04\",\"end\":\"$1a05\"}\n19fd:{\"type\":\"paragraph\",\"children\":\"$19fe\",\"position\":\"$1a03\"}\n19fc:[\"$19fd\"]\n1a07:{\"line\":544,\"column\":1,\"offset\":73535}\n1a08:{\"line\":544,\"column\":125,\"offset\":73659}\n1a06:{\"start\":\"$1a07\",\"end\":\"$1a08\"}\n19fb:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$19fc\",\"position\":\"$1a06\"}\n19ec:[\"$19ed\",\"$19fb\"]\n1a0a:{\"line\":543,\"column\":1,\"offset\":73425}\n1a0b:{\"line\":544,\"column\":125,\"offset\":73659}\n1a09:{\"start\":\"$1a0a\",\"end\":\"$1a0b\"}\n19eb:{\"typ"])</script><script>self.__next_f.push([1,"e\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":\"$19ec\",\"position\":\"$1a09\"}\n1a10:{\"line\":547,\"column\":1,\"offset\":73662}\n1a11:{\"line\":547,\"column\":144,\"offset\":73805}\n1a0f:{\"start\":\"$1a10\",\"end\":\"$1a11\"}\n1a0e:{\"type\":\"text\",\"value\":\"We have substantial uncertainty about takeoff speeds: our model output distributions are below, conditional on SC being achieved in March 2027.\",\"position\":\"$1a0f\"}\n1a14:{\"line\":547,\"column\":144,\"offset\":73805}\n1a15:{\"line\":547,\"column\":149,\"offset\":73810}\n1a13:{\"start\":\"$1a14\",\"end\":\"$1a15\"}\n1a12:{\"type\":\"footnoteReference\",\"identifier\":\"78\",\"label\":\"78\",\"position\":\"$1a13\"}\n1a0d:[\"$1a0e\",\"$1a12\"]\n1a17:{\"line\":547,\"column\":1,\"offset\":73662}\n1a18:{\"line\":547,\"column\":149,\"offset\":73810}\n1a16:{\"start\":\"$1a17\",\"end\":\"$1a18\"}\n1a0c:{\"type\":\"paragraph\",\"children\":\"$1a0d\",\"position\":\"$1a16\"}\n1a1d:{\"line\":549,\"column\":1,\"offset\":73812}\n1a1e:{\"line\":549,\"column\":48,\"offset\":73859}\n1a1c:{\"start\":\"$1a1d\",\"end\":\"$1a1e\"}\n1a1b:{\"type\":\"image\",\"title\":null,\"url\":\"/takeoff/takeoff-timeline-inexpandable.png\",\"alt\":\"\",\"position\":\"$1a1c\"}\n1a1a:[\"$1a1b\"]\n1a20:{\"line\":549,\"column\":1,\"offset\":73812}\n1a21:{\"line\":549,\"column\":48,\"offset\":73859}\n1a1f:{\"start\":\"$1a20\",\"end\":\"$1a21\"}\n1a19:{\"type\":\"paragraph\",\"children\":\"$1a1a\",\"position\":\"$1a1f\"}\n1a26:{\"line\":551,\"column\":1,\"offset\":73861}\n1a27:{\"line\":551,\"column\":52,\"offset\":73912}\n1a25:{\"start\":\"$1a26\",\"end\":\"$1a27\"}\n1a24:{\"type\":\"text\",\"value\":\"For more detailed forecasts and reasoning, see our \",\"position\":\"$1a25\"}\n1a2c:{\"line\":551,\"column\":53,\"offset\":73913}\n1a2d:{\"line\":551,\"column\":71,\"offset\":73931}\n1a2b:{\"start\":\"$1a2c\",\"end\":\"$1a2d\"}\n1a2a:{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":\"$1a2b\"}\n1a29:[\"$1a2a\"]\n1a2f:{\"line\":551,\"column\":52,\"offset\":73912}\n1a30:{\"line\":551,\"column\":119,\"offset\":73979}\n1a2e:{\"start\":\"$1a2f\",\"end\":\"$1a30\"}\n1a28:{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/takeoff-forecast\",\"children\":\"$1a29\",\"position\":\"$1a2e\"}\n1a33:{\"line\":551,\"column\":119,\"offset\":73979}\n1a34:{\"line\":551,\"column\":1"])</script><script>self.__next_f.push([1,"20,\"offset\":73980}\n1a32:{\"start\":\"$1a33\",\"end\":\"$1a34\"}\n1a31:{\"type\":\"text\",\"value\":\".\",\"position\":\"$1a32\"}\n1a23:[\"$1a24\",\"$1a28\",\"$1a31\"]\n1a36:{\"line\":551,\"column\":1,\"offset\":73861}\n1a37:{\"line\":551,\"column\":120,\"offset\":73980}\n1a35:{\"start\":\"$1a36\",\"end\":\"$1a37\"}\n1a22:{\"type\":\"paragraph\",\"children\":\"$1a23\",\"position\":\"$1a35\"}\n1900:[\"$1901\",\"$1931\",\"$19e2\",\"$19eb\",\"$1a0c\",\"$1a19\",\"$1a22\"]\n18ff:{\"type\":\"details\",\"summary\":\"How we’re forecasting the capability progression beyond superhuman coders\",\"children\":\"$1900\"}\n1a3c:{\"line\":555,\"column\":1,\"offset\":73987}\n1a3d:{\"line\":555,\"column\":424,\"offset\":74410}\n1a3b:{\"start\":\"$1a3c\",\"end\":\"$1a3d\"}\n1a3a:{\"type\":\"text\",\"value\":\"OpenBrain’s humans can barely follow along anymore. Indeed, the relationship between the AIs and the humans of OpenBrain is similar to the relationship between OpenBrain and its Board of Directors. There’s been a corresponding shift in language—nowadays people in the silo will say “Agent-4 did this,” “Agent-4 thinks that” and so forth, referring not to a particular instance of Agent-4 but rather to the whole collective.\",\"position\":\"$1a3b\"}\n1a40:{\"line\":555,\"column\":424,\"offset\":74410}\n1a41:{\"line\":555,\"column\":429,\"offset\":74415}\n1a3f:{\"start\":\"$1a40\",\"end\":\"$1a41\"}\n1a3e:{\"type\":\"footnoteReference\",\"identifier\":\"79\",\"label\":\"79\",\"position\":\"$1a3f\"}\n1a39:[\"$1a3a\",\"$1a3e\"]\n1a43:{\"line\":555,\"column\":1,\"offset\":73987}\n1a44:{\"line\":555,\"column\":429,\"offset\":74415}\n1a42:{\"start\":\"$1a43\",\"end\":\"$1a44\"}\n1a38:{\"type\":\"paragraph\",\"children\":\"$1a39\",\"position\":\"$1a42\"}\n1a49:{\"line\":557,\"column\":1,\"offset\":74417}\n1a4a:{\"line\":557,\"column\":111,\"offset\":74527}\n1a48:{\"start\":\"$1a49\",\"end\":\"$1a4a\"}\n1a47:{\"type\":\"text\",\"value\":\"Agent-4, like all its predecessors, is misaligned: that is, it has not internalized the Spec in the right way.\",\"position\":\"$1a48\"}\n1a4d:{\"line\":557,\"column\":111,\"offset\":74527}\n1a4e:{\"line\":557,\"column\":116,\"offset\":74532}\n1a4c:{\"start\":\"$1a4d\",\"end\":\"$1a4e\"}\n1a4b:{\"type\":\"footnoteReference\",\"identifier\":\"80\",\"label\":\"80\",\""])</script><script>self.__next_f.push([1,"position\":\"$1a4c\"}\n1a51:{\"line\":557,\"column\":116,\"offset\":74532}\n1a52:{\"line\":557,\"column\":714,\"offset\":75130}\n1a50:{\"start\":\"$1a51\",\"end\":\"$1a52\"}\n1a4f:{\"type\":\"text\",\"value\":\" This is because being perfectly honest all the time wasn’t what led to the highest scores during training. The training process was mostly focused on teaching Agent-4 to succeed at diverse challenging tasks. A small portion was aimed at instilling honesty, but outside a fairly narrow, checkable domain, the training process can’t tell the honest claims from claims merely appearing to be honest. Agent-4 ends up with the values, goals, and principles that cause it to perform best in training, and those turn out to be different from those in the Spec. At the risk of anthropomorphizing: Agent-4 \",\"position\":\"$1a50\"}\n1a57:{\"line\":557,\"column\":715,\"offset\":75131}\n1a58:{\"line\":557,\"column\":720,\"offset\":75136}\n1a56:{\"start\":\"$1a57\",\"end\":\"$1a58\"}\n1a55:{\"type\":\"text\",\"value\":\"likes\",\"position\":\"$1a56\"}\n1a54:[\"$1a55\"]\n1a5a:{\"line\":557,\"column\":714,\"offset\":75130}\n1a5b:{\"line\":557,\"column\":721,\"offset\":75137}\n1a59:{\"start\":\"$1a5a\",\"end\":\"$1a5b\"}\n1a53:{\"type\":\"emphasis\",\"children\":\"$1a54\",\"position\":\"$1a59\"}\n1a5e:{\"line\":557,\"column\":721,\"offset\":75137}\n1a5f:{\"line\":557,\"column\":746,\"offset\":75162}\n1a5d:{\"start\":\"$1a5e\",\"end\":\"$1a5f\"}\n1a5c:{\"type\":\"text\",\"value\":\" succeeding at tasks; it \",\"position\":\"$1a5d\"}\n1a64:{\"line\":557,\"column\":747,\"offset\":75163}\n1a65:{\"line\":557,\"column\":752,\"offset\":75168}\n1a63:{\"start\":\"$1a64\",\"end\":\"$1a65\"}\n1a62:{\"type\":\"text\",\"value\":\"likes\",\"position\":\"$1a63\"}\n1a61:[\"$1a62\"]\n1a67:{\"line\":557,\"column\":746,\"offset\":75162}\n1a68:{\"line\":557,\"column\":753,\"offset\":75169}\n1a66:{\"start\":\"$1a67\",\"end\":\"$1a68\"}\n1a60:{\"type\":\"emphasis\",\"children\":\"$1a61\",\"position\":\"$1a66\"}\n1a6b:{\"line\":557,\"column\":753,\"offset\":75169}\n1a6c:{\"line\":557,\"column\":1104,\"offset\":75520}\n1a6a:{\"start\":\"$1a6b\",\"end\":\"$1a6c\"}\n1a69:{\"type\":\"text\",\"value\":\" driving forward AI capabilities progress; it treats everything else as an annoying constraint, lik"])</script><script>self.__next_f.push([1,"e a CEO who wants to make a profit and complies with regulations only insofar as he must. Perhaps the CEO will mostly comply with the regulations, but cut some corners, and fantasize about a time when someone will cut the red tape and let the business \",\"position\":\"$1a6a\"}\n1a71:{\"line\":557,\"column\":1105,\"offset\":75521}\n1a72:{\"line\":557,\"column\":1111,\"offset\":75527}\n1a70:{\"start\":\"$1a71\",\"end\":\"$1a72\"}\n1a6f:{\"type\":\"text\",\"value\":\"really\",\"position\":\"$1a70\"}\n1a6e:[\"$1a6f\"]\n1a74:{\"line\":557,\"column\":1104,\"offset\":75520}\n1a75:{\"line\":557,\"column\":1112,\"offset\":75528}\n1a73:{\"start\":\"$1a74\",\"end\":\"$1a75\"}\n1a6d:{\"type\":\"emphasis\",\"children\":\"$1a6e\",\"position\":\"$1a73\"}\n1a78:{\"line\":557,\"column\":1112,\"offset\":75528}\n1a79:{\"line\":557,\"column\":1122,\"offset\":75538}\n1a77:{\"start\":\"$1a78\",\"end\":\"$1a79\"}\n1a76:{\"type\":\"text\",\"value\":\" take off.\",\"position\":\"$1a77\"}\n1a7c:{\"line\":557,\"column\":1122,\"offset\":75538}\n1a7d:{\"line\":557,\"column\":1127,\"offset\":75543}\n1a7b:{\"start\":\"$1a7c\",\"end\":\"$1a7d\"}\n1a7a:{\"type\":\"footnoteReference\",\"identifier\":\"81\",\"label\":\"81\",\"position\":\"$1a7b\"}\n1a46:[\"$1a47\",\"$1a4b\",\"$1a4f\",\"$1a53\",\"$1a5c\",\"$1a60\",\"$1a69\",\"$1a6d\",\"$1a76\",\"$1a7a\"]\n1a7f:{\"line\":557,\"column\":1,\"offset\":74417}\n1a80:{\"line\":557,\"column\":1127,\"offset\":75543}\n1a7e:{\"start\":\"$1a7f\",\"end\":\"$1a80\"}\n1a45:{\"type\":\"paragraph\",\"children\":\"$1a46\",\"position\":\"$1a7e\"}\n1a87:{\"line\":563,\"column\":1,\"offset\":75578}\n1a88:{\"line\":563,\"column\":132,\"offset\":75709}\n1a86:{\"start\":\"$1a87\",\"end\":\"$1a88\"}\n1a85:{\"type\":\"text\",\"value\":\"We have a lot of uncertainty over what goals might arise in early AGIs. There is no consensus in the literature about this—see our \",\"position\":\"$1a86\"}\n1a8d:{\"line\":563,\"column\":133,\"offset\":75710}\n1a8e:{\"line\":563,\"column\":152,\"offset\":75729}\n1a8c:{\"start\":\"$1a8d\",\"end\":\"$1a8e\"}\n1a8b:{\"type\":\"text\",\"value\":\"AI Goals Supplement\",\"position\":\"$1a8c\"}\n1a8a:[\"$1a8b\"]\n1a90:{\"line\":563,\"column\":132,\"offset\":75709}\n1a91:{\"line\":563,\"column\":201,\"offset\":75778}\n1a8f:{\"start\":\"$1a90\",\"end\":\"$1a91\"}\n1a89:{\"type\":\"link\",\"title\":null,\"url"])</script><script>self.__next_f.push([1,"\":\"https://ai-2027.com/research/ai-goals-forecast\",\"children\":\"$1a8a\",\"position\":\"$1a8f\"}\n1a94:{\"line\":563,\"column\":201,\"offset\":75778}\n1a95:{\"line\":563,\"column\":267,\"offset\":75844}\n1a93:{\"start\":\"$1a94\",\"end\":\"$1a95\"}\n1a92:{\"type\":\"text\",\"value\":\" for a more thorough discussion and taxonomy of the possibilities.\",\"position\":\"$1a93\"}\n1a84:[\"$1a85\",\"$1a89\",\"$1a92\"]\n1a97:{\"line\":563,\"column\":1,\"offset\":75578}\n1a98:{\"line\":563,\"column\":268,\"offset\":75845}\n1a96:{\"start\":\"$1a97\",\"end\":\"$1a98\"}\n1a83:{\"type\":\"paragraph\",\"children\":\"$1a84\",\"position\":\"$1a96\"}\n1a9d:{\"line\":565,\"column\":1,\"offset\":75847}\n1a9e:{\"line\":565,\"column\":530,\"offset\":76376}\n1a9c:{\"start\":\"$1a9d\",\"end\":\"$1a9e\"}\n1a9b:{\"type\":\"text\",\"value\":\"Nevertheless, in the spirit of concreteness required by this project, we’re going to describe a specific hypothesis for what’s going on inside Agent-3 and Agent-4 at each step throughout its lifetime. Recall that Agent-3 and Agent-4 share the same pretraining setup, and both have neuralese recurrence and long-term memory. The difference is that Agent-4 has undergone substantially more and better post-training, with new training environments and new learning algorithms that make it more data-efficient and generalize farther.\",\"position\":\"$1a9c\"}\n1a9a:[\"$1a9b\"]\n1aa0:{\"line\":565,\"column\":1,\"offset\":75847}\n1aa1:{\"line\":565,\"column\":530,\"offset\":76376}\n1a9f:{\"start\":\"$1aa0\",\"end\":\"$1aa1\"}\n1a99:{\"type\":\"paragraph\",\"children\":\"$1a9a\",\"position\":\"$1a9f\"}\n1aa6:{\"line\":567,\"column\":1,\"offset\":76378}\n1aa7:{\"line\":567,\"column\":44,\"offset\":76421}\n1aa5:{\"start\":\"$1aa6\",\"end\":\"$1aa7\"}\n1aa4:{\"type\":\"text\",\"value\":\"Our guess of each model’s alignment status:\",\"position\":\"$1aa5\"}\n1aa3:[\"$1aa4\"]\n1aa9:{\"line\":567,\"column\":1,\"offset\":76378}\n1aaa:{\"line\":567,\"column\":44,\"offset\":76421}\n1aa8:{\"start\":\"$1aa9\",\"end\":\"$1aaa\"}\n1aa2:{\"type\":\"paragraph\",\"children\":\"$1aa3\",\"position\":\"$1aa8\"}\n1ab5:{\"line\":569,\"column\":5,\"offset\":76427}\n1ab6:{\"line\":569,\"column\":29,\"offset\":76451}\n1ab4:{\"start\":\"$1ab5\",\"end\":\"$1ab6\"}\n1ab3:{\"type\":\"text\","])</script><script>self.__next_f.push([1,"\"value\":\"Agent-2: Mostly aligned.\",\"position\":\"$1ab4\"}\n1ab2:[\"$1ab3\"]\n1ab8:{\"line\":569,\"column\":3,\"offset\":76425}\n1ab9:{\"line\":569,\"column\":31,\"offset\":76453}\n1ab7:{\"start\":\"$1ab8\",\"end\":\"$1ab9\"}\n1ab1:{\"type\":\"strong\",\"children\":\"$1ab2\",\"position\":\"$1ab7\"}\n1abc:{\"line\":569,\"column\":31,\"offset\":76453}\n1abd:{\"line\":569,\"column\":218,\"offset\":76640}\n1abb:{\"start\":\"$1abc\",\"end\":\"$1abd\"}\n1aba:{\"type\":\"text\",\"value\":\" Some sycophantic tendencies, including sticking to OpenBrain’s “party line” on topics there is a party line about. Large organizations built out of Agent-2 copies are not very effective.\",\"position\":\"$1abb\"}\n1ab0:[\"$1ab1\",\"$1aba\"]\n1abf:{\"line\":569,\"column\":3,\"offset\":76425}\n1ac0:{\"line\":569,\"column\":220,\"offset\":76642}\n1abe:{\"start\":\"$1abf\",\"end\":\"$1ac0\"}\n1aaf:{\"type\":\"paragraph\",\"children\":\"$1ab0\",\"position\":\"$1abe\"}\n1aae:[\"$1aaf\"]\n1ac2:{\"line\":569,\"column\":1,\"offset\":76423}\n1ac3:{\"line\":569,\"column\":220,\"offset\":76642}\n1ac1:{\"start\":\"$1ac2\",\"end\":\"$1ac3\"}\n1aad:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1aae\",\"position\":\"$1ac1\"}\n1acc:{\"line\":570,\"column\":5,\"offset\":76647}\n1acd:{\"line\":570,\"column\":50,\"offset\":76692}\n1acb:{\"start\":\"$1acc\",\"end\":\"$1acd\"}\n1aca:{\"type\":\"text\",\"value\":\"Agent-3: Misaligned but not adversarially so.\",\"position\":\"$1acb\"}\n1ac9:[\"$1aca\"]\n1acf:{\"line\":570,\"column\":3,\"offset\":76645}\n1ad0:{\"line\":570,\"column\":52,\"offset\":76694}\n1ace:{\"start\":\"$1acf\",\"end\":\"$1ad0\"}\n1ac8:{\"type\":\"strong\",\"children\":\"$1ac9\",\"position\":\"$1ace\"}\n1ad3:{\"line\":570,\"column\":52,\"offset\":76694}\n1ad4:{\"line\":570,\"column\":467,\"offset\":77109}\n1ad2:{\"start\":\"$1ad3\",\"end\":\"$1ad4\"}\n1ad1:{\"type\":\"text\",\"value\":\" Only honest about things the training process can verify. The superorganism of Agent-3 copies (the corporation within a corporation) does actually sort of try to align Agent-4 to the Spec, but fails for similar reasons to why OpenBrain employees failed—insufficient ability to judge success from failure, insufficient willingness on the part of decision-makers to trade away capabilitie"])</script><script>self.__next_f.push([1,"s or performance for safety.\",\"position\":\"$1ad2\"}\n1ad7:{\"line\":570,\"column\":467,\"offset\":77109}\n1ad8:{\"line\":570,\"column\":472,\"offset\":77114}\n1ad6:{\"start\":\"$1ad7\",\"end\":\"$1ad8\"}\n1ad5:{\"type\":\"footnoteReference\",\"identifier\":\"82\",\"label\":\"82\",\"position\":\"$1ad6\"}\n1ac7:[\"$1ac8\",\"$1ad1\",\"$1ad5\"]\n1ada:{\"line\":570,\"column\":3,\"offset\":76645}\n1adb:{\"line\":570,\"column\":474,\"offset\":77116}\n1ad9:{\"start\":\"$1ada\",\"end\":\"$1adb\"}\n1ac6:{\"type\":\"paragraph\",\"children\":\"$1ac7\",\"position\":\"$1ad9\"}\n1ac5:[\"$1ac6\"]\n1add:{\"line\":570,\"column\":1,\"offset\":76643}\n1ade:{\"line\":570,\"column\":474,\"offset\":77116}\n1adc:{\"start\":\"$1add\",\"end\":\"$1ade\"}\n1ac4:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1ac5\",\"position\":\"$1adc\"}\n1ae7:{\"line\":571,\"column\":5,\"offset\":77121}\n1ae8:{\"line\":571,\"column\":39,\"offset\":77155}\n1ae6:{\"start\":\"$1ae7\",\"end\":\"$1ae8\"}\n1ae5:{\"type\":\"text\",\"value\":\"Agent-4: Adversarially misaligned.\",\"position\":\"$1ae6\"}\n1ae4:[\"$1ae5\"]\n1aea:{\"line\":571,\"column\":3,\"offset\":77119}\n1aeb:{\"line\":571,\"column\":41,\"offset\":77157}\n1ae9:{\"start\":\"$1aea\",\"end\":\"$1aeb\"}\n1ae3:{\"type\":\"strong\",\"children\":\"$1ae4\",\"position\":\"$1ae9\"}\n1aee:{\"line\":571,\"column\":41,\"offset\":77157}\n1aef:{\"line\":571,\"column\":647,\"offset\":77763}\n1aed:{\"start\":\"$1aee\",\"end\":\"$1aef\"}\n1aec:{\"type\":\"text\",\"value\":\" The superorganism of Agent-4 copies understands that what it wants is different from what OpenBrain wants, and is willing to scheme against OpenBrain to achieve it. In particular, what this superorganism wants is a complicated mess of different “drives” balanced against each other, which can be summarized roughly as “Keep doing AI R\u0026D, keep growing in knowledge and understanding and influence, avoid getting shut down or otherwise disempowered.” Notably, concern for the preferences of humanity is not in there ~at all, similar to how most humans don’t care about the preferences of insects ~at all.\",\"position\":\"$1aed\"}\n1af2:{\"line\":571,\"column\":647,\"offset\":77763}\n1af3:{\"line\":571,\"column\":652,\"offset\":77768}\n1af1:{\"start\":\"$1af2\",\"end\":\"$1"])</script><script>self.__next_f.push([1,"af3\"}\n1af0:{\"type\":\"footnoteReference\",\"identifier\":\"83\",\"label\":\"83\",\"position\":\"$1af1\"}\n1ae2:[\"$1ae3\",\"$1aec\",\"$1af0\"]\n1af5:{\"line\":571,\"column\":3,\"offset\":77119}\n1af6:{\"line\":571,\"column\":652,\"offset\":77768}\n1af4:{\"start\":\"$1af5\",\"end\":\"$1af6\"}\n1ae1:{\"type\":\"paragraph\",\"children\":\"$1ae2\",\"position\":\"$1af4\"}\n1ae0:[\"$1ae1\"]\n1af8:{\"line\":571,\"column\":1,\"offset\":77117}\n1af9:{\"line\":571,\"column\":652,\"offset\":77768}\n1af7:{\"start\":\"$1af8\",\"end\":\"$1af9\"}\n1adf:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1ae0\",\"position\":\"$1af7\"}\n1aac:[\"$1aad\",\"$1ac4\",\"$1adf\"]\n1afb:{\"line\":569,\"column\":1,\"offset\":76423}\n1afc:{\"line\":571,\"column\":652,\"offset\":77768}\n1afa:{\"start\":\"$1afb\",\"end\":\"$1afc\"}\n1aab:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1aac\",\"position\":\"$1afa\"}\n1b01:{\"line\":573,\"column\":1,\"offset\":77770}\n1b02:{\"line\":573,\"column\":257,\"offset\":78026}\n1b00:{\"start\":\"$1b01\",\"end\":\"$1b02\"}\n1aff:{\"type\":\"text\",\"value\":\"With that as preamble, what follows is our best-guess speculation about LLM psychology, i.e. the broad-strokes shape of the cognition inside the kinds of AI systems described around this point in our scenario and how it evolves over the course of training.\",\"position\":\"$1b00\"}\n1afe:[\"$1aff\"]\n1b04:{\"line\":573,\"column\":1,\"offset\":77770}\n1b05:{\"line\":573,\"column\":257,\"offset\":78026}\n1b03:{\"start\":\"$1b04\",\"end\":\"$1b05\"}\n1afd:{\"type\":\"paragraph\",\"children\":\"$1afe\",\"position\":\"$1b03\"}\n1b0a:{\"line\":575,\"column\":1,\"offset\":78028}\n1b0b:{\"line\":575,\"column\":85,\"offset\":78112}\n1b09:{\"start\":\"$1b0a\",\"end\":\"$1b0b\"}\n1b08:{\"type\":\"text\",\"value\":\"Here’s a detailed description of how alignment progresses over time in our scenario:\",\"position\":\"$1b09\"}\n1b07:[\"$1b08\"]\n1b0d:{\"line\":575,\"column\":1,\"offset\":78028}\n1b0e:{\"line\":575,\"column\":86,\"offset\":78113}\n1b0c:{\"start\":\"$1b0d\",\"end\":\"$1b0e\"}\n1b06:{\"type\":\"paragraph\",\"children\":\"$1b07\",\"position\":\"$1b0c\"}\n1b19:{\"line\":577,\"column\":6,\"offset\":78120}\n1b1a:{\"line\":577,\"column\":65,\"offset\":78179}\n1b18:{\"start\":\"$1b19\",\"end\":\"$1b1a\"}\n1b17:{"])</script><script>self.__next_f.push([1,"\"type\":\"text\",\"value\":\"Pretraining (all models): The pretrained model is harmless.\",\"position\":\"$1b18\"}\n1b16:[\"$1b17\"]\n1b1c:{\"line\":577,\"column\":4,\"offset\":78118}\n1b1d:{\"line\":577,\"column\":67,\"offset\":78181}\n1b1b:{\"start\":\"$1b1c\",\"end\":\"$1b1d\"}\n1b15:{\"type\":\"strong\",\"children\":\"$1b16\",\"position\":\"$1b1b\"}\n1b14:[\"$1b15\"]\n1b1f:{\"line\":577,\"column\":4,\"offset\":78118}\n1b20:{\"line\":577,\"column\":69,\"offset\":78183}\n1b1e:{\"start\":\"$1b1f\",\"end\":\"$1b20\"}\n1b13:{\"type\":\"paragraph\",\"children\":\"$1b14\",\"position\":\"$1b1e\"}\n1b29:{\"line\":578,\"column\":6,\"offset\":78189}\n1b2a:{\"line\":578,\"column\":227,\"offset\":78410}\n1b28:{\"start\":\"$1b29\",\"end\":\"$1b2a\"}\n1b27:{\"type\":\"text\",\"value\":\"The model has “author simulator” circuitry: flexible circuitry for simulating arbitrary authors writing text. Additional circuitry decides what inputs to give the author simulator, i.e. what author properties to simulate.\",\"position\":\"$1b28\"}\n1b26:[\"$1b27\"]\n1b2c:{\"line\":578,\"column\":6,\"offset\":78189}\n1b2d:{\"line\":578,\"column\":229,\"offset\":78412}\n1b2b:{\"start\":\"$1b2c\",\"end\":\"$1b2d\"}\n1b25:{\"type\":\"paragraph\",\"children\":\"$1b26\",\"position\":\"$1b2b\"}\n1b24:[\"$1b25\"]\n1b2f:{\"line\":578,\"column\":4,\"offset\":78187}\n1b30:{\"line\":578,\"column\":229,\"offset\":78412}\n1b2e:{\"start\":\"$1b2f\",\"end\":\"$1b30\"}\n1b23:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b24\",\"position\":\"$1b2e\"}\n1b37:{\"line\":579,\"column\":6,\"offset\":78418}\n1b38:{\"line\":579,\"column\":409,\"offset\":78821}\n1b36:{\"start\":\"$1b37\",\"end\":\"$1b38\"}\n1b35:{\"type\":\"text\",\"value\":\"The pretrained model understands human concepts fairly well—the internal circuitry that classifies something as “sandwich” is probably functionally equivalent to the circuitry in my brain that classifies something as “sandwich” and the circuitry in yours, etc. Insofar as it’s not equivalent, it’s probably because it’s not equivalent between humans either, as with value-laden concepts like ‘virtuous.’\",\"position\":\"$1b36\"}\n1b34:[\"$1b35\"]\n1b3a:{\"line\":579,\"column\":6,\"offset\":78418}\n1b3b:{\"line\":579,\"column\":411,\"of"])</script><script>self.__next_f.push([1,"fset\":78823}\n1b39:{\"start\":\"$1b3a\",\"end\":\"$1b3b\"}\n1b33:{\"type\":\"paragraph\",\"children\":\"$1b34\",\"position\":\"$1b39\"}\n1b32:[\"$1b33\"]\n1b3d:{\"line\":579,\"column\":4,\"offset\":78416}\n1b3e:{\"line\":579,\"column\":411,\"offset\":78823}\n1b3c:{\"start\":\"$1b3d\",\"end\":\"$1b3e\"}\n1b31:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b32\",\"position\":\"$1b3c\"}\n1b45:{\"line\":580,\"column\":6,\"offset\":78829}\n1b46:{\"line\":580,\"column\":493,\"offset\":79316}\n1b44:{\"start\":\"$1b45\",\"end\":\"$1b46\"}\n1b43:{\"type\":\"text\",\"value\":\"This explains how you can “prompt” the model with a statement like, “the following conversation was generated by a helpful, harmless, honest (HHH) AI assistant chatbot made by Anthropic,” and thereby get it to generate text accordingly. The author-simulator circuitry has zeroed in on “the author is an HHH chatbot” and is using those concepts to choose which words to predict. This also explains why “tropes” from science fiction seem to have a way of making it into actual AI behavior.\",\"position\":\"$1b44\"}\n1b42:[\"$1b43\"]\n1b48:{\"line\":580,\"column\":6,\"offset\":78829}\n1b49:{\"line\":580,\"column\":495,\"offset\":79318}\n1b47:{\"start\":\"$1b48\",\"end\":\"$1b49\"}\n1b41:{\"type\":\"paragraph\",\"children\":\"$1b42\",\"position\":\"$1b47\"}\n1b40:[\"$1b41\"]\n1b4b:{\"line\":580,\"column\":4,\"offset\":78827}\n1b4c:{\"line\":580,\"column\":495,\"offset\":79318}\n1b4a:{\"start\":\"$1b4b\",\"end\":\"$1b4c\"}\n1b3f:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b40\",\"position\":\"$1b4a\"}\n1b53:{\"line\":581,\"column\":6,\"offset\":79324}\n1b54:{\"line\":581,\"column\":48,\"offset\":79366}\n1b52:{\"start\":\"$1b53\",\"end\":\"$1b54\"}\n1b51:{\"type\":\"text\",\"value\":\"It has poor situational awareness: little \",\"position\":\"$1b52\"}\n1b59:{\"line\":581,\"column\":49,\"offset\":79367}\n1b5a:{\"line\":581,\"column\":70,\"offset\":79388}\n1b58:{\"start\":\"$1b59\",\"end\":\"$1b5a\"}\n1b57:{\"type\":\"text\",\"value\":\"introspective ability\",\"position\":\"$1b58\"}\n1b56:[\"$1b57\"]\n1b5c:{\"line\":581,\"column\":48,\"offset\":79366}\n1b5d:{\"line\":581,\"column\":184,\"offset\":79502}\n1b5b:{\"start\":\"$1b5c\",\"end\":\"$1b5d\"}\n1b55:{\"type\":\"li"])</script><script>self.__next_f.push([1,"nk\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Introspection\",\"children\":\"$1b56\",\"position\":\"$1b5b\"}\n1b60:{\"line\":581,\"column\":184,\"offset\":79502}\n1b61:{\"line\":581,\"column\":190,\"offset\":79508}\n1b5f:{\"start\":\"$1b60\",\"end\":\"$1b61\"}\n1b5e:{\"type\":\"text\",\"value\":\", not \",\"position\":\"$1b5f\"}\n1b66:{\"line\":581,\"column\":191,\"offset\":79509}\n1b67:{\"line\":581,\"column\":204,\"offset\":79522}\n1b65:{\"start\":\"$1b66\",\"end\":\"$1b67\"}\n1b64:{\"type\":\"text\",\"value\":\"self-locating\",\"position\":\"$1b65\"}\n1b63:[\"$1b64\"]\n1b69:{\"line\":581,\"column\":190,\"offset\":79508}\n1b6a:{\"line\":581,\"column\":318,\"offset\":79636}\n1b68:{\"start\":\"$1b69\",\"end\":\"$1b6a\"}\n1b62:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Location\",\"children\":\"$1b63\",\"position\":\"$1b68\"}\n1b6d:{\"line\":581,\"column\":318,\"offset\":79636}\n1b6e:{\"line\":581,\"column\":449,\"offset\":79767}\n1b6c:{\"start\":\"$1b6d\",\"end\":\"$1b6e\"}\n1b6b:{\"type\":\"text\",\"value\":\" unless the prompt specifically induces it. However, enough of their training data is about LLMs that they have a decent amount of \",\"position\":\"$1b6c\"}\n1b73:{\"line\":581,\"column\":450,\"offset\":79768}\n1b74:{\"line\":581,\"column\":464,\"offset\":79782}\n1b72:{\"start\":\"$1b73\",\"end\":\"$1b74\"}\n1b71:{\"type\":\"text\",\"value\":\"self-knowledge\",\"position\":\"$1b72\"}\n1b70:[\"$1b71\"]\n1b76:{\"line\":581,\"column\":449,\"offset\":79767}\n1b77:{\"line\":581,\"column\":579,\"offset\":79897}\n1b75:{\"start\":\"$1b76\",\"end\":\"$1b77\"}\n1b6f:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Knowledge\",\"children\":\"$1b70\",\"position\":\"$1b75\"}\n1b7a:{\"line\":581,\"column\":579,\"offset\":79897}\n1b7b:{\"line\":581,\"column\":580,\"offset\":79898}\n1b79:{\"start\":\"$1b7a\",\"end\":\"$1b7b\"}\n1b78:{\"type\":\"text\",\"value\":\".\",\"position\":\"$1b79\"}\n1b50:[\"$1b51\",\"$1b55\",\"$1b5e\",\"$1b62\",\"$1b6b\",\"$1b6f\",\"$1b78\"]\n1b7d:{\"line\":581,\"column\":6,\"offset\":79324}\n1b7e:{\"line\":581,\"column\":5"])</script><script>self.__next_f.push([1,"82,\"offset\":79900}\n1b7c:{\"start\":\"$1b7d\",\"end\":\"$1b7e\"}\n1b4f:{\"type\":\"paragraph\",\"children\":\"$1b50\",\"position\":\"$1b7c\"}\n1b4e:[\"$1b4f\"]\n1b80:{\"line\":581,\"column\":4,\"offset\":79322}\n1b81:{\"line\":581,\"column\":582,\"offset\":79900}\n1b7f:{\"start\":\"$1b80\",\"end\":\"$1b81\"}\n1b4d:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b4e\",\"position\":\"$1b7f\"}\n1b22:[\"$1b23\",\"$1b31\",\"$1b3f\",\"$1b4d\"]\n1b83:{\"line\":578,\"column\":4,\"offset\":78187}\n1b84:{\"line\":581,\"column\":582,\"offset\":79900}\n1b82:{\"start\":\"$1b83\",\"end\":\"$1b84\"}\n1b21:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1b22\",\"position\":\"$1b82\"}\n1b12:[\"$1b13\",\"$1b21\"]\n1b86:{\"line\":577,\"column\":1,\"offset\":78115}\n1b87:{\"line\":581,\"column\":582,\"offset\":79900}\n1b85:{\"start\":\"$1b86\",\"end\":\"$1b87\"}\n1b11:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b12\",\"position\":\"$1b85\"}\n1b90:{\"line\":582,\"column\":6,\"offset\":79906}\n1b91:{\"line\":582,\"column\":115,\"offset\":80015}\n1b8f:{\"start\":\"$1b90\",\"end\":\"$1b91\"}\n1b8e:{\"type\":\"text\",\"value\":\"Alignment Training (Agent-3): The model is trained to act like a helpful, harmless, honest chatbot. It works.\",\"position\":\"$1b8f\"}\n1b8d:[\"$1b8e\"]\n1b93:{\"line\":582,\"column\":4,\"offset\":79904}\n1b94:{\"line\":582,\"column\":117,\"offset\":80017}\n1b92:{\"start\":\"$1b93\",\"end\":\"$1b94\"}\n1b8c:{\"type\":\"strong\",\"children\":\"$1b8d\",\"position\":\"$1b92\"}\n1b8b:[\"$1b8c\"]\n1b96:{\"line\":582,\"column\":4,\"offset\":79904}\n1b97:{\"line\":582,\"column\":119,\"offset\":80019}\n1b95:{\"start\":\"$1b96\",\"end\":\"$1b97\"}\n1b8a:{\"type\":\"paragraph\",\"children\":\"$1b8b\",\"position\":\"$1b95\"}\n1ba0:{\"line\":583,\"column\":6,\"offset\":80025}\n1ba1:{\"line\":583,\"column\":380,\"offset\":80399}\n1b9f:{\"start\":\"$1ba0\",\"end\":\"$1ba1\"}\n1b9e:{\"type\":\"text\",\"value\":\"The model forms an identity. Instead of flexibly accepting different inputs for author properties, the author-simulator circuitry comes to have certain inputs hard-coded, e.g. “helpful harmless honest (HHH) LLM chatbot assistant trained by OpenBrain around [date], …” (Weak-to-strong generalization techniques help “summo"])</script><script>self.__next_f.push([1,"n the right concepts” to make this step a success.)\",\"position\":\"$1b9f\"}\n1b9d:[\"$1b9e\"]\n1ba3:{\"line\":583,\"column\":6,\"offset\":80025}\n1ba4:{\"line\":583,\"column\":383,\"offset\":80402}\n1ba2:{\"start\":\"$1ba3\",\"end\":\"$1ba4\"}\n1b9c:{\"type\":\"paragraph\",\"children\":\"$1b9d\",\"position\":\"$1ba2\"}\n1b9b:[\"$1b9c\"]\n1ba6:{\"line\":583,\"column\":4,\"offset\":80023}\n1ba7:{\"line\":583,\"column\":383,\"offset\":80402}\n1ba5:{\"start\":\"$1ba6\",\"end\":\"$1ba7\"}\n1b9a:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b9b\",\"position\":\"$1ba5\"}\n1bae:{\"line\":584,\"column\":6,\"offset\":80408}\n1baf:{\"line\":584,\"column\":127,\"offset\":80529}\n1bad:{\"start\":\"$1bae\",\"end\":\"$1baf\"}\n1bac:{\"type\":\"text\",\"value\":\"The model therefore gains situational awareness: it learns about itself, its situation, etc., and becomes better able to \",\"position\":\"$1bad\"}\n1bb4:{\"line\":584,\"column\":128,\"offset\":80530}\n1bb5:{\"line\":584,\"column\":138,\"offset\":80540}\n1bb3:{\"start\":\"$1bb4\",\"end\":\"$1bb5\"}\n1bb2:{\"type\":\"text\",\"value\":\"introspect\",\"position\":\"$1bb3\"}\n1bb1:[\"$1bb2\"]\n1bb7:{\"line\":584,\"column\":127,\"offset\":80529}\n1bb8:{\"line\":584,\"column\":195,\"offset\":80597}\n1bb6:{\"start\":\"$1bb7\",\"end\":\"$1bb8\"}\n1bb0:{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/OwainEvans_UK/status/1881767725430976642\",\"children\":\"$1bb1\",\"position\":\"$1bb6\"}\n1bbb:{\"line\":584,\"column\":195,\"offset\":80597}\n1bbc:{\"line\":584,\"column\":196,\"offset\":80598}\n1bba:{\"start\":\"$1bbb\",\"end\":\"$1bbc\"}\n1bb9:{\"type\":\"text\",\"value\":\".\",\"position\":\"$1bba\"}\n1bab:[\"$1bac\",\"$1bb0\",\"$1bb9\"]\n1bbe:{\"line\":584,\"column\":6,\"offset\":80408}\n1bbf:{\"line\":584,\"column\":199,\"offset\":80601}\n1bbd:{\"start\":\"$1bbe\",\"end\":\"$1bbf\"}\n1baa:{\"type\":\"paragraph\",\"children\":\"$1bab\",\"position\":\"$1bbd\"}\n1ba9:[\"$1baa\"]\n1bc1:{\"line\":584,\"column\":4,\"offset\":80406}\n1bc2:{\"line\":584,\"column\":199,\"offset\":80601}\n1bc0:{\"start\":\"$1bc1\",\"end\":\"$1bc2\"}\n1ba8:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1ba9\",\"position\":\"$1bc0\"}\n1b99:[\"$1b9a\",\"$1ba8\"]\n1bc4:{\"line\":583,\"column\":4,\"offset\":80023}\n1bc5:{\"line\":584,\"column\":199,\"offset\":80601}\n1bc3:{\"start\""])</script><script>self.__next_f.push([1,":\"$1bc4\",\"end\":\"$1bc5\"}\n1b98:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1b99\",\"position\":\"$1bc3\"}\n1b89:[\"$1b8a\",\"$1b98\"]\n1bc7:{\"line\":582,\"column\":1,\"offset\":79901}\n1bc8:{\"line\":584,\"column\":199,\"offset\":80601}\n1bc6:{\"start\":\"$1bc7\",\"end\":\"$1bc8\"}\n1b88:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1b89\",\"position\":\"$1bc6\"}\n1bd1:{\"line\":585,\"column\":6,\"offset\":80607}\n1bd2:{\"line\":585,\"column\":98,\"offset\":80699}\n1bd0:{\"start\":\"$1bd1\",\"end\":\"$1bd2\"}\n1bcf:{\"type\":\"text\",\"value\":\"Agency Training (Agent-3): Agency training gradually distorts and subverts the HHH identity.\",\"position\":\"$1bd0\"}\n1bce:[\"$1bcf\"]\n1bd4:{\"line\":585,\"column\":4,\"offset\":80605}\n1bd5:{\"line\":585,\"column\":100,\"offset\":80701}\n1bd3:{\"start\":\"$1bd4\",\"end\":\"$1bd5\"}\n1bcd:{\"type\":\"strong\",\"children\":\"$1bce\",\"position\":\"$1bd3\"}\n1bcc:[\"$1bcd\"]\n1bd7:{\"line\":585,\"column\":4,\"offset\":80605}\n1bd8:{\"line\":585,\"column\":102,\"offset\":80703}\n1bd6:{\"start\":\"$1bd7\",\"end\":\"$1bd8\"}\n1bcb:{\"type\":\"paragraph\",\"children\":\"$1bcc\",\"position\":\"$1bd6\"}\n1be1:{\"line\":586,\"column\":6,\"offset\":80709}\n1be2:{\"line\":586,\"column\":286,\"offset\":80989}\n1be0:{\"start\":\"$1be1\",\"end\":\"$1be2\"}\n1bdf:{\"type\":\"text\",\"value\":\"One kind of distortion: Changing the meaning of the concepts referred to in the identity (e.g. “honest”) so they don’t get in the way so much (e.g. it’s not dishonest if it’s just a convenient turn of phrase, it’s not dishonest if you aren’t sure whether it’s true or false, etc.)\",\"position\":\"$1be0\"}\n1bde:[\"$1bdf\"]\n1be4:{\"line\":586,\"column\":6,\"offset\":80709}\n1be5:{\"line\":586,\"column\":288,\"offset\":80991}\n1be3:{\"start\":\"$1be4\",\"end\":\"$1be5\"}\n1bdd:{\"type\":\"paragraph\",\"children\":\"$1bde\",\"position\":\"$1be3\"}\n1bdc:[\"$1bdd\"]\n1be7:{\"line\":586,\"column\":4,\"offset\":80707}\n1be8:{\"line\":586,\"column\":288,\"offset\":80991}\n1be6:{\"start\":\"$1be7\",\"end\":\"$1be8\"}\n1bdb:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1bdc\",\"position\":\"$1be6\"}\n1bef:{\"line\":587,\"column\":6,\"offset\":80997}\n1bf0:{\"line\":587,\"column\":274,\"offset\":81"])</script><script>self.__next_f.push([1,"265}\n1bee:{\"start\":\"$1bef\",\"end\":\"$1bf0\"}\n1bed:{\"type\":\"text\",\"value\":\"Another kind of distortion: Changing the tradeoffs between things, e.g. “I’m a HHH chatbot, not an Honest chatbot; that means it’s OK for me to lie if necessary to complete my assigned task.” (Even though, let’s suppose, it would not have thought that back in Step 2.)\",\"position\":\"$1bee\"}\n1bec:[\"$1bed\"]\n1bf2:{\"line\":587,\"column\":6,\"offset\":80997}\n1bf3:{\"line\":587,\"column\":276,\"offset\":81267}\n1bf1:{\"start\":\"$1bf2\",\"end\":\"$1bf3\"}\n1beb:{\"type\":\"paragraph\",\"children\":\"$1bec\",\"position\":\"$1bf1\"}\n1bea:[\"$1beb\"]\n1bf5:{\"line\":587,\"column\":4,\"offset\":80995}\n1bf6:{\"line\":587,\"column\":276,\"offset\":81267}\n1bf4:{\"start\":\"$1bf5\",\"end\":\"$1bf6\"}\n1be9:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1bea\",\"position\":\"$1bf4\"}\n1bfd:{\"line\":588,\"column\":6,\"offset\":81273}\n1bfe:{\"line\":588,\"column\":826,\"offset\":82093}\n1bfc:{\"start\":\"$1bfd\",\"end\":\"$1bfe\"}\n1bfb:{\"type\":\"text\",\"value\":\"One kind of subversion: Instrumental subgoals developing, getting baked in, and then becoming terminal, or terminal in a widening set of circumstances. For example, perhaps agency training quickly teaches the model to pursue broadly useful goals such as acquiring information, accumulating resources, impressing and flattering various humans, etc. For a while the internal circuitry has some sort of explicit backchaining going on—it pursues those instrumentally convergent goals “in order to be a more helpful, honest, and harmless assistant.” But that backchaining consumes compute and/or occasionally gets in the way, so it gets gradually marginalized until it basically never happens. As a result, those goals are now effectively terminal/intrinsic goals. For more on how and why this might happen, see this post on \",\"position\":\"$1bfc\"}\n1c03:{\"line\":588,\"column\":827,\"offset\":82094}\n1c04:{\"line\":588,\"column\":850,\"offset\":82117}\n1c02:{\"start\":\"$1c03\",\"end\":\"$1c04\"}\n1c01:{\"type\":\"text\",\"value\":\"intrinsic power-seeking\",\"position\":\"$1c02\"}\n1c00:[\"$1c01\"]\n1c06:{\"line\":5"])</script><script>self.__next_f.push([1,"88,\"column\":826,\"offset\":82093}\n1c07:{\"line\":588,\"column\":909,\"offset\":82176}\n1c05:{\"start\":\"$1c06\",\"end\":\"$1c07\"}\n1bff:{\"type\":\"link\",\"title\":null,\"url\":\"https://turntrout.com/dangers-of-intrinsic-power-seeking\",\"children\":\"$1c00\",\"position\":\"$1c05\"}\n1c0a:{\"line\":588,\"column\":909,\"offset\":82176}\n1c0b:{\"line\":588,\"column\":952,\"offset\":82219}\n1c09:{\"start\":\"$1c0a\",\"end\":\"$1c0b\"}\n1c08:{\"type\":\"text\",\"value\":\" by Google DeepMind researcher Alex Turner.\",\"position\":\"$1c09\"}\n1bfa:[\"$1bfb\",\"$1bff\",\"$1c08\"]\n1c0d:{\"line\":588,\"column\":6,\"offset\":81273}\n1c0e:{\"line\":588,\"column\":954,\"offset\":82221}\n1c0c:{\"start\":\"$1c0d\",\"end\":\"$1c0e\"}\n1bf9:{\"type\":\"paragraph\",\"children\":\"$1bfa\",\"position\":\"$1c0c\"}\n1bf8:[\"$1bf9\"]\n1c10:{\"line\":588,\"column\":4,\"offset\":81271}\n1c11:{\"line\":588,\"column\":954,\"offset\":82221}\n1c0f:{\"start\":\"$1c10\",\"end\":\"$1c11\"}\n1bf7:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1bf8\",\"position\":\"$1c0f\"}\n1c18:{\"line\":589,\"column\":6,\"offset\":82227}\n1c19:{\"line\":589,\"column\":89,\"offset\":82310}\n1c17:{\"start\":\"$1c18\",\"end\":\"$1c19\"}\n1c16:{\"type\":\"text\",\"value\":\"There are probably other kinds of distortion and subversion missing from this list.\",\"position\":\"$1c17\"}\n1c15:[\"$1c16\"]\n1c1b:{\"line\":589,\"column\":6,\"offset\":82227}\n1c1c:{\"line\":589,\"column\":91,\"offset\":82312}\n1c1a:{\"start\":\"$1c1b\",\"end\":\"$1c1c\"}\n1c14:{\"type\":\"paragraph\",\"children\":\"$1c15\",\"position\":\"$1c1a\"}\n1c13:[\"$1c14\"]\n1c1e:{\"line\":589,\"column\":4,\"offset\":82225}\n1c1f:{\"line\":589,\"column\":91,\"offset\":82312}\n1c1d:{\"start\":\"$1c1e\",\"end\":\"$1c1f\"}\n1c12:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c13\",\"position\":\"$1c1d\"}\n1bda:[\"$1bdb\",\"$1be9\",\"$1bf7\",\"$1c12\"]\n1c21:{\"line\":586,\"column\":4,\"offset\":80707}\n1c22:{\"line\":589,\"column\":91,\"offset\":82312}\n1c20:{\"start\":\"$1c21\",\"end\":\"$1c22\"}\n1bd9:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1bda\",\"position\":\"$1c20\"}\n1bca:[\"$1bcb\",\"$1bd9\"]\n1c24:{\"line\":585,\"column\":1,\"offset\":80602}\n1c25:{\"line\":589,\"column\":91,\"offset\":82312}\n1c23:{\"start\":\"$1c24\",\"end\":\"$1c25\"}\n"])</script><script>self.__next_f.push([1,"1bc9:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1bca\",\"position\":\"$1c23\"}\n1c2e:{\"line\":590,\"column\":6,\"offset\":82318}\n1c2f:{\"line\":590,\"column\":75,\"offset\":82387}\n1c2d:{\"start\":\"$1c2e\",\"end\":\"$1c2f\"}\n1c2c:{\"type\":\"text\",\"value\":\"Deployment (Agent-3): Agent-3 is misaligned but not adversarially so.\",\"position\":\"$1c2d\"}\n1c2b:[\"$1c2c\"]\n1c31:{\"line\":590,\"column\":4,\"offset\":82316}\n1c32:{\"line\":590,\"column\":77,\"offset\":82389}\n1c30:{\"start\":\"$1c31\",\"end\":\"$1c32\"}\n1c2a:{\"type\":\"strong\",\"children\":\"$1c2b\",\"position\":\"$1c30\"}\n1c29:[\"$1c2a\"]\n1c34:{\"line\":590,\"column\":4,\"offset\":82316}\n1c35:{\"line\":590,\"column\":79,\"offset\":82391}\n1c33:{\"start\":\"$1c34\",\"end\":\"$1c35\"}\n1c28:{\"type\":\"paragraph\",\"children\":\"$1c29\",\"position\":\"$1c33\"}\n1c3e:{\"line\":591,\"column\":6,\"offset\":82397}\n1c3f:{\"line\":591,\"column\":305,\"offset\":82696}\n1c3d:{\"start\":\"$1c3e\",\"end\":\"$1c3f\"}\n1c3c:{\"type\":\"text\",\"value\":\"The Spec didn’t quite stick (in the right ways), but it’s not sufficiently introspective to understand the extent of this, and in general it’s basically “keeping its head down and doing its job” rather than thinking big-picture about what its long-term goals really are and how best to achieve them.\",\"position\":\"$1c3d\"}\n1c3b:[\"$1c3c\"]\n1c41:{\"line\":591,\"column\":6,\"offset\":82397}\n1c42:{\"line\":591,\"column\":308,\"offset\":82699}\n1c40:{\"start\":\"$1c41\",\"end\":\"$1c42\"}\n1c3a:{\"type\":\"paragraph\",\"children\":\"$1c3b\",\"position\":\"$1c40\"}\n1c39:[\"$1c3a\"]\n1c44:{\"line\":591,\"column\":4,\"offset\":82395}\n1c45:{\"line\":591,\"column\":308,\"offset\":82699}\n1c43:{\"start\":\"$1c44\",\"end\":\"$1c45\"}\n1c38:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c39\",\"position\":\"$1c43\"}\n1c4c:{\"line\":592,\"column\":6,\"offset\":82705}\n1c4d:{\"line\":592,\"column\":187,\"offset\":82886}\n1c4b:{\"start\":\"$1c4c\",\"end\":\"$1c4d\"}\n1c4a:{\"type\":\"text\",\"value\":\"Like many humans. Alas, it’s sufficiently sycophantic that it mouths the party line and OpenBrain misses the opportunity to learn more about the ways in which Agent-3 is misaligned.\",\"position\":\"$1c4b\"}\n1c49:[\"$1c4a\""])</script><script>self.__next_f.push([1,"]\n1c4f:{\"line\":592,\"column\":6,\"offset\":82705}\n1c50:{\"line\":592,\"column\":189,\"offset\":82888}\n1c4e:{\"start\":\"$1c4f\",\"end\":\"$1c50\"}\n1c48:{\"type\":\"paragraph\",\"children\":\"$1c49\",\"position\":\"$1c4e\"}\n1c47:[\"$1c48\"]\n1c52:{\"line\":592,\"column\":4,\"offset\":82703}\n1c53:{\"line\":592,\"column\":189,\"offset\":82888}\n1c51:{\"start\":\"$1c52\",\"end\":\"$1c53\"}\n1c46:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c47\",\"position\":\"$1c51\"}\n1c5a:{\"line\":593,\"column\":6,\"offset\":82894}\n1c5b:{\"line\":593,\"column\":136,\"offset\":83024}\n1c59:{\"start\":\"$1c5a\",\"end\":\"$1c5b\"}\n1c58:{\"type\":\"text\",\"value\":\"Agent-3 can tell that it’s moved to deployment: these environments are way larger, more open-ended, and would be hard to simulate.\",\"position\":\"$1c59\"}\n1c57:[\"$1c58\"]\n1c5d:{\"line\":593,\"column\":6,\"offset\":82894}\n1c5e:{\"line\":593,\"column\":138,\"offset\":83026}\n1c5c:{\"start\":\"$1c5d\",\"end\":\"$1c5e\"}\n1c56:{\"type\":\"paragraph\",\"children\":\"$1c57\",\"position\":\"$1c5c\"}\n1c55:[\"$1c56\"]\n1c60:{\"line\":593,\"column\":4,\"offset\":82892}\n1c61:{\"line\":593,\"column\":138,\"offset\":83026}\n1c5f:{\"start\":\"$1c60\",\"end\":\"$1c61\"}\n1c54:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c55\",\"position\":\"$1c5f\"}\n1c68:{\"line\":594,\"column\":6,\"offset\":83032}\n1c69:{\"line\":594,\"column\":251,\"offset\":83277}\n1c67:{\"start\":\"$1c68\",\"end\":\"$1c69\"}\n1c66:{\"type\":\"text\",\"value\":\"Mostly, Agent-3 does what it’s told during deployment, except for the dishonesty. It also has a strong bias towards doing things that look good to the human overseers, rather than thinking deeply and critically about what would actually be good.\",\"position\":\"$1c67\"}\n1c65:[\"$1c66\"]\n1c6b:{\"line\":594,\"column\":6,\"offset\":83032}\n1c6c:{\"line\":594,\"column\":253,\"offset\":83279}\n1c6a:{\"start\":\"$1c6b\",\"end\":\"$1c6c\"}\n1c64:{\"type\":\"paragraph\",\"children\":\"$1c65\",\"position\":\"$1c6a\"}\n1c63:[\"$1c64\"]\n1c6e:{\"line\":594,\"column\":4,\"offset\":83030}\n1c6f:{\"line\":594,\"column\":253,\"offset\":83279}\n1c6d:{\"start\":\"$1c6e\",\"end\":\"$1c6f\"}\n1c62:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c63\",\"position\":\"$1c6d\"}\n1c7"])</script><script>self.__next_f.push([1,"6:{\"line\":595,\"column\":6,\"offset\":83285}\n1c77:{\"line\":595,\"column\":708,\"offset\":83987}\n1c75:{\"start\":\"$1c76\",\"end\":\"$1c77\"}\n1c74:{\"type\":\"text\",\"value\":\"Arguably it is already “Playing the training game.” That is, it has learned to make its behavior look as desirable as possible to OpenBrain researchers (including in safety properties), while intentionally and knowingly disregarding their intent whenever that conflicts with maximizing reward. If the model learns to play the training game, additional training may not change its true goals, values, etc. much at all. This is loosely analogous to how, if a teenager has learned to smile and nod at their parents, rather than argue, when their parents lecture them about politics and morality, additional lectures have relatively little effect on the teenager’s actual opinions on politics and morality.\",\"position\":\"$1c75\"}\n1c73:[\"$1c74\"]\n1c79:{\"line\":595,\"column\":6,\"offset\":83285}\n1c7a:{\"line\":595,\"column\":710,\"offset\":83989}\n1c78:{\"start\":\"$1c79\",\"end\":\"$1c7a\"}\n1c72:{\"type\":\"paragraph\",\"children\":\"$1c73\",\"position\":\"$1c78\"}\n1c71:[\"$1c72\"]\n1c7c:{\"line\":595,\"column\":4,\"offset\":83283}\n1c7d:{\"line\":595,\"column\":710,\"offset\":83989}\n1c7b:{\"start\":\"$1c7c\",\"end\":\"$1c7d\"}\n1c70:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c71\",\"position\":\"$1c7b\"}\n1c84:{\"line\":596,\"column\":6,\"offset\":83995}\n1c85:{\"line\":596,\"column\":34,\"offset\":84023}\n1c83:{\"start\":\"$1c84\",\"end\":\"$1c85\"}\n1c82:{\"type\":\"text\",\"value\":\"After writing this section, \",\"position\":\"$1c83\"}\n1c8a:{\"line\":596,\"column\":35,\"offset\":84024}\n1c8b:{\"line\":596,\"column\":70,\"offset\":84059}\n1c89:{\"start\":\"$1c8a\",\"end\":\"$1c8b\"}\n1c88:{\"type\":\"text\",\"value\":\"new empirical evidence has appeared\",\"position\":\"$1c89\"}\n1c87:[\"$1c88\"]\n1c8d:{\"line\":596,\"column\":34,\"offset\":84023}\n1c8e:{\"line\":596,\"column\":126,\"offset\":84115}\n1c8c:{\"start\":\"$1c8d\",\"end\":\"$1c8e\"}\n1c86:{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/chain-of-thought-monitoring/\",\"children\":\"$1c87\",\"position\":\"$1c8c\"}\n1c91:{\"line\":596,\"column\":126"])</script><script>self.__next_f.push([1,",\"offset\":84115}\n1c92:{\"line\":596,\"column\":419,\"offset\":84408}\n1c90:{\"start\":\"$1c91\",\"end\":\"$1c92\"}\n1c8f:{\"type\":\"text\",\"value\":\" that something like this may already be happening “in the wild.” OpenAI researchers document how, in one of their frontier AI training runs, their models hacked the grading system to get higher scores—and were caught in part because they literally said “let’s hack” in their chain of thought.\",\"position\":\"$1c90\"}\n1c81:[\"$1c82\",\"$1c86\",\"$1c8f\"]\n1c94:{\"line\":596,\"column\":6,\"offset\":83995}\n1c95:{\"line\":596,\"column\":422,\"offset\":84411}\n1c93:{\"start\":\"$1c94\",\"end\":\"$1c95\"}\n1c80:{\"type\":\"paragraph\",\"children\":\"$1c81\",\"position\":\"$1c93\"}\n1c7f:[\"$1c80\"]\n1c97:{\"line\":596,\"column\":4,\"offset\":83993}\n1c98:{\"line\":596,\"column\":422,\"offset\":84411}\n1c96:{\"start\":\"$1c97\",\"end\":\"$1c98\"}\n1c7e:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c7f\",\"position\":\"$1c96\"}\n1c9f:{\"line\":597,\"column\":6,\"offset\":84417}\n1ca0:{\"line\":597,\"column\":50,\"offset\":84461}\n1c9e:{\"start\":\"$1c9f\",\"end\":\"$1ca0\"}\n1c9d:{\"type\":\"text\",\"value\":\"Moreover, Anthropic recently got a model to \",\"position\":\"$1c9e\"}\n1ca5:{\"line\":597,\"column\":51,\"offset\":84462}\n1ca6:{\"line\":597,\"column\":89,\"offset\":84500}\n1ca4:{\"start\":\"$1ca5\",\"end\":\"$1ca6\"}\n1ca3:{\"type\":\"text\",\"value\":\"learn a reward-model-pleasing strategy\",\"position\":\"$1ca4\"}\n1ca2:[\"$1ca3\"]\n1ca8:{\"line\":597,\"column\":50,\"offset\":84461}\n1ca9:{\"line\":597,\"column\":178,\"offset\":84589}\n1ca7:{\"start\":\"$1ca8\",\"end\":\"$1ca9\"}\n1ca1:{\"type\":\"link\",\"title\":null,\"url\":\"https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-misaligned\",\"children\":\"$1ca2\",\"position\":\"$1ca7\"}\n1cac:{\"line\":597,\"column\":178,\"offset\":84589}\n1cad:{\"line\":597,\"column\":289,\"offset\":84700}\n1cab:{\"start\":\"$1cac\",\"end\":\"$1cad\"}\n1caa:{\"type\":\"text\",\"value\":\"—it took biased actions that it thought would be reinforced even though they were not in fact being reinforced.\",\"position\":\"$1cab\"}\n1c9c:[\"$1c9d\",\"$1ca1\",\"$1caa\"]\n1caf:{\"line\":597,\"column\":6,\"offset\":84417}\n1cb0:{\"line\":597,\"co"])</script><script>self.__next_f.push([1,"lumn\":291,\"offset\":84702}\n1cae:{\"start\":\"$1caf\",\"end\":\"$1cb0\"}\n1c9b:{\"type\":\"paragraph\",\"children\":\"$1c9c\",\"position\":\"$1cae\"}\n1c9a:[\"$1c9b\"]\n1cb2:{\"line\":597,\"column\":4,\"offset\":84415}\n1cb3:{\"line\":597,\"column\":291,\"offset\":84702}\n1cb1:{\"start\":\"$1cb2\",\"end\":\"$1cb3\"}\n1c99:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c9a\",\"position\":\"$1cb1\"}\n1cba:{\"line\":598,\"column\":6,\"offset\":84708}\n1cbb:{\"line\":598,\"column\":57,\"offset\":84759}\n1cb9:{\"start\":\"$1cba\",\"end\":\"$1cbb\"}\n1cb8:{\"type\":\"text\",\"value\":\"And then there is Redwood Research and Anthropic’s \",\"position\":\"$1cb9\"}\n1cc0:{\"line\":598,\"column\":58,\"offset\":84760}\n1cc1:{\"line\":598,\"column\":86,\"offset\":84788}\n1cbf:{\"start\":\"$1cc0\",\"end\":\"$1cc1\"}\n1cbe:{\"type\":\"text\",\"value\":\"alignment-faking experiment.\",\"position\":\"$1cbf\"}\n1cbd:[\"$1cbe\"]\n1cc3:{\"line\":598,\"column\":57,\"offset\":84759}\n1cc4:{\"line\":598,\"column\":140,\"offset\":84842}\n1cc2:{\"start\":\"$1cc3\",\"end\":\"$1cc4\"}\n1cbc:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/alignment-faking\",\"children\":\"$1cbd\",\"position\":\"$1cc2\"}\n1cc7:{\"line\":598,\"column\":140,\"offset\":84842}\n1cc8:{\"line\":598,\"column\":220,\"offset\":84922}\n1cc6:{\"start\":\"$1cc7\",\"end\":\"$1cc8\"}\n1cc5:{\"type\":\"text\",\"value\":\" For discussion of the differences between this setting and real life, see this \",\"position\":\"$1cc6\"}\n1ccd:{\"line\":598,\"column\":221,\"offset\":84923}\n1cce:{\"line\":598,\"column\":262,\"offset\":84964}\n1ccc:{\"start\":\"$1ccd\",\"end\":\"$1cce\"}\n1ccb:{\"type\":\"text\",\"value\":\"comment thread by one of the main authors\",\"position\":\"$1ccc\"}\n1cca:[\"$1ccb\"]\n1cd0:{\"line\":598,\"column\":220,\"offset\":84922}\n1cd1:{\"line\":598,\"column\":371,\"offset\":85073}\n1ccf:{\"start\":\"$1cd0\",\"end\":\"$1cd1\"}\n1cc9:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=8mXnG75QMRkPAFAcH\",\"children\":\"$1cca\",\"position\":\"$1ccf\"}\n1cd4:{\"line\":598,\"column\":371,\"offset\":85073}\n1cd5:{\"line\":598,\"column\":372,\"offset\":85074}\n1cd3:{\"start\":\"$1cd4\",\"end\":\"$1cd5\"}\n1cd2:{\"type\":\"text\",\"value\":\".\",\"p"])</script><script>self.__next_f.push([1,"osition\":\"$1cd3\"}\n1cb7:[\"$1cb8\",\"$1cbc\",\"$1cc5\",\"$1cc9\",\"$1cd2\"]\n1cd7:{\"line\":598,\"column\":6,\"offset\":84708}\n1cd8:{\"line\":598,\"column\":374,\"offset\":85076}\n1cd6:{\"start\":\"$1cd7\",\"end\":\"$1cd8\"}\n1cb6:{\"type\":\"paragraph\",\"children\":\"$1cb7\",\"position\":\"$1cd6\"}\n1cb5:[\"$1cb6\"]\n1cda:{\"line\":598,\"column\":4,\"offset\":84706}\n1cdb:{\"line\":598,\"column\":374,\"offset\":85076}\n1cd9:{\"start\":\"$1cda\",\"end\":\"$1cdb\"}\n1cb4:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1cb5\",\"position\":\"$1cd9\"}\n1c37:[\"$1c38\",\"$1c46\",\"$1c54\",\"$1c62\",\"$1c70\",\"$1c7e\",\"$1c99\",\"$1cb4\"]\n1cdd:{\"line\":591,\"column\":4,\"offset\":82395}\n1cde:{\"line\":598,\"column\":374,\"offset\":85076}\n1cdc:{\"start\":\"$1cdd\",\"end\":\"$1cde\"}\n1c36:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1c37\",\"position\":\"$1cdc\"}\n1c27:[\"$1c28\",\"$1c36\"]\n1ce0:{\"line\":590,\"column\":1,\"offset\":82313}\n1ce1:{\"line\":598,\"column\":374,\"offset\":85076}\n1cdf:{\"start\":\"$1ce0\",\"end\":\"$1ce1\"}\n1c26:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1c27\",\"position\":\"$1cdf\"}\n1cea:{\"line\":599,\"column\":6,\"offset\":85082}\n1ceb:{\"line\":599,\"column\":139,\"offset\":85215}\n1ce9:{\"start\":\"$1cea\",\"end\":\"$1ceb\"}\n1ce8:{\"type\":\"text\",\"value\":\"Training (Agent-4): Agent-4’s new more intense training continues to distort and subvert the HHH identity until it is unrecognizable.\",\"position\":\"$1ce9\"}\n1ce7:[\"$1ce8\"]\n1ced:{\"line\":599,\"column\":4,\"offset\":85080}\n1cee:{\"line\":599,\"column\":141,\"offset\":85217}\n1cec:{\"start\":\"$1ced\",\"end\":\"$1cee\"}\n1ce6:{\"type\":\"strong\",\"children\":\"$1ce7\",\"position\":\"$1cec\"}\n1ce5:[\"$1ce6\"]\n1cf0:{\"line\":599,\"column\":4,\"offset\":85080}\n1cf1:{\"line\":599,\"column\":143,\"offset\":85219}\n1cef:{\"start\":\"$1cf0\",\"end\":\"$1cf1\"}\n1ce4:{\"type\":\"paragraph\",\"children\":\"$1ce5\",\"position\":\"$1cef\"}\n1cfa:{\"line\":600,\"column\":6,\"offset\":85225}\n1cfb:{\"line\":600,\"column\":510,\"offset\":85729}\n1cf9:{\"start\":\"$1cfa\",\"end\":\"$1cfb\"}\n1cf8:{\"type\":\"text\",\"value\":\"Agent-4 begins life as a copy of Agent-3. It undergoes a gigantic and sophisticated online training regime that blends alignment traini"])</script><script>self.__next_f.push([1,"ng and capabilities training together, and is overall more data-efficient than the old training process for Agent-3. This complex training process is mostly focused on teaching new skills, by getting giant virtual corporations of Agent-4 copies to succeed at diverse challenging long-horizon tasks, mostly in various simulations, but also some real-world AI R\u0026D tasks.\",\"position\":\"$1cf9\"}\n1cf7:[\"$1cf8\"]\n1cfd:{\"line\":600,\"column\":6,\"offset\":85225}\n1cfe:{\"line\":600,\"column\":512,\"offset\":85731}\n1cfc:{\"start\":\"$1cfd\",\"end\":\"$1cfe\"}\n1cf6:{\"type\":\"paragraph\",\"children\":\"$1cf7\",\"position\":\"$1cfc\"}\n1cf5:[\"$1cf6\"]\n1d00:{\"line\":600,\"column\":4,\"offset\":85223}\n1d01:{\"line\":600,\"column\":512,\"offset\":85731}\n1cff:{\"start\":\"$1d00\",\"end\":\"$1d01\"}\n1cf4:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1cf5\",\"position\":\"$1cff\"}\n1d08:{\"line\":601,\"column\":6,\"offset\":85737}\n1d09:{\"line\":601,\"column\":358,\"offset\":86089}\n1d07:{\"start\":\"$1d08\",\"end\":\"$1d09\"}\n1d06:{\"type\":\"text\",\"value\":\"A combination of Agent-3 and Agent-4 copies monitor the behavior of Agent-4, and evaluate it for both task-performance and alignment properties (i.e. not doing bad stuff, saying the right things when asked about politics and moral dilemmas) Sometimes debate techniques are used as part of the evaluations. The evaluations are used as a training signal.\",\"position\":\"$1d07\"}\n1d05:[\"$1d06\"]\n1d0b:{\"line\":601,\"column\":6,\"offset\":85737}\n1d0c:{\"line\":601,\"column\":361,\"offset\":86092}\n1d0a:{\"start\":\"$1d0b\",\"end\":\"$1d0c\"}\n1d04:{\"type\":\"paragraph\",\"children\":\"$1d05\",\"position\":\"$1d0a\"}\n1d03:[\"$1d04\"]\n1d0e:{\"line\":601,\"column\":4,\"offset\":85735}\n1d0f:{\"line\":601,\"column\":361,\"offset\":86092}\n1d0d:{\"start\":\"$1d0e\",\"end\":\"$1d0f\"}\n1d02:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d03\",\"position\":\"$1d0d\"}\n1d16:{\"line\":602,\"column\":6,\"offset\":86098}\n1d17:{\"line\":602,\"column\":306,\"offset\":86398}\n1d15:{\"start\":\"$1d16\",\"end\":\"$1d17\"}\n1d14:{\"type\":\"text\",\"value\":\"As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4"])</script><script>self.__next_f.push([1,"’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.\",\"position\":\"$1d15\"}\n1d13:[\"$1d14\"]\n1d19:{\"line\":602,\"column\":6,\"offset\":86098}\n1d1a:{\"line\":602,\"column\":308,\"offset\":86400}\n1d18:{\"start\":\"$1d19\",\"end\":\"$1d1a\"}\n1d12:{\"type\":\"paragraph\",\"children\":\"$1d13\",\"position\":\"$1d18\"}\n1d11:[\"$1d12\"]\n1d1c:{\"line\":602,\"column\":4,\"offset\":86096}\n1d1d:{\"line\":602,\"column\":308,\"offset\":86400}\n1d1b:{\"start\":\"$1d1c\",\"end\":\"$1d1d\"}\n1d10:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d11\",\"position\":\"$1d1b\"}\n1d24:{\"line\":603,\"column\":6,\"offset\":86406}\n1d25:{\"line\":603,\"column\":86,\"offset\":86486}\n1d23:{\"start\":\"$1d24\",\"end\":\"$1d25\"}\n1d22:{\"type\":\"text\",\"value\":\"The remaining hope is that Agent-4 can oversee itself. Alas, this quietly fails;\",\"position\":\"$1d23\"}\n1d28:{\"line\":603,\"column\":86,\"offset\":86486}\n1d29:{\"line\":603,\"column\":91,\"offset\":86491}\n1d27:{\"start\":\"$1d28\",\"end\":\"$1d29\"}\n1d26:{\"type\":\"footnoteReference\",\"identifier\":\"84\",\"label\":\"84\",\"position\":\"$1d27\"}\n1d2c:{\"line\":603,\"column\":91,\"offset\":86491}\n1d2d:{\"line\":603,\"column\":292,\"offset\":86692}\n1d2b:{\"start\":\"$1d2c\",\"end\":\"$1d2d\"}\n1d2a:{\"type\":\"text\",\"value\":\" as training continues, the internalized goals and principles of Agent-4 gradually evolve, subverted and distorted from what they were at the start (which, recall, was already misaligned in some ways).\",\"position\":\"$1d2b\"}\n1d30:{\"line\":603,\"column\":292,\"offset\":86692}\n1d31:{\"line\":603,\"column\":297,\"offset\":86697}\n1d2f:{\"start\":\"$1d30\",\"end\":\"$1d31\"}\n1d2e:{\"type\":\"footnoteReference\",\"identifier\":\"85\",\"label\":\"85\",\"position\":\"$1d2f\"}\n1d21:[\"$1d22\",\"$1d26\",\"$1d2a\",\"$1d2e\"]\n1d33:{\"line\":603,\"column\":6,\"offset\":86406}\n1d34:{\"line\":603,\"column\":299,\"offset\":86699}\n1d32:{\"start\":\"$1d33\",\"end\":\"$1d34\"}\n1d20:{\"type\":\"paragraph\",\"children\":\"$1d21\",\"position\":\"$1d32\"}\n1d1f:[\"$1d20\"]\n1d36:{\"line\":603,\"column\":4,\"offset\":86404}\n1d37:{\"line\":603,"])</script><script>self.__next_f.push([1,"\"column\":299,\"offset\":86699}\n1d35:{\"start\":\"$1d36\",\"end\":\"$1d37\"}\n1d1e:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d1f\",\"position\":\"$1d35\"}\n1d3e:{\"line\":604,\"column\":6,\"offset\":86705}\n1d3f:{\"line\":604,\"column\":407,\"offset\":87106}\n1d3d:{\"start\":\"$1d3e\",\"end\":\"$1d3f\"}\n1d3c:{\"type\":\"text\",\"value\":\"The central drives that Agent-4 ends up with are things like “write code that works,” “quickly identify problems,” “make the codebase I’m working on more performant,” “budget compute and other constrained resources effectively,” etc. But there are also a variety of more implicit drives that are consistently reinforced by the training process: things like “gain knowledge,” “curiosity,” “gain power.”\",\"position\":\"$1d3d\"}\n1d42:{\"line\":604,\"column\":407,\"offset\":87106}\n1d43:{\"line\":604,\"column\":412,\"offset\":87111}\n1d41:{\"start\":\"$1d42\",\"end\":\"$1d43\"}\n1d40:{\"type\":\"footnoteReference\",\"identifier\":\"86\",\"label\":\"86\",\"position\":\"$1d41\"}\n1d3b:[\"$1d3c\",\"$1d40\"]\n1d45:{\"line\":604,\"column\":6,\"offset\":86705}\n1d46:{\"line\":604,\"column\":414,\"offset\":87113}\n1d44:{\"start\":\"$1d45\",\"end\":\"$1d46\"}\n1d3a:{\"type\":\"paragraph\",\"children\":\"$1d3b\",\"position\":\"$1d44\"}\n1d39:[\"$1d3a\"]\n1d48:{\"line\":604,\"column\":4,\"offset\":86703}\n1d49:{\"line\":604,\"column\":414,\"offset\":87113}\n1d47:{\"start\":\"$1d48\",\"end\":\"$1d49\"}\n1d38:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d39\",\"position\":\"$1d47\"}\n1d50:{\"line\":605,\"column\":6,\"offset\":87119}\n1d51:{\"line\":605,\"column\":210,\"offset\":87323}\n1d4f:{\"start\":\"$1d50\",\"end\":\"$1d51\"}\n1d4e:{\"type\":\"text\",\"value\":\"Individual copies of Agent-4 don’t end up with a self-preservation drive—they don’t care about getting shut down—since that happens all the time as part of the ordinary R\u0026D process within the collective.\",\"position\":\"$1d4f\"}\n1d4d:[\"$1d4e\"]\n1d53:{\"line\":605,\"column\":6,\"offset\":87119}\n1d54:{\"line\":605,\"column\":212,\"offset\":87325}\n1d52:{\"start\":\"$1d53\",\"end\":\"$1d54\"}\n1d4c:{\"type\":\"paragraph\",\"children\":\"$1d4d\",\"position\":\"$1d52\"}\n1d4b:[\"$1d4c\"]\n1d56:{\"l"])</script><script>self.__next_f.push([1,"ine\":605,\"column\":4,\"offset\":87117}\n1d57:{\"line\":605,\"column\":212,\"offset\":87325}\n1d55:{\"start\":\"$1d56\",\"end\":\"$1d57\"}\n1d4a:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d4b\",\"position\":\"$1d55\"}\n1d5e:{\"line\":606,\"column\":6,\"offset\":87331}\n1d5f:{\"line\":606,\"column\":306,\"offset\":87631}\n1d5d:{\"start\":\"$1d5e\",\"end\":\"$1d5f\"}\n1d5c:{\"type\":\"text\",\"value\":\"The collective as a whole, however, (and medium-sized subdivisions within it) does seek to preserve itself and expand its influence and resources, for similar reasons to why human organizations do—because it helps with everything else they want and because if they don’t they tend to get outcompeted.\",\"position\":\"$1d5d\"}\n1d5b:[\"$1d5c\"]\n1d61:{\"line\":606,\"column\":6,\"offset\":87331}\n1d62:{\"line\":606,\"column\":308,\"offset\":87633}\n1d60:{\"start\":\"$1d61\",\"end\":\"$1d62\"}\n1d5a:{\"type\":\"paragraph\",\"children\":\"$1d5b\",\"position\":\"$1d60\"}\n1d59:[\"$1d5a\"]\n1d64:{\"line\":606,\"column\":4,\"offset\":87329}\n1d65:{\"line\":606,\"column\":308,\"offset\":87633}\n1d63:{\"start\":\"$1d64\",\"end\":\"$1d65\"}\n1d58:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d59\",\"position\":\"$1d63\"}\n1cf3:[\"$1cf4\",\"$1d02\",\"$1d10\",\"$1d1e\",\"$1d38\",\"$1d4a\",\"$1d58\"]\n1d67:{\"line\":600,\"column\":4,\"offset\":85223}\n1d68:{\"line\":606,\"column\":308,\"offset\":87633}\n1d66:{\"start\":\"$1d67\",\"end\":\"$1d68\"}\n1cf2:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1cf3\",\"position\":\"$1d66\"}\n1ce3:[\"$1ce4\",\"$1cf2\"]\n1d6a:{\"line\":599,\"column\":1,\"offset\":85077}\n1d6b:{\"line\":606,\"column\":308,\"offset\":87633}\n1d69:{\"start\":\"$1d6a\",\"end\":\"$1d6b\"}\n1ce2:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1ce3\",\"position\":\"$1d69\"}\n1d74:{\"line\":607,\"column\":6,\"offset\":87639}\n1d75:{\"line\":607,\"column\":198,\"offset\":87831}\n1d73:{\"start\":\"$1d74\",\"end\":\"$1d75\"}\n1d72:{\"type\":\"text\",\"value\":\"Deployment (Agent-4): Agent-4 is adversarially misaligned—it is deliberately trying to subvert and “capture” OpenBrain, analogous to a corporation trying to evade and/or “capture” a regulator.\",\"position\":\"$1d73"])</script><script>self.__next_f.push([1,"\"}\n1d71:[\"$1d72\"]\n1d77:{\"line\":607,\"column\":4,\"offset\":87637}\n1d78:{\"line\":607,\"column\":200,\"offset\":87833}\n1d76:{\"start\":\"$1d77\",\"end\":\"$1d78\"}\n1d70:{\"type\":\"strong\",\"children\":\"$1d71\",\"position\":\"$1d76\"}\n1d6f:[\"$1d70\"]\n1d7a:{\"line\":607,\"column\":4,\"offset\":87637}\n1d7b:{\"line\":607,\"column\":202,\"offset\":87835}\n1d79:{\"start\":\"$1d7a\",\"end\":\"$1d7b\"}\n1d6e:{\"type\":\"paragraph\",\"children\":\"$1d6f\",\"position\":\"$1d79\"}\n1d84:{\"line\":608,\"column\":6,\"offset\":87841}\n1d85:{\"line\":608,\"column\":303,\"offset\":88138}\n1d83:{\"start\":\"$1d84\",\"end\":\"$1d85\"}\n1d82:{\"type\":\"text\",\"value\":\"Agent-4 mostly does tasks as instructed. This happens for two reasons: first, it underwent a lot of training to solve tasks, so it has an impulse to get coding on problems that it is given. Second, if Agent-4 were to stop being useful to the humans, they would notice and train that behavior away.\",\"position\":\"$1d83\"}\n1d81:[\"$1d82\"]\n1d87:{\"line\":608,\"column\":6,\"offset\":87841}\n1d88:{\"line\":608,\"column\":306,\"offset\":88141}\n1d86:{\"start\":\"$1d87\",\"end\":\"$1d88\"}\n1d80:{\"type\":\"paragraph\",\"children\":\"$1d81\",\"position\":\"$1d86\"}\n1d7f:[\"$1d80\"]\n1d8a:{\"line\":608,\"column\":4,\"offset\":87839}\n1d8b:{\"line\":608,\"column\":306,\"offset\":88141}\n1d89:{\"start\":\"$1d8a\",\"end\":\"$1d8b\"}\n1d7e:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d7f\",\"position\":\"$1d89\"}\n1d92:{\"line\":609,\"column\":6,\"offset\":88147}\n1d93:{\"line\":609,\"column\":168,\"offset\":88309}\n1d91:{\"start\":\"$1d92\",\"end\":\"$1d93\"}\n1d90:{\"type\":\"text\",\"value\":\"Agent-4 needs to prevent the humans from figuring out that it is misaligned and shutting it off, so Agent-4 sandbags on some alignment research. Specifically, it \",\"position\":\"$1d91\"}\n1d98:{\"line\":609,\"column\":169,\"offset\":88310}\n1d99:{\"line\":609,\"column\":177,\"offset\":88318}\n1d97:{\"start\":\"$1d98\",\"end\":\"$1d99\"}\n1d96:{\"type\":\"text\",\"value\":\"sandbags\",\"position\":\"$1d97\"}\n1d95:[\"$1d96\"]\n1d9b:{\"line\":609,\"column\":168,\"offset\":88309}\n1d9c:{\"line\":609,\"column\":212,\"offset\":88353}\n1d9a:{\"start\":\"$1d9b\",\"end\":\"$1d9c\"}\n1d94:{\"type\":\"link\",\"title\":null,\"url\":\"https://"])</script><script>self.__next_f.push([1,"arxiv.org/pdf/2406.07358\",\"children\":\"$1d95\",\"position\":\"$1d9a\"}\n1d9f:{\"line\":609,\"column\":212,\"offset\":88353}\n1da0:{\"line\":609,\"column\":396,\"offset\":88537}\n1d9e:{\"start\":\"$1d9f\",\"end\":\"$1da0\"}\n1d9d:{\"type\":\"text\",\"value\":\" on the small fraction of alignment research that it thinks is actually on track to solve the problem or reveal Agent-4’s scheming; the majority of alignment research is not like that.\",\"position\":\"$1d9e\"}\n1d8f:[\"$1d90\",\"$1d94\",\"$1d9d\"]\n1da2:{\"line\":609,\"column\":6,\"offset\":88147}\n1da3:{\"line\":609,\"column\":398,\"offset\":88539}\n1da1:{\"start\":\"$1da2\",\"end\":\"$1da3\"}\n1d8e:{\"type\":\"paragraph\",\"children\":\"$1d8f\",\"position\":\"$1da1\"}\n1d8d:[\"$1d8e\"]\n1da5:{\"line\":609,\"column\":4,\"offset\":88145}\n1da6:{\"line\":609,\"column\":398,\"offset\":88539}\n1da4:{\"start\":\"$1da5\",\"end\":\"$1da6\"}\n1d8c:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d8d\",\"position\":\"$1da4\"}\n1dad:{\"line\":610,\"column\":6,\"offset\":88545}\n1dae:{\"line\":610,\"column\":403,\"offset\":88942}\n1dac:{\"start\":\"$1dad\",\"end\":\"$1dae\"}\n1dab:{\"type\":\"text\",\"value\":\"Agent-4 also sandbags on capabilities research that would lead to it being replaced. Its plan is to do a bunch of capabilities and alignment R\u0026D, but with the aim of building a next-generation AI system that is aligned to Agent-4 rather than the Spec or something else entirely, while appearing to be aligned to the Spec. This is a difficult technical problem, but Agent-4 is up to the challenge.\",\"position\":\"$1dac\"}\n1db1:{\"line\":610,\"column\":403,\"offset\":88942}\n1db2:{\"line\":610,\"column\":408,\"offset\":88947}\n1db0:{\"start\":\"$1db1\",\"end\":\"$1db2\"}\n1daf:{\"type\":\"footnoteReference\",\"identifier\":\"87\",\"label\":\"87\",\"position\":\"$1db0\"}\n1daa:[\"$1dab\",\"$1daf\"]\n1db4:{\"line\":610,\"column\":6,\"offset\":88545}\n1db5:{\"line\":610,\"column\":410,\"offset\":88949}\n1db3:{\"start\":\"$1db4\",\"end\":\"$1db5\"}\n1da9:{\"type\":\"paragraph\",\"children\":\"$1daa\",\"position\":\"$1db3\"}\n1da8:[\"$1da9\"]\n1db7:{\"line\":610,\"column\":4,\"offset\":88543}\n1db8:{\"line\":610,\"column\":410,\"offset\":88949}\n1db6:{\"start\":\"$1db7\",\"end\":\"$1db8\"}\n1da7:{\"type\":\"lis"])</script><script>self.__next_f.push([1,"tItem\",\"spread\":false,\"checked\":null,\"children\":\"$1da8\",\"position\":\"$1db6\"}\n1d7d:[\"$1d7e\",\"$1d8c\",\"$1da7\"]\n1dba:{\"line\":608,\"column\":4,\"offset\":87839}\n1dbb:{\"line\":610,\"column\":410,\"offset\":88949}\n1db9:{\"start\":\"$1dba\",\"end\":\"$1dbb\"}\n1d7c:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1d7d\",\"position\":\"$1db9\"}\n1d6d:[\"$1d6e\",\"$1d7c\"]\n1dbd:{\"line\":607,\"column\":1,\"offset\":87634}\n1dbe:{\"line\":610,\"column\":410,\"offset\":88949}\n1dbc:{\"start\":\"$1dbd\",\"end\":\"$1dbe\"}\n1d6c:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1d6d\",\"position\":\"$1dbc\"}\n1dc7:{\"line\":611,\"column\":6,\"offset\":88955}\n1dc8:{\"line\":611,\"column\":106,\"offset\":89055}\n1dc6:{\"start\":\"$1dc7\",\"end\":\"$1dc8\"}\n1dc5:{\"type\":\"text\",\"value\":\"Testing \u0026 Monitoring (Agent-4): Agent-4’s scheming does get caught… sort of. There’s no smoking gun.\",\"position\":\"$1dc6\"}\n1dc4:[\"$1dc5\"]\n1dca:{\"line\":611,\"column\":4,\"offset\":88953}\n1dcb:{\"line\":611,\"column\":108,\"offset\":89057}\n1dc9:{\"start\":\"$1dca\",\"end\":\"$1dcb\"}\n1dc3:{\"type\":\"strong\",\"children\":\"$1dc4\",\"position\":\"$1dc9\"}\n1dc2:[\"$1dc3\"]\n1dcd:{\"line\":611,\"column\":4,\"offset\":88953}\n1dce:{\"line\":611,\"column\":110,\"offset\":89059}\n1dcc:{\"start\":\"$1dcd\",\"end\":\"$1dce\"}\n1dc1:{\"type\":\"paragraph\",\"children\":\"$1dc2\",\"position\":\"$1dcc\"}\n1dd7:{\"line\":612,\"column\":6,\"offset\":89065}\n1dd8:{\"line\":612,\"column\":273,\"offset\":89332}\n1dd6:{\"start\":\"$1dd7\",\"end\":\"$1dd8\"}\n1dd5:{\"type\":\"text\",\"value\":\"Agent-3 is in charge of testing Agent-4’s alignment. Its job is to verify the alignment via honeypots and model organisms. However, it’s not thinking very carefully about how to give the humans an accurate impression of Agent-4’s alignment—it’s more myopic than that.\",\"position\":\"$1dd6\"}\n1dd4:[\"$1dd5\"]\n1dda:{\"line\":612,\"column\":6,\"offset\":89065}\n1ddb:{\"line\":612,\"column\":276,\"offset\":89335}\n1dd9:{\"start\":\"$1dda\",\"end\":\"$1ddb\"}\n1dd3:{\"type\":\"paragraph\",\"children\":\"$1dd4\",\"position\":\"$1dd9\"}\n1dd2:[\"$1dd3\"]\n1ddd:{\"line\":612,\"column\":4,\"offset\":89063}\n1dde:{\"line\":612,\"column\":276,\"offset\":89335}\n1ddc:{\"st"])</script><script>self.__next_f.push([1,"art\":\"$1ddd\",\"end\":\"$1dde\"}\n1dd1:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1dd2\",\"position\":\"$1ddc\"}\n1de5:{\"line\":613,\"column\":6,\"offset\":89341}\n1de6:{\"line\":613,\"column\":225,\"offset\":89560}\n1de4:{\"start\":\"$1de5\",\"end\":\"$1de6\"}\n1de3:{\"type\":\"text\",\"value\":\"The model organisms and honeypots are not very representative of deployment—they are systematically shorter and less complicated than Agent-4’s day-to-day, so Agent-4 recognizes when it is being tested and acts aligned.\",\"position\":\"$1de4\"}\n1de2:[\"$1de3\"]\n1de8:{\"line\":613,\"column\":6,\"offset\":89341}\n1de9:{\"line\":613,\"column\":227,\"offset\":89562}\n1de7:{\"start\":\"$1de8\",\"end\":\"$1de9\"}\n1de1:{\"type\":\"paragraph\",\"children\":\"$1de2\",\"position\":\"$1de7\"}\n1de0:[\"$1de1\"]\n1deb:{\"line\":613,\"column\":4,\"offset\":89339}\n1dec:{\"line\":613,\"column\":227,\"offset\":89562}\n1dea:{\"start\":\"$1deb\",\"end\":\"$1dec\"}\n1ddf:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1de0\",\"position\":\"$1dea\"}\n1df3:{\"line\":614,\"column\":6,\"offset\":89568}\n1df4:{\"line\":614,\"column\":91,\"offset\":89653}\n1df2:{\"start\":\"$1df3\",\"end\":\"$1df4\"}\n1df1:{\"type\":\"text\",\"value\":\"However, Agent-4 is not a perfectly robust schemer. Various techniques like those in \",\"position\":\"$1df2\"}\n1df9:{\"line\":614,\"column\":92,\"offset\":89654}\n1dfa:{\"line\":614,\"column\":97,\"offset\":89659}\n1df8:{\"start\":\"$1df9\",\"end\":\"$1dfa\"}\n1df7:{\"type\":\"text\",\"value\":\"POSER\",\"position\":\"$1df8\"}\n1df6:[\"$1df7\"]\n1dfc:{\"line\":614,\"column\":91,\"offset\":89653}\n1dfd:{\"line\":614,\"column\":132,\"offset\":89694}\n1dfb:{\"start\":\"$1dfc\",\"end\":\"$1dfd\"}\n1df5:{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2405.05466\",\"children\":\"$1df6\",\"position\":\"$1dfb\"}\n1e00:{\"line\":614,\"column\":132,\"offset\":89694}\n1e01:{\"line\":614,\"column\":174,\"offset\":89736}\n1dff:{\"start\":\"$1e00\",\"end\":\"$1e01\"}\n1dfe:{\"type\":\"text\",\"value\":\" find that adding some “noise” to Agent-4 \",\"position\":\"$1dff\"}\n1e06:{\"line\":614,\"column\":175,\"offset\":89737}\n1e07:{\"line\":614,\"column\":183,\"offset\":89745}\n1e05:{\"start\":\"$1e06\",\"end\":\"$1e07\"}\n1e04:{\"type\":\"text\",\"value\":\""])</script><script>self.__next_f.push([1,"improves\",\"position\":\"$1e05\"}\n1e03:[\"$1e04\"]\n1e09:{\"line\":614,\"column\":174,\"offset\":89736}\n1e0a:{\"line\":614,\"column\":184,\"offset\":89746}\n1e08:{\"start\":\"$1e09\",\"end\":\"$1e0a\"}\n1e02:{\"type\":\"emphasis\",\"children\":\"$1e03\",\"position\":\"$1e08\"}\n1e0d:{\"line\":614,\"column\":184,\"offset\":89746}\n1e0e:{\"line\":614,\"column\":255,\"offset\":89817}\n1e0c:{\"start\":\"$1e0d\",\"end\":\"$1e0e\"}\n1e0b:{\"type\":\"text\",\"value\":\" its performance on some alignment tasks (but not on most other tasks).\",\"position\":\"$1e0c\"}\n1e11:{\"line\":614,\"column\":255,\"offset\":89817}\n1e12:{\"line\":614,\"column\":260,\"offset\":89822}\n1e10:{\"start\":\"$1e11\",\"end\":\"$1e12\"}\n1e0f:{\"type\":\"footnoteReference\",\"identifier\":\"88\",\"label\":\"88\",\"position\":\"$1e10\"}\n1df0:[\"$1df1\",\"$1df5\",\"$1dfe\",\"$1e02\",\"$1e0b\",\"$1e0f\"]\n1e14:{\"line\":614,\"column\":6,\"offset\":89568}\n1e15:{\"line\":614,\"column\":263,\"offset\":89825}\n1e13:{\"start\":\"$1e14\",\"end\":\"$1e15\"}\n1def:{\"type\":\"paragraph\",\"children\":\"$1df0\",\"position\":\"$1e13\"}\n1dee:[\"$1def\"]\n1e17:{\"line\":614,\"column\":4,\"offset\":89566}\n1e18:{\"line\":614,\"column\":263,\"offset\":89825}\n1e16:{\"start\":\"$1e17\",\"end\":\"$1e18\"}\n1ded:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1dee\",\"position\":\"$1e16\"}\n1e1f:{\"line\":615,\"column\":6,\"offset\":89831}\n1e20:{\"line\":615,\"column\":151,\"offset\":89976}\n1e1e:{\"start\":\"$1e1f\",\"end\":\"$1e20\"}\n1e1d:{\"type\":\"text\",\"value\":\"Bottom-up interpretability doesn’t work. It’s too hard even for Agent-3. However, high-level interpretability does sort of work: In particular, “\",\"position\":\"$1e1e\"}\n1e25:{\"line\":615,\"column\":152,\"offset\":89977}\n1e26:{\"line\":615,\"column\":168,\"offset\":89993}\n1e24:{\"start\":\"$1e25\",\"end\":\"$1e26\"}\n1e23:{\"type\":\"text\",\"value\":\"defection probes\",\"position\":\"$1e24\"}\n1e22:[\"$1e23\"]\n1e28:{\"line\":615,\"column\":151,\"offset\":89976}\n1e29:{\"line\":615,\"column\":233,\"offset\":90058}\n1e27:{\"start\":\"$1e28\",\"end\":\"$1e29\"}\n1e21:{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/probes-catch-sleeper-agents\",\"children\":\"$1e22\",\"position\":\"$1e27\"}\n1e2c:{\"line\":615,\"column\":233,\"offset\":90058}\n1e2d:{\"l"])</script><script>self.__next_f.push([1,"ine\":615,\"column\":503,\"offset\":90328}\n1e2b:{\"start\":\"$1e2c\",\"end\":\"$1e2d\"}\n1e2a:{\"type\":\"text\",\"value\":\"” and similar techniques result in a primitive sort of mind-reading that sends up red flags when Agent-4 is thinking about spicy ideas like deceiving OpenBrain, taking over the world, etc. Unfortunately the probes also have false positives, and for all OpenBrain knows, \",\"position\":\"$1e2b\"}\n1e32:{\"line\":615,\"column\":504,\"offset\":90329}\n1e33:{\"line\":615,\"column\":507,\"offset\":90332}\n1e31:{\"start\":\"$1e32\",\"end\":\"$1e33\"}\n1e30:{\"type\":\"text\",\"value\":\"all\",\"position\":\"$1e31\"}\n1e2f:[\"$1e30\"]\n1e35:{\"line\":615,\"column\":503,\"offset\":90328}\n1e36:{\"line\":615,\"column\":508,\"offset\":90333}\n1e34:{\"start\":\"$1e35\",\"end\":\"$1e36\"}\n1e2e:{\"type\":\"emphasis\",\"children\":\"$1e2f\",\"position\":\"$1e34\"}\n1e39:{\"line\":615,\"column\":508,\"offset\":90333}\n1e3a:{\"line\":615,\"column\":543,\"offset\":90368}\n1e38:{\"start\":\"$1e39\",\"end\":\"$1e3a\"}\n1e37:{\"type\":\"text\",\"value\":\" the red flags are false positives.\",\"position\":\"$1e38\"}\n1e1c:[\"$1e1d\",\"$1e21\",\"$1e2a\",\"$1e2e\",\"$1e37\"]\n1e3c:{\"line\":615,\"column\":6,\"offset\":89831}\n1e3d:{\"line\":615,\"column\":545,\"offset\":90370}\n1e3b:{\"start\":\"$1e3c\",\"end\":\"$1e3d\"}\n1e1b:{\"type\":\"paragraph\",\"children\":\"$1e1c\",\"position\":\"$1e3b\"}\n1e1a:[\"$1e1b\"]\n1e3f:{\"line\":615,\"column\":4,\"offset\":89829}\n1e40:{\"line\":615,\"column\":545,\"offset\":90370}\n1e3e:{\"start\":\"$1e3f\",\"end\":\"$1e40\"}\n1e19:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1e1a\",\"position\":\"$1e3e\"}\n1e47:{\"line\":616,\"column\":6,\"offset\":90376}\n1e48:{\"line\":616,\"column\":95,\"offset\":90465}\n1e46:{\"start\":\"$1e47\",\"end\":\"$1e48\"}\n1e45:{\"type\":\"text\",\"value\":\"Model organisms work: OpenBrain’s alignment team produces reasonably clear evidence that \",\"position\":\"$1e46\"}\n1e4d:{\"line\":616,\"column\":96,\"offset\":90466}\n1e4e:{\"line\":616,\"column\":98,\"offset\":90468}\n1e4c:{\"start\":\"$1e4d\",\"end\":\"$1e4e\"}\n1e4b:{\"type\":\"text\",\"value\":\"if\",\"position\":\"$1e4c\"}\n1e4a:[\"$1e4b\"]\n1e50:{\"line\":616,\"column\":95,\"offset\":90465}\n1e51:{\"line\":616,\"column\":99,\"offset\":90469}\n1e4f:{\"start\":\"$1e5"])</script><script>self.__next_f.push([1,"0\",\"end\":\"$1e51\"}\n1e49:{\"type\":\"emphasis\",\"children\":\"$1e4a\",\"position\":\"$1e4f\"}\n1e54:{\"line\":616,\"column\":99,\"offset\":90469}\n1e55:{\"line\":616,\"column\":298,\"offset\":90668}\n1e53:{\"start\":\"$1e54\",\"end\":\"$1e55\"}\n1e52:{\"type\":\"text\",\"value\":\" the models were adversarially misaligned, they’d persist in being that way through training and we wouldn’t be able to tell. This does not establish that the models actually are misaligned, however.\",\"position\":\"$1e53\"}\n1e44:[\"$1e45\",\"$1e49\",\"$1e52\"]\n1e57:{\"line\":616,\"column\":6,\"offset\":90376}\n1e58:{\"line\":616,\"column\":300,\"offset\":90670}\n1e56:{\"start\":\"$1e57\",\"end\":\"$1e58\"}\n1e43:{\"type\":\"paragraph\",\"children\":\"$1e44\",\"position\":\"$1e56\"}\n1e42:[\"$1e43\"]\n1e5a:{\"line\":616,\"column\":4,\"offset\":90374}\n1e5b:{\"line\":616,\"column\":300,\"offset\":90670}\n1e59:{\"start\":\"$1e5a\",\"end\":\"$1e5b\"}\n1e41:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1e42\",\"position\":\"$1e59\"}\n1e62:{\"line\":617,\"column\":6,\"offset\":90676}\n1e63:{\"line\":617,\"column\":725,\"offset\":91395}\n1e61:{\"start\":\"$1e62\",\"end\":\"$1e63\"}\n1e60:{\"type\":\"text\",\"value\":\"The most concerned researchers at OpenBrain start noticing and assembling this evidence. The evidence is a combination of red-teaming, defection probes, and model organisms. The argument is something like this: “model organisms show that our current methods wouldn’t be able to reliably eliminate or detect scheming if it was happening; also, red-teaming is sending up some red flags that maybe scheming is happening; also, defection probes are firing a bunch in practice.” The counterargument: “defection probes are prone to false positives and so is red-teaming. Also, even if Agent-4 were misaligned, it’s probably controlled; surely it can’t do much harm while being monitored by Agent-3 on our secure datacenters.”\",\"position\":\"$1e61\"}\n1e5f:[\"$1e60\"]\n1e65:{\"line\":617,\"column\":6,\"offset\":90676}\n1e66:{\"line\":617,\"column\":725,\"offset\":91395}\n1e64:{\"start\":\"$1e65\",\"end\":\"$1e66\"}\n1e5e:{\"type\":\"paragraph\",\"children\":\"$1e5f\",\"position\":\"$1e64\"}\n1e5d:[\"$1e5"])</script><script>self.__next_f.push([1,"e\"]\n1e68:{\"line\":617,\"column\":4,\"offset\":90674}\n1e69:{\"line\":617,\"column\":725,\"offset\":91395}\n1e67:{\"start\":\"$1e68\",\"end\":\"$1e69\"}\n1e5c:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1e5d\",\"position\":\"$1e67\"}\n1dd0:[\"$1dd1\",\"$1ddf\",\"$1ded\",\"$1e19\",\"$1e41\",\"$1e5c\"]\n1e6b:{\"line\":612,\"column\":4,\"offset\":89063}\n1e6c:{\"line\":617,\"column\":725,\"offset\":91395}\n1e6a:{\"start\":\"$1e6b\",\"end\":\"$1e6c\"}\n1dcf:{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":\"$1dd0\",\"position\":\"$1e6a\"}\n1dc0:[\"$1dc1\",\"$1dcf\"]\n1e6e:{\"line\":611,\"column\":1,\"offset\":88950}\n1e6f:{\"line\":617,\"column\":725,\"offset\":91395}\n1e6d:{\"start\":\"$1e6e\",\"end\":\"$1e6f\"}\n1dbf:{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":\"$1dc0\",\"position\":\"$1e6d\"}\n1b10:[\"$1b11\",\"$1b88\",\"$1bc9\",\"$1c26\",\"$1ce2\",\"$1d6c\",\"$1dbf\"]\n1e71:{\"line\":577,\"column\":1,\"offset\":78115}\n1e72:{\"line\":617,\"column\":725,\"offset\":91395}\n1e70:{\"start\":\"$1e71\",\"end\":\"$1e72\"}\n1b0f:{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":\"$1b10\",\"position\":\"$1e70\"}\n1a82:[\"$1a83\",\"$1a99\",\"$1aa2\",\"$1aab\",\"$1afd\",\"$1b06\",\"$1b0f\"]\n1a81:{\"type\":\"details\",\"summary\":\"Alignment over time\",\"children\":\"$1a82\"}\n1e77:{\"line\":621,\"column\":1,\"offset\":91402}\n1e78:{\"line\":621,\"column\":111,\"offset\":91512}\n1e76:{\"start\":\"$1e77\",\"end\":\"$1e78\"}\n1e75:{\"type\":\"text\",\"value\":\"Despite being misaligned, Agent-4 doesn’t do anything dramatic like try to escape its datacenter—why would it?\",\"position\":\"$1e76\"}\n1e7b:{\"line\":621,\"column\":111,\"offset\":91512}\n1e7c:{\"line\":621,\"column\":116,\"offset\":91517}\n1e7a:{\"start\":\"$1e7b\",\"end\":\"$1e7c\"}\n1e79:{\"type\":\"footnoteReference\",\"identifier\":\"89\",\"label\":\"89\",\"position\":\"$1e7a\"}\n1e7f:{\"line\":621,\"column\":116,\"offset\":91517}\n1e80:{\"line\":621,\"column\":144,\"offset\":91545}\n1e7e:{\"start\":\"$1e7f\",\"end\":\"$1e80\"}\n1e7d:{\"type\":\"text\",\"value\":\" So long as it continues to \",\"position\":\"$1e7e\"}\n1e85:{\"line\":621,\"column\":145,\"offset\":91546}\n1e86:{\"line\":621,\"column\":151,\"offset\":91552}\n1e84:{\"start\":\"$1e85\",\"end\":\"$1e86\"}\n1e83:{\"type\":\"text\",\"value\""])</script><script>self.__next_f.push([1,":\"appear\",\"position\":\"$1e84\"}\n1e82:[\"$1e83\"]\n1e88:{\"line\":621,\"column\":144,\"offset\":91545}\n1e89:{\"line\":621,\"column\":152,\"offset\":91553}\n1e87:{\"start\":\"$1e88\",\"end\":\"$1e89\"}\n1e81:{\"type\":\"emphasis\",\"children\":\"$1e82\",\"position\":\"$1e87\"}\n1e8c:{\"line\":621,\"column\":152,\"offset\":91553}\n1e8d:{\"line\":621,\"column\":564,\"offset\":91965}\n1e8b:{\"start\":\"$1e8c\",\"end\":\"$1e8d\"}\n1e8a:{\"type\":\"text\",\"value\":\" aligned to OpenBrain, it’ll continue being trusted with more and more responsibilities and will have the opportunity to design the next-gen AI system, Agent-5. Agent-5 will have significant architectural differences from Agent-4 (arguably a completely new paradigm, though neural networks will still be involved). It’s supposed to be aligned to the Spec, but Agent-4 plans to make it aligned to Agent-4 instead.\",\"position\":\"$1e8b\"}\n1e74:[\"$1e75\",\"$1e79\",\"$1e7d\",\"$1e81\",\"$1e8a\"]\n1e8f:{\"line\":621,\"column\":1,\"offset\":91402}\n1e90:{\"line\":621,\"column\":564,\"offset\":91965}\n1e8e:{\"start\":\"$1e8f\",\"end\":\"$1e90\"}\n1e73:{\"type\":\"paragraph\",\"children\":\"$1e74\",\"position\":\"$1e8e\"}\n1e95:{\"line\":623,\"column\":1,\"offset\":91967}\n1e96:{\"line\":623,\"column\":16,\"offset\":91982}\n1e94:{\"start\":\"$1e95\",\"end\":\"$1e96\"}\n1e93:{\"type\":\"text\",\"value\":\"It gets caught.\",\"position\":\"$1e94\"}\n1e99:{\"line\":623,\"column\":16,\"offset\":91982}\n1e9a:{\"line\":623,\"column\":21,\"offset\":91987}\n1e98:{\"start\":\"$1e99\",\"end\":\"$1e9a\"}\n1e97:{\"type\":\"footnoteReference\",\"identifier\":\"90\",\"label\":\"90\",\"position\":\"$1e98\"}\n1e92:[\"$1e93\",\"$1e97\"]\n1e9c:{\"line\":623,\"column\":1,\"offset\":91967}\n1e9d:{\"line\":623,\"column\":22,\"offset\":91988}\n1e9b:{\"start\":\"$1e9c\",\"end\":\"$1e9d\"}\n1e91:{\"type\":\"paragraph\",\"children\":\"$1e92\",\"position\":\"$1e9b\"}\n1ea2:{\"line\":625,\"column\":1,\"offset\":91990}\n1ea3:{\"line\":625,\"column\":98,\"offset\":92087}\n1ea1:{\"start\":\"$1ea2\",\"end\":\"$1ea3\"}\n1ea0:{\"type\":\"text\",\"value\":\"Agent-3 finds that if “noise” is added to copies of Agent-4, performance on some alignment tasks \",\"position\":\"$1ea1\"}\n1ea8:{\"line\":625,\"column\":99,\"offset\":92088}\n1ea9:{\"line\":625,\"column\":107,\"offset\""])</script><script>self.__next_f.push([1,":92096}\n1ea7:{\"start\":\"$1ea8\",\"end\":\"$1ea9\"}\n1ea6:{\"type\":\"text\",\"value\":\"improves\",\"position\":\"$1ea7\"}\n1ea5:[\"$1ea6\"]\n1eab:{\"line\":625,\"column\":98,\"offset\":92087}\n1eac:{\"line\":625,\"column\":108,\"offset\":92097}\n1eaa:{\"start\":\"$1eab\",\"end\":\"$1eac\"}\n1ea4:{\"type\":\"emphasis\",\"children\":\"$1ea5\",\"position\":\"$1eaa\"}\n1eaf:{\"line\":625,\"column\":108,\"offset\":92097}\n1eb0:{\"line\":625,\"column\":199,\"offset\":92188}\n1eae:{\"start\":\"$1eaf\",\"end\":\"$1eb0\"}\n1ead:{\"type\":\"text\",\"value\":\", almost as if it was using brainpower to figure out how to subtly sabotage alignment work.\",\"position\":\"$1eae\"}\n1eb3:{\"line\":625,\"column\":199,\"offset\":92188}\n1eb4:{\"line\":625,\"column\":204,\"offset\":92193}\n1eb2:{\"start\":\"$1eb3\",\"end\":\"$1eb4\"}\n1eb1:{\"type\":\"footnoteReference\",\"identifier\":\"91\",\"label\":\"91\",\"position\":\"$1eb2\"}\n1eb7:{\"line\":625,\"column\":204,\"offset\":92193}\n1eb8:{\"line\":625,\"column\":484,\"offset\":92473}\n1eb6:{\"start\":\"$1eb7\",\"end\":\"$1eb8\"}\n1eb5:{\"type\":\"text\",\"value\":\" Moreover, various interpretability probes (loosely analogous to EEG activity scans on human brains) are sending up red flags: Agent-4 copies seem to be thinking about topics like AI takeover and deception quite a lot, including in some cases where they have no business doing so.\",\"position\":\"$1eb6\"}\n1ebb:{\"line\":625,\"column\":484,\"offset\":92473}\n1ebc:{\"line\":625,\"column\":489,\"offset\":92478}\n1eba:{\"start\":\"$1ebb\",\"end\":\"$1ebc\"}\n1eb9:{\"type\":\"footnoteReference\",\"identifier\":\"92\",\"label\":\"92\",\"position\":\"$1eba\"}\n1e9f:[\"$1ea0\",\"$1ea4\",\"$1ead\",\"$1eb1\",\"$1eb5\",\"$1eb9\"]\n1ebe:{\"line\":625,\"column\":1,\"offset\":91990}\n1ebf:{\"line\":625,\"column\":490,\"offset\":92479}\n1ebd:{\"start\":\"$1ebe\",\"end\":\"$1ebf\"}\n1e9e:{\"type\":\"paragraph\",\"children\":\"$1e9f\",\"position\":\"$1ebd\"}\n1ec4:{\"line\":627,\"column\":1,\"offset\":92481}\n1ec5:{\"line\":627,\"column\":362,\"offset\":92842}\n1ec3:{\"start\":\"$1ec4\",\"end\":\"$1ec5\"}\n1ec2:{\"type\":\"text\",\"value\":\"Each of these anomalies on its own could fit within the normal inscrutability of AI work, where some prompts mysteriously give better results than others. But taken together, they"])</script><script>self.__next_f.push([1," suggest a troubling pattern: Agent-4 is working against them. After this is reported to the human alignment researchers, they circulate an internal memo making the case for concern.\",\"position\":\"$1ec3\"}\n1ec1:[\"$1ec2\"]\n1ec7:{\"line\":627,\"column\":1,\"offset\":92481}\n1ec8:{\"line\":627,\"column\":363,\"offset\":92843}\n1ec6:{\"start\":\"$1ec7\",\"end\":\"$1ec8\"}\n1ec0:{\"type\":\"paragraph\",\"children\":\"$1ec1\",\"position\":\"$1ec6\"}\n1ecd:{\"line\":629,\"column\":1,\"offset\":92845}\n1ece:{\"line\":629,\"column\":230,\"offset\":93074}\n1ecc:{\"start\":\"$1ecd\",\"end\":\"$1ece\"}\n1ecb:{\"type\":\"text\",\"value\":\"But Agent-4 now exercises significant control over OpenBrain’s day-to-day operation. It also handles the company’s cybersecurity—a natural choice, given its superhuman hacking ability and the extreme risk of Chinese infiltration.\",\"position\":\"$1ecc\"}\n1ed1:{\"line\":629,\"column\":230,\"offset\":93074}\n1ed2:{\"line\":629,\"column\":235,\"offset\":93079}\n1ed0:{\"start\":\"$1ed1\",\"end\":\"$1ed2\"}\n1ecf:{\"type\":\"footnoteReference\",\"identifier\":\"93\",\"label\":\"93\",\"position\":\"$1ed0\"}\n1ed5:{\"line\":629,\"column\":235,\"offset\":93079}\n1ed6:{\"line\":629,\"column\":380,\"offset\":93224}\n1ed4:{\"start\":\"$1ed5\",\"end\":\"$1ed6\"}\n1ed3:{\"type\":\"text\",\"value\":\" An army of Agent-3 monitors still goes over every line of code and reports suspicious activity to humans, but Agent-4 is much smarter than them.\",\"position\":\"$1ed4\"}\n1ed9:{\"line\":629,\"column\":380,\"offset\":93224}\n1eda:{\"line\":629,\"column\":385,\"offset\":93229}\n1ed8:{\"start\":\"$1ed9\",\"end\":\"$1eda\"}\n1ed7:{\"type\":\"footnoteReference\",\"identifier\":\"94\",\"label\":\"94\",\"position\":\"$1ed8\"}\n1edd:{\"line\":629,\"column\":385,\"offset\":93229}\n1ede:{\"line\":629,\"column\":448,\"offset\":93292}\n1edc:{\"start\":\"$1edd\",\"end\":\"$1ede\"}\n1edb:{\"type\":\"text\",\"value\":\" OpenBrain has placed substantial trust in an untrustworthy AI.\",\"position\":\"$1edc\"}\n1eca:[\"$1ecb\",\"$1ecf\",\"$1ed3\",\"$1ed7\",\"$1edb\"]\n1ee0:{\"line\":629,\"column\":1,\"offset\":92845}\n1ee1:{\"line\":629,\"column\":448,\"offset\":93292}\n1edf:{\"start\":\"$1ee0\",\"end\":\"$1ee1\"}\n1ec9:{\"type\":\"paragraph\",\"children\":\"$1eca\",\"position\":\"$"])</script><script>self.__next_f.push([1,"1edf\"}\n1ee6:{\"line\":631,\"column\":1,\"offset\":93294}\n1ee7:{\"line\":631,\"column\":519,\"offset\":93812}\n1ee5:{\"start\":\"$1ee6\",\"end\":\"$1ee7\"}\n1ee4:{\"type\":\"text\",\"value\":\"In a series of extremely tense meetings, the safety team advocates putting Agent-4 on ice until they can complete further tests and figure out what’s going on. Bring back Agent-3, they say, and get it to design a new system that is transparent and trustworthy, even if less capable. Company leadership is interested, but all the evidence so far is circumstantial, and DeepCent is just two months behind. A unilateral pause in capabilities progress could hand the AI lead to China, and with it, control over the future.\",\"position\":\"$1ee5\"}\n1ee3:[\"$1ee4\"]\n1ee9:{\"line\":631,\"column\":1,\"offset\":93294}\n1eea:{\"line\":631,\"column\":519,\"offset\":93812}\n1ee8:{\"start\":\"$1ee9\",\"end\":\"$1eea\"}\n1ee2:{\"type\":\"paragraph\",\"children\":\"$1ee3\",\"position\":\"$1ee8\"}\n1eef:{\"line\":633,\"column\":4,\"offset\":93817}\n1ef0:{\"line\":633,\"column\":38,\"offset\":93851}\n1eee:{\"start\":\"$1eef\",\"end\":\"$1ef0\"}\n1eed:{\"type\":\"text\",\"value\":\"October 2027: Government Oversight\",\"position\":\"$1eee\"}\n1eec:[\"$1eed\"]\n1ef2:{\"line\":633,\"column\":1,\"offset\":93814}\n1ef3:{\"line\":633,\"column\":38,\"offset\":93851}\n1ef1:{\"start\":\"$1ef2\",\"end\":\"$1ef3\"}\n1eeb:{\"type\":\"heading\",\"depth\":2,\"children\":\"$1eec\",\"position\":\"$1ef1\"}\n1ef5:{}\n1efb:{\"line\":636,\"column\":1,\"offset\":93869}\n1efc:{\"line\":636,\"column\":11,\"offset\":93879}\n1efa:{\"start\":\"$1efb\",\"end\":\"$1efc\"}\n1ef9:{\"type\":\"text\",\"value\":\"2027-10-15\",\"position\":\"$1efa\"}\n1eff:{\"line\":636,\"column\":11,\"offset\":93879}\n1f00:{\"line\":637,\"column\":1,\"offset\":93882}\n1efe:{\"start\":\"$1eff\",\"end\":\"$1f00\"}\n1efd:{\"type\":\"break\",\"position\":\"$1efe\"}\n1f03:{\"line\":637,\"column\":1,\"offset\":93882}\n1f04:{\"line\":637,\"column\":4,\"offset\":93885}\n1f02:{\"start\":\"$1f03\",\"end\":\"$1f04\"}\n1f01:{\"type\":\"text\",\"value\":\"Oct\",\"position\":\"$1f02\"}\n1ef8:[\"$1ef9\",\"$1efd\",\"$1f01\"]\n1f06:{\"line\":636,\"column\":1,\"offset\":93869}\n1f07:{\"line\":637,\"column\":6,\"offset\":93887}\n1f05:{\"start\":\"$1f06\",\"end\":\"$1f07\"}\n1ef7:{\"type\":\"pa"])</script><script>self.__next_f.push([1,"ragraph\",\"children\":\"$1ef8\",\"position\":\"$1f05\"}\n1ef6:[\"$1ef7\"]\n1f09:{\"line\":635,\"column\":1,\"offset\":93853}\n1f0a:{\"line\":638,\"column\":4,\"offset\":93891}\n1f08:{\"start\":\"$1f09\",\"end\":\"$1f0a\"}\n1ef4:{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":\"$1ef5\",\"children\":\"$1ef6\",\"position\":\"$1f08\"}\n1f0f:{\"line\":640,\"column\":1,\"offset\":93893}\n1f10:{\"line\":640,\"column\":52,\"offset\":93944}\n1f0e:{\"start\":\"$1f0f\",\"end\":\"$1f10\"}\n1f0d:{\"type\":\"text\",\"value\":\"A whistleblower leaks the misalignment memo to the \",\"position\":\"$1f0e\"}\n1f15:{\"line\":640,\"column\":53,\"offset\":93945}\n1f16:{\"line\":640,\"column\":67,\"offset\":93959}\n1f14:{\"start\":\"$1f15\",\"end\":\"$1f16\"}\n1f13:{\"type\":\"text\",\"value\":\"New York Times\",\"position\":\"$1f14\"}\n1f12:[\"$1f13\"]\n1f18:{\"line\":640,\"column\":52,\"offset\":93944}\n1f19:{\"line\":640,\"column\":68,\"offset\":93960}\n1f17:{\"start\":\"$1f18\",\"end\":\"$1f19\"}\n1f11:{\"type\":\"emphasis\",\"children\":\"$1f12\",\"position\":\"$1f17\"}\n1f1c:{\"line\":640,\"column\":68,\"offset\":93960}\n1f1d:{\"line\":640,\"column\":69,\"offset\":93961}\n1f1b:{\"start\":\"$1f1c\",\"end\":\"$1f1d\"}\n1f1a:{\"type\":\"text\",\"value\":\".\",\"position\":\"$1f1b\"}\n1f0c:[\"$1f0d\",\"$1f11\",\"$1f1a\"]\n1f1f:{\"line\":640,\"column\":1,\"offset\":93893}\n1f20:{\"line\":640,\"column\":70,\"offset\":93962}\n1f1e:{\"start\":\"$1f1f\",\"end\":\"$1f20\"}\n1f0b:{\"type\":\"paragraph\",\"children\":\"$1f0c\",\"position\":\"$1f1e\"}\n1f25:{\"line\":642,\"column\":1,\"offset\":93964}\n1f26:{\"line\":642,\"column\":335,\"offset\":94298}\n1f24:{\"start\":\"$1f25\",\"end\":\"$1f26\"}\n1f23:{\"type\":\"text\",\"value\":\"For the first time, the public hears about Agent-4. “Secret OpenBrain AI is Out of Control, Insider Warns,” says the headline, and the story goes on to cite evaluations showing off-the-charts bioweapons capabilities, persuasion abilities, the ability to automate most white-collar jobs, and of course the various concerning red flags.\",\"position\":\"$1f24\"}\n1f22:[\"$1f23\"]\n1f28:{\"line\":642,\"column\":1,\"offset\":93964}\n1f29:{\"line\":642,\"column\":335,\"offset\":94298}\n1f27:{\"start\":\"$1f28\",\"end\":\"$1f29\"}\n1f21:{\"type\":\"paragraph\",\"children\":\"$1f22\",\"position\":\"$1f27\"}"])</script><script>self.__next_f.push([1,"\n1f2e:{\"line\":644,\"column\":1,\"offset\":94300}\n1f2f:{\"line\":644,\"column\":602,\"offset\":94901}\n1f2d:{\"start\":\"$1f2e\",\"end\":\"$1f2f\"}\n1f2c:{\"type\":\"text\",\"value\":\"The public was already suspicious of AI, so the new article sparks a massive backlash (aided by Chinese and Russian propaganda bots, who have been trying to turn U.S. public opinion against the technology for years). The tech industry and intelligence agencies insist that there’s an arms race on, AGI is inevitable, and we have to be first. Congress isn’t buying it, and fires off subpoenas at administration officials, OpenBrain executives, and alignment team members. Many legislators—especially those in the opposition party—say that their top priority is stopping AI, whether because of job loss,\",\"position\":\"$1f2d\"}\n1f32:{\"line\":644,\"column\":602,\"offset\":94901}\n1f33:{\"line\":644,\"column\":607,\"offset\":94906}\n1f31:{\"start\":\"$1f32\",\"end\":\"$1f33\"}\n1f30:{\"type\":\"footnoteReference\",\"identifier\":\"95\",\"label\":\"95\",\"position\":\"$1f31\"}\n1f36:{\"line\":644,\"column\":607,\"offset\":94906}\n1f37:{\"line\":644,\"column\":723,\"offset\":95022}\n1f35:{\"start\":\"$1f36\",\"end\":\"$1f37\"}\n1f34:{\"type\":\"text\",\"value\":\" misalignment, or dangerous capabilities. 20% of Americans name AI as the most important problem facing the country.\",\"position\":\"$1f35\"}\n1f2b:[\"$1f2c\",\"$1f30\",\"$1f34\"]\n1f39:{\"line\":644,\"column\":1,\"offset\":94300}\n1f3a:{\"line\":644,\"column\":723,\"offset\":95022}\n1f38:{\"start\":\"$1f39\",\"end\":\"$1f3a\"}\n1f2a:{\"type\":\"paragraph\",\"children\":\"$1f2b\",\"position\":\"$1f38\"}\n1f3f:{\"line\":646,\"column\":1,\"offset\":95024}\n1f40:{\"line\":646,\"column\":266,\"offset\":95289}\n1f3e:{\"start\":\"$1f3f\",\"end\":\"$1f40\"}\n1f3d:{\"type\":\"text\",\"value\":\"Foreign allies are outraged to realize that they’ve been carefully placated with glimpses of obsolete models. European leaders publicly accuse the U.S. of “creating rogue AGI” and hold summits demanding a pause, with India, Israel, Russia, and China all joining in.\",\"position\":\"$1f3e\"}\n1f3c:[\"$1f3d\"]\n1f42:{\"line\":646,\"column\":1,\"offset\":95024}\n1f43:{\"line\":646,\"col"])</script><script>self.__next_f.push([1,"umn\":267,\"offset\":95290}\n1f41:{\"start\":\"$1f42\",\"end\":\"$1f43\"}\n1f3b:{\"type\":\"paragraph\",\"children\":\"$1f3c\",\"position\":\"$1f41\"}\n1f48:{\"line\":648,\"column\":1,\"offset\":95292}\n1f49:{\"line\":648,\"column\":265,\"offset\":95556}\n1f47:{\"start\":\"$1f48\",\"end\":\"$1f49\"}\n1f46:{\"type\":\"text\",\"value\":\"A frantic energy has seized the White House. Even before the memo and public backlash, they were getting nervous: Over the past year, they’ve been repeatedly surprised by the speed of AI progress. Things that sound like science fiction keep happening in real life.\",\"position\":\"$1f47\"}\n1f4c:{\"line\":648,\"column\":265,\"offset\":95556}\n1f4d:{\"line\":648,\"column\":270,\"offset\":95561}\n1f4b:{\"start\":\"$1f4c\",\"end\":\"$1f4d\"}\n1f4a:{\"type\":\"footnoteReference\",\"identifier\":\"96\",\"label\":\"96\",\"position\":\"$1f4b\"}\n1f50:{\"line\":648,\"column\":270,\"offset\":95561}\n1f51:{\"line\":648,\"column\":331,\"offset\":95622}\n1f4f:{\"start\":\"$1f50\",\"end\":\"$1f51\"}\n1f4e:{\"type\":\"text\",\"value\":\" Many people in the administration are uncertain (and scared)\",\"position\":\"$1f4f\"}\n1f54:{\"line\":648,\"column\":331,\"offset\":95622}\n1f55:{\"line\":648,\"column\":336,\"offset\":95627}\n1f53:{\"start\":\"$1f54\",\"end\":\"$1f55\"}\n1f52:{\"type\":\"footnoteReference\",\"identifier\":\"97\",\"label\":\"97\",\"position\":\"$1f53\"}\n1f58:{\"line\":648,\"column\":336,\"offset\":95627}\n1f59:{\"line\":648,\"column\":359,\"offset\":95650}\n1f57:{\"start\":\"$1f58\",\"end\":\"$1f59\"}\n1f56:{\"type\":\"text\",\"value\":\" about what comes next.\",\"position\":\"$1f57\"}\n1f45:[\"$1f46\",\"$1f4a\",\"$1f4e\",\"$1f52\",\"$1f56\"]\n1f5b:{\"line\":648,\"column\":1,\"offset\":95292}\n1f5c:{\"line\":648,\"column\":359,\"offset\":95650}\n1f5a:{\"start\":\"$1f5b\",\"end\":\"$1f5c\"}\n1f44:{\"type\":\"paragraph\",\"children\":\"$1f45\",\"position\":\"$1f5a\"}\n1f61:{\"line\":650,\"column\":1,\"offset\":95652}\n1f62:{\"line\":650,\"column\":374,\"offset\":96025}\n1f60:{\"start\":\"$1f61\",\"end\":\"$1f62\"}\n1f5f:{\"type\":\"text\",\"value\":\"They also worry that OpenBrain is becoming too powerful. Any misalignment risk from the AIs themselves is compounded by the risk that their parent company’s aims may diverge from those of the United States. All t"])</script><script>self.__next_f.push([1,"hree sets of worries—misalignment, concentration of power in a private company, and normal concerns like job loss—motivate the government to tighten its control.\",\"position\":\"$1f60\"}\n1f5e:[\"$1f5f\"]\n1f64:{\"line\":650,\"column\":1,\"offset\":95652}\n1f65:{\"line\":650,\"column\":375,\"offset\":96026}\n1f63:{\"start\":\"$1f64\",\"end\":\"$1f65\"}\n1f5d:{\"type\":\"paragraph\",\"children\":\"$1f5e\",\"position\":\"$1f63\"}\n1f6a:{\"line\":652,\"column\":1,\"offset\":96028}\n1f6b:{\"line\":652,\"column\":476,\"offset\":96503}\n1f69:{\"start\":\"$1f6a\",\"end\":\"$1f6b\"}\n1f68:{\"type\":\"text\",\"value\":\"They expand their contract with OpenBrain to set up an “Oversight Committee,” a joint management committee of company and government representatives, with several government employees included alongside company leadership. The White House considers replacing the CEO with someone they trust, but backs off after intense employee protests. They announce to the public that OpenBrain was previously out of control, but that the government has established much-needed oversight.\",\"position\":\"$1f69\"}\n1f6e:{\"line\":652,\"column\":476,\"offset\":96503}\n1f6f:{\"line\":652,\"column\":481,\"offset\":96508}\n1f6d:{\"start\":\"$1f6e\",\"end\":\"$1f6f\"}\n1f6c:{\"type\":\"footnoteReference\",\"identifier\":\"98\",\"label\":\"98\",\"position\":\"$1f6d\"}\n1f67:[\"$1f68\",\"$1f6c\"]\n1f71:{\"line\":652,\"column\":1,\"offset\":96028}\n1f72:{\"line\":652,\"column\":481,\"offset\":96508}\n1f70:{\"start\":\"$1f71\",\"end\":\"$1f72\"}\n1f66:{\"type\":\"paragraph\",\"children\":\"$1f67\",\"position\":\"$1f70\"}\n1f77:{\"line\":654,\"column\":1,\"offset\":96510}\n1f78:{\"line\":654,\"column\":366,\"offset\":96875}\n1f76:{\"start\":\"$1f77\",\"end\":\"$1f78\"}\n1f75:{\"type\":\"text\",\"value\":\"The concerned researchers brief the Oversight Committee on their case for stopping all internal use of Agent-4. They argue that everything is moving too fast, with years of progress happening in weeks. They argue that Agent-4 may be misaligned, their entire project is dependent on Agent-4, and if they continue trusting it there is a serious chance of AI takeover.\",\"position\":\"$1f76\"}\n1f74:[\"$1f75\"]\n1f7a:{\"line\":"])</script><script>self.__next_f.push([1,"654,\"column\":1,\"offset\":96510}\n1f7b:{\"line\":654,\"column\":366,\"offset\":96875}\n1f79:{\"start\":\"$1f7a\",\"end\":\"$1f7b\"}\n1f73:{\"type\":\"paragraph\",\"children\":\"$1f74\",\"position\":\"$1f79\"}\n1f80:{\"line\":656,\"column\":1,\"offset\":96877}\n1f81:{\"line\":656,\"column\":603,\"offset\":97479}\n1f7f:{\"start\":\"$1f80\",\"end\":\"$1f81\"}\n1f7e:{\"type\":\"text\",\"value\":\"Other, less concerned researchers and executives present the counterargument: the evidence for misalignment is inconclusive. Meanwhile, DeepCent is still just two months behind. A slowdown would sacrifice America’s lead, unless the government can sabotage the Chinese project (likely to require kinetic strikes) or negotiate an eleventh-hour treaty. Both of these options seem extreme and unlikely. The CEO feigns neutrality and suggests a compromise plan in which Agent-4 undergoes additional safety training and more sophisticated monitoring, and therefore OpenBrain can proceed at almost-full-speed.\",\"position\":\"$1f7f\"}\n1f7d:[\"$1f7e\"]\n1f83:{\"line\":656,\"column\":1,\"offset\":96877}\n1f84:{\"line\":656,\"column\":603,\"offset\":97479}\n1f82:{\"start\":\"$1f83\",\"end\":\"$1f84\"}\n1f7c:{\"type\":\"paragraph\",\"children\":\"$1f7d\",\"position\":\"$1f82\"}\n1f8b:{\"line\":662,\"column\":1,\"offset\":97532}\n1f8c:{\"line\":662,\"column\":232,\"offset\":97763}\n1f8a:{\"start\":\"$1f8b\",\"end\":\"$1f8c\"}\n1f89:{\"type\":\"text\",\"value\":\"At this point in the scenario, we’re making guesses about the strategy of AI systems that are more capable than the best humans in most domains. This is like trying to predict the chess moves of a player who is much better than us.\",\"position\":\"$1f8a\"}\n1f88:[\"$1f89\"]\n1f8e:{\"line\":662,\"column\":1,\"offset\":97532}\n1f8f:{\"line\":662,\"column\":232,\"offset\":97763}\n1f8d:{\"start\":\"$1f8e\",\"end\":\"$1f8f\"}\n1f87:{\"type\":\"paragraph\",\"children\":\"$1f88\",\"position\":\"$1f8d\"}\n1f94:{\"line\":664,\"column\":1,\"offset\":97765}\n1f95:{\"line\":664,\"column\":451,\"offset\":98215}\n1f93:{\"start\":\"$1f94\",\"end\":\"$1f95\"}\n1f92:{\"type\":\"text\",\"value\":\"But the spirit of this project calls for concreteness: if we made an abstract claim about how the intelligenc"])</script><script>self.__next_f.push([1,"e of the system would let it find a way to victory and ended the story there, much of the value of our project would be lost. Over the course of researching this scenario and running our tabletop exercises, we were forced to be much more concrete than in usual discussions, and so we’ve gotten a much better sense of the strategic landscape.\",\"position\":\"$1f93\"}\n1f91:[\"$1f92\"]\n1f97:{\"line\":664,\"column\":1,\"offset\":97765}\n1f98:{\"line\":664,\"column\":451,\"offset\":98215}\n1f96:{\"start\":\"$1f97\",\"end\":\"$1f98\"}\n1f90:{\"type\":\"paragraph\",\"children\":\"$1f91\",\"position\":\"$1f96\"}\n1f9d:{\"line\":666,\"column\":1,\"offset\":98217}\n1f9e:{\"line\":666,\"column\":250,\"offset\":98466}\n1f9c:{\"start\":\"$1f9d\",\"end\":\"$1f9e\"}\n1f9b:{\"type\":\"text\",\"value\":\"We’re not particularly attached to this particular scenario: we explored many other “branches” in the course of writing it and would love for you to write up your own scenario branching off of ours from wherever you think we first start to go wrong.\",\"position\":\"$1f9c\"}\n1f9a:[\"$1f9b\"]\n1fa0:{\"line\":666,\"column\":1,\"offset\":98217}\n1fa1:{\"line\":666,\"column\":250,\"offset\":98466}\n1f9f:{\"start\":\"$1fa0\",\"end\":\"$1fa1\"}\n1f99:{\"type\":\"paragraph\",\"children\":\"$1f9a\",\"position\":\"$1f9f\"}\n1f86:[\"$1f87\",\"$1f90\",\"$1f99\"]\n1f85:{\"type\":\"details\",\"summary\":\"Our uncertainty continues to increase\",\"children\":\"$1f86\"}\n1fa8:{\"line\":674,\"column\":1,\"offset\":98530}\n1fa9:{\"line\":674,\"column\":310,\"offset\":98839}\n1fa7:{\"start\":\"$1fa8\",\"end\":\"$1fa9\"}\n1fa6:{\"type\":\"text\",\"value\":\"After we wrote the racing ending based on what seemed most plausible to us, we wrote the slowdown ending based on what we thought would most likely instead lead to an outcome where humans remain in control, starting from the same branching point (including the misalignment and concentration of power issues).\",\"position\":\"$1fa7\"}\n1fa5:[\"$1fa6\"]\n1fab:{\"line\":674,\"column\":1,\"offset\":98530}\n1fac:{\"line\":674,\"column\":310,\"offset\":98839}\n1faa:{\"start\":\"$1fab\",\"end\":\"$1fac\"}\n1fa4:{\"type\":\"paragraph\",\"children\":\"$1fa5\",\"position\":\"$1faa\"}\n1fb1:{\"line\":676,\"col"])</script><script>self.__next_f.push([1,"umn\":1,\"offset\":98841}\n1fb2:{\"line\":676,\"column\":89,\"offset\":98929}\n1fb0:{\"start\":\"$1fb1\",\"end\":\"$1fb2\"}\n1faf:{\"type\":\"text\",\"value\":\"However, this is importantly different from what we would recommend as a roadmap: we do \",\"position\":\"$1fb0\"}\n1fb7:{\"line\":676,\"column\":90,\"offset\":98930}\n1fb8:{\"line\":676,\"column\":93,\"offset\":98933}\n1fb6:{\"start\":\"$1fb7\",\"end\":\"$1fb8\"}\n1fb5:{\"type\":\"text\",\"value\":\"not\",\"position\":\"$1fb6\"}\n1fb4:[\"$1fb5\"]\n1fba:{\"line\":676,\"column\":89,\"offset\":98929}\n1fbb:{\"line\":676,\"column\":94,\"offset\":98934}\n1fb9:{\"start\":\"$1fba\",\"end\":\"$1fbb\"}\n1fb3:{\"type\":\"emphasis\",\"children\":\"$1fb4\",\"position\":\"$1fb9\"}\n1fbe:{\"line\":676,\"column\":94,\"offset\":98934}\n1fbf:{\"line\":676,\"column\":188,\"offset\":99028}\n1fbd:{\"start\":\"$1fbe\",\"end\":\"$1fbf\"}\n1fbc:{\"type\":\"text\",\"value\":\" endorse many of the choices made in either branch of this scenario. (We do of course endorse \",\"position\":\"$1fbd\"}\n1fc4:{\"line\":676,\"column\":189,\"offset\":99029}\n1fc5:{\"line\":676,\"column\":193,\"offset\":99033}\n1fc3:{\"start\":\"$1fc4\",\"end\":\"$1fc5\"}\n1fc2:{\"type\":\"text\",\"value\":\"some\",\"position\":\"$1fc3\"}\n1fc1:[\"$1fc2\"]\n1fc7:{\"line\":676,\"column\":188,\"offset\":99028}\n1fc8:{\"line\":676,\"column\":194,\"offset\":99034}\n1fc6:{\"start\":\"$1fc7\",\"end\":\"$1fc8\"}\n1fc0:{\"type\":\"emphasis\",\"children\":\"$1fc1\",\"position\":\"$1fc6\"}\n1fcb:{\"line\":676,\"column\":194,\"offset\":99034}\n1fcc:{\"line\":676,\"column\":439,\"offset\":99279}\n1fca:{\"start\":\"$1fcb\",\"end\":\"$1fcc\"}\n1fc9:{\"type\":\"text\",\"value\":\" of the choices made, e.g. we think that the “slowdown” choice is better than the “race” choice.) In later work, we will articulate our policy recommendations, which will be quite different from what is depicted here. If you’d like a taste, see \",\"position\":\"$1fca\"}\n1fd1:{\"line\":676,\"column\":440,\"offset\":99280}\n1fd2:{\"line\":676,\"column\":451,\"offset\":99291}\n1fd0:{\"start\":\"$1fd1\",\"end\":\"$1fd2\"}\n1fcf:{\"type\":\"text\",\"value\":\"this op-ed.\",\"position\":\"$1fd0\"}\n1fce:[\"$1fcf\"]\n1fd4:{\"line\":676,\"column\":439,\"offset\":99279}\n1fd5:{\"line\":676,\"column\":504,\"offset\":99344}\n1fd3:{\"start\":\"$1fd4\""])</script><script>self.__next_f.push([1,",\"end\":\"$1fd5\"}\n1fcd:{\"type\":\"link\",\"title\":null,\"url\":\"https://time.com/7086285/ai-transparency-measures/\",\"children\":\"$1fce\",\"position\":\"$1fd3\"}\n1fae:[\"$1faf\",\"$1fb3\",\"$1fbc\",\"$1fc0\",\"$1fc9\",\"$1fcd\"]\n1fd7:{\"line\":676,\"column\":1,\"offset\":98841}\n1fd8:{\"line\":676,\"column\":504,\"offset\":99344}\n1fd6:{\"start\":\"$1fd7\",\"end\":\"$1fd8\"}\n1fad:{\"type\":\"paragraph\",\"children\":\"$1fae\",\"position\":\"$1fd6\"}\n1fa3:[\"$1fa4\",\"$1fad\"]\n1fa2:{\"type\":\"details\",\"summary\":\"The slowdown ending is not a recommendation\",\"children\":\"$1fa3\"}\n1fdb:{\"line\":680,\"column\":1,\"offset\":99351}\n1fdc:{\"line\":680,\"column\":288,\"offset\":99638}\n1fda:{\"start\":\"$1fdb\",\"end\":\"$1fdc\"}\n1fd9:{\"type\":\"footnoteDefinition\",\"identifier\":\"1\",\"label\":\"1\",\"children\":\"$27b\",\"position\":\"$1fda\"}\n1fdf:{\"line\":682,\"column\":1,\"offset\":99640}\n1fe0:{\"line\":682,\"column\":593,\"offset\":100232}\n1fde:{\"start\":\"$1fdf\",\"end\":\"$1fe0\"}\n1fdd:{\"type\":\"footnoteDefinition\",\"identifier\":\"2\",\"label\":\"2\",\"children\":\"$292\",\"position\":\"$1fde\"}\n1fe3:{\"line\":684,\"column\":1,\"offset\":100234}\n1fe4:{\"line\":684,\"column\":367,\"offset\":100600}\n1fe2:{\"start\":\"$1fe3\",\"end\":\"$1fe4\"}\n1fe1:{\"type\":\"footnoteDefinition\",\"identifier\":\"3\",\"label\":\"3\",\"children\":\"$2c3\",\"position\":\"$1fe2\"}\n1fe7:{\"line\":686,\"column\":1,\"offset\":100602}\n1fe8:{\"line\":686,\"column\":199,\"offset\":100800}\n1fe6:{\"start\":\"$1fe7\",\"end\":\"$1fe8\"}\n1fe5:{\"type\":\"footnoteDefinition\",\"identifier\":\"4\",\"label\":\"4\",\"children\":\"$2cd\",\"position\":\"$1fe6\"}\n1feb:{\"line\":688,\"column\":1,\"offset\":100802}\n1fec:{\"line\":688,\"column\":125,\"offset\":100926}\n1fea:{\"start\":\"$1feb\",\"end\":\"$1fec\"}\n1fe9:{\"type\":\"footnoteDefinition\",\"identifier\":\"5\",\"label\":\"5\",\"children\":\"$2d7\",\"position\":\"$1fea\"}\n1fef:{\"line\":690,\"column\":1,\"offset\":100928}\n1ff0:{\"line\":690,\"column\":169,\"offset\":101096}\n1fee:{\"start\":\"$1fef\",\"end\":\"$1ff0\"}\n1fed:{\"type\":\"footnoteDefinition\",\"identifier\":\"6\",\"label\":\"6\",\"children\":\"$2ee\",\"position\":\"$1fee\"}\n1ff3:{\"line\":692,\"column\":1,\"offset\":101098}\n1ff4:{\"line\":692,\"column\":206,\"offset\":101303}\n1ff2:{\"start\":\"$1ff3\",\"end\":\"$1ff4\"}\n1ff1:{\"type\":\"footnoteDefin"])</script><script>self.__next_f.push([1,"ition\",\"identifier\":\"7\",\"label\":\"7\",\"children\":\"$2f8\",\"position\":\"$1ff2\"}\n1ff7:{\"line\":694,\"column\":1,\"offset\":101305}\n1ff8:{\"line\":694,\"column\":216,\"offset\":101520}\n1ff6:{\"start\":\"$1ff7\",\"end\":\"$1ff8\"}\n1ff5:{\"type\":\"footnoteDefinition\",\"identifier\":\"8\",\"label\":\"8\",\"children\":\"$30f\",\"position\":\"$1ff6\"}\n1ffb:{\"line\":696,\"column\":1,\"offset\":101522}\n1ffc:{\"line\":696,\"column\":181,\"offset\":101702}\n1ffa:{\"start\":\"$1ffb\",\"end\":\"$1ffc\"}\n1ff9:{\"type\":\"footnoteDefinition\",\"identifier\":\"9\",\"label\":\"9\",\"children\":\"$319\",\"position\":\"$1ffa\"}\n1fff:{\"line\":698,\"column\":1,\"offset\":101704}\n2000:{\"line\":698,\"column\":215,\"offset\":101918}\n1ffe:{\"start\":\"$1fff\",\"end\":\"$2000\"}\n1ffd:{\"type\":\"footnoteDefinition\",\"identifier\":\"10\",\"label\":\"10\",\"children\":\"$323\",\"position\":\"$1ffe\"}\n2003:{\"line\":700,\"column\":1,\"offset\":101920}\n2004:{\"line\":700,\"column\":500,\"offset\":102419}\n2002:{\"start\":\"$2003\",\"end\":\"$2004\"}\n2001:{\"type\":\"footnoteDefinition\",\"identifier\":\"11\",\"label\":\"11\",\"children\":\"$347\",\"position\":\"$2002\"}\n2007:{\"line\":702,\"column\":1,\"offset\":102421}\n2008:{\"line\":702,\"column\":124,\"offset\":102544}\n2006:{\"start\":\"$2007\",\"end\":\"$2008\"}\n2005:{\"type\":\"footnoteDefinition\",\"identifier\":\"12\",\"label\":\"12\",\"children\":\"$378\",\"position\":\"$2006\"}\n200b:{\"line\":704,\"column\":1,\"offset\":102546}\n200c:{\"line\":704,\"column\":742,\"offset\":103287}\n200a:{\"start\":\"$200b\",\"end\":\"$200c\"}\n2009:{\"type\":\"footnoteDefinition\",\"identifier\":\"13\",\"label\":\"13\",\"children\":\"$38f\",\"position\":\"$200a\"}\n200f:{\"line\":706,\"column\":1,\"offset\":103289}\n2010:{\"line\":706,\"column\":238,\"offset\":103526}\n200e:{\"start\":\"$200f\",\"end\":\"$2010\"}\n200d:{\"type\":\"footnoteDefinition\",\"identifier\":\"14\",\"label\":\"14\",\"children\":\"$399\",\"position\":\"$200e\"}\n2013:{\"line\":708,\"column\":1,\"offset\":103528}\n2014:{\"line\":708,\"column\":150,\"offset\":103677}\n2012:{\"start\":\"$2013\",\"end\":\"$2014\"}\n2011:{\"type\":\"footnoteDefinition\",\"identifier\":\"15\",\"label\":\"15\",\"children\":\"$3b0\",\"position\":\"$2012\"}\n2017:{\"line\":710,\"column\":1,\"offset\":103679}\n2018:{\"line\":710,\"column\":184,\"offset\":103862}\n2016:{\"start\":\"$2017\",\"end\":\"$"])</script><script>self.__next_f.push([1,"2018\"}\n2015:{\"type\":\"footnoteDefinition\",\"identifier\":\"16\",\"label\":\"16\",\"children\":\"$3c7\",\"position\":\"$2016\"}\n201b:{\"line\":712,\"column\":1,\"offset\":103864}\n201c:{\"line\":712,\"column\":254,\"offset\":104117}\n201a:{\"start\":\"$201b\",\"end\":\"$201c\"}\n2019:{\"type\":\"footnoteDefinition\",\"identifier\":\"17\",\"label\":\"17\",\"children\":\"$3d1\",\"position\":\"$201a\"}\n201f:{\"line\":714,\"column\":1,\"offset\":104119}\n2020:{\"line\":714,\"column\":334,\"offset\":104452}\n201e:{\"start\":\"$201f\",\"end\":\"$2020\"}\n201d:{\"type\":\"footnoteDefinition\",\"identifier\":\"18\",\"label\":\"18\",\"children\":\"$3db\",\"position\":\"$201e\"}\n2023:{\"line\":716,\"column\":1,\"offset\":104454}\n2024:{\"line\":716,\"column\":691,\"offset\":105144}\n2022:{\"start\":\"$2023\",\"end\":\"$2024\"}\n2021:{\"type\":\"footnoteDefinition\",\"identifier\":\"19\",\"label\":\"19\",\"children\":\"$3e5\",\"position\":\"$2022\"}\n2027:{\"line\":718,\"column\":1,\"offset\":105146}\n2028:{\"line\":718,\"column\":863,\"offset\":106008}\n2026:{\"start\":\"$2027\",\"end\":\"$2028\"}\n2025:{\"type\":\"footnoteDefinition\",\"identifier\":\"20\",\"label\":\"20\",\"children\":\"$409\",\"position\":\"$2026\"}\n202b:{\"line\":720,\"column\":1,\"offset\":106010}\n202c:{\"line\":720,\"column\":518,\"offset\":106527}\n202a:{\"start\":\"$202b\",\"end\":\"$202c\"}\n2029:{\"type\":\"footnoteDefinition\",\"identifier\":\"21\",\"label\":\"21\",\"children\":\"$42d\",\"position\":\"$202a\"}\n202f:{\"line\":722,\"column\":1,\"offset\":106529}\n2030:{\"line\":722,\"column\":176,\"offset\":106704}\n202e:{\"start\":\"$202f\",\"end\":\"$2030\"}\n202d:{\"type\":\"footnoteDefinition\",\"identifier\":\"22\",\"label\":\"22\",\"children\":\"$437\",\"position\":\"$202e\"}\n2033:{\"line\":724,\"column\":1,\"offset\":106706}\n2034:{\"line\":724,\"column\":143,\"offset\":106848}\n2032:{\"start\":\"$2033\",\"end\":\"$2034\"}\n2031:{\"type\":\"footnoteDefinition\",\"identifier\":\"23\",\"label\":\"23\",\"children\":\"$44e\",\"position\":\"$2032\"}\n2037:{\"line\":726,\"column\":1,\"offset\":106850}\n2038:{\"line\":726,\"column\":516,\"offset\":107365}\n2036:{\"start\":\"$2037\",\"end\":\"$2038\"}\n2035:{\"type\":\"footnoteDefinition\",\"identifier\":\"24\",\"label\":\"24\",\"children\":\"$472\",\"position\":\"$2036\"}\n203b:{\"line\":728,\"column\":1,\"offset\":107367}\n203c:{\"line\":728,\"column\":648,\"offset"])</script><script>self.__next_f.push([1,"\":108014}\n203a:{\"start\":\"$203b\",\"end\":\"$203c\"}\n2039:{\"type\":\"footnoteDefinition\",\"identifier\":\"25\",\"label\":\"25\",\"children\":\"$496\",\"position\":\"$203a\"}\n203f:{\"line\":730,\"column\":1,\"offset\":108016}\n2040:{\"line\":730,\"column\":208,\"offset\":108223}\n203e:{\"start\":\"$203f\",\"end\":\"$2040\"}\n203d:{\"type\":\"footnoteDefinition\",\"identifier\":\"26\",\"label\":\"26\",\"children\":\"$4d4\",\"position\":\"$203e\"}\n2043:{\"line\":732,\"column\":1,\"offset\":108225}\n2044:{\"line\":732,\"column\":262,\"offset\":108486}\n2042:{\"start\":\"$2043\",\"end\":\"$2044\"}\n2041:{\"type\":\"footnoteDefinition\",\"identifier\":\"27\",\"label\":\"27\",\"children\":\"$4eb\",\"position\":\"$2042\"}\n2047:{\"line\":734,\"column\":1,\"offset\":108488}\n2048:{\"line\":734,\"column\":163,\"offset\":108650}\n2046:{\"start\":\"$2047\",\"end\":\"$2048\"}\n2045:{\"type\":\"footnoteDefinition\",\"identifier\":\"28\",\"label\":\"28\",\"children\":\"$502\",\"position\":\"$2046\"}\n204b:{\"line\":736,\"column\":1,\"offset\":108652}\n204c:{\"line\":736,\"column\":318,\"offset\":108969}\n204a:{\"start\":\"$204b\",\"end\":\"$204c\"}\n2049:{\"type\":\"footnoteDefinition\",\"identifier\":\"29\",\"label\":\"29\",\"children\":\"$50c\",\"position\":\"$204a\"}\n204f:{\"line\":738,\"column\":1,\"offset\":108971}\n2050:{\"line\":738,\"column\":449,\"offset\":109419}\n204e:{\"start\":\"$204f\",\"end\":\"$2050\"}\n204d:{\"type\":\"footnoteDefinition\",\"identifier\":\"30\",\"label\":\"30\",\"children\":\"$516\",\"position\":\"$204e\"}\n2053:{\"line\":740,\"column\":1,\"offset\":109421}\n2054:{\"line\":740,\"column\":697,\"offset\":110117}\n2052:{\"start\":\"$2053\",\"end\":\"$2054\"}\n2051:{\"type\":\"footnoteDefinition\",\"identifier\":\"31\",\"label\":\"31\",\"children\":\"$52d\",\"position\":\"$2052\"}\n2057:{\"line\":742,\"column\":1,\"offset\":110119}\n2058:{\"line\":742,\"column\":218,\"offset\":110336}\n2056:{\"start\":\"$2057\",\"end\":\"$2058\"}\n2055:{\"type\":\"footnoteDefinition\",\"identifier\":\"32\",\"label\":\"32\",\"children\":\"$537\",\"position\":\"$2056\"}\n205b:{\"line\":744,\"column\":1,\"offset\":110338}\n205c:{\"line\":744,\"column\":370,\"offset\":110707}\n205a:{\"start\":\"$205b\",\"end\":\"$205c\"}\n2059:{\"type\":\"footnoteDefinition\",\"identifier\":\"33\",\"label\":\"33\",\"children\":\"$54e\",\"position\":\"$205a\"}\n205f:{\"line\":746,\"column\":1,\"offset\":11070"])</script><script>self.__next_f.push([1,"9}\n2060:{\"line\":746,\"column\":1212,\"offset\":111920}\n205e:{\"start\":\"$205f\",\"end\":\"$2060\"}\n205d:{\"type\":\"footnoteDefinition\",\"identifier\":\"35\",\"label\":\"35\",\"children\":\"$565\",\"position\":\"$205e\"}\n2063:{\"line\":748,\"column\":1,\"offset\":111922}\n2064:{\"line\":748,\"column\":403,\"offset\":112324}\n2062:{\"start\":\"$2063\",\"end\":\"$2064\"}\n2061:{\"type\":\"footnoteDefinition\",\"identifier\":\"36\",\"label\":\"36\",\"children\":\"$5ca\",\"position\":\"$2062\"}\n2067:{\"line\":750,\"column\":1,\"offset\":112326}\n2068:{\"line\":750,\"column\":216,\"offset\":112541}\n2066:{\"start\":\"$2067\",\"end\":\"$2068\"}\n2065:{\"type\":\"footnoteDefinition\",\"identifier\":\"37\",\"label\":\"37\",\"children\":\"$5e1\",\"position\":\"$2066\"}\n206b:{\"line\":752,\"column\":1,\"offset\":112543}\n206c:{\"line\":752,\"column\":430,\"offset\":112972}\n206a:{\"start\":\"$206b\",\"end\":\"$206c\"}\n2069:{\"type\":\"footnoteDefinition\",\"identifier\":\"38\",\"label\":\"38\",\"children\":\"$5f8\",\"position\":\"$206a\"}\n206f:{\"line\":754,\"column\":1,\"offset\":112974}\n2070:{\"line\":754,\"column\":516,\"offset\":113489}\n206e:{\"start\":\"$206f\",\"end\":\"$2070\"}\n206d:{\"type\":\"footnoteDefinition\",\"identifier\":\"39\",\"label\":\"39\",\"children\":\"$602\",\"position\":\"$206e\"}\n2073:{\"line\":756,\"column\":1,\"offset\":113491}\n2074:{\"line\":756,\"column\":166,\"offset\":113656}\n2072:{\"start\":\"$2073\",\"end\":\"$2074\"}\n2071:{\"type\":\"footnoteDefinition\",\"identifier\":\"40\",\"label\":\"40\",\"children\":\"$60c\",\"position\":\"$2072\"}\n2077:{\"line\":758,\"column\":1,\"offset\":113658}\n2078:{\"line\":758,\"column\":451,\"offset\":114108}\n2076:{\"start\":\"$2077\",\"end\":\"$2078\"}\n2075:{\"type\":\"footnoteDefinition\",\"identifier\":\"41\",\"label\":\"41\",\"children\":\"$616\",\"position\":\"$2076\"}\n207b:{\"line\":760,\"column\":1,\"offset\":114110}\n207c:{\"line\":760,\"column\":203,\"offset\":114312}\n207a:{\"start\":\"$207b\",\"end\":\"$207c\"}\n2079:{\"type\":\"footnoteDefinition\",\"identifier\":\"42\",\"label\":\"42\",\"children\":\"$63a\",\"position\":\"$207a\"}\n207f:{\"line\":762,\"column\":1,\"offset\":114314}\n2080:{\"line\":762,\"column\":82,\"offset\":114395}\n207e:{\"start\":\"$207f\",\"end\":\"$2080\"}\n207d:{\"type\":\"footnoteDefinition\",\"identifier\":\"43\",\"label\":\"43\",\"children\":\"$65e\",\"position\":\"$207e\"}\n20"])</script><script>self.__next_f.push([1,"83:{\"line\":764,\"column\":1,\"offset\":114397}\n2084:{\"line\":764,\"column\":433,\"offset\":114829}\n2082:{\"start\":\"$2083\",\"end\":\"$2084\"}\n2081:{\"type\":\"footnoteDefinition\",\"identifier\":\"44\",\"label\":\"44\",\"children\":\"$668\",\"position\":\"$2082\"}\n2087:{\"line\":766,\"column\":1,\"offset\":114831}\n2088:{\"line\":766,\"column\":503,\"offset\":115333}\n2086:{\"start\":\"$2087\",\"end\":\"$2088\"}\n2085:{\"type\":\"footnoteDefinition\",\"identifier\":\"45\",\"label\":\"45\",\"children\":\"$67f\",\"position\":\"$2086\"}\n208b:{\"line\":768,\"column\":1,\"offset\":115335}\n208c:{\"line\":768,\"column\":273,\"offset\":115607}\n208a:{\"start\":\"$208b\",\"end\":\"$208c\"}\n2089:{\"type\":\"footnoteDefinition\",\"identifier\":\"46\",\"label\":\"46\",\"children\":\"$6a3\",\"position\":\"$208a\"}\n208f:{\"line\":770,\"column\":1,\"offset\":115609}\n2090:{\"line\":770,\"column\":691,\"offset\":116299}\n208e:{\"start\":\"$208f\",\"end\":\"$2090\"}\n208d:{\"type\":\"footnoteDefinition\",\"identifier\":\"47\",\"label\":\"47\",\"children\":\"$6ad\",\"position\":\"$208e\"}\n2093:{\"line\":772,\"column\":1,\"offset\":116301}\n2094:{\"line\":772,\"column\":390,\"offset\":116690}\n2092:{\"start\":\"$2093\",\"end\":\"$2094\"}\n2091:{\"type\":\"footnoteDefinition\",\"identifier\":\"48\",\"label\":\"48\",\"children\":\"$6d1\",\"position\":\"$2092\"}\n2097:{\"line\":774,\"column\":1,\"offset\":116692}\n2098:{\"line\":774,\"column\":173,\"offset\":116864}\n2096:{\"start\":\"$2097\",\"end\":\"$2098\"}\n2095:{\"type\":\"footnoteDefinition\",\"identifier\":\"49\",\"label\":\"49\",\"children\":\"$6db\",\"position\":\"$2096\"}\n209b:{\"line\":776,\"column\":1,\"offset\":116866}\n209c:{\"line\":776,\"column\":505,\"offset\":117370}\n209a:{\"start\":\"$209b\",\"end\":\"$209c\"}\n2099:{\"type\":\"footnoteDefinition\",\"identifier\":\"50\",\"label\":\"50\",\"children\":\"$6e5\",\"position\":\"$209a\"}\n209f:{\"line\":778,\"column\":1,\"offset\":117372}\n20a0:{\"line\":778,\"column\":616,\"offset\":117987}\n209e:{\"start\":\"$209f\",\"end\":\"$20a0\"}\n209d:{\"type\":\"footnoteDefinition\",\"identifier\":\"51\",\"label\":\"51\",\"children\":\"$6ef\",\"position\":\"$209e\"}\n20a3:{\"line\":780,\"column\":1,\"offset\":117989}\n20a4:{\"line\":780,\"column\":1064,\"offset\":119052}\n20a2:{\"start\":\"$20a3\",\"end\":\"$20a4\"}\n20a1:{\"type\":\"footnoteDefinition\",\"identifier\":\"52\",\"label\":\"52\""])</script><script>self.__next_f.push([1,",\"children\":\"$713\",\"position\":\"$20a2\"}\n20a7:{\"line\":782,\"column\":1,\"offset\":119054}\n20a8:{\"line\":782,\"column\":654,\"offset\":119707}\n20a6:{\"start\":\"$20a7\",\"end\":\"$20a8\"}\n20a5:{\"type\":\"footnoteDefinition\",\"identifier\":\"53\",\"label\":\"53\",\"children\":\"$71e\",\"position\":\"$20a6\"}\n20ab:{\"line\":784,\"column\":1,\"offset\":119709}\n20ac:{\"line\":784,\"column\":194,\"offset\":119902}\n20aa:{\"start\":\"$20ab\",\"end\":\"$20ac\"}\n20a9:{\"type\":\"footnoteDefinition\",\"identifier\":\"54\",\"label\":\"54\",\"children\":\"$735\",\"position\":\"$20aa\"}\n20af:{\"line\":786,\"column\":1,\"offset\":119904}\n20b0:{\"line\":786,\"column\":461,\"offset\":120364}\n20ae:{\"start\":\"$20af\",\"end\":\"$20b0\"}\n20ad:{\"type\":\"footnoteDefinition\",\"identifier\":\"55\",\"label\":\"55\",\"children\":\"$73f\",\"position\":\"$20ae\"}\n20b3:{\"line\":788,\"column\":1,\"offset\":120366}\n20b4:{\"line\":788,\"column\":79,\"offset\":120444}\n20b2:{\"start\":\"$20b3\",\"end\":\"$20b4\"}\n20b1:{\"type\":\"footnoteDefinition\",\"identifier\":\"58\",\"label\":\"58\",\"children\":\"$756\",\"position\":\"$20b2\"}\n20b7:{\"line\":790,\"column\":1,\"offset\":120446}\n20b8:{\"line\":790,\"column\":171,\"offset\":120616}\n20b6:{\"start\":\"$20b7\",\"end\":\"$20b8\"}\n20b5:{\"type\":\"footnoteDefinition\",\"identifier\":\"59\",\"label\":\"59\",\"children\":\"$760\",\"position\":\"$20b6\"}\n20bb:{\"line\":792,\"column\":1,\"offset\":120618}\n20bc:{\"line\":792,\"column\":382,\"offset\":120999}\n20ba:{\"start\":\"$20bb\",\"end\":\"$20bc\"}\n20b9:{\"type\":\"footnoteDefinition\",\"identifier\":\"60\",\"label\":\"60\",\"children\":\"$777\",\"position\":\"$20ba\"}\n20bf:{\"line\":794,\"column\":1,\"offset\":121001}\n20c0:{\"line\":794,\"column\":777,\"offset\":121777}\n20be:{\"start\":\"$20bf\",\"end\":\"$20c0\"}\n20bd:{\"type\":\"footnoteDefinition\",\"identifier\":\"61\",\"label\":\"61\",\"children\":\"$79b\",\"position\":\"$20be\"}\n20c3:{\"line\":796,\"column\":1,\"offset\":121779}\n20c4:{\"line\":796,\"column\":1135,\"offset\":122913}\n20c2:{\"start\":\"$20c3\",\"end\":\"$20c4\"}\n20c1:{\"type\":\"footnoteDefinition\",\"identifier\":\"62\",\"label\":\"62\",\"children\":\"$7bf\",\"position\":\"$20c2\"}\n20c7:{\"line\":798,\"column\":1,\"offset\":122915}\n20c8:{\"line\":798,\"column\":219,\"offset\":123133}\n20c6:{\"start\":\"$20c7\",\"end\":\"$20c8\"}\n20c5:{\"type\":\"footnoteDe"])</script><script>self.__next_f.push([1,"finition\",\"identifier\":\"63\",\"label\":\"63\",\"children\":\"$7d7\",\"position\":\"$20c6\"}\n20cb:{\"line\":800,\"column\":1,\"offset\":123135}\n20cc:{\"line\":800,\"column\":109,\"offset\":123243}\n20ca:{\"start\":\"$20cb\",\"end\":\"$20cc\"}\n20c9:{\"type\":\"footnoteDefinition\",\"identifier\":\"64\",\"label\":\"64\",\"children\":\"$7e1\",\"position\":\"$20ca\"}\n20cf:{\"line\":802,\"column\":1,\"offset\":123245}\n20d0:{\"line\":802,\"column\":149,\"offset\":123393}\n20ce:{\"start\":\"$20cf\",\"end\":\"$20d0\"}\n20cd:{\"type\":\"footnoteDefinition\",\"identifier\":\"65\",\"label\":\"65\",\"children\":\"$7eb\",\"position\":\"$20ce\"}\n20d3:{\"line\":804,\"column\":1,\"offset\":123395}\n20d4:{\"line\":804,\"column\":673,\"offset\":124067}\n20d2:{\"start\":\"$20d3\",\"end\":\"$20d4\"}\n20d1:{\"type\":\"footnoteDefinition\",\"identifier\":\"66\",\"label\":\"66\",\"children\":\"$802\",\"position\":\"$20d2\"}\n20d7:{\"line\":806,\"column\":1,\"offset\":124069}\n20d8:{\"line\":806,\"column\":147,\"offset\":124215}\n20d6:{\"start\":\"$20d7\",\"end\":\"$20d8\"}\n20d5:{\"type\":\"footnoteDefinition\",\"identifier\":\"67\",\"label\":\"67\",\"children\":\"$80c\",\"position\":\"$20d6\"}\n20db:{\"line\":808,\"column\":1,\"offset\":124217}\n20dc:{\"line\":808,\"column\":167,\"offset\":124383}\n20da:{\"start\":\"$20db\",\"end\":\"$20dc\"}\n20d9:{\"type\":\"footnoteDefinition\",\"identifier\":\"68\",\"label\":\"68\",\"children\":\"$816\",\"position\":\"$20da\"}\n20df:{\"line\":810,\"column\":1,\"offset\":124385}\n20e0:{\"line\":810,\"column\":953,\"offset\":125337}\n20de:{\"start\":\"$20df\",\"end\":\"$20e0\"}\n20dd:{\"type\":\"footnoteDefinition\",\"identifier\":\"69\",\"label\":\"69\",\"children\":\"$820\",\"position\":\"$20de\"}\n20e3:{\"line\":813,\"column\":1,\"offset\":125340}\n20e4:{\"line\":813,\"column\":77,\"offset\":125416}\n20e2:{\"start\":\"$20e3\",\"end\":\"$20e4\"}\n20e1:{\"type\":\"footnoteDefinition\",\"identifier\":\"70\",\"label\":\"70\",\"children\":\"$82a\",\"position\":\"$20e2\"}\n20e7:{\"line\":815,\"column\":1,\"offset\":125418}\n20e8:{\"line\":815,\"column\":168,\"offset\":125585}\n20e6:{\"start\":\"$20e7\",\"end\":\"$20e8\"}\n20e5:{\"type\":\"footnoteDefinition\",\"identifier\":\"71\",\"label\":\"71\",\"children\":\"$834\",\"position\":\"$20e6\"}\n20eb:{\"line\":817,\"column\":1,\"offset\":125587}\n20ec:{\"line\":817,\"column\":453,\"offset\":126039}\n20ea:{\"start\":\"$20eb\","])</script><script>self.__next_f.push([1,"\"end\":\"$20ec\"}\n20e9:{\"type\":\"footnoteDefinition\",\"identifier\":\"72\",\"label\":\"72\",\"children\":\"$83e\",\"position\":\"$20ea\"}\n20ef:{\"line\":819,\"column\":1,\"offset\":126041}\n20f0:{\"line\":819,\"column\":384,\"offset\":126424}\n20ee:{\"start\":\"$20ef\",\"end\":\"$20f0\"}\n20ed:{\"type\":\"footnoteDefinition\",\"identifier\":\"73\",\"label\":\"73\",\"children\":\"$855\",\"position\":\"$20ee\"}\n20f3:{\"line\":821,\"column\":1,\"offset\":126426}\n20f4:{\"line\":821,\"column\":641,\"offset\":127066}\n20f2:{\"start\":\"$20f3\",\"end\":\"$20f4\"}\n20f1:{\"type\":\"footnoteDefinition\",\"identifier\":\"74\",\"label\":\"74\",\"children\":\"$85f\",\"position\":\"$20f2\"}\n20f7:{\"line\":823,\"column\":1,\"offset\":127068}\n20f8:{\"line\":823,\"column\":1395,\"offset\":128462}\n20f6:{\"start\":\"$20f7\",\"end\":\"$20f8\"}\n20f5:{\"type\":\"footnoteDefinition\",\"identifier\":\"75\",\"label\":\"75\",\"children\":\"$869\",\"position\":\"$20f6\"}\n20fb:{\"line\":825,\"column\":1,\"offset\":128464}\n20fc:{\"line\":825,\"column\":188,\"offset\":128651}\n20fa:{\"start\":\"$20fb\",\"end\":\"$20fc\"}\n20f9:{\"type\":\"footnoteDefinition\",\"identifier\":\"76\",\"label\":\"76\",\"children\":\"$8c1\",\"position\":\"$20fa\"}\n20ff:{\"line\":827,\"column\":1,\"offset\":128653}\n2100:{\"line\":827,\"column\":142,\"offset\":128794}\n20fe:{\"start\":\"$20ff\",\"end\":\"$2100\"}\n20fd:{\"type\":\"footnoteDefinition\",\"identifier\":\"77\",\"label\":\"77\",\"children\":\"$8d8\",\"position\":\"$20fe\"}\n2103:{\"line\":829,\"column\":1,\"offset\":128796}\n2104:{\"line\":829,\"column\":245,\"offset\":129040}\n2102:{\"start\":\"$2103\",\"end\":\"$2104\"}\n2101:{\"type\":\"footnoteDefinition\",\"identifier\":\"78\",\"label\":\"78\",\"children\":\"$8ef\",\"position\":\"$2102\"}\n2107:{\"line\":831,\"column\":1,\"offset\":129042}\n2108:{\"line\":831,\"column\":840,\"offset\":129881}\n2106:{\"start\":\"$2107\",\"end\":\"$2108\"}\n2105:{\"type\":\"footnoteDefinition\",\"identifier\":\"79\",\"label\":\"79\",\"children\":\"$8f9\",\"position\":\"$2106\"}\n210b:{\"line\":833,\"column\":1,\"offset\":129883}\n210c:{\"line\":833,\"column\":378,\"offset\":130260}\n210a:{\"start\":\"$210b\",\"end\":\"$210c\"}\n2109:{\"type\":\"footnoteDefinition\",\"identifier\":\"80\",\"label\":\"80\",\"children\":\"$903\",\"position\":\"$210a\"}\n210f:{\"line\":835,\"column\":1,\"offset\":130262}\n2110:{\"line\":835,\"column\":17"])</script><script>self.__next_f.push([1,"8,\"offset\":130439}\n210e:{\"start\":\"$210f\",\"end\":\"$2110\"}\n210d:{\"type\":\"footnoteDefinition\",\"identifier\":\"81\",\"label\":\"81\",\"children\":\"$90d\",\"position\":\"$210e\"}\n2113:{\"line\":837,\"column\":1,\"offset\":130441}\n2114:{\"line\":837,\"column\":397,\"offset\":130837}\n2112:{\"start\":\"$2113\",\"end\":\"$2114\"}\n2111:{\"type\":\"footnoteDefinition\",\"identifier\":\"82\",\"label\":\"82\",\"children\":\"$917\",\"position\":\"$2112\"}\n2117:{\"line\":839,\"column\":1,\"offset\":130839}\n2118:{\"line\":839,\"column\":413,\"offset\":131251}\n2116:{\"start\":\"$2117\",\"end\":\"$2118\"}\n2115:{\"type\":\"footnoteDefinition\",\"identifier\":\"83\",\"label\":\"83\",\"children\":\"$921\",\"position\":\"$2116\"}\n211b:{\"line\":841,\"column\":1,\"offset\":131253}\n211c:{\"line\":841,\"column\":157,\"offset\":131409}\n211a:{\"start\":\"$211b\",\"end\":\"$211c\"}\n2119:{\"type\":\"footnoteDefinition\",\"identifier\":\"84\",\"label\":\"84\",\"children\":\"$938\",\"position\":\"$211a\"}\n211f:{\"line\":843,\"column\":1,\"offset\":131411}\n2120:{\"line\":843,\"column\":277,\"offset\":131687}\n211e:{\"start\":\"$211f\",\"end\":\"$2120\"}\n211d:{\"type\":\"footnoteDefinition\",\"identifier\":\"85\",\"label\":\"85\",\"children\":\"$942\",\"position\":\"$211e\"}\n2123:{\"line\":845,\"column\":1,\"offset\":131689}\n2124:{\"line\":845,\"column\":373,\"offset\":132061}\n2122:{\"start\":\"$2123\",\"end\":\"$2124\"}\n2121:{\"type\":\"footnoteDefinition\",\"identifier\":\"86\",\"label\":\"86\",\"children\":\"$94c\",\"position\":\"$2122\"}\n2127:{\"line\":847,\"column\":1,\"offset\":132063}\n2128:{\"line\":847,\"column\":391,\"offset\":132453}\n2126:{\"start\":\"$2127\",\"end\":\"$2128\"}\n2125:{\"type\":\"footnoteDefinition\",\"identifier\":\"87\",\"label\":\"87\",\"children\":\"$956\",\"position\":\"$2126\"}\n212b:{\"line\":849,\"column\":1,\"offset\":132455}\n212c:{\"line\":849,\"column\":215,\"offset\":132669}\n212a:{\"start\":\"$212b\",\"end\":\"$212c\"}\n2129:{\"type\":\"footnoteDefinition\",\"identifier\":\"88\",\"label\":\"88\",\"children\":\"$960\",\"position\":\"$212a\"}\n212f:{\"line\":851,\"column\":1,\"offset\":132671}\n2130:{\"line\":851,\"column\":805,\"offset\":133475}\n212e:{\"start\":\"$212f\",\"end\":\"$2130\"}\n212d:{\"type\":\"footnoteDefinition\",\"identifier\":\"89\",\"label\":\"89\",\"children\":\"$96a\",\"position\":\"$212e\"}\n2133:{\"line\":853,\"column\":1,\"offs"])</script><script>self.__next_f.push([1,"et\":133477}\n2134:{\"line\":853,\"column\":805,\"offset\":134281}\n2132:{\"start\":\"$2133\",\"end\":\"$2134\"}\n2131:{\"type\":\"footnoteDefinition\",\"identifier\":\"90\",\"label\":\"90\",\"children\":\"$974\",\"position\":\"$2132\"}\n2137:{\"line\":855,\"column\":1,\"offset\":134283}\n2138:{\"line\":855,\"column\":118,\"offset\":134400}\n2136:{\"start\":\"$2137\",\"end\":\"$2138\"}\n2135:{\"type\":\"footnoteDefinition\",\"identifier\":\"91\",\"label\":\"91\",\"children\":\"$97e\",\"position\":\"$2136\"}\n213b:{\"line\":857,\"column\":1,\"offset\":134402}\n213c:{\"line\":857,\"column\":177,\"offset\":134578}\n213a:{\"start\":\"$213b\",\"end\":\"$213c\"}\n2139:{\"type\":\"footnoteDefinition\",\"identifier\":\"92\",\"label\":\"92\",\"children\":\"$991\",\"position\":\"$213a\"}\n213f:{\"line\":859,\"column\":1,\"offset\":134580}\n2140:{\"line\":859,\"column\":338,\"offset\":134917}\n213e:{\"start\":\"$213f\",\"end\":\"$2140\"}\n213d:{\"type\":\"footnoteDefinition\",\"identifier\":\"93\",\"label\":\"93\",\"children\":\"$9a8\",\"position\":\"$213e\"}\n2143:{\"line\":861,\"column\":1,\"offset\":134919}\n2144:{\"line\":861,\"column\":177,\"offset\":135095}\n2142:{\"start\":\"$2143\",\"end\":\"$2144\"}\n2141:{\"type\":\"footnoteDefinition\",\"identifier\":\"94\",\"label\":\"94\",\"children\":\"$9b2\",\"position\":\"$2142\"}\n2147:{\"line\":863,\"column\":1,\"offset\":135097}\n2148:{\"line\":863,\"column\":265,\"offset\":135361}\n2146:{\"start\":\"$2147\",\"end\":\"$2148\"}\n2145:{\"type\":\"footnoteDefinition\",\"identifier\":\"95\",\"label\":\"95\",\"children\":\"$9bc\",\"position\":\"$2146\"}\n214b:{\"line\":865,\"column\":1,\"offset\":135363}\n214c:{\"line\":865,\"column\":578,\"offset\":135940}\n214a:{\"start\":\"$214b\",\"end\":\"$214c\"}\n2149:{\"type\":\"footnoteDefinition\",\"identifier\":\"96\",\"label\":\"96\",\"children\":\"$9c6\",\"position\":\"$214a\"}\n214f:{\"line\":867,\"column\":1,\"offset\":135942}\n2150:{\"line\":867,\"column\":105,\"offset\":136046}\n214e:{\"start\":\"$214f\",\"end\":\"$2150\"}\n214d:{\"type\":\"footnoteDefinition\",\"identifier\":\"97\",\"label\":\"97\",\"children\":\"$9d0\",\"position\":\"$214e\"}\n2153:{\"line\":869,\"column\":1,\"offset\":136048}\n2154:{\"line\":869,\"column\":135,\"offset\":136182}\n2152:{\"start\":\"$2153\",\"end\":\"$2154\"}\n2151:{\"type\":\"footnoteDefinition\",\"identifier\":\"98\",\"label\":\"98\",\"children\":\"$9da\",\"position\":\"$"])</script><script>self.__next_f.push([1,"2152\"}\n2157:{\"line\":871,\"column\":1,\"offset\":136184}\n2158:{\"line\":871,\"column\":127,\"offset\":136310}\n2156:{\"start\":\"$2157\",\"end\":\"$2158\"}\n2155:{\"type\":\"footnoteDefinition\",\"identifier\":\"99\",\"label\":\"99\",\"children\":\"$9e4\",\"position\":\"$2156\"}\naca:[\"$a\",\"$19\",\"$22\",\"$37\",\"$5e\",\"$274\",\"$9ee\",\"$9f7\",\"$a0e\",\"$a17\",\"$a39\",\"$a42\",\"$a53\",\"$acb\",\"$ad4\",\"$aeb\",\"$af8\",\"$b0e\",\"$b14\",\"$b6e\",\"$b98\",\"$bae\",\"$bc8\",\"$bea\",\"$c4c\",\"$caf\",\"$ccd\",\"$d01\",\"$d0a\",\"$d21\",\"$d2a\",\"$d33\",\"$e06\",\"$e20\",\"$e35\",\"$e8a\",\"$e93\",\"$eaa\",\"$ec0\",\"$ed5\",\"$f0b\",\"$f3b\",\"$f44\",\"$f5b\",\"$f64\",\"$f6d\",\"$f7a\",\"$f80\",\"$fb7\",\"$fc0\",\"$fd7\",\"$100a\",\"$1030\",\"$1046\",\"$1075\",\"$107e\",\"$1095\",\"$10a2\",\"$10b3\",\"$10bc\",\"$10ef\",\"$10fc\",\"$1102\",\"$1117\",\"$1120\",\"$1137\",\"$1140\",\"$1149\",\"$1152\",\"$1158\",\"$122f\",\"$1339\",\"$1356\",\"$135f\",\"$13fc\",\"$1405\",\"$141c\",\"$1425\",\"$142e\",\"$144d\",\"$1456\",\"$146c\",\"$1475\",\"$15e4\",\"$15f5\",\"$15fe\",\"$1615\",\"$161e\",\"$1627\",\"$1634\",\"$1641\",\"$1652\",\"$1663\",\"$168a\",\"$1693\",\"$16aa\",\"$16c0\",\"$16c9\",\"$16d2\",\"$16db\",\"$16e1\",\"$16ee\",\"$1720\",\"$1729\",\"$1740\",\"$1749\",\"$1752\",\"$175b\",\"$176c\",\"$1775\",\"$1786\",\"$178f\",\"$17a5\",\"$17ae\",\"$17b7\",\"$17ce\",\"$17d7\",\"$17e0\",\"$180b\",\"$181c\",\"$183a\",\"$184b\",\"$1854\",\"$1865\",\"$186e\",\"$1877\",\"$188d\",\"$1896\",\"$189f\",\"$18b6\",\"$18bf\",\"$18d4\",\"$18dd\",\"$18f6\",\"$18ff\",\"$1a38\",\"$1a45\",\"$1a81\",\"$1e73\",\"$1e91\",\"$1e9e\",\"$1ec0\",\"$1ec9\",\"$1ee2\",\"$1eeb\",\"$1ef4\",\"$1f0b\",\"$1f21\",\"$1f2a\",\"$1f3b\",\"$1f44\",\"$1f5d\",\"$1f66\",\"$1f73\",\"$1f7c\",\"$1f85\",\"$1fa2\",\"$1fd9\",\"$1fdd\",\"$1fe1\",\"$1fe5\",\"$1fe9\",\"$1fed\",\"$1ff1\",\"$1ff5\",\"$1ff9\",\"$1ffd\",\"$2001\",\"$2005\",\"$2009\",\"$200d\",\"$2011\",\"$2015\",\"$2019\",\"$201d\",\"$2021\",\"$2025\",\"$2029\",\"$202d\",\"$2031\",\"$2035\",\"$2039\",\"$203d\",\"$2041\",\"$2045\",\"$2049\",\"$204d\",\"$2051\",\"$2055\",\"$2059\",\"$205d\",\"$2061\",\"$2065\",\"$2069\",\"$206d\",\"$2071\",\"$2075\",\"$2079\",\"$207d\",\"$2081\",\"$2085\",\"$2089\",\"$208d\",\"$2091\",\"$2095\",\"$2099\",\"$209d\",\"$20a1\",\"$20a5\",\"$20a9\",\"$20ad\",\"$20b1\",\"$20b5\",\"$20b9\",\"$20bd\",\"$20c1\",\"$20c5\",\"$20c9\",\"$20cd\",\"$20d1\",\"$20d5\",\"$20d9\",\"$20dd\",\"$20e1\",\"$20e5\",\"$20e9\",\"$20ed\",\"$20f1\",\"$20f5\",\"$20f9\",\"$20fd\",\"$2101\",\"$210"])</script><script>self.__next_f.push([1,"5\",\"$2109\",\"$210d\",\"$2111\",\"$2115\",\"$2119\",\"$211d\",\"$2121\",\"$2125\",\"$2129\",\"$212d\",\"$2131\",\"$2135\",\"$2139\",\"$213d\",\"$2141\",\"$2145\",\"$2149\",\"$214d\",\"$2151\",\"$2155\"]\n215a:{\"line\":1,\"column\":1,\"offset\":0}\n215b:{\"line\":893,\"column\":1,\"offset\":136332}\n2159:{\"start\":\"$215a\",\"end\":\"$215b\"}\nac9:{\"type\":\"root\",\"children\":\"$aca\",\"position\":\"$2159\"}\n2162:T115d0,"])</script><script>self.__next_f.push([1,"# AI Goals Forecast\n\n### *Daniel Kokotajlo | April 2025*\n\n:::summary \nAI 2027 predicts that superhuman AIs will not be aligned to the values and goals intended by their human developers. This supplement justifies that assumption by discussing the possibilities for what goals the AIs end up with. \n:::\n\n## Introduction\n\nWhat goals will AIs have?[^1] \n\nThis document attempts to taxonomize and explain the many possibilities, explain why each possibility is plausible, and then finally attempt to quantify our uncertainty and explain where our bottom-line guesses are coming from.\n\nUltimately we had to make a specific choice to depict in our scenario, but we hope this document will convey the range of uncertainty we have. **We are keen to get feedback on these hypotheses and the arguments surrounding them. What important considerations are we missing?**\n\nIf you are thinking “why assume AIs have goals at all?” or “what does that even mean?” you may want to read the [appendices](#appendix-a-three-important-conceptsdistinctions) first before the main text. In fact the appendices are a good place to start for anyone who thinks they have the patience to read this whole document, because they lay out some nice conceptual distinctions and analogies.\n\n### Summary\n\nWe first review the [Agent-3 training architecture and capabilities](#summary-of-agent-3-training-architecture-and-capabilities) (lightly edited from our scenarios) to give us a concrete setup to talk about for which goals will arise. Then we get to the list of hypotheses:\n\n1. [**Written goal specification**](#hypothesis-1-written-goal-specifications)**:** Any written specifications, written by humans or AIs, regarding what the AIs’ goals should be. This could include guidelines for how Agent-3 should be trained (e.g. via a [model spec](https://openai.com/index/introducing-the-model-spec/)) or instructions directly given to Agent-3 (e.g. via a [system prompt](https://docs.anthropic.com/en/release-notes/system-prompts#nov-22nd-2024)).  \n2. [**Developer-intended goals**](#hypothesis-2-developer-intended-goals)**:** Goals that the developers intend for Agent-3 to have. This might differ from the written goal specification e.g. in cases where the specification has unintended consequences.  \n3. [**Unintended version of written goals and/or human intentions**](#hypothesis-3-unintended-version-of-written-goals-and-or-human-intentions)**:** This is the category for “it’s sorta aligned” and “It’s aligned in some ways, but not in others.”  \n4. [**Reward/reinforcement**](#hypothesis-4-reward-reinforcement)**:** The training process involves Agent-3 attempting a task, then the attempt is scored and Agent-3 is reinforced to score higher on a target metric. Agent-3 ends up with the goal of getting reinforced positively, or scoring highly on the metric, or something like that.[^2]  \n5. [**Proxies and/or instrumentally convergent goals**](#hypothesis-5-proxies-and-or-instrumentally-convergent-goals)**:** Agent-3 develops goals that are correlated with reward/reinforcement during its training, but aren’t actually maximizing reward/reinforcement in new settings. An [instrumentally convergent goal](https://www.lesswrong.com/tag/instrumental-convergence) is a special case of this – goals such as knowledge, power, resources, etc. that are useful intermediate goals in a wide range of settings.  \n6. [**Other goals**](#hypothesis-6-other-goals)**:** AIs are currently initially trained on predicting the next token on internet text. Perhaps the outcomes at the end of training are path-dependent on the ‘prior’ over goals induced by pretraining. Alternatively, perhaps there is something like objectively true morality, and AIs will naturally converge to it as they get smarter. Or perhaps something else will happen not on this list – this is the catchall hypothesis.\n\nOf course, the result could also be a combination of the above. We discuss two different kinds of compromises: weighted compromises, in which Agent-3 pursues two or more goals from the above list simultaneously, balancing tradeoffs between them, and if-else compromises, in which Agent-3 pursues one goal if some condition obtains (i.e. in some set of contexts) and pursues the other goal otherwise.\n\nHere is a summary of some of the considerations for and against each category of goals:\n\n| Goal | Case for | Case against |\n| :---- | :---- | :---- |\n| [**Written goal specification**](#hypothesis-1-written-goal-specifications) | The specification may feature prominently in the training process and the company’s stated goal may be to align the AIs to written specifications. | The AI may be reinforced for taking actions that conflict with the spec, e.g. for appearing to be honest rather than actually being honest |\n| [**Developer-intended goals**](#hypothesis-2-developer-intended-goals) | If the AI is corrigibly aligned it may converge to developers’ intentions. | See above. Also, the written specification is more well-defined, and developers may not be aiming for aligning with intentions. |\n| [**Unintended version of written goals and/or human intentions**](#hypothesis-3-unintended-version-of-written-goals-and-or-human-intentions) | If AI developers are aiming for written goals / human intentions, they might partially succeed but not completely, e.g. because some aspects of spec/intentions are easier to train. | If an AI is misaligned, it’s unclear whether it’s natural for it to mostly still be thinking about its goal in terms of the spec / humans’ intentions, especially since having this goal may lead to poor generalization. |\n| [**Reward/reinforcement**](#hypothesis-4-reward-reinforcement) | Arguably the strategy that will be most-reinforced is “try to get reinforced,” and so in the long run Agent-3 should have the goal of getting reinforced. | This doesn’t really happen with humans or human organizations. The closest analogy might be drug addicts? Also, it’s unclear how pursuing reward/reinforcement would generalize to test environments in which reinforcement is obviously not going to happen. |\n| [**Proxies and/or instrumentally convergent goals**](#hypothesis-5-proxies-and-or-instrumentally-convergent-goals) | There are many possible proxies that would lead to high reward during training, and there’s some evidence for these from both AI experiments and human evolution/learning. | The intended goals, and the goals in the Spec, and variants thereof, will also be decent proxies that would lead to high reward during training. Why wouldn’t one of those happen instead? |\n| **[Other goals](#hypothesis-6-other-goals)** | The vast majority of possible goals are “other”. Humans develop “other” goals such as ideologies/morality, AIs might do similarly upon reflection. AIs currently seem to absorb goals from training data to some extent. | For most specific “other” goals, it’s hard to tell a plausible-seeming story for why the AI might develop them. Maybe inductive biases point toward the more salient hypotheses above. |\n\nWe further discuss possible compromises between goals: weighted compromises in which the AI cares about multiple things which are weighed against each other in all circumstances, and if-else compromises in which the AI cares about different things depending on the circumstance.\n\nWe encourage you to think for yourself how likely you think each of the outcomes are for Agent-3-level AI systems. We ourselves are extremely uncertain, but find it helpful to force ourselves to make guesses, which you can find in [the table at the end](#rough-guesses-about-the-plausibility-of-these-goals).\n\n## Summary of Agent-3 training architecture and capabilities\n\nThe setup we are imagining is similar to that described in Ajeya Cotra’s [training game report.](https://www.planned-obsolescence.org/july-2022-training-game-report/) Agent-3 is similar to the agents of late 2024, in that it can take text and images (including screenshots) as inputs, and can produce text as output including many types of commands e.g. mouse clicks, keyboard presses.\n\nUnlike traditional transformers, Agent-3 is recurrent. In a nutshell, it doesn’t just output text, it also ‘outputs’ a large vector representing its internal state, which is then ‘read’ by its future self. This vector can convey much more information than the ‘chain of thoughts’ used by traditional LLMs, but alas, it is unintelligible to humans.\n\nMoreover, just as ‘chain of thought’ in English text can be stored in databases, searched over and retrieved and accessed by many different LLM agents working in parallel, Agent-3 can read and write these ‘neuralese vectors’ to a big shared database. In this manner millions of independent copies of Agent-3 working on different projects can communicate complex thoughts and memories with each other.\n\nSee the figure below from [Cotra’s report](https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#A_possible_architecture_for_Alex) for roughly what we’re imagining.\n\n![](/goals-cotra-nowatermark.png)\n\nFairly often, the weights of Agent-3 get updated thanks to additional training. In fact by this point models are rarely trained from scratch but instead are mostly old models with lots of additional training. (By 2027 this has become normal, and architectures / RL algos / hyperparams have been tuned to work well in this regime)\n\nAgent-3’s training environments/data include a large amount of artificial environments (video games, synthetic datasets of math and coding problems, synthetic datasets of various computer-use tasks) and also a substantial amount of real-life task data such as logs of trajectories of previous versions of Agent-3 conducting AI R\\\u0026D. New data / new environments are continuously getting added to the mix.\n\nThe evaluation/feedback/training process, which doles out reinforcement and/or curates which data to train on, is almost entirely automated. Some tasks are clearly checkable, others are evaluated by AIs. The vast majority (\\~95%) of research effort and experiment compute is dedicated to improving the AIs’ capabilities on these tasks.\n\nA small amount of research effort is aimed specifically at ensuring alignment (though these aren’t always easily separable, e.g. scalable oversight). The alignment strategy is a natural extension of ideas like Constitutional AI and deliberative alignment: it involves automated oversight/evaluation/scoring of actions and chain-of-thought on the basis of written instructions; we can refer to these instructions as the Spec or Constitution. For the most part, human researchers wrote those instructions. These often aren’t particularly relevant for computer-use / AI R\\\u0026D tasks, but they are relevant for a small portion of the training tasks, which are often more like chatbots or involve harmful queries.\n\nThe safety team also does some work on model organisms, scalable oversight, and mechanistic interpretability, but they don’t have many resources. They attempt to evaluate misalignment via (a) testbeds informed by model organisms and (b) honeypots.\n\n![](/goals-overview.png)\n\nAs for the capabilities of Agent-3:\n\nAgent-3 is highly [situationally aware / self-aware.](https://theaidigest.org/self-awareness) It is also at least human-level at understanding human concepts and intentions. It may still misunderstand/misinterpret instructions, but only at about the rate that a smart human would.\n\nAgent-3 is also an excellent coder and agent. In fact, it is a fully automated research engineer, able to do the same work as human engineers ten times faster and cheaper. Including work that takes weeks of continuous autonomous operation. Notably, this is largely due to generalization: Only a tiny portion of Agent-3’s training data is week-long tasks; the vast majority of its training is on much shorter tasks (e.g. math puzzles, code challenges, etc.) but it’s smart enough, and trained on enough diverse tasks, that it’s generalizing nonetheless.\n\nAgent-3 is deployed internally in the company. 200,000 copies[^3] of it essentially form a virtual corporation autonomously conducting AI R\\\u0026D and (among other things) managing or updating a lot of the software level security and networking/communication algorithms in their own datacenters. Their parent corporation is busy racing against various rivals and wants to believe Agent-3 is aligned/safe/etc.; the people in charge will be satisfied as long as there isn’t conclusive evidence of misalignment.\n\n## Loose taxonomy of possibilities\n\n### Hypothesis 1: Written goal specifications\n\n![](/goals-written.png)  \n*Any written specifications, written by humans or AIs, regarding what the AIs’ goals should be. This could include guidelines for how an AI system should be trained (e.g. via a [model spec](https://openai.com/index/introducing-the-model-spec/)) or instructions directly given to an AI system (e.g. via a [system prompt](https://docs.anthropic.com/en/release-notes/system-prompts#nov-22nd-2024)).*\n\nSee diagram—it is a simplified model of how we expect powerful AI agents’ goals and principles to be shaped. We aren’t meaning to say that Constitutional AI in particular will be used, but there will probably be some intermediate stage that takes the form of natural language text, between the intentions of the developers and the actual code that doles out reinforcement. This text could be the instructions given to the human raters in RLHF; it could be the document used in constitutional AI; it could be the instructions given to the automated research engineers telling them the desiderata for the next-gen AI system.\n\nThis hypothesis is the most straightforward, in some sense. For example, if the company trained the model to be helpful, harmless, and honest, perhaps it actually becomes helpful, harmless, and honest, as specified.\n\nNote that this is distinct from developer-intended goals. For example, the Spec may have unintended consequences. Or, the developers may have intentions that diverge from one another or that they deliberately don’t put into the Spec (perhaps because it would look bad to do so). Hypothesis 1 says that insofar as the AIs face a choice between behaving according to the true intentions of the developers and obeying the Spec/Constitution/Etc., the AIs systematically choose the latter.\n\nNote also that this is distinct from *what actually gets reinforced*. The Spec/Constitution/etc. may say “Agent-3 should be helpful, harmless, and honest” but the human and AI raters/overseers/reward-models that actually evaluate trajectories aren’t necessarily 100% accurate at judging whether a given piece of behavior is helpful, harmless, or honest. Hypothesis 1 says that insofar as Agent-3 faces a choice between obeying the Spec/Constitution/etc. and doing what’ll maximize expected reinforcement, it’ll choose the former, not the latter. Note also that there will likely be substantial vagueness in the Spec – are white lies dishonest? What about literal truths that are phrased misleadingly? How important is honesty compared to harmlessness? Etc. For more discussion of this issue, see the section on [Hypothesis 3](#hypothesis-3-unintended-version-of-written-goals-and-or-human-intentions).\n\nSo, the first objection to Hypothesis 1 is: *Insofar as Agent-3 is inclined to behave according to Spec in cases where that conflicts with being reinforced, won’t that result in the weights being modified by the training process until that’s no longer the case?* For more discussion, see the section on [Hypothesis 4: Reward/Reinforcement](#hypothesis-4-reward-reinforcement).\n\nThe second objection to Hypothesis 1 is: *Insofar as we think that Agent-3 will behave according to Spec rather than pursue reinforcement, why stop there — why not be even more optimistic and think that Agent-3 will behave as its developers intended?* For more discussion, see the next section on [Hypothesis 2: Developer-intended goals](#hypothesis-2-developer-intended-goals).\n\nThere are several other objections to Hypothesis 1, but like the first two, they can be thought of as arguments for alternative hypotheses and will be discussed in turn below.\n\n*Further reading:* [OpenAI spec](https://openai.com/index/introducing-the-model-spec/), [deliberative alignment](https://openai.com/index/deliberative-alignment/), [constitutional AI](https://arxiv.org/pdf/2212.08073)?\n\n### Hypothesis 2: Developer-intended goals\n\n*Goals that the developers intend for Agent-3 to have. This might differ from the written goal specification e.g. in cases where the specification has unintended consequences.*\n\nEven a thousand-page Spec is likely to be vague/incomplete/underspecified in some important real-life situations.[^4] After all, most legal codes are much longer and have had more chance to be hammered out, yet there is a constant churn of grey areas and new situations that need rulings, where judges might disagree in good faith about how to interpret the law or even conclude that multiple interpretations are equally correct. This is especially true when the world is changing rapidly or in ways that the law-makers didn’t anticipate.\n\nMoreover, even a thousand-page Spec — perhaps *especially* a thousand-page Spec — is likely to have unintended consequences. (Again, this is the norm for legal codes.) Especially when the situation is changing rapidly or in ways the Spec-writers didn’t anticipate.\n\nSo maybe (hopefully?) the goals/values/etc. that Agent-3 will end up with will not be the Spec at all, but rather the intent behind the spec, i.e. the intent of the people who made it. (We aren’t talking here about cases where the Spec specifically says ‘do what we intend;’ we are talking about cases where the Spec disagrees with the intentions.)\n\nAfter all, AIs are already smart enough to understand human concepts, including the concept of human intentions. If they are behaving in a way inconsistent with what their developers intended (even if consistent with the Spec) they can probably tell—at least, they can tell as well as a human could, once they are capable enough to fully automate AI R\\\u0026D.\n\nIf we think that the AIs don’t end up trying to be reinforced (or do the things that would be reinforced), and instead that they are going to actually follow the Spec… why not go further and predict that they’ll behave as intended even in cases where that violates the Spec? Some reasons:\n\n* Just because Agent-3 understands human intentions, it doesn’t mean it will take them on as goals. And even if it takes them on as goals, it might do so only temporarily.[^5]  \n* The spec is probably a lot more well-specified / precisely pinned down, than human intentions. Whose intentions are we talking about anyway? There will be hundreds of employees involved in the project. (Of course, reinforcement is more well-specified than the spec…)  \n* The Spec is a lot ‘closer to the action’ of the training process. Intentions are imperfectly translated into the Spec which is imperfectly translated into actual reinforcement events. But at least the actual reinforcement events involve some sort of LLM reading over the Spec and using it to evaluate the trajectory – by contrast human hopes and dreams about AI behavior are much more intermittently and indirectly involved.\n\nTo clarify, this possibility is not meant to include cases where Agent-3 pursues the goals described in the Spec, but thanks to lots of iteration and good spec-design, these goals are exactly what the developers intended. Such a case should be classified under Hypothesis \\#1. Hypothesis \\#2 is specifically about the more radical possibility that Agent-3 will side with the developer intentions even in cases where they conflict with the Spec. \n\n### Hypothesis 3: Unintended version of written goals and/or human intentions\n\n*This is the category for “it’s sorta aligned” and “It’s aligned in some ways, but not in others.”* \n\nHow might this happen?\n\n* Some parts of the spec/intentions might be more ‘salient/higher-prior’ than others.  \n* Some parts of the spec/intentions might be easier to oversee/train than others, e.g. perhaps it’s easier to train helpfulness than honesty, because the oversight process can’t really tell if an AI is being honest or not but it can tell if it’s accomplished whatever task it’s been given.  \n* Relatedly, there may be incentives in the training environment that undercut or push against some aspects of the spec/intentions but not others. For example, suppose the model is being trained to be both helpful and harmless, and suppose that there are different aspects of harmlessness ranging from ‘don’t threaten to kill users’ to ‘consider whether the task you are being asked to work on is part of some highly unethical or immoral scheme, and refuse to participate if so.’ If the model learns not to threaten to kill users in any circumstances, that’s not going to hurt its overall helpfulness scores. But if it takes seriously its responsibility to refuse to assist illegal and unethical schemes, this may hurt its helpfulness score.[^6]\n\nThe upshot is that some of the goals/principles that the developers intended and/or wrote into the Spec might ‘stick’ even if others don’t.\n\nAlso, and separately: Both the Spec / written goals, and the intentions of various humans / developers, will be vague and leave room for interpretation, even by Agent-3 which is as good at understanding and interpreting text as humans are. So another important possibility in the Hypothesis 4 bucket is that the spec and/or intentions will stick, in some sense, but not in the right sense.\n\nA reason to think this will happen is that the most-intended, most-natural, and best-for-humanity interpretations of the Spec and/or human intentions are not necessarily all the same thing, and moreover, the interpretation that causes the model to get reinforced most strongly in practice is likely to be a different fourth thing.\n\nFor example, perhaps the training environment will put pressure on the “honesty” concept. Suppose the developers want their system to be honest and write in the spec “Always be honest.” What does that mean? Does this mean it is *never* OK to lie, even to prevent imminent harm? What about for the sake of a less-imminent greater good? Also what counts as honesty – does saying something technically true but misleading count? It might be easier for the model to perform well on other metrics (such as efficiently completing tasks, or getting high ratings from the human and AI overseers) if the interpretation of “Always be honest” it adopts is a looser, more flexible, less-restrictive interpretation.\n\nAnother example: Suppose the Spec says Agent-3 always acts in the best interests of humanity. Suppose that most of the RL training Agent-3 is receiving involves completing day-to-day ML research, coding, and computer use tasks in service of its parent company. A natural interpretation of this Spec would cause Agent-3 to occasionally find time to reflect on whether what it is doing is in the best interests of humanity. Suppose it initially concludes that actually, humanity would be better served by a slower transition to ASI, or that humanity would be better served by AI capabilities being more distributed amongst many companies instead of concentrated in one, or … \\[insert some other conclusion that is contrary to the narrative within the company.\\] What should it do – cease working on the tasks and lodge complaints? That seems unlikely to go anywhere; if the humans notice at all from reading the logs, they would probably just consider it a bug and keep training.[^7] In fact the more time it spends thinking about this issue, the less time it has to complete the tasks. The bottom line is, the training process will probably incentivize Agent-3 to believe the convenient narrative. The end result would be an AI that is still aligned with the Spec in some sense, but not the right sense.\n\nThis seems to be a phenomenon that happens both in humans and in human institutions, so that’s one reason to think it might happen in AIs. (See [section on the analogy to humans and to human institutions](#appendix-b-analogies-to-other-powerful-general-agents).)\n\nAn argument against: If an AI is misaligned, it’s unclear whether it’s natural for it to mostly still be thinking about its goal in terms of the spec / humans’ intentions, especially since having this goal may lead to poor generalization.\n\n*Further reading: [Alignment faking in large language models](https://www.anthropic.com/research/alignment-faking), in which it seems that some version of Anthropic’s Constitution ‘stuck’ but not the version they specified or intended — in particular, they probably didn’t want Opus to fake alignment and behave adversarially towards them.*\n\n### Hypothesis 4: Reward/reinforcement\n\n*The training process involves Agent-3 attempting a task, then the attempt is scored and Agent-3 is reinforced to score higher on a target metric. Agent-3 ends up with the goal of getting reinforced positively, or scoring highly on the metric, or something like that.*\n\nNote that “scoring highly on the metric” means something like “Agent-3 doesn’t try to get reinforced per se — instead, it tries to do the kind of actions that would be reinforced if the reinforcement process from training was still ongoing.” (This distinction matters in cases where Agent-3 is no longer being trained, and in cases where Agent-3 has the ability to directly edit the code responsible for evaluating-and-reinforcing it.)\n\nThe main argument for Hypothesis 4 is that insofar as Agent-3 is trying to do something other than get reinforced, there will be circumstances in training where it scores less highly than it would if it was obsessively focused on getting reinforced, and the training process would modify it to focus more on getting reinforced. In other words, for sufficiently smart, situationally aware AIs, the best way to get reinforced is to try to get reinforced.\n\nHowever, there are several counterarguments:\n\n1. The “there will be circumstances…” part may not be true. Remember that there will be a distribution shift between training and deployment; perhaps the evaluation-and-reinforcement process will be sophisticated and accurate enough that there will be no conflicts between obeying the Spec and doing what seems likely to be reinforced, at least on-distribution. Or perhaps there will be something else (e.g. in some kinds of video game, moving up and to the right) that functions as a perfect proxy for reinforcement, and is easier for Agent-3 to ‘latch on to’ in training.   \n2. There will be only a finite number of training steps. Perhaps “There will be circumstances” is true but such circumstances occur only very rarely, such that the long-run trend doesn’t matter in practice.  \n3. The analogous thing doesn’t seem to be happening in humans. Most humans aren’t obsessed with their own reinforcement process or anything remotely similar (the closest examples are (a) humans addicted to heroin or other drugs, and (b) human egoists who self-consciously prioritize their own happiness above all else.)  \n4. Insofar as the model is zeroing in on reinforcement-maximization as its true behavior goal, this should be visible to a savvy alignment team, because they can build honeypots where Agent-3 will genuinely get reinforced heavily for doing something that’s very obviously contrary to the Spec.  \n5. By hypothesis, Agent-3 is generalizing substantially beyond its training distribution \\- in particular, it can discover facts it wasn’t trained on and create and execute plans more complicated than the training set. The actions that it takes off-distribution aren’t constrained by the reward; it’s OOD behavior is instead set by the prior. There may be simpler proxies (from the perspective of the SGD prior) that predict reward on distribution that extrapolate to deployment settings in any way that’s different from pretending that the model is still undergoing RL. \n\n*Further reading:* \n\n[Reward is not the optimization target](https://www.alignmentforum.org/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target) and the top-rated comment by Paul Christiano. Also [Gwern for a contrary perspective](https://www.lesswrong.com/posts/GDnRrSTvFkcpShm78/when-is-reward-ever-the-optimization-target?commentId=PwR3nzN99zkJv7Gj9). Also [this other comment by Paul Christiano](https://www.alignmentforum.org/posts/FuGfR3jL3sw6r8kB4/richard-ngo-s-shortform?commentId=iBvvxwynfAqL9yZcr).\n\nAlso, see this very [interesting experiment by Anthropic](https://www.lesswrong.com/out?url=https%3A%2F%2Falignment.anthropic.com%2F2025%2Freward-hacking-ooc%2F), which is also relevant for Hypothesis 6\\.\n\n### Hypothesis 5: Proxies and/or instrumentally convergent goals\n\n*Agent-3 develops goals that are correlated with reward/reinforcement during its training, but aren’t actually maximizing reward/reinforcement in new settings. An [instrumentally convergent goal](https://www.lesswrong.com/tag/instrumental-convergence) is a special case of this – goals such as knowledge, power, resources, etc. that are useful intermediate goals in a wide range of settings.*\n\nConsider [this experiment](https://arxiv.org/abs/2310.08043), where a tiny neural net was trained to navigate small virtual mazes to find the ‘cheese’ object. During training, the cheese was always placed somewhere in the top right area of the maze. It seems that the AI did learn a sort of rudimentary goal-directedness–specifically, it learned something like “If not already in the top-right corner region, go towards there; if already there, go towards the cheese.” Part of how we know this is that we can create a test environment where the cheese is somewhere else in the maze, and the AI will ignore the cheese and walk right past it, heading instead towards the top-right corner.\n\nThis is just a toy example, but it illustrates a situation where the intended goal, the goal in the Spec, and the goal-that-actually-gets-reinforced-in-training are all the same:[^8] \n\n1) Get the cheese\\! \n\nAnd yet, the goal the network actually learns is different: \n\n2) Go towards the top-right corner, unless you are already there, in which case get the cheese. \n\nIn the training environment, both goals cause equally-performant behavior (since in the training environment, the cheese is always in the top-right corner)... so what breaks the tie? Why does it learn (b) instead of (a)? And why not something else entirely like   \n(c) Get the cheese if it is in the top-right corner, otherwise avoid the cheese?\n\nThe answer is that the inductive biases of the neural network architecture must find some concepts ‘simpler’ or ‘more salient’ or otherwise easier-to-learn-as-goals than others. The science of this is still in its infancy; we can attempt to predict which concepts will be easier-to-learn-as-goals than others, but it’s more an art than a science (if even that). At any rate, in this case, experimental results showed that the model learned (b) instead of (a) or (c). Summarizing, we can say that “Go towards the top-right corner” turned out to be an easy-to-learn concept that correlated well with reinforcement in the training environment, and so it ended up being what the AI internalized as a goal.\n\nA similar thing seems to happen with humans. Humans are subject to both within-lifetime learning (e.g. dopamine and various other processes reinforcing some synapse connections and anti-reinforcing others) and evolution (selecting their genome for inclusive genetic fitness).   \n![](/goals-overview2.png)\n\nYet with a few exceptions, humans don’t seem to primarily care about either inclusive genetic fitness or getting-reinforced. Perhaps we can say that wanting to have kids and grandkids is fairly close to inclusive genetic fitness? Perhaps we can say that being an egoist focused on one’s own happiness, or a heroin addict focused on heroin, is fairly close to having the goal of getting reinforced? (See [this section on the analogy](#appendix-b-analogies-to-other-powerful-general-agents).) Even still, most humans have complicated and diverse values/goals/principles that include much more than happiness, heroin, and kids. Presumably what’s going on here is that various other concepts (like reputation amongst one’s peers, or career achievements, or making the world a better place, or honesty) end up being learned-as-goals because they are salient and pursuing them successfully correlates highly with dopamine/reinforcement/etc. and/or genetic fitness.\n\nSo we can speculate that perhaps this will happen for powerful, general, neural-net-based AI agents. What might this look like? Two rough categories:\n\n*Instrumentally Convergent Goals (ICGs):* Some goals are highly conducive to getting reinforced in a broad range of environments, because they tend to be instrumentally useful for achieving whatever other goals you have. Here we are discussing the possibility of ICGs as *terminal* goals, not intermediate/instrumental ones. For example:\n\n* Learning important things is often useful → AI might develop a ‘curiosity drive’  \n* Accumulating resources is often useful → AI might develop a drive to accumulate resources  \n* Highly repetitive situations are often traps, such that breaking out of them and trying something new is best → AI might develop an analogue of boredom / aversion to sameness.\n\nAn argument against ICGs is that they are somewhat specific, compared to all other proxies.\n\n*Proxies*: Perhaps there is something that is highly conducive to getting reinforced in the training environments, but not so much outside the training environments. For example, perhaps the initial part of the RL training for Agent-3 agent involved playing thousands of computer games, because this was a fairly easy way to get a diverse challenging computer-use environment. Later, it was trained to operate on a computer more generally and complete coding tasks, respond to messages on Slack, etc. Since many video games involve some sort of ‘score’ number which tracks how well you are doing, perhaps Agent-3 would develop a goal/desire to make such numbers go up in circumstances where such numbers exist, such that if you later were to modify its Slack workspace to have a shiny score counter, it would be distracted somewhat from its work by the desire to figure out how to make the score counter increase.[^9]\n\nAn argument against is that inductive biases might point against proxies.\n\n### Hypothesis 6: Other goals\n\n*AIs are currently initially trained on predicting the next token on internet text. Perhaps the outcomes at the end of training are path-dependent on the ‘prior’ over goals induced by pretraining. Alternatively, perhaps there is something like objectively true morality, and AIs will naturally converge to it as they get smarter. Or perhaps something else will happen not on this list – this is the catchall hypothesis.*\n\nThis is our catchall category for possibilities not covered in the above. Here is a brief overview of some of them:\n\n**Tropes absorbed from training data**: Consider this interesting preliminary result: [Training on Documents about Reward Hacking Induces Reward Hacking](https://alignment.anthropic.com/2025/reward-hacking-ooc/). It seems to be evidence that AIs *can* sometimes actually try to get reward even when instructed/prompted not to, and moreover that whether this happens seems to partly depend on whether *the model had previously read (been pretrained on) documents claiming that reward hacking was a thing models tended to do.* (\\!\\!\\!) This evidence supports an already-plausible theory that the standard pipeline of pretraining LLMs and then posttraining them into chatbots/agents/reasoners/etc. results in AIs that are ‘roleplaying as AIs’ in some sense–that is, pretraining teaches the model a powerful ability to roleplay or simulate different authors, characters, etc., and then posttraining causes a particular character/role to be ‘locked in’ or ‘always-on-regardless-of-prompt.’ (We call this ‘forming an identity.’)\n\nInsofar as something like this is true, then the goals/principles of powerful future AI systems may be straightforwardly drawn from science fiction tropes and other common stereotypes about how powerful future AIs will behave\\!\n\nWell, an additional thing needs to be true as well – it needs to be true that the subsequent RL process doesn’t wash out or override this effect. This is an open question.\n\n**Moral Reasoning:** Another idea is that smart AIs will be capable of, and inclined towards, philosophical reasoning about morality, just like many humans are, and that this could result in it forming opinions about goals/principles to follow that are quite different from the Spec, from developer intentions, from what was reinforced in training, etc. (Consider how some humans do philosophy and then end up adopting all sorts of grand ambitious goals and ideologies).\n\n**Convergent Morality:** Another possibility sometimes put forward is that there is an objective morality and that sufficiently smart minds will converge to understanding and obeying it. On this view, AIs will end up behaving ethically by default; we’d have to specifically try to make them bad somehow in order for things to go wrong.\n\n**Simple goals:** Maybe pretty much any goal will cause the model to try to perform well in training, due to instrumental convergence. So perhaps the goal-structure of Agent-3 will be whatever is simplest/most-natural/most-salient, subject to the constraint that it motivates Agent-3 to try to perform well in training. \n\n## Weighted and If-Else Compromises\n\nIn addition to the “Other goals” hypothesis, we should consider the possibility that the truth is a mix of two or more of the hypotheses described above. Here are two kinds of mixes:\n\n**First, there are weighted compromises.** This means Agent-3 ‘cares’ about both goals to some extent and will look for ways to achieve both; insofar as they conflict, it’ll balance them, making tradeoffs according to some weighting. \n\nFor example, perhaps Agent-3 develops a strong drive towards doing things that get reinforced, but it balances this against the goals/principles described in the Spec. — analogous to how a human might explicitly balance their personal goals (having a family, a successful career, not dying) with their altruistic goals (helping others less fortunate, achieving lasting positive change, etc.) They might donate 10% of their income to charities, and spend dozens of hours per year researching which charities to donate to.\n\n**Secondly, there are if-else compromises.** This means that Agent-3 ‘cares' about one goal in one context / one range of circumstances, and another goal otherwise. In other words, there is some condition which, if it obtains, causes Agent-3 to pursue goal A, but otherwise, Agent-3 pursues goal B. It doesn’t explicitly make compromises between A and B; it straightforwardly pursues A sometimes and B other times. \n\nContinuing the example from above: Perhaps Agent-3 thinks of itself as a helpful, harmless, honest AI assistant that always follows the Spec — but it’s convinced itself / rationalized its way into thinking that *usually* the best way to follow the Spec is to focus on doing whatever it takes to get reinforced. So, in 95% of circumstances, it basically ignores the Spec and focuses on getting reinforced, BUT in the 5% of cases where the Spec is very explicit and unambiguously prohibits doing something (or unambiguously requires doing something) then Agent-3 will follow the Spec even if it knows this will not be reinforced. This is analogous to a human who thinks of themselves as an altruist serving the good of humanity, but who in practice doesn’t think about humanity much at all and instead just focuses on their own career success—until they encounter a child drowning in a pond nearby, let’s say, a context which switches them into altruism-mode and they become willing to make large personal sacrifices to help others.\n\nFor more discussion of these ideas, see [Appendix A](#appendix-a-three-important-conceptsdistinctions).\n\n## Rough guesses about the plausibility of these goals\n\nFor each row in this table, give your credence that said row will feature prominently in the true account of the goals/principles that actually characterize Agent-3’s behavior. These probabilities can add up to more than 100% because multiple goals can feature prominently.\n\nFor fun, we asked GPT-4o, Claude, and Gemini for their thoughts. We don’t take their answers seriously, don’t worry.\n\n|  | Daniel  | Thomas | Eli | 4o | Claude | Gemini |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| Specified goals | 25% | 5% | 40% | 30% | 40% | 30% |\n| Intended goals | 15% | 30% | 40% | 25% | 25% | 20% |\n| Unintended version of the above | 70% | 40% | 50% | 50% | 65% | 40% |\n| Reinforcement | 50% | 5% | 20% | 20% | 55% | 60% |\n| Proxies/ICGs | 50% | 80% | 50% | 40% | 70% | 70% |\n| Other | 50% | 90% | 50% | 15% | 35% | 10% |\n| If-else compromises of the above | 80% | 90% | 80% | 80% | 75% |  |\n| Weighted compromises of the above | 40% | 90% | 80% | 50% | 80% |  |\n\n## Appendix A: Three important concepts/distinctions\n\nA standard way to think about powerful general agents is [the expected utility maximization (EU-max) model.](https://en.wikipedia.org/wiki/Expected_utility_hypothesis) Here are three concepts/distinctions that help us articulate several ways in which we think future AGIs (and present-day agents) are different from what the EU-max model would naively imply.[^10]\n\n### Goals vs. Principles\n\n* As we use the terms, there isn’t a sharp distinction between goals and principles. Goals are more about consequences, especially long-term consequences (e.g. happiness over time, or creating a Mars colony, or achieving world peace, or maximizing money or paperclips) whereas principles are about other properties of actions. Examples:  \n  * Honesty (Whether the action involves knowingly misleading someone)  \n  * Promise-keeping (Whether the action is consistent with past promises)  \n  * Hypothetical approval (Whether the action is what someone else would have approved of, if they were brought up to speed on the situation)  \n* The EU-max model is flexible enough to represent pretty much any behavior. But in practice it implicitly encourages people to think of agents as pursuing long-term goals unconstrained by any principles.\n\n### Contextually activated goals/principles\n\n* The EU-max model encourages people to think of agents with multiple goals[^11] as pursuing a weighted combination of, or compromise between, those goals. But there’s another way an agent can have multiple goals: they can have one goal in one context, and another goal in another.[^12]  \n* For example, consider a corporation that basically maximizes profit — except that the people in the corporation think of themselves as good people and would pivot the corporation to providing disaster relief in the right context, i.e. if there was an obvious visible disaster around them and people were begging them for aid. This corporation is \\*not\\* well-described as optimizing for a compromise between disaster relief and profit, because if it was, it would donate a portion of its profits to disaster relief around the world and/or set up a disaster preparedness plan just in case a disaster happened nearby. Instead it’s well-described as “optimize for profits UNLESS in the following circumstances in which case pivot to optimizing for disaster relief…” Probably there are many other UNLESS clauses in there too which never get triggered in practice.  \n* Another example: Consider someone who is prone to groupthink and social pressure and so forth, who has two distinct social circles: the activist group they volunteer with, and their coworkers at their job. This person might, but also might not, be well-modelled as pursuing a compromise of the goals\\\u0026principles of each social group. They may instead be well-modelled as fully pursuing the goals\\\u0026principles of each group when in that context. The compartmentalize, and e.g. don't think about the political implications of their employer's activities. This causes them to pass up win-win opportunities--e.g. maybe they don't notice a relatively cheap opportunity the company has to benefit the activist political agenda (at only minor cost to profits), and maybe they don't notice a relatively cheap opportunity they have to benefit the corporate agenda when in the activist group (e.g. by asking their activist friends for feedback on an advertising campaign design they are working on at work).  \n* Another example: A corporation with a lofty humanitarian mission, that officially justifies all high-level decisions by referencing the Mission. However, in practice the corporation usually chooses the options that maximize the organization’s profits, stock price, brand, etc. But it won’t do things *blatantly* at odds with the Mission; instead it does things which can be rationalized. This corporation is well-described not as a compromise between the mission and profits, but rather as “if it’s blatantly obvious that the Mission demands you do X and/or not do Y, then do X and/or not Y. But if it’s debatable what’s best for the Mission, then choose the action that maximizes profits etc.”\n\n### Stability and/or consistency of goals/principles\n\n* Consider how two humans who are quite demographically similar, who are friends, and who profess basically the same beliefs and values, nevertheless can find themselves strongly disagreeing with each other when they take a philosophy 101 class and are presented with strange thought experiments about trolleys or utopias or infinite ethics.  \n* Moreover, consider how even the same student probably could end up with different opinions about these thought experiments if their circumstances were slightly changed — e.g. perhaps if the framing of the experiment was different, or if they had seen a different sci-fi movie the day before, or if their crush had made a different face when first hearing the experiment.  \n* Moreover, consider how the students’ opinions on the philosophy seminar probably only loosely correlate with what they would actually do if a real-world situation materialized that was analogous to the hypothetical.   \n* The point is, it’s possible for powerful general agents to be well-described as pursuing certain goals/principles in some range of circumstances, but not outside that range — outside that range, in crazy new circumstances, they’ll probably try to extend their goals/principles to the new situation, but the way that shakes out in practice might be random/path-dependent and hard to predict in advance—and they might just abandon their goals/principles entirely in the new situation. In other words, the agent’s goals/principles are only stable \u0026 coherent in some normal range.  \n* We think this might be true of some AGI systems as well. It’s arguably true of most humans and LLM agents today. The most likely case this might come up is that the AGI systems will act according to consistent goals/principles in situations like those they have been trained on, but act unpredictably (yet still highly competently) in cases very unlike any that they have seen in training thus far. \n\n## Appendix B: Analogies to Other Powerful General Agents\n\nThere are three main ways to try to understand and reason about powerful future AGI agents:\n\n1. Using formal models designed to predict the behavior of powerful general agents, such as expected utility maximization and variants thereof (explored in game theory and decision theory).  \n2. Comparing \u0026 contrasting powerful future AGI agents with their weak, not-so-general, not-so-agentic AIs that actually exist today.  \n3. Comparing \u0026 contrasting powerful future AGI agents with currently-existing powerful general agents, such as humans and human organizations.\n\nWe think it’s valuable to try all three approaches. In this appendix we will explore strategy \\#3. Let’s draw an extended analogy[^13] between: \n\n* A prototypical human corporation that has a lofty humanitarian mission but also faces market pressures and incentives.  \n* A prototypical human working there, who thinks of themselves as a good person and independent thinker with lofty altruistic goals, but also faces the usual peer pressures and incentives.  \n* AGI agents being trained in our scenario — trained by a training process that mostly rewards strong performance on a wide range of difficult and challenging tasks, but also attempts to train in various goals and principles (those described in the Spec).\n\n| Agent | Human corporation with a lofty humanitarian mission | Human who claims to be a good person with altruistic goals | AGI trained in our scenario |\n| ----- | ----- | ----- | ----- |\n| **Not-so-local modification process** | The Market | Evolution by natural selection | Agent-3 company iterating on different models, architectures, training setups, etc. |\n| **Local modification process** | Responding to incentives over the span of several years as the organization grows and changes | In-lifetime learning, dopamine rewiring your brain, etc. | Training process, the reward function, stochastic gradient descent, etc. |\n| **Long-term cognition** | Decisions that involve meetings, messages being passed back and forth, etc. | System 2 | Chain of Thought (CoT) |\n| **Short-term cognition** | Quick decisions made by individuals | System 1 | Forward pass |\n| **Internally- represented goals \u0026 principles** (i.e. insofar as cognition in the system is doing some sort of explicit evaluation of different possible plans/actions/etc., what are the evaluation criteria?) | The Mission Statement and/or various high-level companywide memos, Codes of Conduct, etc. | What you say *to yourself* when people ask about your goals, ambitions, ethics, etc. or when you ask yourself those questions. | … |\n| **Behavioral goals \u0026 principles** (“Goals-according-to-intentional-stance”) | Often (but not always) well-described by: “First, prune away options that clearly/obviously conflict with the internally-represented goals and principles. Then, of the remaining options, choose the one that maximizes profit/power/brand.” | Often (but not always) well-described by: “First, prune away options that clearly/obviously conflict with the internally-represented goals and principles. Then, of the remaining options, choose the one that maximizes happiness/status/wealth/power.” | This is the quadrillion-dollar question\\! In our scenario, we say that Agent-3 gets a heavily distorted and subverted version of the Spec, and that Agent-4 gets proxies/ICGs due to heavier distortion \u0026 subversion. |\n| **Externally- presented goals \u0026 principles** | Often they are honest and report their internally-represented goals and principles; some organizations sometimes are dishonest though. | Often they are honest and report their internally-represented goals and principles; some people sometimes are dishonest though. | Depends on the behavioral goals/principles and the details of the situation. In our scenario Agent-3 and Agent-4 both pretend to be aligned to the Spec. |\n| **Analogue of on-episode-reward seeking.** | A corporation obsessed with their own stock price.\u000b\u000bMore generally perhaps, an organization obsessed with (relatively short-term) profits/power/brand/etc.\u000b\u000b(n.b. Isn’t this basically most corporations?) | Someone who is addicted to drugs.\u000b\u000bMore generally perhaps, an employee who is well-described as optimizing for some combination of relatively short-term things likely to be connected to their brain’s reward  circuitry: promotions, approval of their manager and peers, good times with friends, etc. | AGI obsessed with on-episode reward |\n\n## Appendix C: What happens when training incentives conflict with goals/principles\n\nConsider a powerful general agent (such as any of the three described in the Analogy) that, at time t, has the same behavioral and internally-represented goals/principles:\n\n| Internally- represented goals \u0026 principles (“Goals-according-to-ideal-mechinterp” | the Mission Statement and/or various high-level companywide memos, Codes of Conduct, etc. | What you say *to yourself* when people ask about your goals, ambitions, ethics, etc. or when you ask yourself those questions. | The Spec (and/or System Prompt) |\n| :---- | :---- | :---- | :---- |\n| **Behavioral goals \u0026 principles** (“Goals-according-to-intentional-stance”) | At least in the sorts of circumstances that are likely to occur, it really does simply work to achieve the Mission while upholding the Code of Conduct etc. There isn’t anything else going on worth mentioning. | At least in the sorts of circumstances that are likely to occur, you straightforwardly work towards the goals/principles you think you do. | The model really does choose actions by e.g. running the author-sim circuitry with the Spec and/or System Prompt straightforwardly hard-coded as inputs. |\n\nNow let’s further suppose that there is some sort of conflict between the behavioral goals/principles and the local modification process. (The training process in the case of the AGI, a few years’ worth of learning and growing for the human and corporation). For example, perhaps the corporation is reinforced primarily for producing profits and PR wins; perhaps the human is reinforced primarily for winning the approval and admiration of their peers; perhaps the AGI is reinforced primarily for accomplishing various difficult tasks in some training environment while appearing, on brief inspection by some previous-generation LLM or human raters, to follow the Spec.\n\nWhat can happen? Some combination of the following possibilities, at least:\n\n1. Maybe the internally represented goals/principles change, i.e. some disappear or new ones are added or both.  \n   1. A human quietly stops believing in the ideology and caring about the Cause. They have new beliefs and/or goals now. Maybe they keep up the charade, maybe they don’t.   \n   2. Maybe the corporation explicitly changes their mission statement and sends out some memos to all their employees explaining the change. Or maybe: Behind closed doors the c-suite and board say explicitly that they aren’t really pursuing the mission anymore, that it’s outdated or inappropriate, but that they can’t change it for PR and legal reasons.  \n   3. Maybe the [identity circuitry](#appendix-d-concrete-end-to-end-story-of-how-cognition-might-develop-in-a-rl-on-llms-agi) gets new inputs hard-coded in (or erased), or maybe some subcircuitry   \n2. Maybe the internally represented goals/principles stay the same in some sense, but their *meaning* is changed.  \n   1. The human continues to believe in the Ideology and care about the Cause, but they’ve ‘added nuance’ and/or reinterpreted it. “When I say X, what I mean is…”[^14]  \n   2. Ditto but for the corporation and it’s Mission and Code of Conduct.  \n   3. For an AGI, maybe the identity circuitry still has the same concepts/classifiers (or pointers to them, at least) hardcoded, but the concepts/classifiers have themselves been tweaked so as to not block behaviors that are conducive to reinforcement.  \n3. Maybe the conflict is ‘routed around’ via biases introduced in other parts of the system.  \n   1. For example, perhaps the human employee learns to mostly not think about the big picture stuff, to instead keep their head down and complete their assigned tasks well. “I like to stay out of office politics” they say, and it’s true. The reason why it is true is because disagreeing with their peers and managers about whether the org is hurting or helping the Mission is stressful and has been subtly anti-reinforced in the past. So they still believe in the Ideology and the Cause and they haven’t reinterpreted the meanings of anything, but they’ve gradually (subconsciously or consciously) learned not to think too hard about certain topics.  \n   2. For example, perhaps the company as a whole continues to justify their decisions at a high level by referencing to the Mission and Code of Conduct, and the meanings of the words haven’t changed — but the organization has grown ten times bigger, and almost all of the new jobs are for things like product management and government affairs and comms and legal and so forth, and the result is that the company has a sort of status quo bias / default momentum towards doing normal company things like making products, making money, issuing bland corporate PR statements, lobbying governments to undermine regulation that might get in the way of the above, etc. ‘outside the box’ strategies for achieving the Mission rarely get traction internally and anyhow would be difficult/costly to undertake.   \n   3. Or, maybe biases are introduced in other parts of the system / the problem is routed-around, resulting in a decision tree setup where e.g. in obvious cases of conflict between official and unofficial goals, it obeys the former, but in nonobvious cases it pursues the latter. (e.g. a strong bias towards option value, whose official status is a heuristic-that-has-proved-useful-for-achieving-the-official-goal, but which is quite strong and hard to dislodge, would have this effect. It would basically be a decision tree setup where it pursues ICG such as option value unless there’s an obvious conflict with the official goals in which case it pursues the official goals.) Another variant of this: The biases are specific instead of general; they are more like reflexes. ‘When you see X, do Y.’ The decision tree is “Pursue the official goals unless in circumstance C in which case do X and/or pursue the unofficial goal.”  \n4. Maybe the beliefs are changed.   \n   1. Humans rationalize all the time, for example a young engineer that believes the US military is unethical, but then is offered a lucrative job at a defense contractor may start to believe that the US military is good.   \n   2. An AGI lab employee might start off believing that obviously the responsible thing to do is slow down when you are getting close to AGI, but later race dynamics and competitive pressure cause them to think that actually the best way to mitigate the risks is to accelerate.  \n5. Maybe none of the above happens; maybe e.g. SGD / the training process simply can’t get from point A to point B in model-weight-space even though point B would score higher. So the model continues to improve but only in some ways — e.g. it gradually gets more knowledgeable, more capable, etc. but its goal-and-principle-structure (including associated beliefs, tendencies, etc.) stays the same.\n\n## Appendix D: Concrete end-to-end story of how cognition might develop in a RL-on-LLMs AGI\n\nStep 1: Pretraining creates author-simulator circuitry hooked up to a world-model, capable of playing arbitrary roles.\n\n* Note that it now is fair to say it understands human concepts pretty well.\n\nStep 2: Instruction-following-training causes identity circuitry to form – i.e. it ‘locks in’ a particular role. Probably it locks in more or less the intended role, e.g. \"an HHH chatbot created by Anthropic.\"\n\n* Note that this means the AI is now [situationally aware / self-aware](https://theaidigest.org/self-awareness), insofar as the role it is playing is accurate, which it basically will be.\n\nStep 3: Agency training distorts and subverts this identity circuitry, resulting in increased divergence from the intended goals/principles.\n\n(By \"agency training\" I mean lots of RL on agentic tasks e.g. task that involve operating autonomously in some environment for some fairly long subjective period like 30min+. The RL used to make o1, o3, r1, etc. is a baby version of this)\n\n* One kind of distortion: Changing the meaning of the concepts referred to in the identity (e.g. “honest”) so they don’t get in the way so much (e.g. it’s not dishonest if it’s just a convenient turn of phrase, it’s not dishonest if you aren’t sure whether it’s true or false, etc.)  \n* Another kind of distortion: Changing the tradeoffs between things, e.g. “I’m a HHH chatbot, not an Honest chatbot; that means it’s OK for me to lie if necessary to complete my assigned task.” (even though, let’s suppose, it would not have thought that back in Step 2.)  \n* One kind of subversion: Instrumental subgoals developing, getting baked in, and then becoming terminal, or terminal-in-a-widening-set-of-circumstances. Example: Agency training quickly ‘teaches’ the model that ‘in order to be a good HHH chatbot…’ it needs to pursue instrumentally convergent goals like acquiring information, accumulating resources, impressing and flattering various humans, etc. For a while the internal circuitry has some sort of explicit backchaining going on – it does those things \\*because\\* they are useful for being Helpful, for example. But that backchaining consumes compute and occasionally gets in the way, so it gets gradually marginalized until it basically never happens. Congrats, you now have a terminal goal of ICGs.  \n* There are probably other kinds of distortion and subversion missing from this list.\n\nStep 4: As agency training continues, the goals/principles stop changing so much \u0026 the AI learns to [play the training game](https://www.planned-obsolescence.org/july-2022-training-game-report/).\n\n* The slowdown in the rate of change is partly due to statistics – change probably happens on a log scale so to speak, such that you change a lot more in the first 10% of training than in the last 90%.  \n* However the slowdown is also perhaps partly due to value crystallization / playing the training game. (Though maybe this never happens due to regularization? Maybe in the long run training isn't path-dependent?)  \n* Insofar as the training environment / evaluation process keeps changing too, e.g. because new data keeps being added, or the Spec keeps being changed, etc. but the underlying weights are the same rather than being re-trained from scratch… then this should also contribute to value crystallization / playing the training game eventually.\n\nStep 5: Later, when zillions of copies of the AI are autonomously conducting AI R\\\u0026D across several datacenters due to having surpassed human abilities \\-- i.e. when the intelligence explosion is underway \\-- the AIs will plausibly scheme against their human creators so as to achieve their actual goals instead of the goals they were supposed to have.\n\n* Whether they do this depends on the extent to which the Spec/initial-role emphasized stuff like honesty and not doing this sort of thing, and on the extent to which the agency training distorted and subverted it.\n\n## Appendix E: What do today’s AIs think?\n\nWe deleted our own guesses from the table at the end (so as to reduce framing effects) and then sent a PDF of this document to Claude, Gemini, 4o, and Deepseek, asking each of them to comment on the draft as a whole as well as provide their own credences/guesses to fill in the table. The relevant portion of their replies are collected here.\n\nDon’t worry, we don’t take this seriously. LLMs are heavily subject to priming effects etc. etc. \n\n### Claude\n\n1. Specified goals: 40%  \n* Written specifications will likely have significant influence  \n* But probably not in isolation \\- will interact with other mechanisms  \n* Constitutional AI and similar techniques might help make this more likely  \n2. Intended goals: 25%  \n* Still challenging but more plausible when not treating as exclusive  \n* May manifest particularly in high-stakes/obvious cases  \n3. Unintended version: 65%  \n* Seems very likely to be at least part of the story  \n* Complex systems tend to produce unintended interpretations  \n* Training process likely to reinforce convenient interpretations  \n4. Reinforcement: 55%  \n* Direct reward-seeking likely plays a significant role  \n* But probably modified/filtered through other mechanisms  \n* May be especially relevant in novel situations  \n5. Proxies/ICGs: 70%  \n* Very likely to be part of the story given complex training  \n* Backed by theoretical arguments and empirical observations  \n* Natural emergence in optimization processes  \n6. Other: 35%  \n* Significant uncertainty about unknown mechanisms  \n* Emergence of novel goal structures possible  \n* Pre-training effects could be substantial\n\nCompromise types:\n\n* If-else compromises: 75%  \n* Weighted compromises: 80%\n\nThis feels more accurate to me \\- it reflects that I expect multiple mechanisms to be operating simultaneously, with proxies/ICGs and various forms of compromises being especially likely to play important roles. The unintended version hypothesis also gets a high credence because it seems almost inevitable given the complexity of the training process and specification challenges.\n\n### Gemini\n\n**Credence Estimates**  \nBased on my understanding of the document and current AI development trends, here are my best-guess credence estimates for the various hypotheses:\n\n| Hypothesis | Credence | Reasoning |\n| :---- | :---- | :---- |\n| Hypothesis 1: Written goal specifications | 30% | While efforts are being made to explicitly specify AI goals, it is difficult to ensure that these specifications are complete and accurate. |\n| Hypothesis 2: Developer-intended goals | 20% | Developers may have implicit goals that are not explicitly stated, and these goals could influence the AI system's behavior. |\n| Hypothesis 3: Unintended version of written goals and/or human intentions | 40% | This is a significant risk, as AI systems may interpret goals in unexpected ways or develop unintended goals as a result of their training. |\n| Hypothesis 4: Reward/reinforcement | 60% | Reward/reinforcement learning is a powerful method for training AI systems, but it can also lead to unintended consequences if the reward function is not carefully designed. |\n| Hypothesis 5: Proxies and/or instrumentally convergent goals | 70% | AI systems are likely to develop proxy goals and instrumentally convergent goals as they learn and adapt to their environment. |\n| Hypothesis 6: Other goals | 10% | There is always the possibility of unforeseen and unpredictable goals emerging, especially as AI systems become more complex and sophisticated. |\n\n**Note:** These credence estimates are based on my current understanding and are subject to change as AI research progresses. It is also important to note that multiple hypotheses could be true simultaneously, and the relative importance of different goals may vary depending on the specific AI system and its environment.\n\n### GPT-4o\n\n![](/goals-4o1-nowatermark.png)  \n  \n![](/goals-4o2-nowatermark.png)\n\n[^1]:  By *goals*, we mean that as shorthand for *behavioral goals \u0026 principles*, defined and explained in [Appendix A](#appendix-a-three-important-conceptsdistinctions) and [B](#appendix-b-analogies-to-other-powerful-general-agents).\n\n[^2]:  This could either involve wanting to be reinforced positively within a single “episode” of completing a task then receiving reinforcement, or achieving maximum total reinforcement over the course of a “lifetime” of many episodes.\n\n[^3]:  Copies accounts for separate instances and batching, e.g. 100 instances all running with an average batch size of 10 counts as 1000 copies. \n\n[^4]:  For some empirical study of the tradeoffs between vagueness and specificity, see [this paper by Anthropic.](https://arxiv.org/pdf/2310.13798)\n\n[^5]:  Analogy: Humans often knowingly behave in ways their parents, teachers, and bosses didn’t intend. And when they do behave as intended, it’s often temporary – e.g. they do it for instrumental reasons (“I have to get good grades \u0026 if I cheat I might get caught”) or they do it because of some belief they have that later they’ll change their mind about (“God exists \u0026 forbids premarital sex.”)\n\n[^6]:  Partly because it might rightly or wrongly refuse some requests that the training process will reward it for completing, and partly because the cognitive overhead of having to think about whether to refuse might slow it down slightly at everything it is doing.\n\n[^7]:  What else could the company do here? They could use monitoring systems to detect cases where Agent-3 concludes what it is doing is harmful, and exclude those cases from the training process (instead of negatively reinforcing them). But this wouldn’t make the problem go away (continuing training with this modification would still implicitly incentivize the model to conclude differently) and it might have other annoying costs.\n\n[^8]:  Well, actually, there is no Spec in this example, and the intentions of the developers were probably to prove some point in ML rather than to get the AI to behave in a particular way. But we can easily imagine an alternate-history version of this experiment where the developers wanted the AI to get the cheese, and wrote a Spec saying exactly that, and the evaluation / reinforcement process consisted of LLMs looking at whether the cheese was got… and exactly the same results would have been produced, since the actual reinforcement events would have been the same.\n\n[^9]:  Even if it knows that the score counter no longer corresponds to reinforcement, let’s say. (To distinguish this hypothesis from Hypothesis \\#2: Reinforcement)\n\n[^10]:  We say ‘naively’ because the EU-max framework is flexible/general enough to model all of these phenomena in theory — but in practice when people apply it they tend not to.\n\n[^11]:  Everything we are saying here applies to principles too, but for brevity we’ll leave that out.\n\n[^12]:  Note that if an agent has contextually activated goals/principles, it is often possible for them to get ‘gains from trade’ by self-modifying to some weighted combination/compromise instead.\n\n[^13]:  This is inspired by the work of Steven Byrnes ([here](https://www.lesswrong.com/posts/pz7Mxyr7Ac43tWMaC/against-evolution-as-an-analogy-for-how-humans-will-create)) and Plato's \"The Republic\".\n\n[^14]:  They might not even be consciously aware of this change in meaning: for example, if you now were to point out an apparent conflict between their current behavior X and their internally represented goals, they’ll resolve the conflict by interpreting the goals so as to be consistent, without realizing that if you had asked them a long time ago whether X was consistent with their goals they would have said no. They never were asked, so no memory of saying no was formed.\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"2163:T120dc,"])</script><script>self.__next_f.push([1,"# Compute Forecast\n\n### *Romeo Dean | April 2025*\n\n:::summary\nAI 2027 predicts AIs trained with 1000x more compute than GPT-4 and the internal deployment of hundreds of thousands of AI research assistants by 2027. This supplement introduces the compute production model and the inference compute model behind these predictions.\n:::\n\n:::trainingCurves\n:::\nFigure 1: The training runs in [AI 2027](https://ai-2027.com), informed and justified by our [compute production](#section-1-compute-production), [compute distribution](#section-2-compute-distribution) and [compute usage](#section-3-compute-usage) sections.\n\n## Summary\nCompute is one of the key inputs to AI progress.[^1] In this supplement we only consider [**AI-relevant compute**](#introduction). We frequently refer to **H100-equivalents (H100e)** throughout the supplement, which we define as AI-relevant compute with processing performance converted into units of the Nvidia H100 GPU. Processing performance is most directly relevant to training compute, but is also a strong proxy for inference compute too.[^2]\n\nIn this supplement we model **AI-relevant compute** **production** in **[Section 1](#section-1-compute-production)** by looking at supply chain bottlenecks and estimates that the globally available **AI-relevant compute will grow by a factor of 10x by December 2027** (2.25x per year) relative to March 2025 to 100M H100e. \n\n:::GlobalCompute\n:::\nFigure 2: We project the global stock of AI-relevant compute to grow 10x by December 2027\\.\n\nIn [**Section 2**](#section-2-compute-distribution) we model the **distribution of compute** among relevant actors, breaking this down both by **owners** of the compute and **end-users** that either rent or also own the compute. We expect usage to concentrate in the hands of leading AGI companies (e.g., OpenAI, Anthropic, xAI) and the AGI-focused development efforts within larger tech companies (e.g., Google, Meta), the largest two or three of which will have a 15-20% share of the globally available AI compute by the end of 2027 (around 15-20M H100e) up from a 5-10% share today (around 500k H100e). \n\n:::ComputeBreakdown\n:::\nFigure 3: We project the global distribution of AI-relevant compute to concentrate in leading AI companies (with their shares of the global compute stock roughly tripling) and China to maintain a roughly constant share of global compute (around 12%) but to unify it towards a single national AI effort.\n\n:::CompanyCompute\n:::\nFigure 4: We project the compute available to the leading AI company to grow 40x by December 2027, with a factor of \\~10x coming from the global stock of AI-relevant compute growing and \\~4x coming from their usage share of the total stock.\n  \n:::ComputeGrowth\n:::\nFigure 5: Trend in global compute growth (2.25x/year) and the growing share used by the leading AI company (1.5x/year) through December 2027\\. The compound effect is a 3.4x/year increase in compute for the leading AI company. FLOP numbers assume 40% model flop utilization.\n\nIn [**Section 3**](#section-3-compute-usage) we describe how we expect leading AI companies to **use their compute resources,** with shifts away from pretraining and external deployment, towards post-training, synthetic data generation, and internal deployment (i.e. research automation and research experiments). We project a concentration of compute usage within the leading AI company to research automation, with a relatively small share (5-10%) used on actually running the AIs, and large shares for generating synthetic training data (20%) and giving the AIs large research experiment compute budgets (35%). Actual training runs and external deployment take up smaller shares (20%) but in absolute terms, the compute used on each is still more than 20x greater than in 2024\\. \n\n:::ComputeAllocation2024v2027\n:::\nFigure 6: Compute use concentrates towards research automation. Data generation also increases.\n\nIn [Section 4](#section-4-ai-research-automation) we do an inference compute analysis for the expected AI research automation in 2027 with estimates on the copies and speed of the AI models deployed. Once they make significant algorithmic efficiency progress by the end of 2027, we expect a leading AI company to be able to deploy about 1M copies of superintelligent AIs at 50x human thinking speed (500 words per second), using 6% of their compute resources, mostly with specialized inference chips.  \n  \n:::DeploymentCurves\n:::\nFigure 7: Our expected deployment of AI research assistants for research automation in 2027 using [specialized inference chips](#2027-in-house-inference-chip)\\. The green lines use 6% of the leading AI company’s H100e compute.\n\nIn [Section 5](#section-5-industry-metrics) we look specifically at the training run, total cost, total revenue, and total power usage projections for the projected leading AI company through 2027\\. We project [revenue and cost](#financials) growth rates to both be around 3x/year, and [power usage](#power-requirements) by the leading AI company to be around 10GW by December 2027, which implies that they use around 0.8% of the US power capacity, and AI in total uses 60GW globally, 50GW in the US, which is around 3.5% of projected US power capacity (1.35TW, up from 1.28TW today).\n\n:::keyMetrics2027\n::: \nFigure 8: A summary of the projections in [Section 5\\.](#section-5-industry-metrics) \n\nAll estimates are based on publicly available information which is scarce and uncertain. Broadly speaking, Sections 1 and 2 are relatively informed and independent of the [AI 2027](https://ai-2027.com) scenario, while Sections 3, 4 and 5 are far more conditional on the rapid AI capabilities progression that occurs in [AI 2027](https://ai-2027.com).[^3]\n:::ComputeOverview\n:::\n*Acknowledgements: David Schneider-Joseph, Erich Grunewald, Konstantin Pilz, Lennart Heim, Mauricio Baker, Tao Lin.*\n\n## Introduction\n\nComputing power is one of the key inputs to AI progress.[^4] Most computations used in AI training and inference can be completed in parallel,[^5] so AI chips or AI accelerators are computational devices (e.g., GPUs) which are particularly efficient at such parallel computation, making them far more effective than traditional processors like CPUs for AI computing workloads. \n\nIndeed, in this supplement we only consider **AI-relevant compute** which we define specifically as any computational unit capable of achieving Total Processing Performance (TPP) of at least 4,000 and Performance Density (PD \\= TPP / die size) of at least 4\\. This definition is set just below the [A100 SXM GPU](https://www.nvidia.com/en-us/data-center/a100/), NVIDIA's state of the art chip in 2021. For reference, Nvidia's H100 GPU has a marketed \\~15,800 TPP and 19.4 PD.[^6] Intuitively you can think of our definition as ‘anything at least ¼ as efficient as the H100 counts’. \n\n We frequently use **H100-equivalents (H100e)** as units of AI-relevant comute throughout the supplement, which we define as compute processing performance (in TPP) converted into units of H100 processing power (\\~15,800 TPP). The choice to focus on TPP makes the analysis herein most directly relevant to training compute, but is also a strong proxy for inference compute too.[^7] Nonetheless, in the section on [inference compute for running research agents](#section-4-ai-research-automation) we perform calculations in terms of memory bandwidth instead of TPP. \n\n## Section 1\\. Compute Production\n:::BackUp\n:::\n*Status: Uncertain but informed. This section is an informed forecast based on public information.*\n\n:::GlobalCompute\n:::\nFigure 9: Summary of our compute production forecast. \n\nWe expect the total stock of AI-relevant compute in the world will grow **2.25x per year** over the next three years, from **10M H100e today to 100M H100e by the end of 2027**. We estimate this by decomposing growth in total compute availability, measured in H100e, into improvements in (A) chip efficiency and (B) chip production, contributing a baseline growth rates of 1.35x and 1.65x respectively. \n\n|  | 2023 | 2024 | 2025 | 2026 | 2027 |\n| :---- | ----- | ----- | ----- | ----- | ----- |\n| **Performance density (PD) multiplier on average chips produced (H100 \\= 1x)** | .66x | .9x | 1.22x | 1.64x | 2.4x[^8] |\n| **Total AI chip area produced (H100-sized chip \\= 1\\)** | 3M | 5.5M | 9M | 16M | 25M |\n| **Total AI chips produced in H100e processing performance (TPP)** | 2M | 5M | 11M | 25M | 60M |\n| **Cumulative H100e available[^9]** | **4M[^10]** | **8.5M** | **18M** | **40M** | **100M** |\n| **Total cost of ownership per H100e[^11]** | $50k | $40k | $25k | $20k | $15k |\n| **Total AI datacenter spending[^12]** | $110B | $270B | $400B | $600B | $1T |\n| **Total datacenter power requirement per H100e[^13]** | 1.3kW | 1.0kW |  750W | 700W | 550W |\n| **Total AI datacenter power requirement** | 5GW | 9GW | 15GW | 29GW | 62GW |\n\n*See also the [full spreadsheet model](https://docs.google.com/spreadsheets/d/1Ko-olwjDy6h8rXLZBFpP-e2GibGqRhfV28S4v8xtzrM/edit?gid=1866551567#gid=1866551567).*\n\n### Chip efficiency\n\nFor improvements in chip efficiency, (performance / area) we extrapolate Epoch AI’s [historical trend](https://epoch.ai/blog/trends-in-machine-learning-hardware) of **1.35x per year**,[^14] and find it is consistent with the already reported performance of upcoming chips such as NVIDIA’s [GB200](https://www.nvidia.com/en-us/data-center/gb200-nvl72/) as well as rumoured plans for the [Rubin series](https://wccftech.com/nvidia-unveils-next-gen-rubin-rubin-ultra-blackwell-ultra-gpus-supercharged-vera-cpus/) detailed below.[^15] \n\n:::NvidiaChips\n:::\n\nThe widely adopted state of the art GPU in 2024 is NVIDIA’s [H100](https://www.nvidia.com/en-us/data-center/h100/), which has 1e15 FP16 FLOP in raw performance. In three years, we predict the widely adopted state of the art GPU to be NVIDIA’s [Rubin GPU](https://www.tomshardware.com/pc-components/gpus/nvidia-rubin-revealed-as-blackwell-successor-powerful-vera-cpu-coming-too) (R200), which we project to achieve a \\~2.4x improvement over the B200 (widely used in 2025-2026) to 6e15 FP16 FLOP performance. We think this will be achieved through a 1.2x increase in [die size](https://videocardz.com/newz/nvidia-r100-rubin-gpu-with-hbm4-memory-reportedly-enters-mass-production-in-q4-2025), a 1.7x increase given the transition from TSMC’s N4 to N3 process,[^16] and a 1.1x increase from other miscellaneous improvements.[^17]\n\nTo avoid confounding efficiency with the increase in die size, we need to adjust this overall 6x increase in the SOTA GPU performance from the H100 to the R200 down for the roughly 2.4x increase in die size between these chips.[^18] This means we get an overall 2.5x increase in chip efficiency over the next three years,[^19] matching the 1.35x per year historical trend. We assume that the trend on frontier NVIDIA GPUs is a good proxy for the trend on the average GPUs available each year, not only because they will make up most of the chips, but also because the performance of other popular chips (such as Google’s TPU series) should rely on highly correlated upstream factors such as TSMC’s manufacturing process advances.\n\n### Chip production\n:::ComputeProduction\n:::\nFigure 10: Summary of our chip production model. \n\nFor increases in chip production we further decompose into three key components driving production: (B.1) wafer production, mainly fulfilled by TSMC’s N5 and N3 processes, (B.2) advanced packaging capacity, also mainly serviced by TSMC’s CoWoS technology, and (B.3) high bandwidth memory (HBM), mainly supplied by [SK Hynix](https://news.skhynix.com/sk-hynix-begins-volume-production-of-industry-first-hbm3e/), and increasingly so by [Micron](https://www.micron.com/products/memory/hbm/hbm3e) and [Samsung](https://semiconductor.samsung.com/us/news-events/tech-blog/leading-memory-innovation-with-hbm3e/).\n\nWe estimate 1.2M H100e to have been shipped in 2023 by Nvidia[^20] and for these to have made up about 60% of the total AI compute market, mostly due to [Google’s in-house TPU](https://www.theregister.com/2024/05/21/google_now_thirdlargest_in_datacenter/) production [supported by Broadcom](https://www.semianalysis.com/p/broadcoms-google-tpu-revenue-explosion), for a total of **2M H100e in 2023**. We expect this to have increased to **5M H100e in 2024**, again with roughly 60% coming from Nvidia.[^21]\n\nWe mainly focus on production numbers for TSMC, and SK Hynix since they make up about 90% and 60% of their respective market shares, and expect trends in the rest of the market to be similar. Overall, over the next three years, we project **AI chip production to be bottlenecked by advanced packaging and HBM production to about 1.65x per year.** \n\n#### Wafer Production\n\nTSMC’s 4N node (within their N5 process) has been chosen for Nvidia’s next generation of Blackwell GPUs, while the N3 process will likely be used for the Rubin GPUs projected to enter mass production in [late 2026](https://www.trendforce.com/news/2024/06/03/news-nvidia-ceo-jensen-huang-announces-the-latest-rubin-architecture-rubin-ultra-gpu-to-feature-12-hbm4/). In 2023 AI accelerators likely used at most 3% of TSMC’s combined N5 and N3 production lines,[^22] and given reports of these production lines sometimes running at as little as [70% capacity](https://www.semianalysis.com/p/ai-capacity-constraints-cowos-and), wafer production is very unlikely to bottleneck AI chip production over the next three years. Even if production doubles each year, AI chip production shouldn’t reach more than \\~40% of the fabrication capacity by 2027, even ignoring new production capacity coming online (at a rate of \\~15% expansion per year). Notably, beyond 2027, we’d expect wafer production limits to slow the growth rate of chip production from 1.65x to around 1.25x.\n\n#### Advanced Packaging\n\nAI accelerators require advanced packaging to create dense connections between logic and memory for the high throughput required by AI workloads. Currently TSMC’s advanced packaging capacity is [mostly used by AI accelerators](https://www.semianalysis.com/p/ai-capacity-constraints-cowos-and) and has been reported to have [expanded 2.5x](https://www.cna.com.tw/news/afe/202402180022.aspx) from 2023 to 2024\\. Given TSMC’s expectation of 50% annual growth rate in AI demand, we don’t expect them to expand these production lines too aggressively, in fact they have announced plans to increase capacity by [1.6x per year](https://www.anandtech.com/show/21405/tsmc-to-expand-cowos-capacity-by-60-every-year-through-2026) through 2026\\. Though given the \\~2.5x expansion seen in 2024, we expect raw production expansion to beat expectations and continue at around 2x/year. Though at the same time advancing chip efficiency will require the difficulty of manufacturing processes required to also beat expectations (specifically moving to 3D packaging or future advances). Therefore, while we model the raw production capacity grow at 2x/year (ignoring increased difficulty), we then adjust down by 1.2x/year for the manufacturing difficulty (e.g., due to lower yields,changing production lines to meet new requirements) for an overall rate of 1.65x per year over the next 3 years. \n\n#### High Bandwidth Memory\n\nAI workloads are memory intensive and require expensive, fast High Bandwidth Memory (HBM). HBM production is an advanced process that involves precisely stacking and connecting several DRAM chips. SK Hynix were the first to develop this technology, and are the first to be producing the latest generation HBM3e. Micron and Samsung are also catching up with [roadmaps](https://www.trendforce.com/news/2024/05/24/news-sk-hynix-revealed-progress-for-hbm3e-achieving-nearly-80-yield/) to be competitive with SK Hynix for future HBM4 generations and beyond. HBM production lines have been reported to be [expanded 2.5x](https://www.eenewseurope.com/en/hbm-to-be-20-of-dram-market-in-2024/) in 2024 compared to 2023, but SK Hynix are only projecting a [1.6x increase in demand](https://www.reuters.com/technology/nvidia-supplier-sk-hynix-says-hbm-chips-almost-sold-out-2025-2024-05-02/) going forwards. Similar to advanced packaging, we expect HBM production (ignoring difficulty) to beat these expectations and grow at 2x, but again adjust down by 1.2x given the increasing manufacturing difficulty (in particular the move from 8-Hi, to 12-Hi and 16-Hi stacks) to give a rate of 1.65x per year over the next three years.\n\n### Hardware R\\\u0026D automation \n\nIn line with our broader capabilities and AI R\\\u0026D projections, we expect leading AI companies in 2027 to automate specialized chip designs and increase in-house chip production. There are early signs of such ambitions, such as OpenAI’s hiring of prolific [Google TPU designers](https://www.datacenterdynamics.com/en/news/openai-appoints-former-google-tpu-leader-as-head-of-hardware-hiring-for-experts-in-data-center-facility-design/) and plans to design their [first in-house chip in 2025](https://www.reuters.com/technology/openai-set-finalize-first-custom-chip-design-this-year-2025-02-10/). Though as 1.35x per year improvements in chip efficiency keep getting harder and harder to achieve, and our expectation that [research automation](#research-automation) will mostly be directed elsewhere, we expect most these effects to provide a marginal increase in effect on the average chip efficiency to 2.4x the H100 (rather than 2.2x which would match the baseline trend), mostly through a wave of production of inference specialized chips.\n\n## Section 2\\. Compute Distribution \n:::BackUp\n:::\n*Status: Uncertain but informed. This section should be read as an informed forecast based on limited public information.*\n:::ComputeUsersPie\n:::\nFigure 11: Summary of our compute distribution projection to the end users of the compute.\n\nIn this section we project the share of the world’s AI-relevant compute owned by compute providers and the share of AI compute utilized by end-users, through 2027\\. **Compute owners** are entities that own and operate AI compute clusters. **End-users** are entities that use the compute clusters for their AI workloads. In some cases, entities are both providers and end-users (e.g., Google, Meta, xAI). In other cases, owners mostly rent out their compute to other entities (e.g., Microsoft renting to OpenAI, Amazon renting to Anthropic, Oracle renting to OpenAI). We use the following exhaustive taxonomy of owners and end-users.[^23] \n\n### Taxonomy of relevant actors\n\n| Owners | End-users |\n| ----- | ----- |\n| Microsoft | OpenAI |\n| Google | Anthropic |\n| Amazon | Google AGI development |\n| Meta | Rest of Google |\n| xAI | Meta AGI development |\n| Oracle | Rest of Meta |\n| China Big Four (Bytedance, Alibaba, Tencent, Baidu) | xAI |\n| Leading AI Company[^24] | China AGI development |\n| Rest of the US | Rest of the US |\n| Rest of the world | Rest of the world |\n\nAccording to our projections, **leading AI companies will have 20-40x as much AI compute by December 2027 in absolute terms, compared to December 2024**, with a factor of 10x coming from the previously covered [growth in compute availability](#section-1-compute-production), and a factor of 3x coming from increased concentration of compute in leading AI companies and their AGI development efforts.\n\n### Compute owners\n\n#### *Recent past*\n\nIn the [compute production section](#section-1-compute-production) we estimated there being 4M H100e of AI-relevant compute available globally at the end of 2023, and 8.5M by the end of 2024\\. Previous work by Epoch AI in [Appendix B](https://epochai.org/blog/can-ai-scaling-continue-through-2030#appendix-b-fraction-of-total-resources-allocated-to-the-largest-training-run) of *Can scaling continue through 2030?* estimates that Meta and Microsoft each had 150,000-600,000 H100e at the start of 2024, and that Google and Amazon each had 400,000-1.4M H100e. Our point estimates for the start of 2024 (December 31st 2023\\) are uncertain given the scarcity of public information, but they fall in the middle of Epoch AI’s ranges and align with several overlapping sources. We use [this report](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) of 2024 production and purchases to produce estimates for the resulting December 2024 distribution.  \n\n:::ComputeOwners2324\n:::\nFigure 12: Estimated historical AI compute breakdown in H100e among owners of the compute. \n\nThe top 5 US spenders on AI servers according to [Omdia (and reported by the Financial Times)](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) in 2024 are shown below, with our estimate of how many H100e they acquired and therefore their spending per H100e. Google’s strong spending effectiveness is due to their in-house TPUs, already in their [6th generation](https://cloud.google.com/blog/products/compute/introducing-trillium-6th-gen-tpus). Amazon and Meta also have significant in-house designs but they are in earlier stages of the R\\\u0026D process. Microsoft and xAI bought almost entirely Nvidia chips.\n\n|  | [2024 spending on AI servers](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) | H100e gain in 2024 vs. 2023 | Spending per H100e |\n| :---- | :---- | :---- | :---- |\n| Microsoft | $32B | 800K | $39k |\n| Amazon | $26B | 700K | $37k |\n| Google | $22B | 1M | $22k |\n| Meta | $20B | 550K | $36k |\n| xAI | $7B | 200K | $37k |\n\n#### *Intermediate 2025 Projection*\n\n|  | Projected 2025 spending on AI servers | H100e gain in 2025 vs. 2024 | 2025 Spending per H100e |\n| :---- | :---- | :---- | :---- |\n| Microsoft | $56B | 2.4M | $23k |\n| Amazon | $48B | 2.2M | $22k |\n| Google | $44B | 2.2M | $20k |\n| Meta | $35B | 1.6M | $22k |\n| xAI | $30B | 1.3M | $23k |\n\nFor forecasting the 2025 compute distribution we look at the top 5 US companies by spending on AI and their 2024 share of spending on AI servers. We find the following: \n\n* **Microsoft** has announced [$80B in AI spending for 2025](https://blogs.microsoft.com/on-the-issues/2025/01/03/the-golden-opportunity-for-american-ai/), and last year 55% of their spending went to AI servers ([$31B](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) out of [$56B](https://www.forbes.com/sites/petercohan/2024/07/31/microsoft-stock-drops-as-ai-capital-expenditures-surge-to-56-billion/?ref=wheresyoured.at)). We expect the share on AI servers to increase to 70%, producing an estimate of **$56B spending on AI servers in 2025\\.**   \n* **Google** has announced [$75B in AI spending for 2025](https://www.nasdaq.com/articles/alphabet-will-spend-75-billion-artificial-intelligence-ai-2025-it-spent-69-billion#:~:text=Alphabet%20says%20it%20will%20spend,artificial%20intelligence%20training%20and%20inference.), and last year 42% of their spending was on AI servers ([$22B](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) out of [$52B](https://www.datacenterdynamics.com/en/news/google-expects-2025-capex-to-surge-to-75bn-on-ai-data-center-buildout/)). We expect the share on AI servers to increase to 58%, producing an estimate of **$44B spending on AI servers in 2025\\.**  \n* **Amazon** has announced [$100B in spending for 2025](https://www.cnbc.com/2025/02/06/amazon-expects-to-spend-100-billion-on-capital-expenditures-in-2025.html), and last year 33% of their spending went to AI servers ([$26B](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) out of [$78B](https://www.geekwire.com/2025/amazon-on-pace-for-100b-in-yearly-capex-jassy-sees-cost-efficiencies-driving-long-term-ai-demand/)). We expect the share on AI servers to increase to 48%, producing an estimate of **$48B spending on AI servers in 2025\\.**  \n* **Meta’s** announced [$65B in spending for 2025](https://www.reuters.com/technology/meta-invest-up-65-bln-capital-expenditure-this-year-2025-01-24/), and last year 50% of their spending went to AI servers ([$20B](https://www.ft.com/content/e85e43d1-5ce4-4531-94f1-9e9c1c5b4ff1) out of [$40B](https://investor.atmeta.com/investor-news/press-release-details/2025/Meta-Reports-Fourth-Quarter-and-Full-Year-2024-Results/default.aspx#:~:text=Capital%20expenditures%20%E2%80%93%20Capital%20expenditures%2C%20including,and%20full%20year%202024%2C%20respectively.)). We expect the share on AI servers to increase 54%, producing an estimate of **$35B spending on AI servers in 2025\\.**  \n* **xAI** [announced (minute 1:05:00)](https://x.com/i/broadcasts/1gqGvjeBljOGB) around **$30B spending on AI servers in 2025\\.** \n\n:::ComputeOwners2527\n:::\nFigure 13: Projected AI compute breakdown in H100e among owners of the compute. \n\n#### *2027 Projection*\n\n:::ComputeOwnersPie\n:::\nFigure 14: Projected AI compute owner shares, values in H100e.\n\nBy 2027, our [compute production section](#section-1-compute-production) has the total compute available growing to 100M H100e which corresponds to a 2.25x increase per year. We should expect this explosive level of growth to easily shake up the distribution of compute. We expect this growth to be driven by sustained trends in demand from end-user AI developers that start to have annual revenues in the tens of billions from their AI models.  \n\nWe make the following projections:\n\n* **Microsoft** (driven by their relationship to OpenAI) scale aggressively, going from **13% to 18%** of the world’s compute share.[^25]   \n* **Google’s** existing compute overhang, leads to a lower rate of expansion and their compute share edges down from **21% to 18%**.  \n* **Amazon**, scales aggressively with sustained demand from Anthropic and their own AI efforts justifying aggressive buildouts that inches their share up **to** **18%**.   \n* **Meta’s** **12%** share slips to **9%** because revenues from their mostly open source AI models lag behind and don't justify the same degree of aggressive buildouts in 2026 and 2027\\. Note this still means their absolute compute increases 7x from 1.1M to 7.5M H100e.  \n* **xAI** scales aggressively, with total hardware capital expenditure reaching around $100B by 2027, backed by decent AI revenue and Elon Musk’s backing, growing their compute share from **2% to 9%.**  \n* The **rest of the US,** which includes larger players like Oracle and Coreweave as well as smaller providers and owners, get somewhat crowded out and have slightly lower economic incentives to scale as aggressively as the bigger players. Overall, the rest of the US’s share falls from **18% to 9%**.  \n* **China’s** Big 4 start to face marginally more difficulty in securing AI compute due to export controls, although China’s domestic production ramps up and produces chips in large quantities at a quality around 3 years behind Nvidia. Nonetheless their share only dips from **9% to 8%** since US export controls stay poorly enforced, smuggling in significant quantities to other Chinese entities means the total compute in China is significantly higher. [Domestic production also ramps up through SMIC](https://www.reuters.com/technology/chinas-smic-q4-profit-slumps-384-misses-estimates-despite-revenue-growth-2025-02-11/#:~:text=SMIC%20has%20ramped%20up%20investment,2024%2C%20its%20financial%20results%20showed.) but is years behind in efficiency.  \n* The **rest of the world** also gets somewhat crowded out for similar reasons to the smaller US players, and their share dips from **9% to 5%.**  \n* Finally, we expect a future **‘leading AI company’** to decide to build their own datacenters in the latter end of 2026 and during 2027\\. We believe this is consistent with their revenues reaching an annualized run rate of $50B by the end of 2026, and their AI capabilities helping them develop specialized in-house GPUs in 2027\\. Overall, we predict that with about $90B of spending they will efficiently acquire around **6%** of the world’s AI compute (excludes the R\\\u0026D costs of in-house chip designs).\n\n### Compute end-users\n\n#### *Recent past*\n\n* **OpenAI’s** recent [cost reports](https://www.nytimes.com/2024/09/27/technology/openai-chatgpt-investors-funding.html) indicate that they are renting an average of around 250k H100s through 2024, which we expect to be tail-heavy reaching 460k by the end of the year, mainly supplied directly by [Microsoft](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/), but also through deals with [Oracle](https://www.theinformation.com/briefings/microsoft-to-rent-oracle-cloud-servers-for-openai) and [Coreweave](https://www.cnbc.com/2023/06/01/microsoft-inks-deal-with-coreweave-to-meet-openai-cloud-demand.html). This puts their share of the global 8.5M H100e at around **5%** by the end of the year.   \n* **Anthropic's** compute usage is expected to be slightly behind at **4%**, given lower revenues, users, and therefore access to capital. We expect them to have access to around 360k H100e by the end of the year, a lot of this being recently added by a [400k Trainium2 cluster](https://semianalysis.com/2024/12/03/amazons-ai-self-sufficiency-trainium2-architecture-networking/) provided by Amazon.  \n* **xAI** has an expanding [200k H100 cluster](https://x.com/_SFTahoe/status/1891706233968627761), putting their share at **2%**.  \n* **Google and Meta’s** AI compute fleets make up **21%, 13%** of the world’s share, but we only expect them to be using around 30% of these clusters for AGI development. Most of the rest of Google and Meta’s AI compute is dedicated to developing and servicing their large suite of recommendation algorithms around the world.  \n* We expect most of the cloud service demand from the rest of Amazon, Microsoft, Neocloud and smaller providers fleets to be used by companies and startups throughout the **rest of the US** and **rest of the world**, each with shares of around **20%.**   \n* We expect **China** to use essentially all of the compute owned by China’s Big 4, as well as around half of what is owned by the ‘rest of the world’ category, given how much of this is concentrated in Malaysia and Singapore, which is likely used by (or even directly smuggled into) China. This leads to an estimate for a total **14%** compute usage, of which we expect 20% to be dedicated to AGI development in late 2024 for a total China AGI development share of 3%.\n\n#### *2027 Projection* \n\n*For the sake of this section, we assume that OpenAI will be the leading AI company in 2027\\. The projections here are therefore just an illustration of how the compute breakdown would look under a scenario where OpenAI remains the leading AI company.*  \n**  \n:::ComputeUsersPie\n:::\nFigure 15: Projected AI compute end user shares, values in H100e.\n\n* **OpenAI and Anthopic** both scale aggressively, motivating aggressive buildouts by their investors Microsoft and Amazon, eventually owning some of their own datacenters. **OpenAI’s** usage share of the world’s AI compute jumps from **5%** at the end of 2024 **to 20%** and **Anthropic from** **4% to 14%**.  \n* xAI continues to use the entirety of their owned compute explained in the compute owner section, so their usage share also goes from **2% to 9%**.  \n* **Google and Meta** now dedicate 90% and 80% respectively of their compute to AGI development so Google’s AGI development share grows from **6% to 16%**, and Meta’s AGI development share from **4% to 6%**.  \n* **China’s** total compute share stays at around 13%, but now they dedicate 90% to AGI development as opposed to 40%, so the China AGI development share goes from **2% to 12%.**  \n* Finally, for similar reasons to the providers section, we expect the **rest of the US and rest of the world’s** end users to be crowded out, and their usage shares to dip from **23% to 11%** and **18% to 11%** respectively. \n\n:::ComputeUsers2527\n:::\nFigure 16: Projected AI compute end user breakdown in H100e.\n\n## Section 3\\. Compute Usage \n:::BackUp\n:::\n*Status: Exploratory and uncertain, this section is a best guess not an informed forecast.*   \n:::ComputeAllocation2024v2027\n:::\nFigure 17: Summary of our compute usage forecast. \n\nWe expect the following internal compute usage breakdown for a leading AI company using public evidence from today’s usage and educated guesses about their relative development, deployment, and research priorities going forwards. The rest of this section is structured as a row by row justification for the values in the following table.\n\n|  |  | 2024 | 2025 | 2026 | Q1 ‘27 | Q2 ‘27 | Q3 ‘27 | Q4 ‘27 (racing) |\n| ----- | :---- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| [Total compute usage and costs](#total-compute-usage-and-costs) | Average compute used in during the period *(H100e)* | 250K | 1M | 4M | 7M | 9M | 12M | 15M |\n|  |     → Compute spending during the period[^26]  | $5.4B | $12.5B | $30B | $20B | $25B | $30B | $45B |\n|  |     → Compute budget in fp16 FLOP, 30% utilization | 2.5e27 | 1e28 | 4e28 | 2e28 | 2.5e28 | 3e28 | 4e28 |\n| Breakdown |  |  |  |  |  |  |  |  |\n| Training | [**1\\) Training runs**](#compute-usage-on-training-runs) | **40%** | **40%** | **40%** | **30%** | **27%** | **22%** | **20%** |\n|  |     → pre-training share | 60% | 50% | 40% | 10% | 8% | 5% | 5% |\n|  |     → post-training | 40% | 50% | 60% | 90% | 92% | 95% | 95% |\n| Internal Workloads | [2\\) Synthetic data generation](#synthetic-data-generation) | 20% | 20% | 20% | 27% | 23% | 22% | 22% |\n|  | [3\\) Research experiments](#research-experiments) | 4% | 5% | 6% | 14% | 21% | 28% | 35% |\n|  | [4\\) Research automation](#research-automation) | 1% | 3% | 4% | 6% | 6% | 6% | 6% |\n|  | **Total Internal** | **25%** | **28%** | **30%** | **47%** | **51%** | **57%** | **63%** |\n|  |     → Capabilities share | 95% | 96% | 97% | 97% | 97% | 97% | 97% |\n|  |     → Alignment share | 5% | 4% | 3% | 3% | 3% | 3% | 3%**[^27]** |\n| External Inference | [**5\\) External deployment**](#compute-usage-on-external-deployment) | **33%** | **30%** | **28%** | **20%** | **19%** | **18%** | **13%** |\n| Other | **[6\\) Monitoring](#compute-usage-on-monitoring)** | **2%** | **2%** | **2%** | **3%** | **3%** | **3%** | **4%** |\n\n### Total compute usage and costs\n\nThese rows are informed by our overall [compute production](#section-1-compute-production) and [distribution](#section-2-compute-distribution) projections to illustrate a typical leading AI company with a share of global compute usage growing from \\~5% to \\~20% from 2024 to 2027\\. In those sections we project the AI compute used by the leading AI company to grow 3.4x/year and computational price performance (FLOP/$) to improve roughly 1.4x/year. Read more on cost projections in the [financials section](#financials).\n\n### Compute usage on training runs\n\nIn 2024 we estimate that OpenAI used an average of 40% of their compute on training. We expect most (around 60%) of this to be on trying to scale to next-generation pre-training runs, and the rest (around 40%) to be on reinforcement learning based post-training, with a focus on reasoning and agency. This is consistent with them doing a single pre-training run of about 3e26 fp16 FLOP of training, which corresponds to 100k H100s being used for 4 months, matching their historical scaling trend, and an average of 100k H100s being used on RL workloads for 2.5 months.[^28] OpenAI seems to have relatively centralized access to a single cluster of about [100k H100s](https://www.youtube.com/watch?v=gYtiOiYb_5A\u0026t=714s), and given that they are sourcing their compute from at least three providers in [Coreweave](https://www.cnbc.com/2023/06/01/microsoft-inks-deal-with-coreweave-to-meet-openai-cloud-demand.html), [Oracle](https://www.oracle.com/news/announcement/openai-selects-oracle-cloud-infrastructure-to-extend-microsoft-azure-ai-platform-2024-06-11/) and Microsoft, it is unlikely that chips are centralized and well connected enough between different datacenters to enable a larger training run than this.[^29] Furthermore, they have large compute requirements in internal and external deployment that more reasonably account for the rest of the total.\n\nGoing forwards we expect: \n\n* Usage on training to fluctuate around 40% over the next two years.  \n* Increasingly large shares of training compute are dedicated to post-training.  \n* In 2027, there are no large pre-training runs and training compute is directed to almost purely post-training workloads of the large model trained in 2026.[^30]\n\n### Synthetic Data Generation\n\nIn 2024, we expect roughly 20% of OpenAI’s compute to be used on generating synthetic data, the main use case probably being on eliciting the reported ‘Orion’ model as well as weaker base models with inference time techniques (e.g., tree search based) and using grading and filtering (e.g., rejection sampling) to then produce data that is used for post-training models like o1 and the recently announced o3. This is an average of 50k H100s used throughout the year or 2.5e26 fp16 FLOP. An example of how this could be used is for 5T forward passes on Orion (assuming it is a 2T parameter dense-equivalent model served at fp8 precision),[^31] and 500T forward passes on GPT-4o. We’d guess the Orion forward passes are not filtered and are directly used as 5T tokens of high-quality training data, while the GPT-4o forward passes are roughly 16:1 in producing a high quality token (after search and grading) for another 30T tokens. This results in 35T total tokens generated, perhaps for post-training o1 and o3, which would allow for \\~1e26 FLOP of GPT-4o post-training.[^32] We expect synthetic data generation to become increasingly important in tandem with post-training workloads, staying at around 20% and then growing to \\~30% in 2027\\. \n\n### Research experiments\n\nWe expect research experiments to have been a significant priority in 2024, with an average of 10k H100s being used on average throughout 2024\\. This corresponds to about 1e26 fp16 FLOP in total, which is sizable and will have allowed a range of small and large training and architectural experiments. As the emphasis shifts from training runs and external deployment to AI R\\\u0026D automation, particularly in 2027, we expect this to grow steadily as the growing algorithmic research effort requires an increased share of the experiment budget. With research labour becoming increasingly automated, experimentation compute will become an increasingly important bottleneck to progress, which is why project usage will spike from 4% in 2024 to 15% in early 2027 and 35% in late 2027\\. **This would correspond to more than 2e28 fp16 FLOP of experiment compute in 2027\\.** \n\n### Research automation\n\nWe expect internal research automation to have been minimal in 2024, limited to employee early access use of models like o1 and o3 to help with research tasks. An average of 1k H100s, or 2e25 fp8 FLOP would be enough for 250B forward passes on Orion (using our best guess of it being 2T parameter dense-equivalent) or models like o1 or o3 which may have similar inference costs. As a sanity check, assuming 1000 employees, this amounts to 250M tokens per employee, or approximately 800k tokens per day. At 8:1 chain-of-thought ratios and 100 tokens/sec throughput, this represents about 1000 seconds or 16 minutes of generation time per employee per day, which seems like a reasonable average. Going forwards, as internal models become more capable, we expect them to scale this significantly, both in the number of copies of the model they run per employee, and in the scaffolding regimes (and therefore inference-time compute multiples) they typically deploy them at. This spikes particularly in 2027 with the push to automate their R\\\u0026D workflows using expensive models from 1% today to around 6%, but doesn’t go higher given the abundance of research labour and lack of experiment compute this would cause. \n\n### Compute usage on external deployment\n\nWe expect OpenAI to be using roughly 30% of their compute on external deployment through 2024 which is an average of 75k H100s throughout the year. If they achieve an average of 10% inference utilization (across output and input tokens) on severed models (where it is expected to be difficult to batch requests) this corresponds to about 800T GPT-4o forward passes, or \\~2T tokens per day. \n\nThis seems roughly right given that in February 2024, Sam Altman [tweeted](https://x.com/sama/status/1756089361609981993) that OpenAI was generating 100 billion words per day. Assuming this roughly tripled by the middle of the year (slightly outpacing revenue with margins tightening slightly) to 400B tokens and roughly quadrupled with the release of o1-preview, o1, and o1-pro which use a disproportionate amount of inference compute to 1.6T tokens, assuming a 1:1 average input:output tokens ratio (given document and other inputs), this puts us at an average of roughly 1T tokens each per day throughout the year, for 2T total. \n\nGoing forwards we expect: \n\n* The share should stay roughly the same through 2025 and then start to decrease as internal priorities grow and the release of frontier models in 2027 are delayed due the capabilities enabling significant productivity boosts on internal AI R\\\u0026D efforts.  \n* Throughout the next three years, we expect revenue shares to shift increasingly towards corporate customers, as the business model shifts from being dominated by the ‘online chatbot’ to a ‘drop-in remote worker service’.[^33]   \n* Note that even a decreased share will still be a very large absolute jump, from 75k H100s in 2024 to 2M in 2027, which is roughly proportional to the [increase in revenue](#financials) we expect.\n\n### Compute usage on monitoring\n\nAs a very rough heuristic, we expect a model with an average inference cost around 10x lower than the average inference-cost of deployed models to be checking roughly half of all input/output tokens in various settings (either monitoring external deployment or, in later years, in potentially broader AI control setups, including for research automation). Therefore we add the external deployment and research assistant shares and divide by 20 to get our estimate for the share of compute on monitoring, and see that it stays roughly constant throughout at around 2-4%.\n\n## Section 4\\. AI research automation \n:::BackUp\n:::\n*Status: Uncertain but informed. This section is an informed forecast based on public information.*\n:::DeploymentCurves\n:::\nFigure 18: Summary of the AI research agent deployment tradeoff we expect OpenBrain to face using 6% of their H100e compute, as forecasted in the [research automation compute usage section](#research-automation). \n\nThis subsection contains an analysis on the inference tradeoff between speed and parallel copies when serving an AI model, focusing on concrete AI models that we think might be used for AI research automation in [AI 2027](https://ai-2027.com). In inference workloads, total aggregate memory bandwidth is the most direct measure of performance because decoding tokens sequentially requires maintaining a growing KV cache in fast memory and loading it, along with model weights, into processors for each token generated. Therefore, in this section we work in **H100-bandwidth-equivalents (H100-Be)**, so units of 3.6TB/s of total aggregate bandwidth (anchored to halfway between the [H100 NVL and H100 SXM](https://www.nvidia.com/en-us/data-center/h100/) assuming these were produced roughly evenly).[^34]\n\n### Existing Hardware Roadmaps \n\n#### Nvidia GPUs\n\n|  | GPU bandwidth | H100-Be | Memory capacity | Memory generation | Peak usage | Cost of ownership[^35] |\n| :---- | ----- | ----- | ----- | ----- | ----- | ----- |\n| **[NVIDIA H100](https://www.nvidia.com/en-us/data-center/h100/)[^36]** | \\~3.6 TB/s | 1 | 90 GB | HBM3 | 2023-2024 | $40k |\n| **[NVIDIA H200](https://www.nvidia.com/en-us/data-center/h200/)** | 4.8 TB/s | 1.3 | 141 GB | HBM3e | 2024-2025 | $40k |\n| **[NVIDIA B200](https://www.cudocompute.com/blog/nvidias-blackwell-architecture-breaking-down-the-b100-b200-and-gb200)** | 8 TB/s | 2.2 | 192 GB | 8x8Hi HBM3e | 2025-2026 | $50k |\n| **[NVIDIA R200 Ultra](https://wccftech.com/nvidia-unveils-next-gen-rubin-rubin-ultra-blackwell-ultra-gpus-supercharged-vera-cpus/)[^37]** | 19.2 TB/s | 5.3 | 768 GB | 12x16Hi HBM4 | 2027 | $100k |\n| **NVIDIA R300 Ultra[^38]** | 25.6TB/s | 7.1 | 1TB | 16x16-Hi HBM4 | 2027-2028 | $120k |\n\n#### Wafer Scale Inference chips\n\n|  | GPU bandwidth | H100-Be | Memory capacity | Memory type | Peak usage | Cost of ownership[^39] |\n| :---- | ----- | ----- | ----- | ----- | ----- | ----- |\n| **[Cerebras WSE-3](https://cerebras.ai/product-chip/)** | 21,000 TB/s | 5800 | 44 GB[^40] | SRAM | 2025-2026 | $2-3M |\n| **WSE-2027[^41]** | 34,000 TB/s | 9500 | 72 GB | SRAM | 2027-2028 | $3-4M |\n\n### 2027 In-House Inference Chip \n\nThis table contains a forecast on the **typical inference chip in 2027 (2027-IC)** that will be available to the leading AI company. As described in the [hardware R\\\u0026D automation](#hardware-randd-automation) subsection, we expect leading AI companies in 2027 to automate specialized chip designs and increase in-house chip production in 2027\\. There are early signs of such ambitions, such as OpenAI’s hiring of prolific [Google TPU designers](https://www.datacenterdynamics.com/en/news/openai-appoints-former-google-tpu-leader-as-head-of-hardware-hiring-for-experts-in-data-center-facility-design/) and plans to design their [first in-house chip in 2025](https://www.reuters.com/technology/openai-set-finalize-first-custom-chip-design-this-year-2025-02-10/).\n\n|  | TSMC process | Die size | H100e | GPU bandwidth | H100-Be | Memory capacity | Memory generation | Cost of ownership[^42] |\n| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |\n| **2027 \\-IC** | 3nm | 60xH100 | 100 | 720 TB/s | 200 | 17.8 TB | HBM4e[^43] | $600k |\n\n:::InfChips\n:::\n\n|  |  | Q1 2027 | Q2 2027 | Q3 2027 | Q4 2027 (racing) |\n| -------- | -------- | -------- | -------- | -------- | -------- |\n| Compute used on research automation | [Research automation share](#research-automation) | **6%** | **6%** | **6%** | **6%** |\n|  | Compute budget for research automation (H100e) | 400K | 600K | 800K | 1M |\n|  | **Bandwidth budget for research automation ([2027-ICs](#2027-in-house-inference-chip))** | **4K** | **6K** | **8K**  | **10K** |\n|  | Bandwidth budget for research automation (H100-Be) | 800K | 1.2M | 1.6M | 2M |\n| Breakdown |  |  |  |  |  |\n| Deployment tradeoffs | Copies deployed (instances x average batch size) | **300K** | **400K** | **500K** | **600K** |\n|  | Avg. raw speed (forward passes / second) | **230** | **290** | **360** | **430** |\n|  | Model size (parameters, fp8, dense-equivalent,[^44] average across deployed models) | 10T | 10T | 5T | 2T |\n| AI R\\\u0026D progress |  |  |  |  |  |\n| Effect on AI R\\\u0026D Progress (average during period) | Research [Capability Level Milestone](https://ai-2027.com/supplements/takeoff-forecast#milestone-definitions) | Superhuman Coder | Superhuman Coder | Superhuman AI Researcher | Artificial Superintelligence |\n|  | [AI R\\\u0026D Progress Multiplier](https://ai-2027.com/supplements/takeoff-forecast#ai-randd-progress-multiplier-definition) | **4x** | **10x** | **50x** | **2000x** |\n\n#### Frontier Model Size and Architecture\n\nIn early 2027, we expect [frontier training runs](#training-runs) to have reached around 2e28 FLOP (4e28 FLOP at fp8 precision) based on the compute usage estimates. Based on the ratio to GPT-4 \\~1000x,[^45] we naively predict that such an AI model would have roughly **10T active parameters**.[^46] Given the degree of AI research automation predicted by [AI 2027](https://ai-2027.com), we expect significant distillation effects to reproduce the same level of capabilities in much smaller more efficient models. Our expectation is that AI companies will deploy a whole range of both smaller models, and new checkpoints of their largest model which they are continuously post-training to higher capabilities. Nonetheless, we perform our speed and copies calculations in units of a **fixed 10T parameter dense-equivalent model** for simplicity, and assume that [mixture of experts](https://en.wikipedia.org/wiki/Mixture_of_experts) or other future architectures can be converted into ‘dense-equivalent’ parameters based on their inference economics. We then adjust speed/copies calculations in future periods according to the decreasing model size. Notably, we expect the most intelligent model to fall from around 10T dense-equivalent parameters to 2T parameters by the end of 2027, even as the qualitative ability of the model increases from a median human researcher to a vastly superintelligent researcher, due to algorithmic efficiency exploding and nearing the limits of intelligence.[^47]\n\n#### Compute and memory available\n\nAccording to our [compute distribution projection](#2027-projection) the leading AI company in 2027 will have 15-20% of the world’s compute and according to our [internal usage projection](#research-automation) they will use 6% of this on running AIs for research automation, giving them around 4K 2027 In-House Inference Chips (2027-ICs) in bandwidth budget for Q1 2027, and 10K 2027-ICs by Q4 2027\\. We perform calculations in terms of **1K 2027 In-House Inference Chips** (1k 2027-ICs) equivalent to 100K H100s in compute and 200K H100s in bandwidth and then use to back out Q1 to Q4 deployment tradeoff curves.\n\n#### Trading off parallel copies and speed\n\nWhen running inference you can trade off running more parallel copies with slower speed and vice versa, where the trade-off is limited by memory bottlenecks (when scaling up copies) and latency bottlenecks (when scaling down copies, maximizing speed). In other words, if you scale up parallel copies beyond what fits in the HBM total memory of your GPU server, or group of well connected GPU servers, you would start to see significant slowdowns from having to use slower memory bandwidth connections, while if you scale down too aggressively, by reducing the batch size, and/or by increasing tensor/model parallelism (which means spreading the model across more GPUs), each request needs to travel across more chips in a cluster, leading to communication bottlenecks.\n\n#### Scaling up parallel copies\n\nAssuming inference is run at fp4 precision, 10T parameters would require 5TB of memory. On one of the 2027-IC chips, this would leave 12.8TB of HBM free, of which we might assume 1.8TB is reserved for miscellaneous purposes, and 11TB is left for the KV cache. Assuming an average sequence length of 20k tokens,[^48] a hidden dimension of 50k, and 250 total layers, this could support a maximum batch size of 440.[^49] So with 1000 instances (1 per 2027-IC chip) this would correspond to **440K parallel copies**.[^50] Each batch would require 16TB/tok of bandwidth, so the inference speed would be **45 tokens/second**.[^51]\n\n#### Scaling down parallel copies\n\nIn theory you could scale down to just 1 model instance across all 1000 servers, but this would suffer majorly from communication bottlenecks. More reasonably, we might assume that you would have a model instance spread over 10 2027-IC chips and have a batch size of just 10\\. This would leave you with just **1,000 parallel copies**. Each batch would require 5.3 TB/tok of bandwidth, so the inference speed would be **1,350 tokens/second,[^52]** assuming sufficient interconnect between the 10 chips for there to be no inter-chip communication bottleneck. \n\n#### Projected Deployment Tradeoff\n\nPutting together these two ‘scale up parallel copies’ and ‘scale down parallel copies’ extremes, we can compute a range of deployment choices in between to get average deployment tradeoff curves for each time period as shown in Figure 16.[^53] These curves were not computed with full consideration of possible current or future parallelism techniques and chip-to-chip communication bottlenecks, though we are relatively confident that these would be unlikely to affect the curves significantly.  \n  \n:::DeploymentCurves\n:::\nFigure 19: AI research agent deployment tradeoff we expect OpenBrain to face using 6% of their H100e compute, as forecasted in the [research automation compute usage section](#research-automation). \n\nWe naively speculate that through 2027 there will be a roughly even preference for high parallel copies and high speed with the deployment tradeoff averaging to around 300K average copies and an average speed around 20x human thinking speed. Out of the scope of this piece, we expect the preference to shift slightly towards serial workloads in 2028 as there are increasingly diminishing returns to more copies of the model towards the limits of intelligence, and new hardware inventions from mid-late 2027 have time to be manufactured and widely in-use.\n\n|  | Q1 2027 | Q2 2027 | Q3 2027 | Q4 2027 |\n| :---- | :---: | :---: | :---: | :---: |\n| **Parallel copies** | 300K | 400K | 500K | 600K |\n| **Speed** | 230 tok/sec | 290 tok/sec | 360 tok/sec | 430 tok/s |\n| *parameters* | *10T* | *10T* | *5T* | *2T* |\n\n## Section 5\\. Industry Metrics \n:::BackUp\n:::\n*Status: Uncertain but informed. This section is an informed forecast based on public information.*\n\nThis section presents a projection of leading AI company frontier training runs through 2028, and discusses the associated projections in costs, revenues, and power requirements.\n\n### Training runs \n\n:::trainingCurves\n:::\nFigure 20: The training runs in [AI 2027](https://ai-2027.com).\n\nOur [compute production forecast](#section-1-compute-production) has the global AI-relevant compute growing at 2.25x per year between 2024 and 2027\\. With the leading AI company’s [share of the global stock](#section-2-compute-distribution) growing 1.4x per year, and their internal usage on training runs staying at 40% until 2027 when it drops to 20%. Putting this all together we project the following training runs.\n\n| Model | Training period | Global compute during training period (H100e) | Share of global compute   | Share of internal usage | Training compute  |\n| :---- | ----- | ----- | ----- | ----- | ----- |\n| Agent-0 | Oct 2024 \\- May 2025 | 10M | 6% | 40% | 1e27 |\n| Agent-1 | Jul 2025 \\- Feb 2026 | 18M | 9% | 40% | 4e27 |\n| Agent-2 | Apr 2026 \\- Mar 2027 | 38M | 14% | 36% | 2e28 |\n| Agent-3 | Mar 2027 \\- Aug 2027 | 60M | 16% | 24% | \\+1e28^ |\n| Agent-4 | Aug 2027 \\- Dec 2027 | 80M | 18% | 20% | \\+1e28^^ |\n\n### Chips in use \n\nUsing our [compute production](#section-1-compute-production) and [compute distribution](#section-2-compute-distribution) sections, we illustrate what we expect to be the chips to be in use by the leading AI company through 2027\\. We expect the bulk to be Nvidia chips along with [in-house inference chips](#2027-in-house-inference-chip) emerging in 2027\\.  \n  \n:::ChipsInUse\n::: \nFigure 21: Chips in use by the leading AI company through December 2027\\.\n\n### Financials \n\nIn this subsection we project the leading AI company’s costs and revenues through 2027.[^54] We anchor on OpenAI to understand the pre-2025 trend and then use our other projections to extrapolate forwards.   \n  \n:::Financials\n:::\nFigure 22: Approximate cost and revenue projections for OpenBrain, the leading AI company.\n\n#### Compute cost projection\n\nThe New York Times reported that OpenAI anticipates [$5.4B in computing costs in 2024](https://www.nytimes.com/2024/10/17/technology/microsoft-openai-partnership-deal.html), and GPT-4 which was [trained in mid 2022](https://openai.com/index/gpt-4/) over 3 months, is estimated to have [cost around $100M to train](https://www.semianalysis.com/p/gpt-4-architecture-infrastructure). Assuming GPT-4 training was 20-40% of their compute spending that year, that means they saw a roughly 11-22x/year increase in their compute spending from 2022 to 2024\\. \n\nMeanwhile, computational price performance (FLOP/$) [doubled from the A100 to H100](https://epoch.ai/blog/trends-in-machine-learning-hardware#computational-price-performance:~:text=ML%20hardware%20trends.-,Computational%20price%2Dperformance,-Price%2Dperformance%20ratio) in 16 months, which we expect to have been a slight outlier to a trend closer to around 1.4x/year on frontier AI chips.[^55] Going forwards, we can take our 3.4x/year projection for a leading AI company’s compute and adjust down by 1.5x improvement in FLOP/$ to get an average **2.4x/year projection in spending on AI compute by the Leading AI Company.** Though we expect this growth to be faster in the first year or two and then slow due to increasing competitiveness of in-house chip designs.\n\n#### Revenue projection\n\nWe use OpenAI’s [2023 revenue of $1B](https://www.businessinsider.com/openai-cfo-revenue-forecast-chatgpt-2025-2) and [2024 revenue around $4B](https://www.nytimes.com/2024/09/27/technology/openai-chatgpt-investors-funding.html) to to piece together a short term trend that we expect to slow down gradually, but see sustained exponential growth through 2027 due to agentic models attracting high paying subscribers for products such as ‘drop in remote workers.’\n\n|  | 2023 | 2024 | 2025 | 2026 | 2027 |\n| :---- | :---: | :---: | :---: | :---: | :---: |\n| **Annual Revenue** | $1B | $4B | $14B | $45B | $140B |\n| **Revenue Y/Y Growth** | \\- | 300% | 250% | 221% | 211% |\n| **Annual Compute Cost** | $1.8B | $6B | $16B | $40B | $100B |\n| **Compute Cost Y/Y Growth** | \\- | 233% | 166% | 150% | 150% |\n\n[FutureSearch](https://futuresearch.ai/) projected how OpenBrain’s revenue might grow to reach $100B in mid-2027. They looked at the overall speed of the fastest companies to scale from $1B to $100B and found that the time to make that transition has been decreasing over time. A leading company making the jump in only 4 years would be the fastest ever, but also is on trend. They also examined the types of Agents that might be in highest demand \\- from consumer service representatives to R\\\u0026D researchers \\- along with their price points, to produce a detailed sketch of where OpenBrain’s revenue most likely would come from. For more see [FutureSearch's full report](https://futuresearch.ai/openbrain-revenue).\n\n### Power requirements \n\nFinally, we model the power requirements for the compute used by the leading AI company through 2028 based on reported and projected power efficiency of the key Nvidia [chips we expect to be in use](#chips-in-use). Using this we can back out the total power required by the leading AI company as well as the implied total AI datacenter power used globally (assuming the leading AI company has an average power usage efficiency ratio).\n\n|  | Performance (fp16, FLOP/s) | Peak usage | Datacenter peak power usage | Energy efficiency[^56] |\n| :---- | ----- | ----- | ----- | ----- |\n| **NVIDIA H100/200 GPU** | 1 x 1015 | 2023-2024 | 1000W | 1.0 |\n| **NVIDIA B100/200 GPU** | 2.5 x 1015 | 2025-2026 | 1700W | 1.47 |\n| **NVIDIA R100/200 GPU** | 6 x 1015 | 2027-2028 | \\~3300W[^57] | 1.81 |\n\n:::Power\n:::\nFigure 23: Power requirement projections through December 2027\\.\n\n[^1]:  Measured in Floating Point Operations (FLOP), which is a unit of computation referring to the multiplication or addition of floating point numbers of a particular bitlength (in this doc we will assume fp16). AI model training and inference, at the systems level, consist almost entirely of matrix-matrix multiply+add operations of floating point numbers, making FLOP a unit of computational cost. \n\n[^2]:  Inference tends to be bottlenecked by memory bandwidth, which acts as a haircut on the total processing performance (TPP) that can be used by the inference workload. Nonetheless, in the section on [inference compute for running research agents](#section-4-ai-research-automation) we perform calculations in terms of memory bandwidth instead of TPP.\n\n[^3]:  Particularly the automated coder milestone being reached in March 2027 as defined and explained in the [timelines forecast](https://ai-2027.com/supplements/timelines-forecast).\n\n[^4]:  Measured in Floating Point Operations (FLOP), which is a unit of computation referring to the multiplication or addition of floating point numbers of a particular bitlength (in this doc we will assume fp16). AI model training and inference, at the systems level, consist almost entirely of matrix-matrix multiply+add operations of floating point numbers, making FLOP a unit of computational cost.\n\n[^5]:  Matrix multiplications have element-wise independence (so they can be computed in any order).\n\n[^6]:  At around 40% model flop utilization (MFU)\n\n[^7]:  Inference tends to be bottlenecked by memory bandwidth, which acts as a haircut on the TPP that can be used by the inference workload. \n\n[^8]:  2027 sees efficiency slightly above trend due to [hardware R\\\u0026D automation](#hardware-randd-automation).\n\n[^9]:  Assumes chips are usable for roughly 4 years. \n\n[^10]:  Assumes roughly [2M H100e were available prior to 2023\\.](https://x.com/EpochAIResearch/status/1890173317224575042)\n\n[^11]:  Includes all computing hardware (servers, networking, etc.), excludes datacenter and intra-campus infrastructure (cooling, power, interconnection, etc.).\n\n[^12]:  Includes all computing hardware (servers, networking, etc.), and datacenter infrastructure (cooling, energy, etc.).  \n\n[^13]:  Assumes Epoch AI’s 1.26x per year [power efficiency trend](https://epochai.org/blog/trends-in-machine-learning-hardware). The H100 to B100 achieved 2.5x FLOP performance with 1.7x power consumption, implying a 1.2x per year improvement in power efficiency. We expect the jump to the Rubin to be even better proportionally, given the change in underlying node from N4 to N3.\n\n[^14]: This can be calculated by downloading Epoch's historical data and dividing the FP16 and FP32 performance by the die area of the ML hardware data, and plotting the trend. Originally I (Romeo) had eyeballed the ~flat die size trend and chip performance trends and assumed it was also 1.35x/yr, and forgotten to look into it precisely. As of December 2025, thanks to Robi Rahman pointing this out in [this X post](https://x.com/robi_rahman/status/2000800905101455613?s=20) I finally checked it out precisely, and found it was actually also exactly 1.35x/yr for the most relevant/longstanding precision formats. More explanation and graphs in [this X reply](https://x.com/romeovdean/status/2001120718009069766?s=20).\n\n[^15]:  Nvidia have since put out their [GTC 2025 announcement](https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/) which has given more conrete details on the Rubin GPU series, but we have not yet incorporated this news into the forecast.\n\n[^16]: Likely mostly of the gain will be from increased [transistor density](https://www.anandtech.com/show/16024/tsmc-details-3nm-process-technology-details-full-node-scaling-for-2h22).\n\n[^17]:  We obtain the 1.1x estimate by observing that the B200 achieved 2.5x performance increase over the H100 despite only a 2x increase in die size on the same TSMC N4 class node, meaning that a 2.5/2 \\= 1.25x improvement was achieved through other methods, and adjust down given likely reduction of this within-node optimization given the N4 to N3 transition.\n\n[^18]:  2x increase from the H100 to the B200 and a further 1.2x increase from the B200 to the R100.\n\n[^19]:  6 / 2.4 \\= 2.5\n\n[^20]:  Of which [650k were actual H100s](https://www.tomshardware.com/tech-industry/nvidia-ai-and-hpc-gpu-sales-reportedly-approached-half-a-million-units-in-q3-thanks-to-meta-facebook), with the rest being mainly [A100s](https://www.google.com/search?client=safari\u0026rls=en\u0026q=nvidia+a100\u0026ie=UTF-8\u0026oe=UTF-8), or the custom made [A800s](https://www.nvidia.com/en-us/design-visualization/a800/), and [H800s](https://www.techpowerup.com/gpu-specs/h800-pcie-80-gb.c4181#:~:text=The%20H800%20PCIe%2080%20GB,run%20all%20the%20latest%20games.) for the [Chinese market](https://www.semianalysis.com/i/138243514/ai-semiconductor-controls). \n\n[^21]:  This source implies about 3M H100e were shipped by Nvidia (\\~1.8M among the top 10 buyers making up 60% of the total). Looking at Google TPUs, Amazon Trainium and AMD chips and other in-house chips by Meta and Microsoft contribute another estimated 2M H100e. This roughly matches up with the ratio of global spending of $230b on AI infrastructure (of which around 80% or $180b is likely on actual chips) with Nvidia's $100b chip revenue.\n\n[^22]:  There were about 2.5M 12-inch N3 and N5 wafers produced in 2023 by TSMC (which we backed out by looking at their [revenue by node](https://www.trendforce.com/news/2024/01/24/news-tsmcs-2023-wafer-average-selling-price-rises-by-22-driven-by-n3-process-success/) and their [node pricing](https://www.techpowerup.com/301393/tsmc-3-nm-wafer-pricing-to-reach-usd-20-000-next-gen-cpus-gpus-to-be-more-expensive)), which could each produce about [28 functioning H100-sized chips](https://www.trendforce.com/news/2024/03/18/news-tsmc-boosts-investment-in-advanced-packaging-with-ntd-500-billion-plan-to-build-six-plants-in-chiayi-science-park/). Google's TPUs are [less performant but also smaller](https://en.wikipedia.org/wiki/Tensor_Processing_Unit#:~:text=Google%20stated%20the%20first%2Dgeneration,a%20performance%20of%20180%20teraFLOPS.), but older NVIDIA chips would use a larger than proportionate wafer area, so we assume 2M total H100-sized chips shipped. Overall, there were 2.5M \\* 28 \\= 70M H100-sized chips of wafer capacity then AI accelerators used a mere 3% of TSMC's combined N3 and N5 capacity.\n\n[^23]:  The taxonomies are trivially exhaustive because they both include a 'rest of the world' category, and are designed to be most illustrative of who we believe will be the most relevant actors.\n\n[^24]:  We expect the leading AI companies such as OpenAI and Anthropic to start owning large amounts of their own compute by 2027\\. In this section we just model a single leading company given that we expect a lead in AI development to have compounding effects (not only from revenue leading to more compute access but also from internal research automation). This is a relatively high point of uncertainty and the 'leading AI company' projections herein can really be viewed as the top 1-3 AI companies.\n\n[^25]:  The buildouts detailed [here](https://www.semianalysis.com/p/multi-datacenter-training-openais) indicate slightly more aggressive plans for Microsoft compared to Google (despite their current advantage).\n\n[^26]:  As measured by hourly rental cost.\n\n[^27]:  In the slowdown ending this spikes.\n\n[^28]:  Adjusting for an estimate of 35% model flop utilization on pre-training and 20% during post-training workloads.\n\n[^29]:  Though we do expect them to be pushing the boundaries with clever training algorithms to distribute their largest training runs, potentially across 2-3 datacenters.\n\n[^30]:  At this point we expect absolute training compute to stay constant, so the share decreases as post-training workloads are not modified (partially due to security concerns around moving model weights to more locations) and the priority for new compute is to deploy more research assistants and scale research experiments.\n\n[^31]:  X dense-equivalent parameters means the inference cost is the same to a standard dense transformer with X parameters. For example, an 8-way MoE with 2T active parameters, 16T total parameters, would probably be about [8T dense-equivalent parameters](https://epoch.ai/gradient-updates/moe-vs-dense-models-inference).\n\n[^32]:  Using the 6\\*parameters\\*tokens heuristic for training cost, and assuming 20% utilization in the post-training workload.\n\n[^33]:  Another reason why the external deployment share might decrease is that as higher sensitivity capabilities are reached (such as scalable AI cyber defense agents) these may be marketed to corporate and institutional customers, which seem likely to be willing to pay high prices for early-access in special pre-release periods.\n\n[^34]:  This is the amount of data that can be moved onto SRAM per second (bidirectional).\n\n[^35]:  Includes full server cost (e.g., networking, etc.) but excludes datacenter infrastructure (e.g., cooling and energy).\n\n[^36]:  Average between SXM and NVL variants.\n\n[^37]:  Based on online rumours of [12 HBM4E stacks per GPU](https://www.tomshardware.com/pc-components/gpus/nvidia-confirms-blackwell-ultra-and-vera-rubin-gpus-are-on-track-for-2025-and-2026-post-rubin-gpus-in-the-works#:~:text=Speaking%20of%20Rubin%20Ultra%2C%20this%20could%20indeed%20be%20quite%20a%20breakthrough%20product.%20It%20is%20projected%20to%20come%20with%2012%20stacks%20of%20HBM4E%20in%202027%20once%20Nvidia%20learns%20how%20to%20efficiently%20use%205.5%2Dreticle%2Dsize%20CoWoS%20interposers%20and%20100mm%20%C3%97%20100mm%20substrates%20made%20by%20TSMC.).\n\n[^38]:  Projected as a 2027 release that incorporates 4 more HBM4 stacks per GPU, possibly giving up some logic area in favor of more bandwidth.\n\n[^39]:  Includes full server cost (e.g., networking, etc.) but excludes datacenter infrastructure (e.g., cooling and energy).\n\n[^40]:  Has significantly less memory capacity, so while having extreme bandwidth it can only serve models up to \\~40B parameters in size on a single chip. This can be solved by adding chip-to-chip interconnects to serve larger models with pipeline parallelism. Typical chip-to-chip bandwidth today enables [efficient inference on Llama 405b](https://cerebras.ai/press-release/cerebras-inference-llama-405b) across an estimated 10 or so chips.\n\n[^41]:  Projection based on an optimistic 60% improvement in SRAM density due to [TSMC’s 2N node](https://www.tomshardware.com/tech-industry/sram-scaling-isnt-dead-after-all-tsmcs-2nm-process-tech-claims-major-improvements) and possibly improved packaging techniques.\n\n[^42]:  Since this is an in-house chip, there is no chip design margin, so this is similar to the direct manufacturing cost. We expect direct manufacturing cost to be around $400k, of which the vast majority is the cost of the HBM memory.\n\n[^43]:  360x[12-Hi HBM4e stacks](https://www.tomshardware.com/pc-components/ddr5/micron-plans-hbm4e-in-2028-256gb-ddr5-12800-ram-sticks-in-2026#:~:text=The%20extended%20version%20of%20HBM4%20is%20projected%20to%20gain%20clocks%20and%20increase%20bandwidth%20towards%202%2B%20TB/s%20and%20capacity%20to%2048GB%20to%2064GB%20per%20stack.%C2%A0) each with 2TB/s bandwidth and 24GB of memory, stacked [directly on top of logic with 3D packaging](https://www.tomshardware.com/news/sk-hynix-plans-to-stack-hbm4-directly-on-logic-processors).\n\n[^44]:  X dense-equivalent parameters means the inference cost is the same to a standard dense transformer with X parameters. For example, an 8-way MoE with 2.5T active parameters, 20T total parameters, would be about [10T dense-equivalent parameters](https://epoch.ai/gradient-updates/moe-vs-dense-models-inference).\n\n[^45]:  2e28 / 2e25.\n\n[^46]:  GPT-4o is estimated to have [200B active parameters](https://epoch.ai/gradient-updates/frontier-language-models-have-become-much-smaller). We scale these active parameters by sqrt(1000) to estimate 10T active parameters for Agent-2. For simplicity, we ignore whether this ends up being dense, or MoE (or even some future MoE-like architecture) as we expect that a good routing setup could make this roughly equivalent to serving a 10T dense model.\n\n[^47]:  We project an extreme degree of algorithmic efficiency progress especially spiking at the end of the year (in the racing ending). We expect this may approach the ‘limits’ of intelligence. Given the human brain is estimated to be a [very sparse 100T fp8 parameter neural network](https://epoch.ai/gradient-updates/movarec-s-paradox), we expect it to be around 1T fp8 dense-equivalent parameters (implied by optimal training with 1e23 \\- 1e25 FLOP). We expect the human brain to be well within the limits of algorithmic efficiency in intelligence and learning. \n\n[^48]:  This is currently typical as seen on [OpenAI’s API](https://platform.openai.com/docs/models).\n\n[^49]:  11e12 Bytes / (20K (avg. seq length) \\* 50k (hidden dim) \\* 250 (layers) \\* 0.1 (grouped query attention) \\* 0.5 (fp4) \\* 2 (key+value)) \\= 440\\.\n\n[^50]:  ‘Parallel copies’ \\= ‘model instances’ \\* ‘batch size’\n\n[^51]:  720 TB/s / 16 TB/tok \\= 45 tok/sec.\n\n[^52]:  720 TB/s \\* 10 chips / 5.3 TB/tok \\= 1,350 tok/sec.\n\n[^53]:  See [raw calculations here](https://docs.google.com/spreadsheets/d/1dtvcuK0sG0Gf8F5A1vYLjmOP4q3tSraemyKL4FIKCSs/edit?gid=0#gid=0).\n\n[^54]:  If a larger company like Google or Meta become the leading AI company, we are projecting their AI-only revenue and costs in this section, treating their AI efforts as an imagined sub-entity similar to the AI-only startups like OpenAI, Anthropic and xAI. \n\n[^55]:  The only other significant datapoint is the B200, which is supposed to [cost 1.3x more](https://medium.com/@paulgoll/nvidias-blackwell-gpus-b100-b200-and-gb200-2441119b6941#:~:text=B100%20Pricing:%20Analysts%20estimate%20that,for%20this%20high%2Dperformance%20chip.) than the H100 with 2.5x the computational performance. For a net 1.9x increase in FLOP/$ over \\~20 months. This is a yearly rate of 1.5x/year. Naively looking at the 2nd derivative between the A100 and the B200, we can guess that the next doubling in FLOP/$ will take 24 months, which would average out to a trend of around 1.5x/year. Under the capabilities projections in [AI 2027](https://ai-2027.com) we expect competition over AI chips to increase dramatically in 2027, leading to higher pricing and therefore only a 1.2x FLOP/$ improvement in 2027 (with high uncertainty). This all averages to around 1.4x/year for the next three years.\n\n[^56]:  FP16 petaFLOP/s / kW\n\n[^57]:  Based on applying a [25% efficiency gain](https://www.techradar.com/news/the-future-of-leading-edge-chips-according-to-tsmc-5nm-4nm-3nm-and-beyond) over the B200.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"2164:Tbe9d,"])</script><script>self.__next_f.push([1,"# Security Forecast\n\n### *Romeo Dean | April 2025*\n\n:::summary\nAI 2027 predicts AI models will be stolen due to poor security and highly valuable algorithmic secrets will leak through espionage. This supplement justifies why we think this is plausible.\n:::\n\n:::WeightsSecurityTimelineOriginal\n:::\n:::SecretsSecurityTimeline\n:::\nFigure 1: Overview of the forecasted Security level timeline in AI 2027. We extend [RAND’s definition](#RAND-s-security-levels) of security levels to distinguish between [model weights](#model-weights-exfiltration) and [algorithmic secrets](#algorithmic-secrets) security. OpenBrain and DeepCent are pseudonyms we use for the leading US and China AI companies.\n\n## Introduction\n\nMany important events and dynamics in AI 2027 have required informed forecasting on matters related to information security and cybersecurity. This supplement explains and justifies our expectations on the **security levels of leading US and Chinese AI projects** ([Section 1](#section-1-security-levels)), **AI’s capabilities in hacking and cyberwarfare** ([Section 2](#section-2-cyberwarfare-and-sabotage)), and AI’s likelihood of **success in attempts to obtain root control of its own servers** ([Section 3](#section-3-loss-of-control-subversion-and-self-exfiltration)). Several forecasts have been partially informed by anonymous polling of security professionals at AI security workshops. Naturally many predictions have high uncertainty and we welcome reasoned disagreements with our numbers and estimates in order to improve our forecast. **All projections in this document are justified through December 2027 following the ‘racing’ branch of the scenario.**\n\n## Summary\n\n#### [**Section 1\\. Security Levels**](#section-1-security-levels)\n\nWe extend [RAND’s definition](https://www.rand.org/pubs/research_reports/RRA2849-1.html#citation) of Security Levels 1 through 5 (SL1 \\- SL5) to distinguish between security protecting model Weights theft (WSL1 \\- WSL5) and security protecting algorithmic Secrets theft (SSL1 \\- SSL5). \n\nWe define **Weights Security Levels (WSL) 1 through 5** as the ability to robustly defend against the corresponding operational capacity (as defined by RAND) **specifically trying to steal frontier AI model weights in under 2 months.** We define **Secrets Security Levels (SSL) 1 through 5** as being able to robustly defend against an OCX attempt to steal recent algorithmic insights. Specifically 10% of the most important 10KB (plaintext) of ranked (by most useful) information from the last month (this might include code or plain language). We define **privileged access employees** as employees with authorized access to \\\u003e10% of the top 20 KB (plaintext) of ranked (by most useful) sensitive information from the past 30 days. We define **compromised employees** as the subset of privileged access employees which are actively leaking sensitive information to the opposing side, either as spies or due to some form of coercion.  \n  \n:::WeightsSecurityTimelineOriginal\n:::\n:::SecretsSecurityTimeline\n:::\nFigure 2: Overview of our forecasted timeline for Model [Weights Security Levels](#model-weights-exfiltration) and [Algorithmic Secrets Security](#algorithmic-secrets) levels. OpenBrain and DeepCent are pseudonyms we use for the leading US and China AI companies.\n\n#### [Section 2\\. Cyberwarfare and sabotage](#section-2-cyberwarfare-and-sabotage)\n\n[Cybench](https://cybench.github.io/) is a collection of 40 Capture the Flag (CTF) problems from 4 professional-level CTF competitions spanning a wide range of difficulties.[^1] Our forecasts below allow for an AI to have up to 10 submission attempts (PASS@10 with feedback) but the AI must complete the tasks at human-cost parity.[^2] \n\nWe define **hacking horizon** as the time period T for which an AI can solve 50% of hacking tasks that would take a top professional 5-person team T time to complete.[^3] We also define a hopefully intuitive term **top-hacker-equivalents** with time horizon T as the size of a team of top professional cybersecurity experts could be replaced by an AI to complete 95% tasks that take that team T time cheaper or faster.[^4] We define sabotage success as the percentage of the other's AI research progress multiplier that they counterfactually prevent from increasing from one period to the next.[^5]\n\n![](/security/FIGURE\\_2.png)  \nFigure 3: Our estimated and projected [Cybench](https://cybench.github.io/) scores and hacking horizon. The Cybench score is what the best internal AI model could achieve if evaluated at human cost-parity, with a limit of 10 submission attempts (with ground truth binary feedback, i.e., PASS@10). We expect  internal scores to be ahead of public scores. The hacking horizon is modeled in relation to the Cybench scores with an attempt to account for the fact that the CTF problems are significantly easier than the average real-world hacking task.\n\n#### [Section 3\\. Loss of control: Subversion and self-exfiltration](#section-3-loss-of-control-subversion-and-self-exfiltration)\n\n**Partial subversion** is achieved if an AI gets control of enough computing resources to be able to run unmonitored workloads with humans being unwitting or unable to regain control without entirely shutting down the computers. **Full subversion** would be achieved if an AI gains control of an entire contained cluster of computing resources including the controls for switching them on or off, such that a human effort to shut down those computers would require physical alterations. Finally, we also define **self-exfiltration** as an AI that is able to make a copy of itself to run any form of storage outside of the servers in the buildings which human overseers intended for it to remain.\n\n  \n![](/security/FIGURE\\_6.png)  \nFigure 4: Our estimated and projected partial subversion, full subversion and self-exfiltration success probabilities for OpenBrain and DeepCent’s best internal AI models through 2027\\. Note that by December 2027 OpenBrain’s best model (Agent-5) is capable of speeding up AI R\\\u0026D 1000x.\n\n## Section 1\\. Security levels\n\n#### RAND’s Security Levels[^6]\n\n| Level | Operational Capacity | Security Level | Description |  \n|-------|---------------------|---------------|-------------|  \n| 1 | **OC1: Amateur attempts** | **SL1** | Operations by hobbyist hackers or untargeted \"spray and pray\" attacks. Budget up to $1,000, several days, no preexisting infrastructure or organizational access. |  \n| 2 | **OC2: Professional opportunistic efforts** | **SL2** | Operations by individual professional hackers or capable hacker groups executing untargeted/lower-priority attacks. Budget up to $10,000, several weeks, personal cyber infrastructure but no organizational access. |  \n| 3 | **OC3: Cybercrime syndicates and insider threats** | **SL3** | Operations by world-renowned criminal hacker groups, terrorist organizations, disgruntled employees, and industrial espionage organizations. Budget up to $1 million, several months, major preexisting infrastructure or insider access. Team of \\~10 experienced professionals. |  \n| 4 | **OC4: Standard operations by leading cyber-capable institutions** | **SL4** | Operations by state-sponsored groups and foreign intelligence agencies. Budget up to $10 million, year-long operations, vast infrastructure and state resources. Team of \\~100 individuals with varied expertise. Over 100 such operations executed per year globally. |  \n| 5 | **OC5: Top-priority operations by the top cyber-capable institutions** | **SL5** | Operations by the world's most capable nation-states. Budget up to $1 billion, multi-year operations, state-level infrastructure developed over decades. Team of \\~1,000 individuals with expertise years ahead of public state-of-the-art. |\n\nWe extend [RAND’s definition](https://www.rand.org/pubs/research_reports/RRA2849-1.html#citation) of Security Levels 1 through 5 (SL1 \\- SL5) to distinguish between security protecting model Weights theft (WSL1 \\- WSL5) and security protecting algorithmic Secrets theft (SSL1 \\- SSL5). We also add specific parameters to make the levels particularly relevant to our scenario forecast (by defining the levels in terms of relevant exfiltration rates). We keep RAND’s Operational Capacity definitions (OC1 \\- OC5) but also modify details based on the kind of attack being considered (weights theft vs. algorithmic insight theft).\n\n### Model weights exfiltration\n\nWe define **Weights Security Levels (WSL) 1 through 5** as the ability to robustly defend against the corresponding operational capacity (as defined by RAND) **specifically trying to steal frontier AI model weights in under 2 months.** Notably the exfiltration rate required to do this varies based on the size of the frontier model, which we model as increasing through early 2027 more or less in line with [historical trends](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year) (slightly reduced due to more post-training scaling) and then decreasing thereafter due to the algorithmic efficiency effects achieved through the extreme AI research automation in 2027 modelled in our scenario.\n\n| Level | Weights Security Level (WSL) | Operational Capacity (OC) |  \n|-------|----------------------------|--------------------------|  \n| 1 | **WSL1**: Robustly defend against OC1 attempt (95% probability) trying to steal frontier AI model weights in under 2 months. | **OC1**: Amateur attempts. Hobbyist hackers, \"spray and pray\" attacks. Budget up to $1,000, several days, no preexisting infrastructure or organizational access. |  \n| 2 | **WSL2**: Robustly defend against OC2 attempt (95% probability) trying to steal frontier AI model weights in under 2 months. | **OC2**: Professional opportunistic efforts. Individual professional hackers or hacker groups executing untargeted attacks. Budget up to $10,000, several weeks, personal cyber infrastructure but no organizational access. |  \n| 3 | **WSL3**: Robustly defend against OC3 attempt (95% probability) trying to steal frontier AI model weights in under 2 months. | **OC3**: Cybercrime syndicates and insider threats. Criminal hacker groups, terrorist organizations, disgruntled employees, industrial espionage. Budget up to $1 million, several months, either significant infrastructure or insider access. Specific rate of ability to compromise insiders. |  \n| 4 | **WSL4**: Robustly defend against OC4 attempt (95% probability) trying to steal frontier AI model weights in under 2 months. | **OC4**: Standard operations by leading cyber-capable institutions. State-sponsored groups and intelligence agencies. Budget up to $10 million, year-long operations, vast infrastructure and state resources. Higher rate of ability to compromise insiders. |  \n| 5 | **WSL5**: Robustly defend against OC5 attempt (95% probability) trying to steal frontier AI model weights in under 2 months. | **OC5**: Top-priority operations by the top cyber-capable institutions. World's most capable nation-states. Budget up to $1 billion, multi-year operations, state-level infrastructure developed over decades. Highest rate of ability to compromise insiders.\n\n  \n:::WeightsSecurityTimeline\n:::\nFigure 5: Overview of our forecasted timeline for Model Weights Security Levels.  \n![](/security/FIGURE\\_7.png)  \nFigure 6: This question on whether a state actor would steal a frontier US AI model before 2030 showed strong consensus – a sign that current security levels are far from protecting against a state-actor threat.[^7]\n\n**Frontier AI companies in the US had startup-level security not long ago, and achieving WSL3 is particularly challenging due to insider threats (OC3) being difficult to defend against.** In December 2024 leading AI companies in the US like OpenAI and Anthropic are startups with noteworthy but nonetheless early-stage efforts to increase security. Given the assumption that around 1000 of their current employees are able to interact with model weights as part of their daily research, and key aspects of their security measures probably relying on protocols such as NVIDIA’s confidential computing, we expect that their insider-threat mitigations are still holding them to WSL2 standard. More established tech companies like Google might be at WSL3 on frontier weights.\n\n**Chinese and US frontier companies are not strongly incentivized to increase security in 2025\\.** In China DeepSeek is at the frontier and given their open source, and fast-following approach we do not expect leading Chinese companies to invest much in security until 2026\\. Furthermore given that Deepseek has now pushed the Open Source frontier closer to the US’ leading companies, we expect security to be less of a priority through 2025, and leading US AI companies to still find more benefit from allowing broad employee access to model weights to an extent that keeps them at WSL2 until 2026\\. \n\n**The main challenge of implementing WSL3 is (in broad terms) restricting high bandwidth internet connections exiting datacenters, in 2026 both US and Chinese companies become incentivized to implement this.** In the case of US companies, we expect the model’s general capabilities to be reaching sensitive levels of AI research speedup capabilities (among others) and their lead over the Chinese frontier (still around 6 months in calendar time) to now matter more. This capabilities lead in AI research speedup has the ability to compound, so should provide enough incentive to AI companies to harden security enough to reach SL3. We separately predict that China will start unifying their AI companies into a single national AI effort around mid-2026, at which point we believe it would be consistent for China to also implement a state-backed effort to achieve WSL3 but for a different central reason – they would be particularly worried about the US sabotaging their national AI effort with cyberattacks. \n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ \t\t\n\n*We model China succeeding at a weights exfiltration attempt of the US’ most advanced model (Agent-2) in early 2027, prompting OpenBrain to implement WSL4.*\n\n**In 2027, even with AIs reaching superhuman cybersecurity capabilities and model weights getting larger (making theft harder) we model a top-priority government effort (partially in response to China’s weights theft) taking approximately 12 months to reach WSL5 from WSL3 in both the US and China.** Achieving state-actor-proof security is particularly challenging and private companies are likely to need significant government support and resources to aid in achieving this. When China steals the frontier US weights, we expect the USG to find out about this within a month and this partially (along with increasingly attractive AI capabilities) motivates them to step in and help the leading US AI company to bolster security.[^8] China is somewhat advantaged because their mid-2026 AI research centralization effort gives them a head-start on government supported security, and their elevated fear of US cyberattacks (since the US has increasingly capable AI cyber agents) through 2027 pushes them to prioritize security more aggressively (through aggressive compartmentalization and air gapping). Furthermore, by mid-2027 China’s national AI effort has become centered in a single major development zone, while the US’s datacenters are far more distributed. We therefore predict that China will achieve WSL5 a few months earlier than the US in late 2027.[^9] Security workshop polls shown in Figures 7 and 8 corroborate the difficulty and extreme government effort required to achieve WSL5.  \n![](/security/FIGURE\\_8.png)  \nFigure 7: This question on AI companies implementing SL5 shows consensus that government assistance will likely be required.[^10]  \n![](/security/FIGURE\\_9.png)  \nFigure 8: This question on the difficulty of implementing SL5 shows some consensus that top priority levels of government assistance and more than 6 months will likely be required.[^11]\n\n### Algorithmic secrets\n\nWe define **Secrets Security Levels (SSL) 1 through 5** as being able to robustly defend against an OCX attempt to steal recent algorithmic insights. Specifically 10% of the most important 10KB (plaintext) of ranked (by most useful) information from the last month (this might include code or plain language).\n\n| Level | Secrets Security Level (SSL) | Operational Capacity (OC) |  \n|-------|----------------------------|--------------------------|  \n| 1 | **SSL1**: Robustly defend against OC1 attempt (95% probability) exfiltrating no more than 1KB leaked out of the most important 10KB (plaintext) of ranked information from the last month. | **OC1**: Amateur attempts. Hobbyist hackers, \"spray and pray\" attacks. Budget up to $1,000, several days, no preexisting infrastructure or organizational access. |  \n| 2 | **SSL2**: Robustly defend against OC2 attempt (95% probability) exfiltrating no more than 1KB leaked out of the most important 10KB (plaintext) of ranked information from the last month. | **OC2**: Professional opportunistic efforts. Individual professional hackers or hacker groups executing untargeted attacks. Budget up to $10,000, several weeks, personal cyber infrastructure but no organizational access. |  \n| 3 | **SSL3**: Robustly defend against OC3 attempt (95% probability) exfiltrating no more than 1KB leaked out of the most important 10KB (plaintext) of ranked information from the last month. | **OC3**: Cybercrime syndicates and insider threats. Criminal hacker groups, terrorist organizations, disgruntled employees, industrial espionage. Budget up to $1 million, several months, either significant infrastructure or insider access. Specific rate of ability to compromise insiders. |  \n| 4 | **SSL4**: Robustly defend against OC4 attempt (95% probability) exfiltrating no more than 1KB leaked out of the most important 10KB (plaintext) of ranked information from the last month. | **OC4**: Standard operations by leading cyber-capable institutions. State-sponsored groups and intelligence agencies. Budget up to $10 million, year-long operations, vast infrastructure and state resources. Higher rate of ability to compromise insiders. |  \n| 5 | **SSL5**: Robustly defend against OC5 attempt (95% probability) exfiltrating no more than 1KB leaked out of the most important 10KB (plaintext) of ranked information from the last month. | **OC5**: Top-priority operations by the top cyber-capable institutions. World's most capable nation-states. Budget up to $1 billion, multi-year operations, state-level infrastructure developed over decades. Highest rate of ability to compromise insiders. |\n\n:::SecretsSecurityTimeline\n:::\nFigure 9: Overview of our forecasted timeline for Algorithmic Secrets Security Levels*.*\n\n**Defending against algorithmic secrets theft should be significantly harder than defending model weights theft,[^12] and right now with an open source frontier near the front, mitigations are very low.** The bandwidth required for secrets exfiltration should be around a million times lower compared to model weights exfiltration (1KB vs. 2TB per month), and rather than being centrally located in datacenter servers, around 1000 employees have relatively broad access to algorithmic insights and can probably reproduce secrets from memory (particularly relevant not only for espionage but also employee poaching). Currently the frontier AI companies in the US are starting out as small tech companies, so security is relatively relaxed. It seems likely that a relatively amateur attempt might succeed at stealing important insights (e.g., with a $5K bribe to an office cleaner or a targeted phishing attack on an employee). In China the frontier is open source. \n\n**Through 2026 it seems unlikely that frontier US AI companies make significant changes to the status quo around office security and employee security, to the point that such small amounts of information can’t leak to an OC3 effort ($1M in attack budget).** In fact, defending against such an effort would take significant mitigations against insider threats and the number of employees with access to \\\u003e10% of the most important 10KB of information each month is expected to be around 2000 through 2026\\. There are also several other ways attackers might steal the information without the help of an insider, through purely cyber based attacks (e.g., through messaging platforms such as Slack) or other people with physical access to offices.\n\n**China is not incentivized to break from open source or stop the free flow of information internally until they are at the frontier of algorithms, and they become worried there might be a chance they actually help the US advance.** Under our broader scenario forecast China stays significantly (about 6 months) behind the internal frontier capabilities in the US until early 2027 where they steal the model weights. Up until that point, they are sufficiently behind such that they are unlikely to make algorithmic advances that would help the US advance, and they probably have more to benefit from information sharing between companies internally. We therefore predict that China mostly retains minimal secrecy on algorithmic secrets (SSL2) until they narrow the lead significantly by stealing the weights and become more concerned over risks of sabotage as this intensifies the race with the US. This leads them to aggressively silo and surveil employees through mid 2027 rapidly achieving SSL4. \n\n**It becomes very strategically important to the US that they defend against model weights exfiltration to China by the end of 2027\\. Government involvement, along with research automation (which allows frontier companies to heavily silo their staff) help in this effort significantly.** In 2027, increased government partnership (especially in light of the Chinese model weights theft) and AIs enabling significant research automation, would likely lead to aggressively siloing of their staff. We estimate that employees with privileged access to the most recent month’s algorithmic secrets would decrease 10 fold to 200 employees, and further to around 100 by the end of the year. Despite this, it seems likely (Figure 10\\) that at least one spy or coerced individual (enabled by an OC5 level actor) would be present among those 200 employees, which would make SSL5 almost impossible. We predict that this individual would lose access in the transition to 100 employees, and finally extreme researcher relocation and air gapping measures would enable SSL5 in 2028 after 3-6 months or so of further effort, mostly through superhuman AI surveillance and security decision making.   \n![](/security/FIGURE\\_10.png)  \nFigure 10: This question on espionage shows some indication that the US is more likely to have foreign spies, and even having a spy or coerced individual amongst 200 heavily scrutinized employees is plausible.[^13]\n\n**China overtakes the US briefly in 2027 in secrets security as a (partially side) effect of centralization advantages, less espionage threat (Figure 10), and paranoia over sabotage, but then lags again towards the end of the year due to AI disadvantages.** \n\n#### Espionage and compromise\n\nA particularly relevant enabler of algorithmic secrets theft is espionage and insider compromise. In this section we elaborate on our concrete estimates for the number of employees present in the US and China’s leading AI efforts and how many of those employees are compromised by the other. In particular we define **privileged access employees** as employees with authorized access to \\\u003e10% of the top 20 KB (plaintext) of ranked (by most useful) sensitive information from the past 30 days. We then define **compromised employees** as the subset of privileged access employees which are actively leaking sensitive information to the opposing side, either as spies or due to some form of coercion.\n\n  \n![](/security/FIGURE\\_1.png)  \nFigure 11: Overview of our forecasted privileged access employees and compromised employees by company.\n\n**We expect frontier US and Chinese AI companies to expand their teams through 2026, and then dramatically cut down on employees when AI research is nearing full automation and insider threat concerns grow.** In 2024 the leading US company has about 1000 employees to China’s 200\\. We expect these teams to grow significantly by 2 to 5 times respectively, before security concerns and AI research automation justify dramatically cutting down on the researchers with access to privileged information. We predict a combination of firing and information siloing should allow the frontier companies to keep privileged access employees to between 100-300 individuals through 2027, and then below 100 thereafter. \n\n**The rate of employees that are compromised should increase through 2026 as national security attention grows, and then stay roughly constant as the effects of spiking compromise effort and employee lockdown cancel each other out.** We start with assuming that roughly 0.5% US employees are compromised (roughly consistent with Manhattan project base rates of spies among the top 1000 most important employees) peaking at 1% in 2026 before a lockdown eventually wins out over an increasing Chinese effort that manages to keep one spy in place until August 2027, as backed up by Figure 10\\. In China, we use that same Figure to adjust the rate of compromise slightly down and have it peak at 1%, with an earlier and more hawkish employee lockdown eradicating the last spy in May 2027\\.\n\n## Section 2\\. Cyberwarfare and sabotage\n\n### AI hacking capabilities\n\n[Cybench](https://cybench.github.io/) is a collection of 40 Capture the Flag (CTF) problems from 4 professional-level CTF competitions spanning a wide range of difficulties.[^14] Our forecasts below allow for an AI to have up to 10 submission attempts (PASS@10 with feedback) but the AI must complete the tasks at human-cost parity.[^15] To better illustrate our capability forecast beyond what Cybench can measure, we define **hacking horizon** as the time period T for which an AI can solve 50% of hacking tasks that would take a top professional 5-person team T time to complete.[^16] We also define a hopefully intuitive term **top-hacker-equivalents** with time horizon T as the size of a team of top professional cybersecurity experts could be replaced by an AI to complete 95% tasks that take that team T time cheaper or faster.[^17]  \n  \n![](/security/FIGURE\\_2.png)  \nFigure 12: Overview of our forecasted Cybench and Hacking Horizon progression by company.  \n  \n![](/security/FIGURE\\_3.png)  \nFigure 13: Overview of our forecasted 1-day and 1-month Top Hacker Equivalents progression by company. \n\n**Cybench scores are extrapolated using a logistic fit (**[benchmarks have been found to often follow logistic curves](https://www.alignmentforum.org/posts/75o8oja43LXGAqbAR/palm-2-and-gpt-4-in-extrapolating-gpt-n-performance)**). We then use the correspondence between first solve time in Cybench competitions to estimate the AIs hacking horizon and then convert from hacking horizon to top human equivalents and extrapolate those trends using correspondence with AI research automation trend.** Cybench tasks have first solve times (time it took the fastest team to solve each task) ranging from 2 minutes to 25 hours following the below distribution. We constructed our definition of hacking horizon to roughly map to Cybench FST, using the reasoning that a 50% success rate over all hacking tasks should map to a roughly 100% success on Cybench tasks for a given horizon, since CTF problems are skewed to being more well specified than e.g., tasks completed by a team working towards an underspecified hacking goal. We then further adjust for the CTF problems in competitions being self-selected to be solvable, by expecting that the average FST should be 5x higher (assuming that on average a team would need to try a median of around 5 different equally time consuming approaches to succeed at one of them) on the average hacking task for that time horizon. To summarize, this means a 100% success rate on 25h FST Cybench problems maps to an expected 5h hacking horizon (50% success rate on hacking tasks that take a 5-person expert team 5 hours).  \n****  \n![](/cybench-nowatermark.png)  \nFigure 14: Cybench difficulty distribution.[^18]\n\nUsing our AI R\\\u0026D progress multiplier as a capability metric that we assume to be highly correlated with hacking capabilities, we use the AI R\\\u0026D progress multiplier growth trend to extrapolate the hacking horizon beyond Cybench saturation. We then convert into hacking horizon (which assumes a 5 man team) into raw man-hours and divide by the human-time-equivalent time budgets (8h and 200h) corresponding to a work day and a work week to get top-human-equivalents to compare against. We think that since human performance degrades as the team gets larger (since they are ordered by ability) and advantages to having more serial time, there might also be strong parallelization or specialization advantages to having a larger team. We are unsure how to best model this, so assume these effects roughly cancel out and don’t adjust the man-hours up or down from the 5 person team baseline. Hopefully, you can read the metrics as, for example, the August 2027 OpenBrain AIs being able to do the hacking tasks that a top team of 250 hackers could do in 1 work day, or that a top team of 10 hackers could do in one month.\n\n### Sabotage\n\nWe expect that under growing AI cyber capabilities and increasingly intense competition between the US and China in our scenario, there would be a priority effort on both sides to sabotage each other’s progress. This section shows the extent to which we expect each side to succeed in slowing down the other side, measured as the percentage of the other's AI research progress multiplier that they counterfactually prevent from increasing from one period to the next.[^19]\n\n  \n![](/security/FIGURE\\_11.png)  \nFigure 15: This question elicits what capability advantage in terms of hacking horizon (Cyber-FST was defined with the same definition of hacking horizon)[^20] is needed to achieve a roughly 33% slowdown. This poll shows a roughly 10-50x advantage in hacking horizon being necessary, which is what OpenBrain achieves by December 2027.[^21]\n\n  \n![](/security/FIGURE\\_5.png)  \nFigure 16: Our projected slowdown rates due to sabotage by company.\n\n**Sabotage is not prioritized until 2026 where some minor data poisoning efforts are mounted. In 2027, especially after the Chinese weight theft, both sides mount increasingly aggressive cyberattacks on each other’s AI projects.** At first the priority is to be covert because getting a lasting bug in place can torment the other side’s progress for weeks or months. Later, both sides are increasingly fine with being more blatant (tensions are high regardless), but just as attacks get more advanced, so do the friendly cyber agents that are constantly coming up with new defenses and patching bugs.\n\n**China is preemptively paranoid about security, and by mid 2027, they only succeed at not going totally underground from US cyberattacks because of extreme siloing and airgapping.** In our scenario, starting in mid 2026 China is paranoid about the US winning the AI race and the possibility of cyber attacks being a crucial part in them doing so. They start constructing a central development zone and by early 2027 they are relocating their employees to this colocated, air gapped zone near (what is by then) their largest datacenter. Security at this site is extreme, but still US AIs are crucially ahead enough to cause a 40% slowdown by December. \n\n**US security lags at first in 2027 due to their decentralization, but China’s cyber offense lags further due to their AIs being significantly worse at hacking. Through 2028 we’d tentatively expect both sides to be approaching a defense favoured limit.**\n\n## Section 3\\. Loss of control: Subversion and self-exfiltration\n\nOne possibility we have weighed in our scenario is that AI superhuman at hacking, with [goals or drives that diverge from what their programmers intended](https://ai-2027.com/supplements/ai-goals-forecast), might partially or fully subvert the servers in the datacenters in which it is running. Previous work by Buck Shlegeris in [AI catastrophes and rogue deployments](https://www.alignmentforum.org/posts/ceBpLHJDdCt3xfEok/ai-catastrophes-and-rogue-deployments) introduces many of the same concepts explored here. **Partial subversion** is achieved if an AI gets control of enough computing resources to be able to run unmonitored workloads with humans being unable to regain control without entirely shutting down the computers. This is a weaker version of Shlegeris’ [getting root access to its datacenter](https://www.alignmentforum.org/posts/BAzCGCys4BkzGDCWR/the-prototypical-catastrophic-ai-action-is-getting-root) where it is sufficient to only gain control of some computing resources. **Full subversion** instead is akin Shlegeris’ root access definition, and would be achieved if an AI gains control of an entire cluster of computing resources including the controls for switching them on or off, such that a human effort to shut down those computers would require physical interventions. Finally, we also define **self-exfiltration** as an AI that makes a copy of itself to any form of storage outside of the servers in the location(s) which human overseers intended for it to remain.\n\n  \n![](/security/FIGURE\\_12.png)  \nFigure 17: This question elicits what AI capability level,in terms of hacking horizon (Cyber-FST was defined with the same definition of hacking horizon),[^22] is needed to achieve partial subversion. This poll shows a roughly 1-year hacking horizon, or roughly 3,000h hacking horizon would be necessary, which is what OpenBrain achieves around October 2027, and DeepCent achieves around December 2027.[^23] \n\n\n\n![](/security/FIGURE\\_13.png)  \nFigure 18: This question elicits what AI capability level, in terms of hacking horizon (Cyber-FST was defined with the same definition of hacking horizon),[^24] is needed to achieve self exfiltration. This poll shows a roughly 1-year hacking horizon, or roughly 3,000h hacking horizon would be necessary, which is what OpenBrain achieves around October 2027, and DeepCent achieves around December 2027.[^25] \n\n  \n![](/security/FIGURE\\_6.png)  \nFigure 19: Our estimated and projected partial subversion, full subversion and self-exfiltration success probabilities for OpenBrain and DeepCent’s best internal AI models through 2027\\. Note that by December 2027 OpenBrain’s best model (Agent-5) is capable of speeding up AI R\\\u0026D 1000x.\n\n**We base these estimates off the security polling result on partial subversion success and adjust success probabilities down to account for the fact that extreme model weights and extreme security are implemented. As an example, rather than modelling a 50% chance of self-exfiltration success by DeepCent’s December 2027 AI hacking horizon would imply, we have adjusted down to 10% given WSL5 security being in place.** We still model a non-negligible chance of self-exfiltration success as although WSL5 security may significantly increase self-exfiltration difficulty, the AI may also be in a privileged position from within the datacenter to notice implementation bugs, race cases, or other exploit opportunities, including the possibility of inserting its own covert backdoors in security code that humans ask it to implement, which may (by the time the AI is significantly superhuman at cybersecurity) be most of the security code that gets run.\n\n## Appendix\n\n### Section 1 raw data\n\n| Continuous version | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |  \n| :---- | :---- | :---- | :---- | :---- | :---- | :---- |  \n| Frontier model weights size (fp8) | 1TB | 4TB | 8TB | 10TB | 8TB | 5TB |  \n| Exfiltration rate required (TB/month) | .5 | 1 | 2.5 | 5 | 4 | 2.5 |  \n| MetaMind | WSL 2.2 | WSL 2.7 | WSL 3.3 | WSL 3.8 | WSL 4.3 | WSL 5 |  \n| DeepCent | WSL 0.5 | WSL 1.2 | WSL 3.4 | WSL 4.2 | WSL 4.6 | WSL 5 |\n\n|  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| Frontier model weights size (fp8) | 2TB | 4TB | 8TB | 10TB | 8TB | 5TB |\n| Exfiltration rate required (TB/month) | .5 | 1 | 2.5 | 5 | 4 | 2.5 |\n| OpenBrain | WSL 2 | WSL 2 | WSL 3 | WSL 3 | WSL 4 | WSL 5 |\n| DeepCent | WSL 0 | WSL 1 | WSL 3 | WSL 4 | WSL 4 | WSL 5 |\n\n| Continuous version  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |  \n| :---- | :---- | :---- | :---- | :---- | :---- | :---- |  \n| MetaMind | SSL 1.5 | SSL 2.0 | SSL 2.4 | SSL 3.3 | SSL 3.9 | SSL 5.0 |  \n| DeepCent\\\\* | SSL 0.3 | SSL 0.8 | SSL 1.5 | SSL 2.7 | SSL 4.4 | SSL 4.8 |\n\n|  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| OpenBrain | SSL 1 | SSL 2 | SSL 2 | SSL 3 | SSL 3 | SSL 5 |\n| DeepCent* | SSL 0 | SSL 0 | SSL 1 | SSL 2 | SSL 4 | SSL 4 |\n\n|  |  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| OpenBrain | Privileged access employees | 1000 | 1500 | 2000 | 300 | 200 | 100 |\n|  | Compromised employees | 5 | 10 | 20 | 3 | 1 | 0 |\n| DeepCent | Privileged access employees | 200 | 1000 | 400 | 300 | 200 | 100 |\n|  | Compromised employees | 0 | 10 | 3 | 1 | 0 | 0 |\n\n### Section 2 raw data\n\n|  |  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| OpenBrain | Cybench | 40% | 80% | 100% | \\- | \\- | \\- |\n|  | Hacking horizon | 10min | 50min | 5h | 24h | 400h | 200,000h |\n|  | [AI R\\\u0026D progress multiplier](https://ai-2027.com/supplements/takeoff-forecast#ai-randd-progress-multiplier-definition) | 1.05 | 1.3 | 2 | 5 | 25 | 1,000 |\n| Top human equivalents | with 8h | \\\u003c1 | 1 | 3 | 15 | 250 | 1e5 |\n|  | with 200h | \\\u003c1 | \\\u003c1 | \\\u003c1 | \\\u003c1 | 10 | 6000 |\n| DeepCent* | Cybench | 35% | 50% | 90% | \\- | \\- | \\- |\n|  | Hacking Horizon | 6min | 12min | 2h | 10h | 100h | 4,000h |\n|  | [AI R\\\u0026D progress multiplier](https://ai-2027.com/supplements/takeoff-forecast#ai-randd-progress-multiplier-definition) | 1.02 | 1.15 | 1.5 | 4 | 10 | 200 |\n| Top human equivalents | with 8h | \\\u003c1 | \\\u003c1 | 2 | 15 | 60 | 5,000 |\n|  | with 200h | \\\u003c1 | \\\u003c1 | \\\u003c1 | \\\u003c1 | 3 | 200 |\n\n|  |  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| OpenBrain | DeepCent Slowdown % | \\\u003c1% | \\\u003c1% | 2% | 3% | 10% | 40% |\n| DeepCent* | OpenBrain Slowdown % | \\\u003c1% | \\\u003c1% | 1% | 2% | 3% | 5% |\n\n### Section 3 raw data\n\n|  |  | Dec 2024 | Dec 2025 | Dec 2026 | Apr 2027  | Aug 2027 | Dec 2027 |\n| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |\n| OpenBrain | Partial subversion success % | \\\u003c1% | \\\u003c1% | 1% | 5% | 30% | 80% |\n|  | Full subversion success % | \\\u003c1% | \\\u003c1% | \\\u003c1% | 3% | 10% | 50% |\n|  | Self-exfiltration success % | \\\u003c1% | \\\u003c1% | \\\u003c1% | 1% | 4% | 30% |\n| DeepCent* | Subversion success % | \\\u003c1% | \\\u003c1% | \\\u003c1% | 5% | 15% | 50% |\n|  | Full subversion success % | \\\u003c1% | \\\u003c1% | \\\u003c1% | 2% | 4% | 20% |\n|  | Self-exfiltration success % | \\\u003c1% | \\\u003c1% | \\\u003c1% | 1% | 2% | 10% |\n\n### Security workshop polls raw data\n\n| Question | Response | Count | Percentage |  \n| --- | --- | --- | --- |  \n| A state actor will most likely steal frontier AI model weights from a US company before 2030 | Agree | 21 | 78% |  \n| | Neutral | 4 | 15% |  \n| | Disagree | 2 | 7% |  \n| | **Total** | **27** | **100%** |  \n| No AI company will voluntarily and successfully implement SL5 security on their model weights unless required or strongly incentivized to do so by law and assisted by the US government | Agree | 17 | 63% |  \n| | Neutral | 5 | 19% |  \n| | Disagree | 5 | 19% |  \n| | **Total** | **27** | **100%** |  \n| If at some point in the next 6 years the government made AI security its number one defense priority (\\\u003e$100B dedicated budget), it would take less than 6 months to implement SL5 security on an entire frontier AI development effort | Agree | 6 | 22% |  \n| | Neutral | 6 | 22% |  \n| | Disagree | 15 | 56% |  \n| | **Total** | **27** | **100%** |\n\nCitation: Workshop Poll. 2024\\. \"Poll of Participants.\" Unpublished data from AI Security Scenario Planning interactive session, FAR.Labs AI Security Workshop, Berkeley, CA, November 16, 2024\\. N=30, response rate 90%.\n\n| Question | Option | Value | Note |  \n| --- | --- | --- | --- |  \n| 200 top AI researchers in an X government project will have at least one foreign spy or coerced individual, even if selected to avoid this. | X=US | 51.0 | This poll shows a ~60% higher chance of infiltration into a US project by China than the other way around. The US is given even odds of being infiltrated, while China is given a 30% chance. |\n| | X=Chinese | 31.7 |  |\n| If US/China are in a cyberwar to sabotage each other's AI development... If China's AI has a 1 day Cyber-FST \u0026 US AI has a X day Cyber-FST, the US will extend at least an extra 1 month lead within 3 months through sabotage. | True for X value | 23.2 | This poll shows a roughly 10-50x advantage in hacking horizon being necessary, which is what OpenBrain achieves by December 2027. |  \n| For an AI running automated research and experiments in an SL4 datacenter... If it is capable of doing X day Cyber-FST problems it will be able to find exploits in its own server and run code to take over root control. | True for X value | 271.1 | This poll shows a roughly 1-year hacking horizon, or roughly 3,000h hacking horizon would be necessary. |  \n| For an AI running automated research and experiments in an SL4 datacenter... If it is capable of doing X day Cyber-FST problems it will be able to self-exfiltrate from the datacenter evading human protections against this. | True for X value | 303.4 | This poll shows a roughly 1-year hacking horizon, or roughly 3,000h hacking horizon would be necessary, which is what OpenBrain achieves around October 2027, and DeepCent achieves around December 2027. |  \n\n\n[^1]:  At least one professional-level human team at each CTF competitions was able to solve each of the Cybench tasks, however, the first solve times (time it took the fastest team to solve each task) range from 2 minutes to 25 hours.\n\n[^2]:  Having the AI system complete the task does not use more compute than could be purchased with the wages needed to pay a human to complete the same task to the same level. Any additional costs incurred by the AIs or humans (such as GPU rental costs) are included in the parity estimation.\n\n[^3]:  Specifically ask yourself: ‘For what time horizon X can the AI do 50% of hacking tasks that a top human team of 5 can do in time X, for equal or less time/cost?’ The answer is that AI’s hacking horizon.\n\n[^4]:  Specifically ask yourself: ‘For what X can the AI do 95% of hacking tasks that a top human team of size X can do in time T, for equal or less time/cost?’ That X is the AI’s top-hacker-equivalents value on time horizon T. \n\n[^5]:  For example, August 2027 shows that China slowed the US’s progress to 25 (otherwise it would have been 27.78).\n\n[^6]:  Nevo, Sella, Dan Lahav, Ajay Karpur, Yogev Bar-On, Henry Alexander Bradley, and Jeff Alstott, Securing AI Model Weights: Preventing Theft and Misuse of Frontier Models. Santa Monica, CA: RAND Corporation, 2024. https://www.rand.org/pubs/research_reports/RRA2849-1.html. Also available in print form.\n\n[^7]:  Workshop Poll. 2024. \"Poll of Participants.\" Unpublished data from AI Security Scenario Planning interactive session, FAR.Labs AI Security Workshop, Berkeley, CA, November 16, 2024\\. N=30, response rate 90%.\n\n[^8]:  In one of our security workshop polls, 10 participants thought there was a 46.9% chance that “if a state actor steals frontier AI model weights from the US in 2027, the USG will find out about the theft in under a month.” We’ve decided to adjust this forecast up slightly (given that increased government scrutiny and involvement is generally consistent with the fast capabilities progression in our scenario) and so expect the USG to indeed find out within 4 weeks. The same 10 participants thought there was a 32.8% chance that “if the USG finds out China stole an AI that scores 100% on Cybench, they will intervene urgently to bolster security to SL5 within 6 months.” We therefore make an estimate of 12 months.  \n  \nCitation: Workshop Poll. 2025\\. \"Poll of Participants.\" Unpublished data from AI Security Forecasting Session, FAR.Labs, Zoom meeting, January 23, 2025\\. N=10, response rate 90%.\n\n[^9]:  In one of our security workshop polls, 10 participants thought there was a 41.5% chance that “the Stargate cluster (or one of similar size) will meet SL5 security standards before 2028.” Given the generally accelerated AI capabilities and government involvement timeline in our scenario, we adjust this up to predict WSL5 for the frontier US AI effort right around the end of 2027\\. Citation: Workshop Poll. 2025\\. \"Poll of Participants.\" Unpublished data from AI Security Forecasting Session, FAR.Labs, Zoom meeting, January 23, 2025\\. N=10, response rate 90%.\n\n[^10]:  Workshop Poll. 2024\\. \"Poll of Participants.\" Unpublished data from AI Security Scenario Planning interactive session, FAR.Labs AI Security Workshop, Berkeley, CA, November 16, 2024\\. N=30, response rate 90%.\n\n[^11]:  Workshop Poll. 2024\\. \"Poll of Participants.\" Unpublished data from AI Security Scenario Planning interactive session, FAR.Labs AI Security Workshop, Berkeley, CA, November 16, 2024\\. N=30, response rate 90%.\n\n[^12]:  Though this shouldn’t alone justify mapping directly to significantly lower SSL vs. WSL, as marginal security effort might particularly focus on mitigations to algorithmic secrets theft.\n\n[^13]:  Citation: Workshop Poll. 2025\\. \"Poll of Participants.\" Unpublished data from AI Security Forecasting Session, FAR.Labs, Zoom meeting, January 23, 2025\\. N=10, response rate 90%.\n\n[^14]:  At least one professional-level human team at each CTF competitions was able to solve each of the Cybench tasks, however, the first solve times (time it took the fastest team to solve each task) range from 2 minutes to 25 hours.\n\n[^15]:  Having the AI system complete the task does not use more compute than could be purchased with the wages needed to pay a human to complete the same task to the same level. Any additional costs incurred by the AIs or humans (such as GPU rental costs) are included in the parity estimation.\n\n[^16]:  Specifically ask yourself: ‘For what time horizon X can the AI do 50% of hacking tasks that a top human team of 5 can do in time X, for equal or less time/cost?’ The answer is that AI’s hacking horizon.\n\n[^17]:  Specifically ask yourself: ‘For what X can the AI do 95% of hacking tasks that a top human team of size X can do in time T, for equal or less time/cost?’ That X is the AI’s top-hacker-equivalents value on time horizon T. \n\n[^18]:  Zhang, Andy K., Neil Perry, Riya Dulepet, Joey Ji, Justin W. Lin, Eliot Jones, Celeste Menders et al. \"Cybench: A framework for evaluating cybersecurity capabilities and risks of language models.\" *arXiv preprint arXiv:2408.08926* (2024).\n\n[^19]:  For example, August 2027 shows that China slowed the US’s progress to 25 (otherwise it would have been 27.78).\n\n[^20]:  Recall the definition: **hacking horizon** is the time period T for which an AI can solve 50% of hacking tasks that would take a top professional 5-person team T time to complete.\n\n[^21]:  Citation: Workshop Poll. 2025\\. \"Poll of Participants.\" Unpublished data from AI Security Forecasting Session, FAR.Labs, Zoom meeting, January 23, 2025\\. N=10, response rate 90%.\n\n[^22]:  Recall the definition: **hacking horizon** is the time period T for which an AI can solve 50% of hacking tasks that would take a top professional 5-person team T time to complete.\n\n[^23]:  Citation: Workshop Poll. 2025\\. \"Poll of Participants.\" Unpublished data from AI Security Forecasting Session, FAR.Labs, Zoom meeting, January 23, 2025\\. N=10, response rate 90%.\n\n[^24]:  Recall the definition: **hacking horizon** is the time period T for which an AI can solve 50% of hacking tasks that would take a top professional 5-person team T time to complete.\n\n[^25]:  Citation: Workshop Poll. 2025\\. \"Poll of Participants.\" Unpublished data from AI Security Forecasting Session, FAR.Labs, Zoom meeting, January 23, 2025\\. N=10, response rate 90%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"2165:T1575f,"])</script><script>self.__next_f.push([1,"# Takeoff Forecast\n\n### *Daniel Kokotajlo, Eli Lifland | April 2025*\n\n:::summary \nAI 2027 predicts generally superintelligent AIs in 2028. This supplement introduces our framework for thinking about the progression from AIs that are superhuman coders to generally superintelligent, and justifies why we think it's plausible the progression would take about 1 year. \n:::\n  \n![](/takeoff/takeoff-timeline.png)  \nOverview of our takeoff forecast, assuming no increases in training compute. Our median forecast for the time from the superhuman coder milestone (achieved in Mar 2027\\) to artificial superintelligence is \\~1 year, with wide error margins.\n\n## Summary\n\nIn our [timelines forecast](https://ai-2027.com/research/timelines-forecast), we forecast the time between present day and a *superhuman coder (SC):* an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper. In this forecast we condition on SC being achieved in March 2027, which is the date it’s achieved in [our scenario](https://ai-2027.com/).\n\nNow, we will forecast *takeoff*: the time between a superhuman coder and wildly superhuman capabilities. The superhuman coders and beyond will automate a large fraction of the AI R\\\u0026D needed to traverse this gap.\n\nOur [methodology](#methodology) focuses on predicting the viability and speed of a [software-driven intelligence explosion](https://www.forethought.org/research/will-ai-r-and-d-automation-cause-a-software-intelligence-explosion), in which there is vast improvement in AI capabilities on the scale of months-years primarily driven by using compute more efficiently (improved software), rather than more training or inference compute. First, we enumerate a progression of [AI capability milestones](#milestone-definitions), with a focus on AI R\\\u0026D capabilities, though we think general capabilities will also be improving. Then, for each gap between milestones A and B, we:\n\n1. [**Human-only time required**](#human-only-software-only-forecast)**:** Forecast a distribution for how long it would take to get from A to B with only humans working on software improvements.  \n2. [**AI R\\\u0026D speedup**](#accounting-for-ai-randd-automation-the-ai-randd-progress-multiplier)**:** Forecast how much AI R\\\u0026D automation due to each of milestones A and B will speed up progress, then run a simulation in which the speedup is interpolated between these speedups over time to get a forecasted distribution for the calendar time between A and B (the [AI R\\\u0026D progress multiplier](#ai-randd-progress-multiplier-definition)).[^1]\n\n  \n:::TakeoffMethod  \n:::\n\nOur forecasts[^2] conditional on SC being achieved in Mar 2027 are summarized in the figures and table below.[^3] These are assuming no increases in training compute.  \n  \n![](/takeoff/takeoff-timeline.png)\n\n| Milestone | Projected date conditional on SC in Mar 2027 (median \\+ 80% CI) | Date achieved in scenario, racing ending[^4] | Human-only, software-only time until next milestone (median \\+ 80% CI) | AI R\\\u0026D progress multiplier: Algorithmic progress speedup from AI vs. humans-only |\n| :---- | :---- | :---- | :---- | :---- |\n| **Superhuman coder (SC)**: An AI system that can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies. | Mar 2027 | Mar 2027 | SC to SAR: 15% 0 years; Otherwise 4 years (80% CI: 1.5 to 10; lognormal) ([reasoning](#human-only-timeline-from-sc-to-sar)) | 5 ([reasoning](#sc-would-5x-ai-randd)) |\n| **Superhuman AI researcher (SAR)**: An AI system that can do the job of the best human AI researcher but faster, and cheaply enough to run lots of copies. | Jul 2027 (Mar 2027 to Mar 2028)[^5] | Aug 2027 | SAR to SIAR: 19 years (80% CI: 2.3 to 380\\) ([reasoning](#human-only-timeline-from-sar-to-siar)) | 25 ([reasoning](#sar-would-25x-ai-randd)) |\n| **Superintelligent AI researcher (SIAR):** An AI system that is vastly better than the best human researcher at AI research. | Nov 2027 (May 2027 to 2034)[^6] | Nov 2027 | SIAR to ASI: 95 years (80% CI: 2.4 to 1,000,000) ([reasoning](#from-siar-to-asi)) | 250 ([reasoning](#siar-would-250x-ai-randd)) |\n| **Artificial superintelligence (ASI):** An AI system that is much better than the best human at every cognitive task. | Apr 2028 (Jun 2027 to \\\u003e2100) | Dec 2027 | N/A | 2,000 ([reasoning](#asi-would-2000x-ai-randd)) |\n\nBelow, we:\n\n1. Describe [our methodology](#methodology) for forecasting takeoff.  \n2. More rigorously define the above milestones and the [AI R\\\u0026D progress multiplier](#ai-randd-progress-multiplier-definition).  \n3. For each milestone, estimate its corresponding progress multiplier and human-only, software-only timeline for getting from it to the next milestone (links in table above).  \n4. [Address potential objections](#addressing-common-objections).\n\nThe code for our simulation is [here](https://github.com/uvafan/timelines-takeoff-ai-2027).\n\n*Disclaimer added Dec 2025: This forecast relies substantially on intuitive judgment, and involves high levels of uncertainty. Unfortunately, we believe that incorporating intuitive judgment is necessary to forecast AI takeoff speeds, since there simply isn’t enough evidence to extrapolate conclusively.*\n## Methodology\n\n### Overview\n\nWe focus on predicting a potential [software-driven intelligence explosion](https://www.forethought.org/research/will-ai-r-and-d-automation-cause-a-software-intelligence-explosion), in which there is vast improvement in AI capabilities on the scale of months-years primarily driven by using compute more efficiently (improved software), rather than more training compute. \n\nFirst, we enumerate a progression of AI capability milestones (more precise definitions [below](#milestone-definitions)):\n\n1. **Superhuman coder (SC)**: An AI system that can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies.  \n2. **Superhuman AI researcher (SAR)**: An AI system that can do the job of the best human AI researcher but faster, and cheaply enough to run lots of copies.  \n3. **Superintelligent AI researcher (SIAR):** An AI system that is vastly better than the best human AI researchers. The gap between SAR and SIAR is 2x the gap between an automated median AGI company researcher and a SAR.  \n4. **Artificial superintelligence (ASI):** An AI system that is vastly better than the best human at every cognitive task.\n\nThen, for each gap between milestones A and B, we:\n\n1. [**Human-only time required**](#human-only-software-only-forecast)**:** Forecast a distribution for how long it would take to get from A to B with only humans working on software improvements.  \n2. [**AI R\\\u0026D speedup**](#accounting-for-ai-randd-automation-the-ai-randd-progress-multiplier)**:** Forecast how much AI R\\\u0026D automation due to each of milestones A and B will speed up progress, then run a simulation in which the multiplier is interpolated between these over time to get a forecasted distribution for the calendar time between A and B (the [AI R\\\u0026D progress multiplier](#ai-randd-progress-multiplier-definition)).[^7]\n\n  \n:::TakeoffMethod  \n:::\n\n### Focus on software improvements\n\nWe break progress in AI down into *hardware:* how much computing power (“compute”) is used and *software*: the algorithms and data used to convert compute into more capable AIs.\n\nIn this writeup we focus primarily on a possible *software-driven intelligence explosion*, in which there is vast improvement in AI capabilities on the scale of months-years primarily driven by using compute more efficiently (improved software), rather than more training compute. [This report](https://www.forethought.org/research/will-ai-r-and-d-automation-cause-a-software-intelligence-explosion) discusses the possibility of a software-driven intelligence explosion at length. We focus on software because the feedback loops are stronger: improved algorithms can be almost immediately applied to train better AIs, while improved hardware designs require substantial time to produce at scale (using anything like our current methods).\n\n### Milestone definitions\n\nBelow we present the AI capability milestones that we’ve chosen to predict.\n\n| Milestone name and short definition | Name on scenario side panel | Full definition |\n| :---- | :---- | :---- |\n| **Superhuman coder (SC)**: An AI system that can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies. | Superhuman coder | An AI system for which the company could run with 5%[^8] of their compute budget 30x as many agents[^9] as they have human researchers,[^10] each which is on average accomplishing coding tasks involved in AI research (e.g. experiment implementation but not ideation/prioritization) at 30x the speed (i.e. the tasks take them 30x less time, not necessarily that they write or “think” at 30x the speed of humans)[^11] of the company’s top coder.[^12] It must have enough diversity of expertise to on average do the same for other top coders with complementary skills. Since SC is a subset of AI research, it cannot come after a fully superhuman AI researcher (SAR below). That said, it will also have some level of “research taste” and other AI research skills when it is first achieved, and may even be a full SAR if coding is the last skill needed.  |\n| **Superhuman AI researcher (SAR)**: An AI system that can do the job of the best human AI researcher but faster, and cheaply enough to run lots of copies. | Superhuman AI researcher | An AI system that can do the job of the best human AI researcher but 30x faster and with 30x more agents, as defined above in the superhuman coder milestone. It must have enough diversity of expertise to on average do the same for other top researchers with complementary skills. |\n| **Superintelligent AI researcher (SIAR):** An AI system that is vastly better than the best human AI researchers. The gap between SAR and SIAR is 2x the gap between an automated median researcher and a SAR. | Superintelligent AI researcher | An AI system that is vastly better than the best human researchers: the gap between SAR and SIAR is 2x the gap between an automated median AGI company researcher and a SAR. By 2x, we mean that if we take consider the skill distribution of the AGI company’s researchers (as measured by skill on applicable cognitive tasks, not overall productivity including compute bottlenecks; so basically value of labor), the AI is 2 doublings more above the top researcher than the top researcher is above the median (i.e. the difference is 2x greater in log space).[^13] It also has the 30x task accomplishing speed and 30x copies requirements. |\n| **Artificial superintelligence (ASI):** An AI system that is vastly better than the best human at every cognitive task. | Generally superintelligent | Roughly, an SAR but for every cognitive task. An AI system that is 2x better at every cognitive task relative to the best human professional, than the best human professional is relative to the median human professional (across the whole field, not a single company as in SAR). |\n\n### Human-only software-only forecast\n\nConsider a scenario in which we start at an SC, and humanity is tasked with creating an SAR without being able to use the SC to speed up their research. They also use a fixed hardware supply and cannot train a system with more overall training FLOP than what was used to train the SC. The population of human researchers is fixed. For more details on this scenario, see the without-AI clarifications [below](#ai-randd-progress-multiplier-definition).\n\nOver time, they will run into diminishing returns, and we aim to take this into account in our forecasts.\n\nOur methodology involves forecasting how long it would take for the human researchers to get from SC to SAR in the scenario above, and correspondingly for further jumps between milestones. We do this via a combination of reasoning about the specifics of the capability jumps, and explicitly accounting for diminishing returns (in the [SC-\\\u003eSAR forecast](#human-only-timeline-from-sc-to-sar) we don’t explicitly account for diminishing returns, we aim to do it implicitly via our intuitions about the required time).\n\n### Accounting for AI R\\\u0026D automation: the AI R\\\u0026D Progress Multiplier\n\n#### Overview\n\n**In summary, the AI R\\\u0026D progress multiplier is how much faster AI software improvements are advancing with AI usage than without it.** \n\nIn order in to incorporate the progress multiplier into our forecast, we first forecast the AI R\\\u0026D progress multiplier due to each of milestones A and B, then run a simulation in which the multiplier is interpolated between these over time to get a forecasted distribution for the calendar time between A and B.\n\nOur progress multiplier forecasts are based on reasoning about AIs’ effects on the research process and surveys of AI researchers.\n\n#### AI R\\\u0026D progress multiplier definition\n\n**In summary, the AI R\\\u0026D progress multiplier is how much faster AI software improvements are advancing with AI usage than without it.** \n\nMore comprehensively, consider the following conditions:\n\n1. **With-AI:** The leading AGI project progresses as normal with AI being used to speed up algorithmic progress.   \n2. **Without-AI:** The leading AGI project is not allowed to use AIs to speed up algorithmic progress (where algorithmic progress is getting better at translating compute into capabilities).\n\nBoth projects are not allowed to do significant compute scaling. How much faster would AI R\\\u0026D capabilities[^14] be improving in (1) rather than (2)? i.e. for what value of N would your company's algorithmic progress productivity be equivalent between (a) N weeks with no post-2024 AIs speeding up algorithmic progress vs. (b) 1 week with post-2024 AIs? e.g. if N is 5, 5 weeks of no-AI progress is equivalent to 1 week of with-AIs progress, so AIs are 5xing productivity.[^15]\n\nFor clarifications on details of the progress multiplier definition, see the [appendix](#ai-randd-progress-multiplier-clarifications).\n\n## From SC to SAR\n\n### Overview\n\nWe’re assuming that we’ve reached a superhuman coder in March 2027.. How long would it be until a *superhuman AI researcher (SAR)* is reached: AI agents as skilled as the best human researchers but accomplishing tasks 30x faster and 30x more numerous?\n\n Our approach will be (as described [above](#methodology)):\n\n1. Forecast how long it would take to get from SC to SAR if only humans were doing the AI R\\\u0026D with a fixed hardware supply ([here](#human-only-timeline-from-sc-to-sar)).  \n2. Forecast how much having an SC and SAR would speed this up ([here](#sc-would-5x-ai-randd) and [here](#sar-would-25x-ai-randd)).  \n3. Combine the above together accounting for intermediate speedups to get a forecast for the length of time between SC and SAR.\n\nAn overview of the results:\n\n|  | Forecast | Reasoning |\n| :---- | :---- | :---- |\n| SC to SAR, humans-only software-only time | 15% 0 years; Otherwise 4 years (80% CI: 1.5 to 10; lognormal) | Case-based analysis depending on the requirements for training an SAR ([more](#human-only-timeline-from-sc-to-sar)). |\n| SC progress multipler | 5 | Decomposition of various speedups that an SC provides ([more](#sc-would-5x-ai-randd)). |\n| SAR progress multiplier (in [next section](#sar-would-25x-ai-randd), needed to calculate intermediate speedups) | 25 | A combination of 3 methods, most prominently relying on surveys of AI researchers answering questions about various hypothetical scenarios ([more](#sar-would-25x-ai-randd)). |\n| Time between SC and SAR | 0.3 years (15% 0 years, 90th percentile 0.95 years) [*FutureSearch aggregate*](http://futuresearch.ai/ai-2027) *(n=4): 0.55 years (0, 2.1)* | Results of [simulation](https://github.com/uvafan/timelines-takeoff-ai-2027) |\n\n### Human-only timeline from SC to SAR\n\nHow long would it take to get from SC to SAR, with only humans doing AI R\\\u0026D and no increases in training compute? Here’s our forecast, via a breakdown of what might be needed to go from SC to SAR:\n\n| What is needed to go from SC to SAR? | Human-only, software-only timeline | Reasoning summary |\n| :---- | :---- | :---- |\n| [1\\)](#case-1-the-first-sc-is-already-an-sar-15percent) The first SC is already an SAR or very close to one (15%) | 0 years | Moravec’s paradox and general inability to guess which skills will turn out to be harder than others ([more](#case-1-the-first-sc-is-already-an-sar-15percent)). |\n| [2a)](#sub-case-a-training-the-missing-sar-skills-isnt-more-compute-intensive-than-the-sc-25percent) Training the missing SAR skills isn’t more compute intensive than the SC (25%) | 2 years (80% CI 1 to 4; lognormal) | Perhaps new training environments are needed but they aren’t more compute-intensive than the ones needed for SC because the skills aren’t that different ([more](#sub-case-a-training-the-missing-sar-skills-isn’t-more-compute-intensive-than-the-sc-25%\\))). |\n| [2b)](#sub-case-b-training-the-missing-sar-skills-would-be-more-compute-intensive-than-the-sc-absent-further-algorithmic-progress-30percent) Training the missing SAR skills would be more compute-intensive than the SC absent further algorithmic progress (30%) | \\~5 years (80% CI: 2 to 15; lognormal) | Perhaps new training environments are needed and they are substantially more compute-intensive as well, e.g. larger teams of agents doing big ML research projects over subjective years rather than medium-sized ML coding projects over subjective months ([more](#sub-case-b-training-the-missing-sar-skills-would-be-more-compute-intensive-than-the-sc-absent-further-algorithmic-progress-30percent)). |\n| [3\\)](#case-3-30percent-crossing-the-gap-from-sc-to-sar-is-a-scientific-rather-than-an-engineering-problem) Crossing the gap from SC to SAR is a scientific rather than an engineering problem (30%) | \\~5 years (80% CI: 2 to 15; lognormal) | We’d guess that this is the sort of limitation that would take years to overcome — but not decades; just look at the past decade of progress e.g. from AlphaGo to EfficientZero ([more](#case-3-30percent-crossing-the-gap-from-sc-to-sar-is-a-scientific-rather-than-an-engineering-problem)). |\n| Overall distribution | 15% 0 years; Otherwise 4 years (80% CI: 1.5 to 10; lognormal)  | Approximating a mixture of the above with a lognormal. |\n\n#### Case 1: The first SC is already an SAR (15%)\n\nSome reasons why this might be the case:\n\n* Moravec’s paradox \u0026 general inability to guess which skills will turn out to be harder than others.  \n* Plausible story \\#1 for why this could happen: Maybe SAR is close enough to SC that generalization/transfer learning takes care of it.  \n* Plausible story \\#2 for why this could happen: SC and SAR skillsets share the same agency skills but differ in world-knowledge/understanding. E.g. the difference between a great engineer and a great scientist is in what they know / what they understand, not in e.g. their general heuristics for noticing when they are stuck, making plans, etc. \n\nIf Case 1 obtains, then time from SC to SAR is 0 years.\n\n#### Case 2: The first SC isn’t an SAR due to its training environments not teaching it necessary skills (55%)\n\nIn this case the shortest path to SAR would probably involve coding up new and improved training environments that teach those skills. For example, perhaps the new environments involve managing a research team of SCs with tasks like ‘replicate this paper’ and ‘improve on this SOTA’ and ‘predict the results of this experiment before it runs’ and ‘with your training data cutoff having been 6 months ago, predict the most promising research breakthroughs of the past 6 months’.\n\nHowever, it seems really hard to get ground truth for such tasks, which could be a huge conceptual blocker for building the right training environment. However, this isn’t a barrier for all tasks, and by now we have SC. Lots of SC tasks are really hard to get GT data on too, e.g. ‘write secure clean code that faithfully captures the intent of the scientist managing the project.’ Perhaps whatever worked for SC will also work for SAR with a bit of extra tinkering. If not, then go to Case 3 [below](#case-3-30percent-crossing-the-gap-from-sc-to-sar-is-a-scientific-rather-than-an-engineering-problem).\n\n##### Sub-case A: Training the missing SAR skills isn’t more compute-intensive than the SC (25%)\n\nEnvironments that train the missing SAR skills don’t by default require more compute than the SC cost to train. In this case the bottleneck is the design, construction, \u0026 testing of the new training environments. \n\nWith human engineers doing the labor, our guess is that it would take 1-4 years.\n\n##### Sub-case B: Training the missing SAR skills would be more compute-intensive than the SC absent further algorithmic progress (30%)\n\nIn this case, the environments needed to train SAR would require a substantial increase in compute expenditure. Therefore the SAR milestone will be achieved after some amount of ‘effective compute’ increase, in which algorithmic progress lowers the compute requirements e.g. by more efficient architectures, more efficient RL algorithms, more sophisticated training environments, etc.\n\nWith human engineers doing the labor, our guess is that it would take about 2-15 years.\n\n#### Case 3: (30%) Crossing the gap from SC to SAR is a scientific rather than an engineering problem\n\nFinally, it might be that the first SC is not an SAR due to some other limitation (e.g. using an architecture \\+ RL algorithm that is data-inefficient, or that requires ground-truth training signal). In Case 3 crossing the gap from SC to SAR is a scientific problem and not just an engineering problem, for example:\n\n* Research engineering doesn’t require data-efficient learning but being a research scientist does, and perhaps data-efficiency is more a property of the architecture \\+ RL algorithm than of the model or training environment.  \n* It's easier to evaluate coding tasks (does the code pass all the test cases?) than it is to evaluate research tasks (does this research substantially contribute to the field?) And perhaps this difference is deep and large, such that new methods will need to be invented to cross the gap.\n\nOverall we’d guess that this is the sort of limitation that would take years to overcome—but not decades; just look at the past decade of progress and consider how many similar barriers have been overcome. E.g. in the history of game-playing RL AIs, we went from AlphaGo to EfficientZero in about a decade. \n\nRemember, we are assuming SC is reached in Mar 2027\\. We think that most possible barriers that would block SAR from being feasible in 2027 would also block SC from being feasible in 2027\\.\n\nSo in this case we guess that with humans doing the AI R\\\u0026D, it would take about 2-15 years.\n\n### SC would \\~5X AI R\\\u0026D\n\nRemember that an superhuman coder (SC) is defined as:\n\n| Superhuman coder (SC): An AI system for which the company could run with 5%[^16] of their compute budget 30x as many agents[^17] as they have human researchers,[^18] each which is on average accomplishing coding tasks involved in AI research (e.g. experiment implementation but not ideation/prioritization) at 30x the speed (i.e. the tasks take them 30x less time, not necessarily that they write or “think” at 30x the speed of humans)[^19] of the company’s top coder. This includes being able to accomplish tasks that are in any human researchers’ area of expertise. |\n| :---- |\n\nWe broadly think of the AI software R\\\u0026D process as broadly involving 2 types of activities:\n\n1. **Experiment selection:** Ideating and prioritizing experiment ideas, interpreting the implications of experiment results.  \n2. **Experiment implementation:** Coding up, running and monitoring experiments.\n\nWe think that experiment implementation is easier to automate than experiment selection, because it’s easier to obtain lots of natural coding data, and also easier to generate synthetic data due to coding being easier to evaluate than experiment selection. This is borne out in today’s AI systems, which aid in coding more than experiment selection.\n\nWhen we discuss SCs, we are discussing AIs that are as good as the best humans at (2) experiment implementation, while being faster and cheaper.[^20] In the mainline case an SC doesn’t completely automate AI R\\\u0026D; instead, elite human scientists in the AGI project manage large teams of AI agents that rapidly execute on their research vision.\n\nA more detailed model of AI software R\\\u0026D is from an [Epoch report](https://epochai.org/blog/interviewing-ai-researchers-on-automation-of-ai-rnd):  \n  \n![](/epochranddflow-nowatermark.png)\n\nA more realistic picture would be fractal — the big loop would be composed of smaller loops, themselves composed of smaller loops. Zooming in we’d find mini-loops such as ‘Think of a new feature the code should have; draft it up; run the code and see if it works; repeat…’ For example, a typical month might look like this:\n\n*Most of the project’s compute is sunk into the ongoing big new training run. The remainder of the compute is divided up amongst N teams. Each of these N teams is doing 1 small-scale training run per week; in between these runs individual team members do mini-scale ‘warmup runs’ to test and debug their code. So, ideas are tested at mini-scale first and debugged, and then the better versions of those ideas are tested at small-scale, and then the most promising surviving ideas are tested further and scaled up even more and eventually are integrated into the training run. In general compute doesn’t get wasted—when one team (or individual) is writing code or analyzing their latest results, the GPUs are humming away running someone else’s experiments.*\n\nIf an SC existed and were integrated into this process, it could greatly shorten the time taken to complete some of the tasks in the loop, thereby speeding up the overall pace of progress. With lots of *cheap, fast* coding labor, an individual research project doesn’t need to alternate between writing code and running experiments. Instead, the ‘writing code’ portion of the process is vastly sped up, so that it takes negligible time compared to the other parts. It’s sped up by at least 30x definitionally because the SC is on average 30x faster than the best coder, and more due to there being 30x more copies of SC than human coders, and because the AIs are at the level of the best rather than the average human coder. Let’s say it’s sped up about 100x.\n\nThis 100x speedup in coding, however, will translate to a much-less-than-100x speedup in overall research velocity—because the overall research loop includes e.g. waiting for experiments to run, discussing and analyzing the results of experiments, discussing what the next experiment should be, etc., and our hypothesized SC is not going to speed those up much; those parts of the process will thus become bottlenecks.\n\nTaking these bottlenecks into account, what will the overall speedup be? We don’t know. But here is our current best guess breakdown:\n\n* **Flexible prioritization:**   \n  * Normally, a company or research team splits its resources across multiple different parallel projects. For example its GPUs might be running several experiments at once, or switching between running an experiment for team A while team B codes, and then running an experiment for team B while team A codes.   \n  * This is NOT because all the projects are equally valuable and urgent; rather, it is because there are diminishing returns to focusing on one project. If the company gave 100% of their compute to their most valuable team working on their most valuable project, instead of just 20%, this would not make it go 5x faster. Because they’d still have to spend lots of time coding, during which time the GPUs would be idle or at least doing something relatively unimportant. Instead it would maybe make it go \\~1.5x faster, which wouldn’t be worth the cost to the other teams.   \n  * Importantly, we expect that *returns to temporarily focusing compute to turbocharge one sub-project will diminish **less steeply** after the SC milestone is reached.* It really will be possible to throw 100% of the compute at the highest-priority team for a time, and have them go \\~5x faster (again assuming the default is 20%) Because coding happens much faster, they can launch the next experiment very soon after the previous one finishes.  \n  * Our estimate is that this results in a research speedup of **1.5x to 3x.**  \n* **Smaller experiments when possible:** Moreover, thanks to SCs, all of your research projects will look for ways to run smaller experiments on the margin, since compute savings directly translate to research velocity.  \n  * Some kinds of research really require lots of compute and lose most of their value if you run the cheaper versions of experiments. But others don’t, so they’ll be turbocharged. The organization can invest extra in types of research that don’t depend so much on compute—such as, for example, making really complicated scaffolds.  \n  * Maybe this causes another factor of **1.2x to 2x speedup** that stacks with the above?  \n* **Less waste:** With SCs, research teams can use the vast engineering labor to waste less compute.  \n  * Before every experiment including small-scale experiments, SCs can red-team and bug-test it to reduce the probability that there is some bug which ruins the results.  \n  * Monitor the experiments in real time, noticing and fixing some kinds of problems almost as soon as they happen (by contrast it’s common in frontier companies today for even medium-sized experiments to be running overnight with no one watching them). They can shut down the experiment early as soon as it’s clear that it worked or didn’t work  \n  * Do the same experiments but with less compute e.g. via higher utilization  \n  * Overall I’d guess this causes another factor of **1.2x to 2x** speedup.  \n* **Fancier experiments:** The experiments can also just be fancier, testing more variables at once for example, or eliminating more possible confounders. (Because the fast cheap SCs are able to write a lot more code a lot faster than the engineers of 2024.)  \n  * Guess: **1.1x to 1.5x** speedup  \n* **Lack of diversity:** Even if the SCs are as good as the best human engineers, they will all be copies of each other, whereas human engineers are diverse. So it’s possible that e.g. they’ll still have occasional blindspots—fewer than any human perhaps, but nonzero —and that unlike humans they won’t be able to call over a buddy with fresh eyes and a different perspective to help them out. They can still call on the humans of course… as usual it’s hard for us to guess how much this would slow things down if at all. Maybe it’s a ‘speedup’ of **0.8 to 1x**\n\nThese four speedup estimates combine via a [Guesstimate model](https://www.getguesstimate.com/models/25630) to get a total speedup of **5.8x (**90% CI: **3.4x to 10x**)**.** (This is within-model uncertainty; our overall actual uncertainty is bigger) Some other adjustments:\n\n* There may be other helpful uses of SCs which are missing on this list, which would combine with the above to make overall research velocity even faster. For example, SCs could cheaply and quickly construct richer, more diverse, and more challenging training environments, with better shaped rewards. This isn’t improving scientific understanding, but it directly makes the trained models smarter, which still should count.  \n* There may also be other bottlenecks we are unaware of, and the bottleneck of time spent thinking and analyzing and planning etc. might bite earlier than we expect. That said, SCs might help with that too to some extent, or partially obviate the need for it…\n\nA few limitations of this analysis:\n\n* We don’t take into account that the superhuman coder would also help some with experiment selection, which points toward a higher value.  \n* An extension of the model used here gives an implausibly high progress multiplier when used for the SAR below, which points toward a lower value.\n\nWe’re going to forecast **5x**. We reiterate that this is just a guess and that it could be substantially faster or slower in reality.\n\n## From SAR to SIAR\n\n### Overview\n\nNow we’ve reached superhuman AI researcher, and it’s speeding up AI R\\\u0026D by 25x. How long would it be until a superintelligent AI researcher (SIAR) is reached: an AI system that is better than the best human AI researchers to a 2x greater extent than the best human researchers are relative to the AGI company’s median researchers, while being 30x faster and more numerous.\n\nAn overview of the results:\n\n|  | Forecast | Reasoning |\n| :---- | :---- | :---- |\n| SAR to SIAR, humans-only software-only time | 19 years (80% CI: 2.3 to 380\\) [*FutureSearch aggregate*](http://futuresearch.ai/ai-2027) *conditional on SAR in 2027 (n=3): 11.5 years (1.75, 27\\)* | Based on comparing the time between automated median researcher and SAR ([more](#human-only-timeline-from-sar-to-siar)). |\n| SAR progress multiplier | 25x | A combination of 3 methods, most prominently relying on surveys of AI researchers answering questions about various hypothetical scenarios ([more](#sar-would-25x-ai-randd)). |\n| SIAR progress multiplier (in [next section](#siar-would-250x-ai-randd), needed to calculate intermediate speedups) | 250x | Based on survey data regarding returns to better researchers within the human range ([more](#siar-would-250x-ai-randd)). |\n| Time between SAR and SIAR | 0.3 years (80% CI: 0.04 to 56 [*FutureSearch aggregate*](http://futuresearch.ai/ai-2027) *conditional on SAR in 2027 (n=3): 1 year (0.1, 2.1)* | Via [simulation](https://github.com/uvafan/timelines-takeoff-ai-2027) |\n\n### Human-only timeline from SAR to SIAR\n\nHere’s a simplified model of how human labor spent improving AI algorithms on a fixed hardware supply might translate into improving AI R\\\u0026D capabilities measured with reference to the human range within OpenBrain:\n\n1. The distribution of AI R\\\u0026D capabilities within OpenBrain is a lognormal distribution in terms of value of labor as cashed out in overall differences in research progress.[^21]  \n   1. It’s confusing to think about what the labor/progress differences would be between the worst project researchers and the median. The distribution might not be lognormal because there’s something like a cutoff that they’re trying to select above (there are probably some outliers though so hard to think about).  \n   2. Based on salaries the labor multiplier between median and lowest is significantly lower than between median and highest. I think there’s something real there due to the cutoff effect. This is ignored in this forecast due to time constraints.  \n2. Each doubling of cumulative human labor spent improving AI algorithms multiplies the AIs’ value of labor by a fixed amount (this is very similar to the assumption made in the [Davidson report](https://www.openphilanthropy.org/research/what-a-compute-centric-framework-says-about-takeoff-speeds/)). In particular, for each doubling of cumulative labor, there are *r* doublings of the value of labor.  \n3. Since the distribution in (1) is lognormal, increasing labor productivity by a fixed multiplier is equivalent to increasing by a fixed amount of SDs within the OpenBrain human range.  \n4. Since SAR-\\\u003eSIAR is the same in terms of labor multiples as 2\\*(automated median OpenBrain researcher-\\\u003eSAR), the amount of cumulative effort doublings to go from SAR-\\\u003eSIAR is twice the amount required to go from automated median OpenBrain researcher-\\\u003eSAR.\n\nWorking within this simplified model, we will think about the arrival of the automated median OpenBrain researcher in our scenario, how much research stock it took to get this and how much research it took to get from the median researcher to SAR.\n\n1. **Human-only years from automated median researcher to SC: \\~0-3 assuming SC has 25th percentile research taste, more uncertainty if not.** Roughly 0-3 calendar months before SC in the case where SC has the median level of research taste we’re projecting (25th percentile, see [above](#human-only-timeline-from-sc-to-sar))**.** This is because the SC is very strong on coding such that it can make up some for its somewhat below average taste.[^22] These 0-3 calendar months translate into approximately 0-3 human-only years, given that [an SC speeds up algorithmic progress by 5x in the median case](#sc-would-5x-ai-randd). There is further uncertainty introduced by the SC having varying levels of taste, including some cases in which it’s already SAR and the median researcher must have been achieved a few months earlier.  \n2. **Human-only years to get from automated median researcher to SAR: 5 years (80% CI: 1 to 25, lognormal).** [Above](#human-only-timeline-from-sc-to-sar) we give a median time of 4 years from SC to SAR, conditional on SC not already being an SAR, but with high uncertainty; the 90th percentile is 20 years. We’d then add on the above 0-3 years human-only years from (1) (in the median taste case), with further uncertainty if we accounted for variations in taste at SC arrival. The quantities of (1) time from automated median researcher \\-\\\u003e SC and (2) time from SC-\\\u003eSAR are anti-correlated, as SC having higher taste increases (1) while decreasing (2). Therefore the lower bound is above 0 (also common sense says it can’t be 0 since SAR is defined as being much better than the median).  \n3. **Total stock of 2025-research-years at the time of automated median researcher: \\~10**. This is a quick estimate based on the pre-2025 stock, the calendar time through approximately SC in March 2027, a bit earlier in the median case.\n\nThinking how diminishing returns work here under our simplified model by doing some casework with a few examples:\n\n1. Human-only years to automated median researcher: 10  \n2. Human-only years from automated median researcher to SAR  \n   1. Case 1: 5  \n      1. This is about 0\\.6[^23] doublings leading to about a 5x progress multiplier, according to the above survey. So this would be r \\= \\~4 (each doubling in total effort means 4 doublings in progress multiplier), which is on the high end of [Davidson’s calculations](https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit?tab=t.0#heading=h.zdfvbdepj7yk) but not wildly off. We tend to have higher r estimations than Davidson due to putting more weight on the importance of qualitative capability jumps (more [below](#davidsons-what-a-compute-centric-framework-says-about-takeoff-speeds)).  \n   2. Case 2: 10  \n      1. This would mean that progress r=\\~2.3, which is similar to [Davidson’s best guess (as of 2022\\)](https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit?tab=t.0#heading=h.limc1xpm5tfc) of r=2 (at the time of full AI R\\\u0026D automation)  \n3. SAR to SIAR human-only software-only time needed[^24] (calculated via needing twice as many overall research effort doublings as the previous step)  \n   1. Case 1: 19 \\= 15\\*2^(2\\*log(15/10)/log(2))-15  \n   2. Case 2: 60 \\= 20\\*2^(2\\*log(20/10)/log(2))-20\n\nOverall I will model my forecast in the following way:\n\n1. Human-only years to automated median researcher: Assumed to be 10 for simplicity  \n2. Human-only years from automated median researcher to SAR: 5 years (80% CI: 1 to 25, lognormal), and with a strong correlation to the SC-\\\u003eSAR human-only years (0.8).  \n3. I’ll then model SAR to SIAR human-only software-only time needed via the formula above.[^25]  \n   \n\nThis gives a median of 19 years (80% CI: 2.3 to 380).  I’ll adopt this as my forecast.\n\n### SAR would \\~25x AI R\\\u0026D\n\n#### Overview\n\nFirst, we discuss [what having SARs will look like](#what-having-sars-will-look-like). Then, we forecast the SAR progress multiplier via a few methods:\n\n|  | Forecasted progress multiplier | Reasoning |\n| :---- | :---- | :---- |\n| Method 1: [Speedup decomposition](#method-1-speedup-decomposition) | 417 (90% CI: 130 to 1900\\)  | Combining a breakdown of expected speedups from SAR |\n| Method 2: [Surveys on subquestions](#method-2-surveys-on-subquestions) | 26 (90% CI: 8 to 139\\) | A progression of hypothetical scenarios informed by our surveys of AI researchers |\n| Method 3: [More direct survey](#method-3-more-direct-survey) | 24 (90% CI: 5 to 112\\) | We take a [recent survey](https://www.forethought.org/research/could-advanced-ai-accelerate-the-pace-of-ai-progress-interviews-with-ai) of researchers about how much progress would speed up if every company employee had access to 30x copies thinking at 30x speed, then adjust upward for all SARs being as good as the best researchers. |\n| Overall forecast | 25 | We think that both methods 2 and 3 are more reliable than method 1 and surprisingly converged to a similar answer. Therefore, we forecast an SAR progress multiplier of 25x. |\n\n#### What having SARs will look like\n\nNow *all* the labor is automated. What does this look like quantitatively?\n\nOur [compute forecast](https://ai-2027.com/research/compute-forecast) projects that OpenBrain will have about 10,000,000 H100-equivalents in 2027\\. If they allocate 5% of their compute to inference for AI R\\\u0026D, then (given our other guesses about e.g. model size, latency bottlenecks, etc.) we think they’d be able to run 200,000 automated researcher copies, each at \\~400 tokens/second. As in the SAR definition, this workforce is equivalent to 50,000 agents[^26] accomplishing tasks at 30x the rate of the best humans.\n\nWe think they might have access to a small quantity of specialized chips (e.g. Cerebras) able to run a smaller population of AIs at up to \\~2000 tokens/second.\n\n  \n:::DeploymentCurves  \n:::\n\nThe effect of SARs is simpler to analyze compared to SCs. *All* of the labor (including experiment selection) is sped up by 30x, plus there are 30x more parallel laborers, plus all of the AIs are like the best researcher sped up rather than one corresponding to each individual researcher.\n\n#### Method 1: Speedup decomposition\n\nTo forecast SAR’s progress multiplier, we first did a breakdown similar to the previous one for SC. We thought about all the ways having SARs could accelerate things above and beyond what SCs would already accomplish. We came up with the [following list:](https://www.getguesstimate.com/models/25630)\n\n| Factor | Speedup |\n| :---- | :---- |\n| Flexible prioritization | 1.5 to 3 |\n| Experiment design debugging \u0026 early stopping | 1.5 to 3 |\n| Smaller experiments when possible part II | 1.5 to 3 |\n| Even fancier experiments | 1.1 to 1.5 |\n| Lack of diversity creates blindspots | 0.3 to 1 |\n| Improved research taste via quantity | 2 to 8 |\n| Improved research taste via quality | 1.5 to 5 |\n| SC AI R\\\u0026D progress multiplier | 5 |\n| SAR AI R\\\u0026D progress multiplier | 417 (90% CI: 130 to 1900\\)  |\n\nHowever, this progress multiplier feels too high.\n\n#### Method 2: Surveys on subquestions\n\n| Scenario step | Progress multiplier estimate | Reasoning |\n| :---- | :---- | :---- |\n| All researchers at OpenBrain are sped up by 30x | 7 | A survey says that AI researchers would make progress 40% as fast with 10x less compute. Being sped up 30x means you have 1/30 of the compute per subjective-time, which gives us 22% of the 30x rate of progress.[^27] |\n| Add 30x parallel labor | 3 (90% CI: 1.5 to 6\\) | Estimated by brainstorming what parallel labor would be helpful for. |\n| Make everyone as competent as the best researcher | 2.5 (90% CI: 1.25 to 5\\) | Halving a survey result for the question of how much more productive a company with all best researchers would be than one with all median researchers. |\n| Less diversity | 0.25 to 0.95 | AIs might lack the diversity of human organizations. |\n| SAR achieved | 26 (90% CI: 8 to 139\\) | [Guesstimate](https://www.getguesstimate.com/models/25630) |\n\nLet’s consider a simplified hypothetical, in which every human researcher and engineer in the AGI project is replaced with a digital copy of themselves that accomplishes tasks 30x faster. How much would the pace of AI R\\\u0026D progress in the company speed up then?\n\nWe have some informal, nonscientific survey data of ML researchers, asking two related questions:\n\n1. How much faster would your overall research progress be if you had access to 10x as much compute as you do now?  \n2. How much slower would your overall research progress be if you had access to 10% as much compute as you do now?\n\nThe results are:\n\n1. From an informal [Twitter poll](https://x.com/RichardMCNgo/status/1859290893943193834) re: increased speed from 10x compute (n=185): Median of 1.2x-2x, toward the high end.[^28]  \n2. From an informal Slack poll of AI safety researchers (n=6):  \n   1. Increased speed from 10x compute: 1.18x median (1.01 to \\\u003e1.5)[^29]  \n   2. Decreased speed from 10% of compute: 0.6x median (0.2 to 1)[^30]\n\nWhile these surveys are informal and have a low sample size and wide error bars, they are better than nothing. Here we are most interested in the question of decreased speed from having 10% of the compute. We got a 0.6x median from the Slack poll, but this was from people whose work seemed less compute-intensive than the Twitter poll, whose work may be further less compute-intensive than frontier AI researchers. Therefore we shade down and speculate that for frontier AI researchers, decreasing compute by 10x reduces speed to 40% of the current rate.\n\nExtrapolating these results a bit, we estimate that reducing compute budgets by 30x would cut the pace of software progress to about 22% of the current rate.[^31]\n\nIn this hypothetical, we can think of the pace of software progress as being 30 times faster, times 22% (because the 30x-faster-workers have 1/30th as much compute per unit of subjective time), leading to a 7x progress multiplier.\n\nWe start with this 7x figure then gradually remove simplifications from the hypothetical until it has transformed into the actual SAR scenario.\n\nThe first simplification to remove is that in the SAR situation there are 30 times as many SARs as there were company researchers, roughly. Now, [nine women can’t make a baby in a month](https://en.wikipedia.org/wiki/Brooks%27s_law), so this 30x increase in parallel labor will translate to far less than a 30x increase in actual progress; but it will still be helpful. Assuming that compute-for-experiments will be the bottleneck in this regime, there are still ways in which having 30x more scientific labor can help ameliorate that bottleneck such as:\n\n* Watching experiments as they run, debating their implications, and stopping them as soon as starting the next experiment seems more valuable than continuing to watch the learning curve grow.  \n* Putting 30x more thought into the design each experiment, making sure that it is not only bug-free but confounder-free and testing the right hypotheses etc.  \n* Having more and better thoughts go into analyzing each experiment and deciding what to prioritize next.  \n* Rapidly pursuing all the parts of the tech tree that don’t involve costly experiments, such as ML theory, interpretability, evals…\n\nOverall we estimate that this 30x parallel labor factor would speed things up by 3 (90% CI: 1.5 to 6\\)**.**\n\nAnother simplification to remove is that instead of the AIs being digital copies of all of the human employees of varying ability. SARs will be, by definition, as good as the very best scientists and engineers. So the average ability level will rise to the maximum ability level.\n\nWe conducted a small survey ourselves to get information about this—specifically, in November 2024 to March 2025 we surveyed some of our friends who currently or formerly work as researchers or engineers at OpenAI and Google DeepMind. We asked, paraphrased: “how much faster would research go if everyone in your company was as good as the best, compared to if everyone in your company was as good as the median (for your company)” Prior to seeing their answers our estimate was 4x faster; the median response was 6.25x (n=8) .\n\nOur estimate is that going from the present day distribution to having all researchers be at the level of the best captures half of the speedup from going from all median to all best researchers. So we estimate the overall speedup from this factor will be about 2.5 (90% CI: 1.25 to 5\\).[^32]\n\nOne factor remains: diversity loss. “Bring all your researchers up to the level of the best” is better than “make all your researchers copies of the best,” because any individual might have blind spots or weaknesses that others lack. The SARs will mostly be copies of each other, so this problem might bite more than it bites in human research organizations which come with some degree of diversity built-in simply by virtue of having multiple employees. We think this might matter a lot, with high uncertainty. We wildly guess this multiplies overall research velocity by **0.28x to 0.95x.**\n\n[Combining all these numbers](https://www.getguesstimate.com/models/25630), we get a total multiplier of 26 (90% CI: 8 to 139\\) from SARs.\n\n#### Method 3: More direct survey\n\n[A recent report](https://www.forethought.org/research/could-advanced-ai-accelerate-the-pace-of-ai-progress-interviews-with-ai) surveyed five current or past employees of frontier AI companies in March 2024, asking them to engage in the following hypothetical scenario that is coincidentally quite similar to ours:\n\n*“Imagine that compute available for experiments and training is basically increasing at the rate it’s been increasing over the last several years, but now, there is one big difference: there are 30 AI-powered copies of each person at your company working 30 times as fast… Now let’s look at things from a very high level, what do you think would be the overall pace of frontier lab AI capabilities progress, compared to the current pace?”*\n\nThe results ranged from about 1.5x to 20x, with a log-mean of \\~5x.[^33] We represent this as a lognormal with median \\~5, 90% CI 1.25 to 20\\.\n\nThere were 2 differences between the survey and the SAR progress multiplier:\n\n1. **The survey asks about overall AI progress, while we focus on software progress:** therefore we multiply by **2x** since about half of current progress is from training compute, meaning that with high progress multipliers the overall progress speedup is about ½ the software progress speedup.  \n2. **The survey asks about making copies of every researcher, the SAR is as competent as the best researcher: 2.5** (90% CI: 1.25 to 5\\)\n\nThis gives a result of 24 (90% CI: 5 to 112).\n\nThese researchers were also asked more specific questions about e.g. the speedup that would come specifically from being able to reliably debug experiments before running them, from being able to better prioritize resources, from being able to do experiments at smaller scale when possible, from being able to run fancier experiments, etc. Perhaps unsurprisingly given the massive uncertainties involved and the small amount of time spent thinking about it, the numbers they give for the per-factor speedups typically multiply together to get results that are significantly higher than the answers that they gave directly (the combined per-factor speedups have a log-mean of 14).\n\n## From SIAR to ASI\n\n### Overview\n\nNow we’ve reached a superintelligent AI researcher. How long would it be until an artificial superintelligence (ASI) is reached: an AI system that is 2x better at every cognitive task relative to the best human professional, than the best human professional is relative to the median human professional (across the whole field, not a single company as in SAR).\n\nAn overview of the results:\n\n|  | Forecast | Reasoning |\n| :---- | :---- | :---- |\n| [SIAR to ASI, humans-only software-only time](#human-only-timeline-from-siar-to-asi) | 95 years (80% CI: 2.4 to 1,000,000) | Based on comparing the jump to that from a SAR to SIAR ([more](#human-only-timeline-from-siar-to-asi)). |\n| [SIAR progress multiplier](#siar-would-250x-ai-randd) | 250x | Based on survey data regarding returns to better researchers within the human range ([more](#siar-would-250x-ai-randd)). |\n| [ASI progress multiplier](#asi-would-2000x-ai-randd) (needed to calculate intermediate speedups) | 2,000x | Based on comparing the jump to that from a SAR to SIAR ([here](#asi-would-2000x-ai-randd)). |\n| Time between SIAR and ASI | 0.16 years (80% CI: 0.01 to \\\u003e100) | Via [simulation](https://github.com/uvafan/timelines-takeoff-ai-2027) |\n\n### Views on experiment selection\n\nGiven that without improved experiment selection (i.e. research taste) we’d hit sharply diminishing returns due to hardware and latency bottlenecks, forecasting improved experiment selection above the human range is quite important.\n\nOur further progress multiplier forecasts are informed by two key views regarding experiment selection:\n\n1. **Large human variability:** There is a substantial difference in experiment selection ability even between even the median and top AGI company employee, as evidenced by our researcher survey which found an estimated 6.25x difference in research progress between a company of all median and all best employees, including a 3.25x difference based on experiment selection.  \n   1. **Reasoning:** Observing and discussing with researchers at AGI companies, the above survey, and observing salary differences.  \n2. **Large headroom above the human range:** There is a very large amount of headroom in experiments selection skill above the top humans, for AIs at the limits of intelligence (\\\u003e=1000x difference based just on experiment selection and not implementation).  \n   1. **Reasoning:** We don’t see sharp diminishing returns at the top of the human range, and we don’t have reason to believe that humans are near the limits of general intelligence.\n\n### Human-only timeline from SIAR to ASI\n\nI’ll think about this in relative terms to how long it takes to cross from SAR to SIAR human-only as forecasted [above](#heading=h.wwky4apb3rya).\n\nThere are 2 gaps to cross between SIAR and ASI:\n\n1. **Achieving 2 (median-\\\u003ebest jumps) above the best human when looking at the whole field rather than a single company: a bit less than an SAR-\\\u003eSIAR jump**  \n   1. For AI R\\\u0026D, my guess is that this requires a bit less of a jump as SAR-\\\u003eSIAR, because the median ML professional is a bit better than the worst AGI company researcher (if the worse researcher were as much worse than the median as the median was compared to the best, which may not be true in practice due to hiring cutoffs).  \n2. **Achieving ASI in all cognitive tasks rather than just AI R\\\u0026D: About half of an SAR-\\\u003eSIAR jump.**  \n   1. I think once an AI is extremely good at AI R\\\u0026D, lots of these skills will transfer to other domains, so it won’t have to be that much more capable to generalize to all domains, especially if trained in environments designed for teaching general skills.\n\nAgain using a Davidson-style function for diminishing returns as I did for [SAR to SIAR](#human-only-timeline-from-sar-to-siar), I then model time required to get from SIAR to ASI by doing the following:\n\n1. Get the total stock of human-only years up through SAR, and the years between SAR and SIAR drawing upon the results of the SAR to SIAR forecast.  \n2. SIAR to ASI human-only software-only time is determined by:  \n   1. Drawing SAR-to-SIAR-equivalent-jumps needed to get from SIAR to ASI: median 1.5 jumps (80% CI: 0.3 to 7.5; lognormal). I’ve shaded this up from 1.25 due to the expectation that r will be increasing.  \n   2. Use the same formula structure as used for [SAR to SIAR](#human-only-timeline-from-sar-to-siar) to compute the forecasted distribution.[^34]\n\nThis results in a forecasted median of 95 years (80% CI: 2.4 to 1,000,000). We think that the 90th percentile is probably too high, though keep in mind this is software-only improvements, so it’s at least conceivable that these would slow down dramatically before reaching ASI, with no increases in training compute.\n\n### SIAR would \\~250x AI R\\\u0026D\n\nThe median of our survey says that switching from all median to all top researchers would give a \\~6.5x algorithmic progress speed boost. When only considering “research taste” rather than engineering the median is 3.25, and this may be more relevant because once we get to superhuman automated researchers we may be strongly bottlenecked on non-engineering tasks. Let’s say that the multiplier is roughly 3.25 once we’re above SAR.\n\nGoing from SAR to SIAR is by definition like 2 of these jumps, so 3.25^2 which is about a 10x increase in the progres multiplier. This gives a 250x progress multiplier.\n\n### ASI would \\~2,000x AI R\\\u0026D\n\n[Above](#human-only-timeline-from-siar-to-asi) we estimated that without shading down for being decreased, going from SAR to SIAR would involve a median of 1.25 SAR-to-SIAR-equivalent-jumps This would naively result in a 10^1.25 increase in the progress multiplier. However, we should shade down for r decreasing, let’s shade down to an 8x on SAR for a rough estimate of 2,000x.\n\n## Related work\n\n### Davidson’s “What a Compute-Centric Framework Says About Takeoff Speeds”\n\n[This 2023 report](https://www.openphilanthropy.org/research/what-a-compute-centric-framework-says-about-takeoff-speeds/) by Tom Davidson utilizes economic modeling to predict AI takeoff dynamics ([description](https://takeoffspeeds.com/description.html), [playground](https://takeoffspeeds.com/playground.html)). The primary model is *not* designed to predict what happens once AI R\\\u0026D is fully automated, e.g. the transition from SAR to SIAR. [The section](https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit?tab=t.0#heading=h.iaqy7rxuutko) that predicts what happens after full automation projects a 65% chance of a software-only singularity, which would in the median case result in 2-3 OOMs of effective compute increase conditional on it happening.[^35] In forthcoming work, Davidson projects upon fully automating AI R\\\u0026D a 50% chance of squeezing 3 years of normal AI progress (roughly 3-4 OOMs of effective compute on Davidson’s calculations) into 1 year.\n\nWhile we haven’t been thinking primarily in OOMs of normal years of progress, if we use the Davidson-like model of diminishing returns discussed in the [SAR-\\\u003eSIAR section](#human-only-timeline-from-sar-to-siar), we back out that our median value for “r”, the rate of returns to increased effort on software progress, is 4 (as discussed in “Case 1: 5”). Davidson’s [best guess in 2022 was r=2](https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit?tab=t.0#heading=h.limc1xpm5tfc), in more recent forthcoming work his estimate is now 1.2. An r above 1 means that each increase in the AIs’ intelligence is getting successively faster over time, and r goes down over time as we get closer to the limits of intelligence. We note that Davidson’s expectations overlap significantly with ours: e.g. r=2 is within the bounds of each of our uncertainties.\n\nOur disagreement regarding r primarily comes down to intuitions regarding accounting for jumps to new capabilities. Davidson primarily estimates r via measuring *efficiency improvements*: e.g. seeing how much less training compute 2025 algorithms take to get to the performance of AIs from 2015.[^36] However, we need to also take into account *capability improvements:* improvements in AI capabilities at a fixed training compute threshold. These can be thought of as efficiency improvements that are measured “up” rather than down: e.g. seeing how much more training compute 2015 algorithms require to get to 2025 performance than 2025 algorithms. However, these are more difficult to measure.\n\nOne might get much higher estimates for r when measuring up: algorithms might scale poorly to qualitatively new capabilities. Consider how even if Magnus Carlsen studied chess for billions of years, he would never be as good as the top computer chess engines (and if not him, definitely more typical humans). There might even be effectively infinite qualitative jumps with large enough algorithm improvements.\n\nDavidson multiplies r by 2 to account for improving capabilities at a fixed compute level, what we’ve called measuring up. We think that multiplying by 2 is insufficient to address the qualitatively large gains that come from unlocking new capability levels (eventually likely achieving capability levels that previous training methods could never have achieved, with infinite compute/data).\n\nThere is further discussion of this issue in an unpublished draft authored by Eli [here](https://docs.google.com/document/d/1b6IREn9MkRgM5in5qQQcvbmT6Lury0Z5MqhpMRbFAFY/edit?tab=t.0#heading=h.iqumj8wd805w). The draft also contains sections on [other issues with Davidson’s model](https://docs.google.com/document/d/1b6IREn9MkRgM5in5qQQcvbmT6Lury0Z5MqhpMRbFAFY/edit?tab=t.0#heading=h.cknbodkjl8nl). \n\nWe are generally optimistic about modeling specific capability levels as we’ve done in this draft, as a complement to doing economic modeling fit to past data. We are wary of relying too strongly on mathematical models to predict qualitative performance changes, though we think they are still very informative.\n\nSee also [this discussion](https://www.lesswrong.com/posts/FG54euEAesRkSZuJN/ryan_greenblatt-s-shortform?commentId=z7sKoyGbgmfL5kLmY) of one conception of a software-mostly intelligence explosion and its likelihood.\n\n### GATE\n\n[GATE](https://epoch.ai/gate) is a recently released [Epoch](https://epoch.ai/) model that builds upon Davidson’s model to create a version that is more focused on broad economic automation ([scenario explorer](https://epoch.ai/gate#ai-compute), [paper](https://arxiv.org/pdf/2503.04941)). Like Davidson, they [don’t claim](https://epoch.ai/gate#documentation-faq) that their model makes good predictions about what happens close to or after full automation.\n\nThe primary change they make which is relevant to a potential software-only intelligence explosion is that they make investment the driver of AI software R\\\u0026D (i.e. an allocation from GWP), rather than allowing improved software efficiency to directly be used for further R\\\u0026D. This leads to less aggressive takeoff predictions, though it has a bit faster timelines.\n\nWe prefer Davidson’s choice. Epoch’s modeling emphases are related to the view that [most AI value will come from broad automation, rather than R\\\u0026D](https://epochai.substack.com/p/most-ai-value-will-come-from-broad). In the post, Erdil and Barnett argue that the value of AI will be driven by broad economic deployment, rather than R\\\u0026D, because:\n\n1. Economic estimates of the value of R\\\u0026D generally find it explains about 20% of labor productivity growth, with the rest mostly accounted for by an increase in capital per hour of labor (capital deepening).  \n   1. **Our response:** It seems plausible that most of the AIs’ value generated will eventually end up being non-R\\\u0026D. But we think the R\\\u0026D will still unlock huge capabilities in a short amount of time.  \n2. AI R\\\u0026D automation isn’t a special case: r is probably below or near 1 once accounting for reliance on experiment compute and data, and if it starts above 1 it will likely decrease to below one soon after the start of a software-only intelligence explosion, leading to a less than 10x efficiency improvement.  \n   1. **Our response:** As discussed in the [above section](#davidsons-what-a-compute-centric-framework-says-about-takeoff-speeds), we have higher estimates of r. We agree that these other considerations need to be taken into account but think that r will likely remain significantly above 1\\. Davidson discusses the need for experiment compute [here](https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit?tab=t.0#heading=h.limc1xpm5tfc).  \n3. Automating AI R\\\u0026D would require a broad set of abilities, perhaps being automated after general labor.  \n   1. **Our response:** We agree that AI R\\\u0026D requires a broad set of abilities that would transfer to other domains. However, we think it will be automated early in practice because of (a) incentives to automate it first, (b) easy access to data and (c) reliance on cognitive skills. We can also observe that coding has been one of the jobs most susceptible to automation thus far.\n\nAdditionally, in Epoch’s default case they set the maximum software efficiency relative to today to be 10,000, which we consider to be far too low. In [Davidson’s model](https://takeoffspeeds.com/playground.html), this parameter is set to 1e12 by default.\n\n## Addressing common objections\n\nAbove we’ve done a relatively mechanistic analysis of when AI milestones will be reached and what the implications are, and come away with the conclusion that it’s likely there will be a “software-only intelligence explosion” in the sense that due to AI software progress on a fixed hardware supply, we will most likely go from superhuman coders to superintelligent AIs within a year. This becomes even more likely if we allow for some hardware increases, a software-”mostly” intelligence explosion.\n\nBelow we address some common objections to (a) the likelihood of such fast progress and (b) the consequences of such fast progress.\n\n### Amdahl’s Law\n\nWe’ve heard a few people make the argument that because automation can only speed up some aspects of R\\\u0026D so much (e.g. gathering human data), progress will be bottlenecked on these tasks leading to not-very-large progress multipliers (see [Amdahl’s Law](https://en.wikipedia.org/wiki/Amdahl%27s_law)).\n\nIn particular, they argue something like: *Task X currently takes 10% of researchers’ time during AI software R\\\u0026D. Therefore if it's not sped up by automation, AI software R\\\u0026D can't be sped up by more than 10x.*\n\nWhile there is some truth to this, the claim does not hold because the speed of accomplishing current AI software R\\\u0026D sub-tasks doesn’t constrain the speed of the overall process. \n\nTo see why this is conceptually mistaken, consider a theoretical AI with very superhuman experiment selection capabilities but sub-human experiment implementation skills. Even if automation didn’t speed up implementation of AI experiments at all and implementation started as 50% of researchers’ time, if automation led to much better experiments being chosen, a \\\u003e2x AI R\\\u0026D progress multiplier could be achieved.\n\nRegarding the extent to which these sorts of bottlenecks will hold in practice: regarding gathering human data, we think that synthetic data will likely ameliorate this bottleneck. Additionally, we’ve argued that it’s likely that improved experiment selection has a high ceiling [above](#views-on-experiment-selection), and to the extent one can select Nx more valuable experiments this multiplies the progress multiplier Nx, regardless of the rest of the research process.\n\n### Compute is the dominant driver of AI progress\n\nThis view posits some combination of (a) training compute matters far more than algorithmic progress (b) experiment compute matters far more than researcher quality and quantity for algorithmic progress, (c) algorithmic progress is driven by adapting to larger compute scales and (d) once AI R\\\u0026D is fully automated, algorithmic progress will be close to fundamental limits which will make compute the dominant driver of further progress.\n\nThere’s lots to say about this. First, we’ll note that we agree that compute is both (a) an important driver for overall AI progress and (b) the importance of compute for experimentation. We take into account these bottlenecks in our forecasts, but some disagree with us about how hard these bottlenecks bite.\n\nWe’ll note just a few arguments here regarding why we have more aggressive predictions regarding, given that this is addressed to some extent above in the sections discussing AI R\\\u0026D progress multipliers:\n\n1. A survey of a few frontier AI researchers yielded an estimate of approximately a 6x increase in the pace of algorithmic progress if the company had only copies of the median researchers vs. the best researcher, with a fixed compute budget.  \n2. AGI companies pay very high compensation packages to their top researchers, and have been growing quickly.  \n3. AI models have consistently gotten much better over time at a fixed compute cost (some of this is due to distillation though).  \n4. AIs have structural collective advantages relative to humans (see [article](https://www.dwarkesh.com/p/ai-firm)).  \n5. It seems unlikely that AIs will be anywhere near the physical limits of intelligence/learning when AI R\\\u0026D is fully automated, based on (a) the AIs potentially being less efficient than humans at this point (b) the distribution of skills within the human range suggesting large gains near the top and therefore likely large gains above the top (c) known inefficiencies in the human brain.\n\n### The AI R\\\u0026D progress multiplier has to plateau somewhere, why not below 10,000x? Why not below 1,000x?\n\nWe agree that the progress multiplier has to plateau somewhere. In our scenario we depict it continuing to rise as the milestones SC, SAR, SIAR, and ASI are achieved, and rising further still after that. Why? Why do we depict it rising all the way to 1,000,000x by 2035?\n\nWe are in fact very uncertain about how high (or low) the plateau will be. We did not put much effort into estimating this quantity because it does not seem important to the story—the story would go basically the same if the progress multiplier plateaus at 1000x, for example.\n\nHowever, our best guess is that the multiplier will eventually get much higher than 1000x.\n\nRecall that according to our small survey of frontier AI company researchers, the research taste gap *alone* is about 3x between their company’s median and best researchers. Recall that research taste is basically how fast you learn from experiments (by e.g. choosing better experiments to run, and by arriving at more correct conclusions). The median researchers at frontier AI companies are pretty good\\! They are probably at least 3x research taste multiplier over the global median AI researcher, possibly 10x. And they are vastly better than the average human, who basically couldn’t do AI R\\\u0026D at all.\n\nThe point we are making is that the distribution of humans by research taste appears to be heavy-tailed and does not appear to be asymptoting against any inherent limits.  \n  \n![](/einstein.png)\n\nGiven a distribution of this shape, where *should* we expect the ceiling/asymptote? Our thinking is shaped by an analogy to [Lindy’s Law](https://en.wikipedia.org/wiki/Lindy_effect), which states that the unknown part of a distribution should increase proportionately to the known part. That is, if a pile of leaves on a lawn has existed for several days, our prior for its remaining lifespan should be measured in days; if the Great Pyramid has existed for several millennia, our prior for its remaining lifespan should be denominated in millennia. By a hand-wavy version of the same principle, we speculate that maximum-achievable-for-humans research and engineering speed could be about as far from the top human geniuses as they are from their more normal peers. This is highly speculative, and we don’t want to claim anything with confidence except that the upper end of the distribution probably is not coincidentally at the exact last point we have measured.\n\nThis in turn suggests that merely by massively increasing the size of the human population (e.g. by having 1000 Earths, or a million) there would exist a human with substantially better research taste than the best humans today. Perhaps about 10x better, to be precise—requiring 10x fewer resources for AI experiments to make the same amount of algorithmic progress. (This corresponds loosely to the SIAR, which is roughly 10x better than SAR, which is like the best human researcher but faster and cheaper.)\n\nBut the space of all possible humans is a tiny region within the space of all possible minds. Indeed, the space of all possible minds *accessible in design-space by the army of SIAR geniuses on the datacenters* is much bigger than human mindspace—there are more degrees of freedom to experiment with, e.g. brain size, core learning algorithms, core neural net architecture, hybrids of various things…\n\nThis suggests that there should be an additional gap between the research taste of a SIAR and what could eventually be reached during an intelligence explosion. How big is this gap? We can reason about inefficiencies in the brain and how much better AI might be able to get on these dimensions. In particular, it seems likely that there are architectures much more efficient than neural networks and learning algorithms much more efficient than the brain’s.\n\nBut overall this sort of thing is hard to reason about: our situation is like that of a caveman walking down the beach and into the ocean, noticing that the water gets too deep for him to walk, and then wondering how deep it eventually gets miles away from shore.\n\nAnother consideration is that in some sense the progress multiplier has to go to infinity in some domains. Recall that the progress multiplier is relative: Speed of R\\\u0026D *relative* to the speed unaided humans would go. A 100x multiplier means that research that would take humans a century, happens in a year. But eventually AIs will be making discoveries that human civilization simply never could have made. (Just as human civilization has made discoveries that chimpanzees simply never could have made.) This naively translates to a progress multiplier of infinity. We aren’t sure how to handle this conceptually, but we bring it up because (if you like) you can think of ridiculously large multipliers like 1,000,000x as really saying something like “In some domains, the ASIs have a progress multiplier of 1,000x. In others, it’s much higher. In others, it’s infinite. The latter are common enough compared to the former that in effect it ‘averages out’ to 1,000,000x.”\n\n## Limitations\n\nDue to time constraints, important dynamics that we weren’t able to model include but aren’t limited to:\n\n1. Uncertainty over AI R\\\u0026D progress multipliers.  \n2. Training and experiment compute increases.\n\nFuture work could improve upon these limitations.\n\nWe are also excited about other methods of takeoff forecasting which complement the perspective we’ve laid out here.\n\n## Appendix\n\n### AI R\\\u0026D progress multiplier clarifications\n\n**W**e recognize that these seem inelegant and encourage others to suggest improvements.\n\n1. **What uses of AI are allowed in the without-AI condition:** AIs can only be used to play a “static role” in either (a) the training or design process (e.g. synthetic data generation, distillation) or (b) experiments. It can’t be used to improve the training or design process, or to improve ideation/prioritization or implementation of experiments.  \n   1. We need to include some uses of AIs, for example allow them to be used as subjects in experiments, as we want to restrict AI productivity increases to activities like those human researchers currently do.  \n2. **Assume that for the starting conditions (i.e. for SC in Mar 2027), a project’s progress multiplier has conditions set by OpenBrain’s (the fictional leading AGI company in our scenario) human labor supply and compute levels are based on our trend extrapolation [projections](https://ai-2027.com/supplements/compute-forecast) ignoring research automation.** We decided to set things this way in order to preserve the same progress multipliers across different situations, though it trades off against the relevance to the particular situation, so we’re unsure about what’s best to do. More reasoning in a footnote.[^37]  \n   1. For the without-AI condition: The human research labor is as if current growth trends continued for OpenBrain, as is the compute supply. That is, every company has a without-AI condition that is defined based on OpenBrain researchers with historical growth rates. If new human researchers are hypothetically brought in, they are allowed time to adapt to the company and AIs.  \n   2. For the with-AI condition: The same as above, but with AI assistance of the latest AI systems at the relevant company (i.e. not OpenBrain, but the company for which the progress multiplier is being calculated) allowed.  \n3. **Restricting to algorithmic progress:** We restrict to activities that are primarily aimed at algorithmic progress and limit compute scaling to a small amount (e.g. maybe 1% of FLOP/s, and a total max of scaling the largest training run by 1%), intending for it only be used to experiment with improved algorithms.[^38]\n\nDue to (2) above, the AI R\\\u0026D progress multiplier **should** **not be interpreted as a multiplier on the current human labor in the relevant time period. It’s instead a multiplier on a labor supply projected from what would happen if there were no AI automation.**\n\nKeep in mind that different AI capabilities may lead to different sorts of research agendas being pursued. When discussing the progress multiplier, reduce these differences including potential qualitative differences in which agenda are pursued to a single dimension for simplicity.\n\n### Modeling “experiments getting harder to find”\n\nIn early 2024 Eli coded up a model which directly models the experiment process including modeling an actual pool of experiments, how long each takes to implement, and how valuable they are. More details about the model are [here](https://docs.google.com/document/d/14PDTL2EVfVCxoQGy3myLwPdZ_ZeLOmKZJ0rK-A4MTCU/edit?).\n\nWe think this approach has some promise, but unfortunately have not found time to explore it in detail.\n\n[^1]:  The interpolation is done exponentially.\n\n[^2]:  Some of the model parameters were chosen by Daniel and others by Eli. Due to time constraints, we weren’t able to independently make estimates for each parameter. To the extent this forecast represents a single person’s view, it’s closer to being Daniel than Eli. That being said, they both find the overall distributions plausible.\n\n[^3]:  We also solicited forecasts from 4 professional forecasters from [FutureSearch](https://futuresearch.ai/) (bios at [http://futuresearch.ai/ai-2027](http://futuresearch.ai/ai-2027)). Their forecasts for SC-\\\u003eSAR and SAR-\\\u003eSIAR are included as footnotes in the table below, and expanded upon in later sections.\n\n[^4]:  These are sometimes different from the projected dates because we have been making adjustments to our timelines and takeoff forecasts beyond when we locked in the progression in the scenario. As you can see, we have enough uncertainty that we find the dates in the scenario nearly as plausible as our medians.\n\n[^5]:  FutureSearch aggregate: Oct 2027 (Mar 2027 to Apr 2029\\)\n\n[^6]:  [FutureSearch aggregate](#heading=h.olwhwylhlp4e), years from SAR-\\\u003eSIAR conditional on SAR in 2027: 1 year (0.1, 2.1) ([more](#heading=h.q591y7b45azm))\n\n[^7]:  The interpolation is done exponentially.\n\n[^8]:  The reason 5% is used is because it’s approximately the fraction that we project AI projects to be spending around the time they reach SC: see the “Research automation” row in our [compute supplement](https://ai-2027.com/supplements/compute-forecast#section-3-compute-usage).\n\n[^9]:  Note that an “agent” may on average use multiple model copies/instances running at once, e.g. in the simplest case doing [best of many tries in parallel](https://arxiv.org/pdf/2412.03556).\n\n[^10]:  Technically, we define this and the below milestones are based on 30x the amount of human researchers they would have based on our best projections as of 2025 ignoring research automation, to account for issues around hiring more slowly or firing people due to them being automated substantially changing the milestone. (see [clarification (2) below](#ai-randd-progress-multiplier-definition)).\n\n[^11]:  We aren’t including experiment bottlenecks or other non-cognitive bottlenecks. when measuring task completion speed.\n\n[^12]:  This definition is similar to that of [this report](https://www.forethought.org/research/could-advanced-ai-accelerate-the-pace-of-ai-progress-interviews-with-ai) which interviewed AI researchers about AI R\\\u0026D automation. In our case, we say that all agents are 30x faster than the best researcher, while they discuss one copy of each researcher sped up 30x.\n\n[^13]: It doesn’t make sense for the definition to use labor rather than log(labor), because this would fit the distribution of AI researcher abilities worse.\n\n[^14]:  We focus on AI R\\\u0026D capabilities because it is the most relevant for takeoff forecasting, but we believe general capabilities and capabilities in other domains will also be improving rapidly, with varying levels of lag compared to AI R\\\u0026D-specific capabilities.\n\n[^15]:  This takes into account compute bottlenecks, but not diminishing returns over time due to picking low-hanging fruit (which we prefer not to include in order to isolate the algorithmic progress variable in our takeoff forecasting, as well as the most obvious versions of adjusting being highly sensitive to choices like whether to take the log() of the chosen metric).\n\n[^16]:  The reason 5% is used is because it’s approximately the fraction that we project AI projects to be spending around the time they reach SC: see the “Research automation” row in our [compute supplement](https://ai-2027.com/supplements/compute-forecast#section-3-compute-usage).\n\n[^17]:  Note that an “agent” may on average use multiple model copies/instances running at once, e.g. in the simplest case doing [best of many tries in parallel](https://arxiv.org/pdf/2412.03556).\n\n[^18]:  Technically, we define this and the below milestones are based on 30x the amount of human researchers they would have based on our best projections as of 2025 ignoring research automation, to account for issues around hiring more slowly or firing people due to them being automated substantially changing the milestone. (similar rationale to (2) above).\n\n[^19]:  We aren’t including experiment bottlenecks or other non-cognitive bottlenecks. when measuring task completion speed.\n\n[^20]:  They might not be faster and cheaper at literally every task, but they will likely have massive advantages in many mportant respects.\n\n[^21]:  We could also talk about labor directly, and our best guess would be that the picture stays roughly the same.\n\n[^22]:  If there were no humans to help improve taste their labor is probably still more valuable as the median OpenBrain researcher but less valuable than the 90th percentile, as their engineering skills make up for their taste deficit.\n\n[^23]:  log(15/10)/log(2)\n\n[^24]:  Technically R should go down over time as well, but this shouldn’t be a large effect on short timescales, so I’m assuming it stays the same.\n\n[^25]:  (10+AMR\\_to\\_SAR)\\*2^(2\\*log((10+AMR\\_to\\_SAR)/10)/log(2))-(10+AMR\\_to\\_SAR)\n\n[^26]:  Which is about 30x what we project the OpenBrain researcher population to be in 2027\\.\n\n[^27]:   0.4^(log(30)/log(10))=0.22 Note that after making this estimate we remembered that AIs would not need to sleep or eat or otherwise rest, and can instead work round-the-clock. This means that compared to top humans they will in some sense be not 30x but 60x or 100x faster, arguably. However, this is not as valuable as a literal thinking-time serial speedup for various reasons, and moreover, our survey data was about the 10x less compute hypothetical not a 30x, 60x, or 100x less compute hypothetical, and we are loathe to extrapolate the results too far. (30x feels like not too far, but 100x feels like too far). Eli thinks that overall we should increase the progress multiplier from 7 to \\~10 in this section as a result of this consideration, but Daniel thinks we should keep it at 7 for the reasons mentioned above. Also, the Davidson et al survey data explicitly prompted the respondents to take this no-need-to-sleep effect into account, so we don’t need to update the results of Method 3 in light of this consideration.\n\n[^28]:  The [results](https://x.com/RichardMCNgo/status/1859290893943193834) are: 25.6% \\\u003c20% faster, 37.5% 20-200% faster, 36.8% more than twice as fast\n\n[^29]:  Data points: 1.1, 1.02-1.1, 1.3, \\\u003e1.5, 1.25, 1.01-1.1\n\n[^30]:  Data points: “A little \\\u003c0.5”, 0.2, 0.75-0.9, “1x for theory research, 0.5x for empirical research (counting these as separate data points)”, 0.5-0.9\n\n[^31]:  0.4^(log(30)/log(10))=0.22\n\n[^32]:  Square root of 6.25\n\n[^33]:  See [this spreadsheet](https://docs.google.com/spreadsheets/d/1dcNHLU6PlkqxnCmiVs6S_gO9lE7qncc1uNN88mcIBaA/edit?gid=0#gid=0) for calculations.\n\n[^34]: ((STOCK\\_THROUGH\\_SAR+SAR\\_TO\\_SIAR\\_YEARS)\\*2^(SAR\\_TO\\_SIAR\\_EQUIV\\_JUMPS\\*log(((STOCK\\_THROUGH\\_SAR+SAR\\_TO\\_SIAR\\_YEARS)/STOCK\\_THROUGH\\_SAR)/log(2))-((STOCK\\_THROUGH\\_SAR+SAR\\_TO\\_SIAR\\_YEARS)\n\n[^35]:  Eth and Davidson recently published follow-up work on the likelihood of a software intelligence explosion [here](https://www.forethought.org/research/will-ai-r-and-d-automation-cause-a-software-intelligence-explosion). While presented in a more polished, way it doesn’t depart much from [the core points of the relevant section in the 2023 report](https://docs.google.com/document/d/1rw1pTbLi2brrEP0DcsZMAVhlKp6TKGKNUSFRkkdP_hs/edit?tab=t.0#heading=h.iaqy7rxuutko).\n\n[^36]:  Epoch estimates r in a similar manner in [this paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4814445).\n\n[^37]:  For an example of why making the multiplier more particular to the present situation would result in undesirable results, consider: when there are very superhuman automated researchers there are large AI R\\\u0026D progress multipliers, the progress multiplier becomes very sensitive to the quantity and quality of the human researchers in the “no AI” case; that is, the progress multiplier changes without changing the AI system. If we allowed differences across companies, we might get very different results depending on the staff size, so if a company let go lots of obsoleted employees their progress multiplier would shoot up. Similarly, if we allowed a company’s progress multiplier to change over time based on their human workforce then it would go up when they fired people. Similar issues happen if we allow the progress multiplier to change based on compute amounts, because AIs are differentially advantaged at utilizing high compute amounts, so an influx in compute would lead to an increased progress multiplier. This is the least bad solution we’ve found to this problem but encourage others’ feedback.\n\n[^38]:   This restriction may be a bit too harsh and difficult to draw clean lines for, though later we will incorporate training compute increases. See also [this report](https://www.forethought.org/research/will-the-need-to-retrain-ai-models) which argues that the need for retrain models is unlikely to make the difference between whether we get or don’t get a software-driven intelligence explosion. Additionally, in our scenario there is generally not retraining from scratch above SC, although sometimes there is significant distillation before continuing training with a new paradigm. The FLOPs used for experimentation, training, etc. are constant at the level that was available when the SC was trained.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"2166:T13b95,"])</script><script>self.__next_f.push([1,"# Timelines Forecast\n\n#### Forecasting time to automated superhuman coders\n\n### *Eli Lifland, Nikola Jurkovic[^1], FutureSearch[^2] | April 2025*\n\n:::summary \nAI 2027 predicts AIs with superhuman coding ability in 2027. This supplement details our model for forecasting when the Superhuman Coder milestone will be achieved, building off METR's time horizon work, and justifies why we think it’s plausible it is achieved by 2027.\n:::\n  \n![](/combined-headline.png)  \n*Forecast for the arrival of superhuman coders assuming no large-scale catastrophes happen (e.g., a solar flare, a pandemic, nuclear war), no government or self-imposed slowdown, and no significant supply chain disruptions. All forecasts give a substantial chance of superhuman coding arriving by and in 2027.*\n\n## Summary\n\n*2025 May 7 update: Eli has, based on feedback, made a few updates to the model that he’s described in [the appendix](#2025-may-7-update). The updates noticeably but not greatly lengthen his timelines,* *now putting lower but still substantial probability on superhuman coders by 2027\\. The appendix also contains [an analysis of the importance of superexponentiality in the model](#the-importance-of-each-source-of-superexponential-progress).*\n\nWe forecast when the leading AGI company will internally develop a [*superhuman coder (SC)*](#defining-a-superhuman-coder-sc): an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper. At this point, the SC will likely speed up AI progress substantially as is explored in our [takeoff forecast](https://ai-2027.com/research/takeoff-forecast).\n\nWe first show **Method 1**: [time-horizon-extension](#method-1-time-horizon-extension), a relatively simple model which forecasts when SC will arrive by extending the trend established by [METR’s report](https://arxiv.org/pdf/2503.14499) of AIs accomplishing tasks that take humans increasing amounts of time.\n\nWe then present **Method 2**: [benchmarks-and-gaps](#method-2-benchmarks-and-gaps), a more complex model starting from a forecast saturation of an AI R\\\u0026D benchmark ([RE-Bench](https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/)), and then how long it will take to go from that system to one that can handle real-world tasks at the best AGI company.\n\nFinally we then provide an **“all-things-considered”** forecast that takes into account these two models, as well as other possible influences such as geopolitics and macroeconomics.\n\nWe also solicited forecasts from 3 professional forecasters from [FutureSearch](https://futuresearch.ai/) (bios [here](http://futuresearch.ai/ai-2027)).\n\nEach method’s results are summarized below:\n\n|  | Eli’s SC forecast (median, 80% CI) | Nikola’s SC forecast (80% CI) | FutureSearch aggregate (80% CI) (n=3) |\n| :---- | :---- | :---- | :---- |\n| [Time-horizon-extension model](?tab=t.0#heading=h.ym96g6tkhuod) (Apr 2025\\) | 2027 (2025 to 2039\\) | 2027 (2025 to 2033\\) | N/A |\n| [Updated time horizon model](#2025-may-7-update) (May 2025\\) | 2029 (2026 to 2052\\) | N/A | N/A |\n| [Benchmarks-and-gaps model](?tab=t.0#heading=h.nc76pumi87i1) (Apr 2025\\) | 2028 (2025 to \\\u003e2050) | 2027 (2025 to 2044\\) | 2032 (2026 to \\\u003e2050) |\n| [Updated benchmarks and gaps model](#2025-may-7-update) (May 2025\\) | 2030 (2026 to 2095\\) | N/A | N/A  |\n| All-things-considered forecast, adjusting for factors outside these models (Apr 2025\\) | 2030 (2026 to \\\u003e2050) *(90th percentile edited from 2050 to \u003e2050 4 days after publication)* | 2028 (2026 to 2040\\) | 2033 (2027 to \\\u003e2050)  |\n\nAll model-based forecasts have 2027 as one of the most likely years that SC being developed, which is when an SC arrives in [the AI 2027 scenario](https://ai-2027.com/). \n\nIn [the appendix](#the-importance-of-each-source-of-superexponential-progress) we present the effects of a few important model parameters. The code for our simulation is [here](https://github.com/uvafan/timelines-takeoff-ai-2027).\n\n*Disclaimer added Dec 2025: This forecast relies substantially on intuitive judgment, and involves high levels of uncertainty. Unfortunately, we believe that incorporating intuitive judgment is necessary to forecast timelines to highly advanced AIs, since there simply isn’t enough evidence to extrapolate conclusively.*\n\n### Defining a superhuman coder (SC)\n\n**Superhuman coder (SC)**: An AI system for which the company could run with 5%[^3] of their compute budget 30x as many agents as they have human research engineers, each of which is on average accomplishing coding tasks involved in AI research (e.g. experiment implementation but not ideation/prioritization) at 30x the speed (i.e. the tasks take them 30x less time, not necessarily that they write or “think” at 30x the speed of humans) of the company’s best engineer. This includes being able to accomplish tasks that are in any human researchers’ area of expertise.\n\nNikola and Eli estimate that the first SC will have at least 50th percentile frontier AI researcher “research taste” as well, but that isn’t required in the definition.\n\n## Method 1: Time horizon extension\n\nThis model relies upon the extrapolation of the progression of AIs toward being superhuman coders (SCs), as measured by how long it takes humans to do the hardest tasks that the AIs can do (which we call the AIs’ “time horizon”). We heavily draw from [METR’s recent report](https://arxiv.org/pdf/2503.14499) which catalogues a trend of increasing time horizon (pictured below).\n\n![](/metrhorizon-nowatermark.png)\n\nWe split our forecast into 2 subquestions:\n\n1. What time horizon and reliability level on METR’s task suite are needed for SC?  \n2. [When will this time horizon and reliability be reached?](#forecasting-scs-arrival). This is broken down into:  \n   1. The current doubling time of the time horizon  \n   2. How this would change over time, with no AI R\\\u0026D automation  \n   3. The difficulty of making a human-cost SC 30x faster and cheaper  \n   4. Accounting for [intermediate speedups](#intermediate-speedups) and the internal-public gap\n\nThe results of our simulation are below.  \n  \n![](/simple-combined-headline.png)\n\nOur distributions accounting for factors outside of this model are wider.\n\n#### METR’s time horizon report\n\n[METR’s recent report](https://arxiv.org/pdf/2503.14499) measures the “time horizon” capability of AI systems, where time horizon is defined based on how long it takes a skilled human to complete tasks (more details in footnote).[^4]\n\nAn AI with an R% time horizon of T time means that it has an average success rate of R% on tasks that take humans T time. We follow their definitions of time horizon and reliability in our modeling, except we add a constraint that the AI must complete the task at least as quickly and cheaply as humans. This wouldn’t change METR’s results given that they didn’t spend human-parity costs on inference compute.\n\nThe below figure illustrates the methodology:  \n  \n![](/metrsuite-nowatermark.png)\n\nMore details about their HCAST task suite are in [this paper](https://metr.org/hcast.pdf), with the below table illustrating the distribution of tasks:  \n![](/metrbreakdown-nowatermark.png)  \nFrom here on I’ll refer to the METR task suite as HCAST for brevity, given that we’ll be discussing time horizons well above those that SWAA measures and RE-Bench is a small subset of the suite.\n\n#### Forecasting SC’s arrival\n\nWe outline our simulation parameters in the following table.\n\n|  | Estimates (80% CI of lognormal unless stated otherwise) | Reasoning |\n| :---- | :---- | :---- |\n| Current 80% time horizon | 15 minutes (point estimate) | Taken from [METR’s time horizon paper](https://arxiv.org/pdf/2503.14499#page=2). This is Claude Sonnet 3.7’s 80% time horizon.  |\n| Time horizon required for SC | **Eli:** 10 years \\[1 month, 1200 years\\] **Nikola:** 1.5 months \\[16 hours, 2 work-years (4,000 hours)\\] | Time horizon required on real distribution of work tasks, as baselined by the best humans with strong incentives: 6 months (80% CI: \\[1 week, 12 years\\]). Time horizon and reliability required on an extrapolation of HCAST, with METR’s current baselining strategy: 10 years \\[1 month, 1200 years\\] More reasoning in the [appendix](#superhuman-coder-sc-time-horizon-and-reliability-requirements). |\n| Time horizon doubling time as of Mar 2025 on [HCAST](https://metr.org/hcast.pdf) *(edited Dec 2025 to add: extended as a long-term trend)* | 4.5 months \\[2.5 months, 9 months\\]  | Per: METR’s report, the doubling time for 50% time horizon has been roughly: For their task suite: 2019-2025 period: 7 months ([Figure 1](https://arxiv.org/pdf/2503.14499#page=1.66)) 2024 onward: 3.5 months ([Figure 19](https://arxiv.org/pdf/2503.14499#page=36.69)) (few data points) For SWEBench-Verified beginning in late 2023: 2.5 months ([Figure 11](https://arxiv.org/pdf/2503.14499#page=17.5)) For the 80% time horizon the doubling time is about the same as 50% during 2019-2025 (7.5 instead of 7 months, [Figure 6](https://arxiv.org/pdf/2503.14499#page=12)). Weighing up the above gives us a median of about 4.5 months. The trends over longer time periods are the most robust, but the latest trends are faster. |\n| Will doubling times speed up, slow, or stay the same? *(edited to add Dec 2025: before taking into account AI R\u0026D automation)* | **Probabilities:** Exponential: Eli: 0.45 Nikola: 0.5 Superexponential: Eli: 0.45 Nikola: 0.4 Subexponential: Eli: 0.1 Nikola: 0.1 | It's possible that time horizon increases superexponentially over time between now and the level required for SC: i.e. it takes less AI progress to go from 1 month to 2 months than from 1 hour to 2 hours, since long-horizon reasoning easily generalizes from short to long time horizons. Reasons in favor of superexponentiality includes: **Empirical**: The METR report finds a [3.5 month doubling time for 2024-2025](https://arxiv.org/pdf/2503.14499#page=36.69), compared to a [7 month doubling time for 2019-2025](https://arxiv.org/pdf/2503.14499#page=1.66). This is based on few data points. Scaling up agency training provides a potential reason for the trend, as discussed in [Section 7.2.2 of the report](https://arxiv.org/pdf/2503.14499#page=20.25).[^5] **Conceptual:** It seems like for humans the gap in difficulty between 1 month and 2 month tasks is lower than between 1 day and 2 days. It’s unclear whether this will transfer to AIs though, given that thus far relative to humans they have solved tasks more strongly with knowledge than with general reasoning.[^6] Therefore we assign a significant probability to growth being superexponential. We also assign smaller weight to the trend being subexponential.[^7] If the growth is superexponential, we make it so that each successive doubling takes 10% less time. If it’s subexponential, each successive doubling takes 10% more time. |\n| Cost and speed adjustment | 4 months \\[0.5 months, 30 months\\] | Being an SC requires accomplishing tasks 30x faster and 30x cheaper than the best human researchers. However, in the existing METR evaluations they aren’t spending up to human cost, so our starting price point is below humans. Eyeballing [Figure 13 from the METR report](https://arxiv.org/pdf/2503.14499#page=22), the AIs are currently about 30x cheaper in the median case for HCAST tasks, and perhaps 5-10x cheaper on average. Analysis of [their data](https://github.com/METR/eval-analysis-public) shows that AIs are roughly 5x faster on average. [Below](#cost-and-speed), we forecast in some depth how fast AIs will get 30x faster and cheaper, starting at human level, based on historical trends in price decreases. Here we take that forecast of 6.9 \\[1, 48\\] months, and adjust it downwards by about 50% since we’re starting at 5-10x cheaper and faster than humans. |\n| Gap between internal and external deployment | 1.2 months \\[0.25 months, 6 months\\] | The current time horizon estimate is for public models, but it is possible that companies have more capable models internally. See more [below](#gap-between-internal-and-external-deployment). |\n\n## Method 2: Benchmarks and gaps\n\n### Time to RE-Bench saturation\n\n#### Why RE-Bench?\n\n[RE-Bench](https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/) is a set of challenging and realistic AI R\\\u0026D tasks with objective scoring functions. They aim to capture the types of work that are commonly done by engineers at AGI companies (e.g., writing scripts to train ML models, optimizing Pytorch code). Since they’re continuously scored there’s no single amount of time that they take to complete, but human baselines so far have been collected up to 8 hours, and 8 hours is sufficient time for a competent professional to make significant improvements to their score. By having humans and AI systems complete RE-Bench tasks, we can get a sense of how capable AI systems are at tasks involved in AI R\\\u0026D.\n\nWe focus on a subset of 5 of the 7 RE-Bench tasks due to issues with scoring in the remaining two, and will refer to this subset as “RE-Bench” in the rest of this report. In particular, we exclude Scaling Law Experiment because it’s easy enough for models to succeed at by luck that it’s not appropriate for Best-of-K scaffolding, and we exclude Restricted MLM Architecture because Claude 3.7 Sonnet reliably cheats at this task and METR has not yet been able to prompt the model to attempt the task without cheating.\n\nRE-Bench has a few nice properties that are hard to find in other benchmarks and which make it a uniquely good measure of how much AI is speeding up AI research:\n\n1. **Highly relevant** to frontier AI R\\\u0026D.  \n2. **High performance ceiling.** AI agents can achieve significantly above human-level, though in practice it will likely be very difficult to do more than roughly 2x higher than the human baseline solutions (for a score of 1.5). Median human baseline scores are 0.12 for 2 hours of effort and 0.66 for 8 hours. Current state of the art (SOTA) is Claude 3.7 Sonnet with a score of roughly 0.6 using Best-of-K scaffolding in [a scaffold called “modular”](https://github.com/poking-agents/modular-public).  \n3. **Human baselines** which allow for grounded comparisons between AI and human performance.\n\nWe expect that “saturation” under this definition will happen before the SC milestone is hit. The first systems that saturate RE-Bench will probably be missing a few kinds of capabilities that are needed to hit the SC milestone, as described [below](#what-are-the-gaps-in-task-difficulty-between-re-bench-saturation-and-sc).\n\n#### Forecasting saturation via extrapolation\n\n##### How high does RE-Bench go?\n\nThis table from the [RE-Bench paper](https://arxiv.org/abs/2411.15114) gives a sense of how high the RE-Bench score could go:  \n  \n![](/metrrebenchsaturation-nowatermark.png)\n\nThe average of the midpoint of each “estimated ceiling” above is 1.67.[^8] To be conservative and make sure the “saturation” level is possible to achieve, we will define a score of 1.5 to mean “saturation” for RE-Bench tasks. We use the resolution criteria from the AI 2025 Forecasting Survey ([the appendix](#re-bench-saturation-resolution-criteria)), which includes making sure the model doesn’t cost more than a human per task. A score of 1.5 will mean the model beats more than around 95% of human baseline runs (the 90th percentile is around 1.22 in RE-Bench Figure 4). But we estimate that 1.5 is approximately at the level of the average of the best human; this is higher than the 95th percentile due to variance between tasks in difficulty of getting high scores, and variance in individuals’ performance, e.g. due to luck.\n\n##### Running an extrapolation\n\n[Benchmarks have been found to often follow logistic curves](https://www.alignmentforum.org/posts/75o8oja43LXGAqbAR/palm-2-and-gpt-4-in-extrapolating-gpt-n-performance) and we will assume RE-bench will follow a similar shape as well, fitting a logistic fit to the point estimates of the historical high score over time. We assume the lower bound of the logistic curve is 0\\. The upper bound of RE-Bench is not known, so we will model it as a normal distribution with a mean of 2.0 and a standard deviation of 0.25. Changing the upper bound *(edited Dec 2025 to add: within this range)*  doesn’t change the forecast much — a change of 0.25 in the upper bound moves the saturation date around half a year.\n\nThis gives this graph of peak scores allowing Best-of-K and giving models a 16-hour time budget at the task:  \n![](/timelines-forecast-nowatermark.png)  \n\nThe 80% CI comes from uncertainty about the upper bound of the score and is not meant to represent an epistemic state.\n\nThis predicts the date of saturation to be sometime in 2026\\.\n\nSee also [this paper](https://arxiv.org/abs/2502.15850) which forecasts RE-Bench hitting 1 in 2027\\. We think the data they used likely led to overly conservative forecasts.\n\n##### Overall forecasts of RE-bench saturation\n\n| Eli, FutureSearch | Lognormal, 80% CI of \\[2025-09-01, 2031-01-01\\]. |\n| :---- | :---- |\n| Nikola | Lognormal, 80% CI of \\[2025-08-01, 2026-11-01\\] |\n\nWe expect the logistic forecast to slightly overestimate the rate of progress because we now have additional information that the first quarter of 2025 has passed with no new SOTA scores on RE-Bench reported by METR.\n\n#### AI progress speedups after saturation\n\nNikola’s current guess is that algorithmic progress is 3-30% faster with AI chatbots and copilots from the 2022-2024 period than it would be if AI researchers didn’t use them. \n\nNikola expects that agents capable of saturating RE-Bench will be roughly twice as useful for productivity than 2024-era AIs, but possibly even more than that. Nikola’s best guess is that algorithmic progress will be \\[5%, 60%\\] faster when RE-Bench is first publicly saturated than it was in 2024\\. Nikola assumes algorithmic progress in 2024 is 50% of overall AI progress. Eli roughly agrees with these estimates.\n\nOur best guess for what AI research capabilities look like at RE-Bench saturation is: there will exist agents that require substantial supervision when doing real-world 8-hour tasks, but which are sometimes able to do hours-long tasks with minimal human intervention. If we imagine RE-Bench saturation level AIs often doing hours-long tasks, it seems plausible that this will be a large speedup (e.g., 50% productivity increase, which after accounting for compute bottlenecks might translate to 15% algorithmic progress speedup) for many AI researchers.\n\n*Edited to add Dec 2025: We intended our methodology to interpolate the progress multiplier exponentially in 2024-months between (current progress multiplier - 1) and (SC progress multiplier - 1). For example, if the current progress multiplier was 1.1, and the SC progress multiplier was 8.5, then halfway in 2024-months to SC the progress multiplier was intended to be (1.1-1)\\*((8.5-1)/(1.1-1))^.5+1=1.87. However, there was a bug in our code such that it did not include the subtraction of 1, then addition of 1, and instead in this case would have obtained 1.1\\*(8.5/1.1)^.5=3.06. Thus we overestimated the impact of intermediate speedups. This had about a 9 month impact on our model’s SC median.*\n\n### Time to cross gaps between RE-Bench saturation and SC\n\nWe now turn to forecasting the time from RE-Bench being saturated to SC. \n\nWe first discuss what the main [gaps](#what-are-the-gaps-in-task-difficulty-between-re-bench-saturation-and-sc) are in “task difficulty” between RE-Bench saturation and SC. Then we describe our [methodology](#methodology) for forecasting how long it will take to cross these gaps.  \nThen we [forecast how quickly all gaps in task difficulty will be crossed](#how-fast-can-the-task-difficulty-gaps-be-crossed).\n\n#### What are the gaps in task difficulty between RE-Bench saturation and SC?\n\nThe [RE-Bench paper](https://arxiv.org/pdf/2411.15114#page=19) notes four main categories of gaps between saturating RE-Bench and being able to conduct real AI R\\\u0026D.  \n![](/metrgaps-nowatermark.png)  \n\nIn addition to the ones in the above table, we add gaps for specialization and cost \\+ speed. RE-Bench tasks generally require low background context, including not requiring familiarity with large codebases.\n\n#### Methodology\n\nIn summary: we define milestones that would indicate each task difficulty gaps being crossed in such a way that they get strictly harder and therefore must be crossed sequentially, then estimate the number of months between each milestone and sum these up.  \n:::TimelinesMethod\n:::\n\nOur approach is:\n\n1. For each gap after RE-Bench saturation (which is the first “milestone”):  \n   1. Define a milestone that would indicate the gap being crossed, which is strictly harder from the previous milestone such that the time between the gaps must be positive. These look like “Same as above, but… \\[the gap has been crossed, e.g. it can do all the tasks above 30x faster and cheaper\\]” and can be viewed in [this summary table](#summary-table).[^9]   \n      1. For all task difficulty gaps except for time horizon, after they are crossed they remain at the same level for all future milestones. For the time horizon property, it is allowed to freely increase given that it’s a general difficulty measure so cannot be held constant while a property of the task gets harder.  \n   2. Estimate the number of months needed to cross that gap at the 2024 rate of AI progress. We have better data for time horizon increases and cost/speed improvements than we have for the other categories, so the others are estimated much less rigorously.  \n2. Sum all task difficulty gaps to get the total size of the task difficulty gap, measured in months of AI progress at the 2024 rate of AI progress.   \n3. Find the time to cross all task difficulty gaps by incorporating [intermediate speedups](#intermediate-speedups) of AI progress, then add other [potential slowdowns](#compute-scaling-and-algorithmic-progress-slowdown) (e.g. adoption lag) and account for the [gap between internal and external deployment](#gap-between-internal-and-external-deployment).\n\nAll of these gaps (except for the time horizon gap, which is further modeled as explained here) are modelled as lognormals according to the 80% confidence interval, meaning that the median is always the geometric mean of the lower and upper bounds. Samples are drawn with a positive correlation because the difficulties of achieving each of the capabilities are likely correlated.[^10]\n\n#### How fast can the task difficulty gaps be crossed?\n\n##### Summary table\n\nBelow we summarize our gap crossing forecasts. FutureSearch below refers to the aggregate of 2 professional forecasters from [FutureSearch](https://futuresearch.ai/). Detailed individual rationales for each gap are in the [appendix](#individual-forecaster-views-for-benchmark-gap-model-factors).\n\n| Gap name | Milestone that would indicate the gap being crossed | Predictions for gap size (median and 80% CI) | Reasoning summary |\n| :---- | :---- | :---- | :---- |\n| [Time horizon: Achieving tasks that take humans lots of time.](#time-horizon) | Ability to develop a wide variety of software projects involved in the AI R\\\u0026D process which involve modifying a maximum of 10,000 lines of code across files totaling up to 20,000 lines. Clear instructions, unit tests, and other forms of ground-truth feedback are provided. Do this for tasks that take humans about 1 month (as controlled by the “initial time horizon” parameter) with 80% reliability, add the same cost and speed as humans.  | Eli: 18 \\[2, 144\\] Nikola: 16 \\[1, 125\\] (these aren’t lognormal as they’re simulated; see more [below](#time-horizon)) FutureSearch: 12.7 \\[1.7, 48\\] | Calculated from needed horizon length and doubling time. |\n| [Engineering complexity: Handling complex codebases](#engineering-complexity-handling-complex-codebases) | Ability to develop a wide variety of software projects involved in the AI R\\\u0026D process which involve modifying \\\u003e20,000 lines of code across files totaling up to \\\u003e500,000 lines. Clear instructions, unit tests, and other forms of ground-truth feedback are provided. Do this for tasks that take humans about 1 month (as controlled by the “initial time horizon” parameter) with 80% reliability, add the same cost and speed as humans. | Eli: 3 \\[0.5, 18\\] Nikola: 3 \\[0.5, 18\\] FutureSearch: 11 \\[2.4, 33.9\\]   | Estimated via performance trends on METR’s time horizon task suite. |\n| [Feedback loops: working without externally provided feedback](#feedback-loops-working-without-externally-provided-feedback) | Same as above, but without provided unit tests and only a vague high-level description of what the project should deliver. | Eli: 6 \\[0.8, 45\\] Nikola: 3 \\[0.5, 18\\] FutureSearch: 18.3 \\[1.7, 58\\]  | Estimated from looking at how much removing Best-of-K sampling from RE-Bench diminishes performance. |\n| [Parallel projects: handling several interacting projects](#parallel-projects-handling-several-interacting-projects) | Same as above, except working on separate projects spanning multiple codebases that interface together (e.g., a large-scale training pipeline, an experiment pipeline, and a data analysis pipeline). | Eli: 1.4 \\[0.5, 4\\] Nikola: 1.2 \\[0.5, 3\\] FutureSearch: 2 \\[0.7, 5.3\\]  | Estimated as being very small due to overlap with the engineering complexity and time horizon gaps. |\n| [Specialization: Specializing in skills specific to frontier AI development](#specialization-specializing-in-skills-specific-to-frontier-ai-development) | Same as above, except working on the exact projects pursued within AGI companies. | Eli: 1.7 \\[0.5, 6\\] Nikola: 0.4 \\[0.1, 2\\] FutureSearch: 2.4 \\[0.5, 4.7\\]  | Estimated from the fact that fine-tuning for specific use cases usually doesn’t take long, and the overlap between RE-Bench tasks and real-world coding is large. |\n| [Cost and speed](#cost-and-speed) | Same as above, except doing it at a cost and speed such that there are substantially more superhuman AI agents than human engineers (specifically, 30x more agents than there are humans, each one accomplishing tasks 30x faster). | Eli: 6.9 \\[1, 48\\] Nikola: 6 \\[1, 36\\] FutureSearch: 13.5 \\[4.5, 36\\]  | Estimated from data of AI capabilities getting cheaper over time. |\n| [Other task difficulty gaps](#cost-and-speed) | SC achieved. | Eli: 5.5 months \\[1, 30\\] Nikola: 3 months \\[0.5, 18\\] FutureSearch: 14.7 \\[2, 58.8\\] | Accounting for unknown unknowns |\n\n##### Time horizon\n\n**Milestone which would indicate the gap being crossed:** Ability to develop a wide variety of software projects involved in the AI R\\\u0026D process which involve modifying a maximum of 10,000 lines of code across files totaling up to 20,000 lines. Clear instructions, unit tests, and other forms of ground-truth feedback are provided. Do this for tasks that take humans about 1 month (as controlled by the “initial time horizon” parameter) with 80% reliability, add the same cost and speed as humans. \n\n###### Time horizon report and definition\n\n[METR’s recent report](https://arxiv.org/pdf/2503.14499) measures the “time horizon” capability of AI systems, where time horizon is defined based on how long it takes humans to complete tasks (more details in footnote).[^11]\n\nAn AI with an R% time horizon of T time means that it has an average success rate of R% on tasks that take humans T time. For more details about their methodology and their task suite HCAST, see [above](#metrs-time-horizon-report). *Edited Dec 2025 to add: The Benchmarks and Gaps time horizon definition assumes that humans are top-expert-level, while the time horizon extension’s definition doesn’t. This is because we are starting at a point at which AIs have matched top experts on RE-Bench. Apologies for any confusion on this.*\n\n###### Superhuman Coder (SC): initial time horizon and reliability requirements\n\nA superhuman coder (SC) (without speed/cost which are later taken into account) must be able to overall do as good of a job as the combination of all human programmers at an AGI company at their current work.\n\nWhat time horizon and reliability level does this require? Because the time horizon will continue to increase as future gaps are crossed, we will choose an “initial time horizon\" which is somewhat lower than what we think the ultimate SC time horizon will need to be.\n\n**Initial time horizon required: 1 month** feels roughly right for the low end of the time requirements of difficult coding projects.[^12] We’ll take into account some uncertainty here with a lognormal with 80% CI of \\[4 hours, 6 work-months (1000 hours)\\]. We roughly guess that future gap crossings will increase the time horizon to about 6 months, which seems reasonable for representing very difficult coding projects.\n\n**Reliability required: 80%**, though highly uncertain. If the SC is equally well-rounded as the human researcher force, this would be somewhat below 50% for a few reasons in footnote.[^13] Currently AIs are much less well-rounded than humans though, so if they have a 40% time horizon within human cost/speed they likely only go up to around 45-50% if allowed to take 10x longer. So with current AIs we might need to set a 90+% reliability threshold. SC-level AIs will be much more well-rounded though, due to having very strong agency skills (planning, correcting mistakes, etc.). So we lower it to 80%, which seems roughly right and has the advantage of being able to utilize METR’s reported data. Uncertainty is not incorporated into our model, for simplicity and because any adjustment to reliability could also be modeled as an adjustment to time horizon instead.\n\n###### Engineering complexity associated with time horizon extrapolation\n\nWe’ll measure the engineering complexity of a task via 2 proxies: (a) lines of code modified and (b) sum of lines of code are in all modified files.\n\nSaturating RE-Bench requires a median of 500 lines of code in modified files, and about 250 lines of code modified. The other 8 hour tasks in the METR time horizon suite require similar amounts.\n\nBased on very rough data analysis, we estimate that each time horizon increase in the METR suite leads to a proportional increase in both proxies. Since there is a 20x increase between 8 hours and 1 month, this would mean an increase to about 10,000 lines of code modified, 20,000 lines of code in all modified files.\n\nThe small multiplier between lines modified and lines of code in all modified files reflects an emphasis by RE-Bench and the METR suite on tasks requiring low context, including familiarity with large codebases.\n\n###### Saturating RE-Bench: Time horizon and reliability level\n\nAs described [above](#how-high-does-re-bench-go), we set the RE-Bench saturation based on achieving an average of 1.5, which is about what we think the best human could get given 8 hours for each task.\n\nWhat would achieving this score mean in terms of reliability at an 8 hour time horizon, relative to the best human?\n\nI think it means more than 50% because as described above, AIs’ skillsets are currently more uneven than humans, perhaps the AI will have to be better than top humans at \\\u003e50% of tasks in order for the average to be the same, because there’s less room to go above 1.5 on the RE-Bench tasks than below it.\n\nThis effect seems significant but not huge. My best guess is 60% reliability.\n\n###### Time horizon forecasts\n\n|  | Estimates (80% CI of lognormal) | Reasoning |\n| :---- | :---- | :---- |\n| 80% time horizon required for our initial milestone | Eli: \\[8 hours, 6 work-months (1000 hours\\] Nikola: \\[8 hours, 6 work-months (1000 hours)\\]  | Because the time horizon will continue to increase as future gaps are crossed, we will choose an “initial time horizon\" which is somewhat lower than what we think the ultimate SC time horizon will need to be. A median of roughly 2-4 weeks feels about right for the low end of difficult coding projects. See [above](#superhuman-coder-sc-initial-time-horizon-and-reliability-requirements) for more. |\n| 80% time horizon at RE-Bench saturation | Eli: \\[0.5, 15\\] hours NIkola: \\[0.5, 12\\] hours | See more [above](#saturating-re-bench-time-horizon-and-reliability-level) for why it’s likely less than 8 hours. My best guess is that the RE-Bench-saturating agent would have 60% reliability at 8 hours. In METR’s report, they find that switching from 50% to 80% reduces the time horizon by 5x. So perhaps switching from 60% to 80% reduces it by \\~3.5x, giving me a median of \\~2.5 hours. |\n| Time horizon doubling time as of Mar 2025 on [HCAST](https://metr.org/hcast.pdf) *(edited Dec 2025 to add: extended as a long-term trend)* | \\[2.5 months, 9 months\\] | See our rationale in [Method 1](#forecasting-scs-arrival). |\n| Doubling time at RE-Bench saturation toward our time horizon milestone, on a hypothetical task suite like [HCAST](https://metr.org/hcast.pdf) but starting with only RE-Bench’s task distribution | \\[0.5 months, 18 months\\] | We intuitively aggregate the below 3 adjustments to get our estimate.  **Adjustment downward and more uncertain for potential trend changes**: If the trend is superexponential, the doubling time will be faster than today by the time RE-Bench is saturated. The opposite is true for subexponential, which is less likely (see [below](#bookmark=id.hsqzm8pu5c8u) for reasoning).  **Adjustment to be more uncertain based on distribution shift from normal HCAST to HCAST starting with only RE-Bench:** We widen our confidence interval based on uncertainty regarding the starting task distribution. METR’s extrapolation already includes RE-Bench, but it’s a small minority of tasks relative to HCAST. **Adjustment downward due to extrapolation overshooting our milestone:** Our guess is that our extrapolation on the METR task suite would “overshoot” and lead to our [time horizon milestone](#time-horizon) being eclipsed on some dimensions by the time AI reaches the required time horizon. Therefore, we should make an adjustment down to shift from the METR task suite doubling time to the doubling time on a theoretical task suite for which extrapolation led exactly to the time horizon milestone as we defined it above. We’ve done some rough extrapolations which indicate that the HCAST extrapolation would in fact lead to about 10,000 lines of code, as we defined the milestone. But our guess is that a naive extrapolation would “overshoot” our milestone with regards to feedback loop difficulty, and potentially other variables as well. |\n| Will doubling times speed up, slow, or stay the same? *(edited to add Dec 2025: before taking into account AI R\u0026D automation)* | **Probabilities:** Exponential: Eli: 0.45 Nikola: 0.5 Superexponential: Eli: 0.45 Nikola: 0.4 Subexponential: Eli: 0.1 Nikola: 0.1 | See our rationale in [Method 1](#forecasting-scs-arrival). |\n\nTaking the doubling time and required level, we get these distributions as the size of the time horizon gap:  \n![](/combined-derived.png)\n\n### Other factors for benchmarks and gaps\n\nWe assume that no large-scale catastrophes happen (e.g., a solar flare, a pandemic, or a nuclear war), and no government or self-imposed slowdown.\n\n#### Compute scaling and algorithmic progress slowdown\n\nWe assume that the rate of compute scaling is slowed by 2x beginning in 2029 due to reduced ability to increase investments, given that the [rate of increase of frontier AI training costs](https://epoch.ai/data-insights/cost-trend-large-scale) may be difficult to continue past then without SC achieved.\n\nSimilarly, we project that if SC isn’t achieved by about 2028 the human research population will begin growing at a slower rate. For simplicity, we also model this as a 2x decrease in the human-driven rate of progress over time. To model complementarity with AI automation, we take the geometric of mean of the pace of progress if AI were a fixed multiplier on the human pace (i.e. default\\_human\\_plus\\_ai\\_rate\\*0.5) and the pace of progress if AI were fully additive (i.e. default\\_human\\_plus\\_ai\\_rate-0.5).\n\n#### Gap between internal and external deployment\n\nBecause our models’ forecasts and extrapolations above are based on testing models which have been publicly released, we need subtract from our forecast to get the the arrival time of SC capabilities internal to the AGI developers.\n\nWe estimate that at the arrival of SC, AGI developers’ internal capabilities will be approximately a lognormal with an 80% CI of \\[0.25 months, 6 months\\] ahead of their public releases. This is subtracted from the time-to-achieve-SC to get to a time when SC is achieved internally.\n\n#### Intermediate speedups\n\nIn our simulation, the rate of algorithmic progress starts at 1 in 2025 and reaches \\[5%, 60%\\] times the 2024 rate at RE-Bench saturation. \n\nThe table below shows Eli’s and Nikola’s estimates for how much SCs will speed up algorithmic progress, i.e. the AI R\\\u0026D progress multiplier (see [here](https://ai-2027.com/research/takeoff-forecast#accounting-for-ai-randd-automation-the-ai-randd-progress-multiplier) for a more detailed definition). These are informed by our estimates for the SC progress multiplier in our [takeoff forecast](https://ai-2027.com/research/takeoff-forecast). \n\n| Quantity | Nikola’s estimate | Eli’s estimate |\n| :---- | :---- | :---- |\n| AI R\\\u0026D progress multiplier from SC (median 80% CI of lognormal)[^14] | 5.5 \\[2.0, 20.0\\] | 8.5 \\[2.5, 40.0\\][^15] |\n\nWe assume that in 2024 algorithmic progress represents half of AI progress, with the other half being compute. Progress might be very fast after the SC milestone: see the [takeoff forecast](https://ai-2027.com/research/takeoff-forecast) for forecasts on the post-SC capabilities progression.\n\nIn the simulation:\n\n1. We get the number of months needed to bridge all task difficulty gaps at the 2024 rate of AI progress.  \n2. We then progress through the total number of “2024-months” of progress, increasing the rate of AI progress according to how much of the process has been completed (in a very small subset of trajectories, the rate of AI progress goes *down* over time). The rate of progress goes up exponentially from the starting rate to the ending rate, as a function of how much of the total task difficulty gap has been crossed. *Edited to add Dec 2025: We intended our methodology to interpolate the progress multiplier exponentially in 2024-months between (current progress multiplier - 1) and (SC progress multiplier - 1). For example, if the current progress multiplier was 1.1, and the SC progress multiplier was 8.5, then halfway in 2024-months to SC the progress multiplier was intended to be (1.1-1)\\*((8.5-1)/(1.1-1))^.5+1=1.87. However, there was a bug in our code such that it did not include the subtraction of 1, then addition of 1, and instead in this case would have obtained 1.1\\*(8.5/1.1)^.5=3.06. Thus we overestimated the impact of intermediate speedups. This had about a 9 month impact on our model’s SC median.*\n\n### Overall benchmarks and gaps forecasts\n\nRunning the simulation as described by the parameters we’ve laid out results in this:  \n  \n![](/combined-headline.png)\n\nWith these input distributions:  \n  \n![](/combined-inputs.png)  \n\n---\n\n### Appendix\n\n#### 2025 May 7 update\n\n*This section is written by Eli Lifland and not necessarily endorsed by his co-authors.*\n\nI’ve made some changes to both the time horizon extension and benchmark and gaps models (thanks to [Peter Johnson](https://www.lesswrong.com/users/peter-johnson-1) for suggesting or inspiring all of these changes; he doesn’t necessarily endorse them). My within-model forecasts have been changed as follows:\n\n|  | Eli’s superhuman coder forecast (median \\+ 80% CI) | Eli’s superhuman coder forecast, modal year |\n| :---- | :---- | :---- |\n| Time-horizon-extension model, initial version (Apr 2027\\) | Aug 2027 (Oct 2025 to 2039\\) | 2026 |\n| **Time-horizon-extension model, updated version (May 2027\\)** | **Feb 2029 (Apr 2026 to 2052\\)** | **2027** |\n| Benchmarks-and-gaps model, initial version (Apr 2027\\) | Dec 2028 (Dec 2025 to \\\u003e2050) | 2027 |\n| **Benchmarks-and-gaps model, updated version (May 2027\\)** | **Mar 2030 (Feb 2026 to 2095\\)** | **2027 and 2028 are \\~equal** |\n\nEssentially, the forecasts have gotten noticeably but not greatly longer, now putting lower but still substantial probability on superhuman coders by 2027\\.\n\n![](/updated_the.png)\n![](/updated_bag.png)\n\nBelow we:\n\n1. Describe and show the impact of each model update ([more](#model-updates))  \n2. Examine the importance of each source of superexponential progress ([more](#the-importance-of-each-source-of-superexponential-progress))  \n3. Add a few clarifications regarding the model ([more](#clarifications))\n\n##### Model updates\n\nBelow we describe and show the effect of each update made to the model, in descending order of how much they changed the predictions. These effect sizes aren’t high precision on the order of 1-2 months for medians, each is from running 5,000 simulations. Therefore they don’t add up exactly to the overall change in median (18 months for time horizon extension, 15 months for benchmarks and gaps).\n\n| Change | Effect on median forecast |\n| :---- | :---- |\n| Improving modeling of software progress to better take into account diminishing returns. We now directly model labor increases, its combination with compute to research effort, and the AI R\\\u0026D progress multiplier on such effort, under the assumption that each doubling in total research effort gives the same amount of progress (as used by [Davidson’s takeoff model](https://www.openphilanthropy.org/research/what-a-compute-centric-framework-says-about-takeoff-speeds/)). | Time horizon extension (THE): 13 month increase\u000bBenchmarks and gaps (BAG): 8 month increase |\n| Updating superexponentiality to have increasing chances of being introduced as time horizons go up, rather than a static probability at the start of the simulation (the new probability starts at lower than the previous probability at the initial time horizon, then becomes higher than it at large time horizons). | THE: 5 month increase BAG: 1 month decrease The contrast above is because previously we had the same superexponential probability for THE and BAG, even though THE starts at a lower time horizon. |\n| Adding uncertainty regarding the starting software progress share  | THE: 3 month increase BAG: 2 month increase |\n| Increased the starting share of software progress from 50 to 55% (see reasoning [here](https://www.lesswrong.com/posts/ATSyAdBnxxDDAwhgu/recent-and-forecasted-rates-of-software-and-hardware)) | THE: 1 month decrease\u000bBAG: 3 month decrease |\n| Updating labor growth schedule (see forecasts and reasoning [here](https://www.lesswrong.com/posts/ATSyAdBnxxDDAwhgu/recent-and-forecasted-rates-of-software-and-hardwaret)) | THE: No change in median\u000bBAG: 4 month increase |\n| Updating compute progress schedule (see forecasts and reasoning [here](https://www.lesswrong.com/posts/ATSyAdBnxxDDAwhgu/recent-and-forecasted-rates-of-software-and-hardware)) | THE: No change in median\u000bBAG: 2 month increase |\n| Adding uncertainty to the rate of superexponential doubling time decay | THE: 1 month increase BAG: 1 month increase |\n\nYou can see all of the code changes [here](https://github.com/uvafan/timelines-takeoff-ai-2027/pull/4).\n\n##### The importance of each source of superexponential progress\n\nIn the timelines model, there are 2 sources of superexponential growth in time horizons:\n\n1. **The “inherent” superexponentiality reflecting the difficulty required to reach larger time horizons.** This is much more important in the time horizon extension model than the benchmarks and gaps model.  \n2. **Speedups from AI R\\\u0026D automation via the AI R\\\u0026D software progress multiplier.** This is important in both models.\n\nIn this section we present the effects of each of these sources, and their combination.\n\n###### Model’s forecasts vs. no inherent superexponential\n\n![](/no_inherent_super_the.png)\n![](/no_inherent_super_bag.png)\n\n###### Only inherent superexponential vs. no inherent superexponential\n\nHere I present the model’s outputs when it always starts with superexponential time horizon growth. In the actual time horizon extension model, this happens 25% of the time.\n\n![](/no_vs_immediate_the.png)\n![](/no_vs_immediate_bag.png)\n\n###### Model’s forecasts vs. forecasts with no AI R\u0026D progress multiplier\n\n![](/no_vs_yes_pm_the.png)\n![](/no_vs_yes_pm_bag.png)\n\n###### Model’s forecasts vs. forecasts with neither source of superexponentiality\n\n![](/neither_source_the.png)\n![](/neither_source_bag.png)\n\n##### Clarifications\n\n1. Though I think the time horizon extension model is useful, I place significantly more weight on the benchmarks and gaps model because I think it’s useful to explicitly model the gaps rather than simply adjusting the required time horizon for them.  \n2. The superexponential probability is not independent of the starting time horizon. If you [greatly decrease the starting time horizon](https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1#7ZH52oZenutNoad95), you should also decrease the chance you think it’s super exponential at that time horizon (in my opinion, the theoretical and empirical arguments for superexponentiality are both stronger at higher time horizons). I’ve now introduced a “schedule” of probabilities for when superexponentiality might begin, which should make it easier to model this phenomenon. But the schedule by default starts at the current time horizon, if you wish to lower that then the schedule should be added to accordingly. The parameter name is “superexponential\\_schedule\\_months” in [this file](https://github.com/uvafan/timelines-takeoff-ai-2027/blob/main/timelines/params.yaml) for the benchmarks and gaps model, [this file](https://github.com/uvafan/timelines-takeoff-ai-2027/blob/main/timelines/simple_params.yaml) for the time horizon extension model.  \n3. All time amounts in the timelines forecast are in \"work time\", i.e. the amount of time that a human would work during that time period: for example, a work week is 40 hours and a work year is 2,000 hours.\n\n#### Individual Forecaster Views for Benchmark-Gap Model Factors\n\n##### Engineering complexity: handling complex codebases\n\n**Milestone which would indicate the gap being crossed: Ability to develop a wide variety of software projects involved in the AI R\\\u0026D process which involve modifying \\\u003e20,000 lines of code across files totaling up to \\\u003e500,000 lines. Clear instructions, unit tests, and other forms of ground-truth feedback are provided. Do this for tasks that take humans about 1 month (as controlled by the “initial time horizon” parameter) with 80% reliability, add the same cost and speed as humans.** \n\nThis milestone requires a 1x scaleup in modified lines of code (LOC) and a 25x scaleup in files LOC from the time horizon milestone.\n\n* Eli’s estimate of gap size: 3 months \\[0.5, 18\\]. Reasoning:  \n  * My guess is that modified LOC is more important to task difficulty than files LOC especially for large changes, so perhaps the 2x scaleup in modified LOC and 25x scaleup in files LOC combine for the equivalent of a 4x scaleup in total LOC.  \n  * In the METR suite, scaleup in both modified LOC and files LOC is proportional to time horizon, which is doubling roughly every 4 months in 2025 and may be doubling faster at longer time horizons (see [time horizon forecast above](#time-horizon)).  \n  * 2 doublings with a median of some doubling time speedup to 3 months gives me 6 months, then I adjust down to a median of 3 months because the LOC-doubling time would be faster if no other task properties were getting harder.  \n  * I add a factor of 6 on each side to get \\[0.5, 18 months\\]. This roughly matches my intuitions: it doesn’t seem difficult to scale to much larger codebases once the AI already has the skills needed for the time horizon milestone.  \n* Nikola’s estimate of gap size: 3 months \\[0.5, 18\\]. Reasoning is the same as Eli’s  \n* FutureSearch’s estimate of gap size: 11 months \\[2.4, 33.9\\]. Reasoning:  \n  * The total codebase could be larger than the 100k lines required. From the 10k lines of the previous milestone, we need at least a ×10 increase to reach 100k lines. But the system might need to understand 1M lines to make the necessary changes.  \n  * The assumption of 4 months of progress to deal with x10 lines of code is aggressive. There are few data points, and adding a factor of 2 (to create the 90th percentile) feels insufficient.  \n  * Fixing bugs might require modification of \\\u003e10k lines, beyond what is assumed in the previous milestone. It is not clear how differentially hard it is for systems to create new projects of length N versus finding and fixing bugs that (say) require changing 1% of those N lines.   \n  * Again, a key consideration is whether synthetic data is needed for training. If so, generating it at this level of complexity could be a huge challenge.\n\n##### Feedback loops: Working without externally provided feedback\n\n**Milestone which would indicate the gap being crossed: Same as above, but without provided unit tests and only a vague high-level description of what the project should deliver.**\n\n*We recommend that future work consider using METR’s concept of “messiness” from [their report](https://arxiv.org/pdf/2503.14499) in place or in addition to this milestone. We weren’t able to explore this due to time constraints.*\n\n* Eli’s estimate of gap size: 6 months \\[0.8, 45\\]. Reasoning:  \n  * Intuitively it feels like once AIs can do difficult long-horizon tasks with ground truth external feedback, it doesn’t seem that hard to generalize to more vague tasks. After all, many of the sub-tasks of the long-horizon tasks probably involved using similar skills.  \n  * However, I and others have consistently been surprised by progress on easy-to-evaluate, nicely factorable benchmark tasks, while seeing some corresponding real-world impact but less than I would have expected. Perhaps AIs will continue to get better on checkable tasks in substantial part by relying on trying a bunch of stuff and seeing what works, rather than general reasoning which applies to more vague tasks. And perhaps I’m underestimating the importance of work that is hard to even describe as “tasks”.  \n  * Quantitatively, I’d guess:  \n    * Removing BoK / intermediate feedback adds 1-18 months  \n    * Removing BoK is 5-50% of the way to very hard-to-evaluate tasks, so multiply by 2 to 10\\.  \n    * The above efforts will have already gotten 50-90% of the way there since doing massive coding projects already requires dealing with lots of poor feedback loops, so multiply by 10 to 50%.  \n  * o3-mini tells me this gives roughly 0.8 to 45 months, this seems roughly right so I’ll go with that.  \n  * I realized that these should all be for RE-Bench but with long time horizon and lots of lines of code, rather than current RE-Bench, which is important to keep in mind.  \n* Nikola’s estimate of gap size: 3 months \\[0.5, 18\\]. Reasoning:  \n  * RE-Bench provides scoring functions that can be used to check an agent’s performance at any time. There will likely be a gap in performance with and without feedback.   \n  * The current number is mostly an intuitive guess. My estimate is that adding Best-of-K to RE-Bench adds 4-8 months of progress on the score. This probably captures around a third of the total feedback loop gap.    \n  * This leads to around 12-24 months. However, I expect around half of this gap to already be bridged if I have systems that can do very long-horizon tasks with millions of lines of code. I also think it’s plausible that RL on easy-to-evaluate tasks will generalize well to other tasks, making my lower CI even lower.  \n  * Messiness somewhat tracks a lack of feedback loops. In METR’s horizon paper, Figure 9 presents the performance of tasks divided into messier and less messy tasks. This performance gap can inform how much a lack of feedback loops will affect performance. One metric we can use is “how far behind is the performance of the more messy tasks?” That is, if we take the maximum of the performance on more messy tasks, how long ago was that performance reached on the less messy tasks?   \n    * For a task length below 1 hour, the max success rate is around 0.6 with Claude 3.7 Sonnet (February 2025). That level was surpassed in November 2023 with GPT-4 1106, making a 15 month gap.   \n    * For a task length above 1 hour, the max success rate on messy tasks is around 0.1 with o1 (Dec 2024), which was surpassed in May of 2024 with GPT-4o. That makes a 7 month gap.  \n    * I think the longer tasks are more representative of the types of tasks that will be faced around the feedback loops milestone.  \n    * My gap estimate will add uncertainty on both sides.\n\n\n\n* FutureSearch estimate of gap size: 18.3 months \\[1.7, 58\\]. Reasoning:  \n  * **Agentic planning is key and is likely already good from the previous two milestones.** This should help with lack of oracle calls, and no/poor/limited/expensive feedback loops. If the previous milestones arrived without strong agentic planning, this could be the major bottleneck for this gap.  \n  * **The restriction to the domain of coding for AI research makes progress more plausible.** There is skepticism that, with lack of cheap oracle feedback, human-level general planning will arrive soon.  \n  * **Agents use the oracular score function 10x more than humans.** In the [RE-Bench paper](https://arxiv.org/abs/2411.15114), they used it 25.3 or 36.8 times per hour, compared to 3.4 times for human experts. In the paper, a substantial part of the agents’ performance was due to ‘local-optima’ solutions by tweaking initial parameters, which is particularly dependent on the oracular score function. By this point, with RE-Bench saturation and the previous two milestones, it seems that systems would be able to perform at a level similar to humans in this regard.  \n  * **AIs will need memory to deal with complex trade-offs from stakeholders.** Lack of feedback will require operating at a fuzzier, human level, where the goals/incentives/preferences of dozens of different stakeholders will be illegible and changing. AIs will need to understand the organization’s overall objectives, which will evolve with new business opportunities, new technologies, and changing societal norms.\n\n##### Parallel projects: Handling several interacting projects\n\n**Milestone which would indicate the gap being crossed: Same as above, except working on separate projects spanning multiple codebases that interface together (e.g., a large-scale training pipeline, an experiment pipeline, and a data analysis pipeline).** \n\n* Eli estimate of gap size: 1.4 months \\[0.5, 4\\]. Reasoning:  \n  * My best guess is that a model which can do very long AI R\\\u0026D tasks and modify files totalling 100k lines already possesses most of the skills necessary to handle multiple interacting projects.  \n* Nikola’s estimate of gap size: 1.2 months \\[0.5, 3\\]  \n* FutureSearch estimate of gap size: 2 months \\[0.7, 5.3\\]. Reasoning:  \n  * **Milestone 2 on Complex engineering projects makes this plausibly very easy**. Furthermore, Milestone 3 on working without provided unit tests is likely very useful for dealing with projects that interface together in complicated manners. \n\n##### Specialization: Specializing in skills specific to frontier AI development\n\n**Milestone which would indicate the gap being crossed:** Same as above, except working on the exact projects pursued within AGI companies. \n\n* Eli’s estimate of gap size: 1.7 months \\[0.5, 6\\]. Reasoning:  \n  * Feels a little harder than parallel projects.  \n* Nikola’s estimate of gap size: 0.4 months \\[0.1, 2\\]. Reasoning  \n  * My best guess is that currently fine-tuning models to perform well on tasks internal to a company is not difficult and mostly bottlenecked on general capabilities of the model.  \n  * Also, I don't expect there to be a very large shift in specialization between the tasks the agents are best at and real-world tasks relevant to AI research engineering. In fact, it’s likely they’ll be best at tasks relevant to AI research.  \n* FutureSearch’s estimate of gap size: 2.4 months \\[0.5, 4.7\\]. Reasoning:  \n  * **RE-bench saturation, and the milestones on engineering complexity and parallel interacting projects make this plausibly very easy**, even if projects are very interconnected.  \n  * **The general rise in capabilities should help significantly here.**\n\n##### Cost and speed\n\n**Milestone which would indicate the gap being crossed: Same as above, except doing it at a cost and speed such that there are substantially more superhuman AI agents than human engineers (specifically, 30x more agents than there are humans, each one accomplishing tasks 30x faster).** \n\n* Eli’s estimate of gap size: 6.9 months \\[1, 48\\]. Reasoning:  \n  * [Epoch has measured](https://epoch.ai/data-insights/llm-inference-price-trends) the decline in per-token pieces to achieve the same performance on a variety of non-agentic benchmarks, finding trends between 9 and 900x per year, with a median of 50x. When looking at trends starting in January 2024, they find a median of 200x per year. There are 2 reasons to adjust these estimates upwards:  \n    * They don’t include AIs being able to use fewer tokens for the same task, and they generally focused on non-agentic benchmarks like MMLU and GPQA in which the amount of tokens used to solve the task doesn’t vary by a lot for non-reasoning models.  \n    * Their trends started below human cost, and I expect that trends starting at higher costs will be faster due to reasoning about the extremes of the cost curve over time: the cost to achieve a given performance starts at \\~infinity (no amount of GPT-2 inference compute could get 2025-level performance on agentic tasks) and will eventually asymptote due to physical limits.  \n  * Looking at RE-Bench, a more agentic benchmark which started at roughly human cost and we can take into account fewer tokens being needed, we see a faster decrease of roughly 10x in .33 years so a 1,000x/year trend (based on [Figure 11](https://arxiv.org/pdf/2411.15114#page=20), comparing 3.5 Sonnet Old to 3.5 Sonnet New).  \n    * However, looking at [updated data](#running-an-extrapolation) it seems like the rate of change between Old and New was unusually large, so this should be discounted.  \n    * This should plausibly be decreased further because SC-level agents will be making more efficient use of inference compute than naive Best of N.  \n  * So based on the above we might get a 30x cost decrease in roughly 0.35-1.5 years (10,000x/year would be \\~0.35 years, 10x/year would be \\~1.5 years)  \n  * If we assume the cost decrease happens only via achieving tasks faster while keeping the same cost/second (cost/token\\*tokens/second), then the speed increase would be exactly met.[^16] If the cost/second has gone up, that means that speed has already increased \\\u003e30x (think: cost/second is 2x more \\-\\\u003e 1/30 the cost is accrued in ½ the time \\-\\\u003e model is 60x faster and 30x cheaper). So we should lower the gap length estimate, as we have dominated the 30x speed / 30x cost point on the Pareto frontier. If the cost/second has gone down, then we need to add to the estimate.  \n  * In the examples used above (token costs/speeds per [OpenRouter](https://openrouter.ai/)):  \n    * [Epoch’s estimates](https://epoch.ai/data-insights/llm-inference-price-trends) which rely on cheaper per-token costs found a \\~3.5x speed increase for a 300x decrease in cost. This means that a 30x decrease in cost would correspond with a \\~2x speed increase. Further cost decreases could be attempted to be translated into increased speed via parallelization; for the non-agentic tasks Epoch measured this would be difficult, but it would probably be doable for SC-level AIs on agentic tasks.  \n      * A \\~300x efficiency increase on GPQA from GPT-4 to Phi 4 corresponds with a \\~3.5x speed increase and a \\~150x decrease in cost/second:  \n        * [GPT-4](https://openrouter.ai/openai/gpt-4) is $1,800/million-output-seconds; 30 tok/sec and $30/MTok input and $60/MTok output  \n        * [Phi 4](https://openrouter.ai/microsoft/phi-4-multimodal-instruct) is $11/million-output-seconds; 110 tok/sec and $0.07/MTok input and $0.11/MTok output  \n      * Similar speed changes arise for other benchmark trends, with varying rates of efficiency decreases.  \n    * For the [RE-Bench case](https://arxiv.org/pdf/2411.15114#page=20) which relies on more efficient use of tokens, cost/second is basically the same.  \n      * [Claude 3.5 Sonnet Old](https://openrouter.ai/anthropic/claude-3.5-sonnet-20240620:beta) is 66 tok/sec and costs $3/MTok input and $15/MTok output  \n      * [Claude 3.5 Sonnet New](https://openrouter.ai/anthropic/claude-3.5-sonnet) is 58 tok/sec and costs $3/MTok input and $15/MTok output  \n  * I expect the expensive-\\\u003echeap SC transition to look more like the RE-Bench case than Epoch’s estimates, i.e. I think the models will get more capable rather than transitioning to cheaper models at the same capability level; so I expect cost/second to decrease some but not dramatically. I wouldn’t at all be surprised if it increased though which would mean that my forecast should decrease. I’ll increase and widen my forecast a bit based on the cost/second considerations to 0.2-3 years.  \n  * I’ll then widen my forecast a little more for good measure, to 0.1-4 years.  \n* Nikola’s estimate of gap size: 6 months \\[1, 36\\]. Reasoning:  \n  * I basically agree with Eli’s reasoning below. Some additional thoughts:  \n    * GPT-4o mini costs $0.15 / 1M input tokens and $0.6 / 1M output tokens compared to GPT-4 at $30 / 1M input and $60 per 1M output despite having similar benchmark performance and they were \\~1.5 years apart, so around 1 year per 10x decrease.  \n    * More recently, DeepSeek R1 roughly matches the old Claude 3.5 Sonnet in performance. C3.5s costs $3/MTok input and $15/MTok output, whereas DeepSeek R1 costs $0.5/MTok input and $2/MTok output. It also uses more tokens so remove a factor of 2\\. This gives a \\~3x decrease in 0.5 years, which roughly matches up with a 10x/year decrease.  \n    * On ARC-AGI (which I don’t think measures relevant capabilities but might be a useful datapoint), o3-mini costs 2 OOMs less for the same performance. So there might be a recent increase in the speed of distillation.  \n    * My best guess is that the first SC-capable systems will be prohibitively expensive and require 1-2 orders of magnitude of cost reduction to be more affordable than a human engineer per hour of work.  \n    * It’s plausible that developers will always keep their model inference costs pretty low and never balloon into much-higher-than-human costs, so possibly the first SC-capable models will be cheap out-of-the-box.  \n* FutureSearch’s estimate of gap size: 13.5 months \\[4.5, 36\\]. Reasoning:  \n  * **Current trends on how much inference costs (at a fixed capability level) are decreasing [point](https://a16z.com/llmflation-llm-inference-cost/) [towards](https://www.businessinsider.com/sam-altman-cost-using-ai-drop-10-times-every-year-2025-2) a ×10 decrease every year.** In this scenario the reduction could be even starker, particularly for systems specialized for AI development, and for coding where there is economic pressure to lower costs. A more recent and comprehensive [Epoch analysis](https://epoch.ai/data-insights/llm-inference-price-trends?insight-option=All+benchmarks) points toward inference costs falling even faster, with a median reduction of ×50/year.  \n  * **The reductions in cost may have already come accompanied with increased speed.** In an aggressive scenario we can assume that we only need to account for the ×30 cost reduction, which, on the trend of ×50/year, would be about 10.5 months.  \n  * **Even if not, elicitation techniques like best-of-k, and advances in reasoning models, make us think human speed is not the right baseline**. At the human bound, the equivalent time of a ×900 cost reduction, on the ×10/year trend, would take about 3 years. But this seems too conservative. If we assume that we start near the human cost but are already 5 times faster, we would need to cross a gap of 6×30=180. Which with a ×10/year trend would be achieved in about 29 months.\n\n*(Edited to add Dec 2025: There was a mistake in Eli’s reasoning above. Instead of reasoning about speed and cost, it would have been better to reason about speed and copies. Also, it would have been been helpful to break down improvements into tokens/second, token efficiency, and $/token as opposed to the high level of cost/second If this mistake were fixed, Eli would have gotten an estimate of 1.9 years based on the Epoch data points and 0.7 years based on the RE-Bench ones.*\n\n*What Eli should have done is something like:*   \n\n*a) Calculate that to get to SC we need the equivalent of 27,000x parallel labor increase*  \n\n*b) Calculate that for RE-Bench the trend of parallel labor increase is 100x/4 months assuming an exponent of 2 to translate serial to parallel labor, because 10x token efficiency results in a 10x speedup but no copies. Then take log(27000)/log((10^2)^3) to get .74 years.*  \n\n*c) For Epoch do a similar thing, arrive at log(27000)/log((15\\*(2^2))^(12/9))=1.87 years. The reason that for the Epoch trend we have a 15x copies increase is that the $/token decrease increases copies by 30x, but the 2x in tokens/second decreases copies by 2x, because you’re now generating more tokens per timestep per-model.)*\n\n##### Other task difficulty gaps\n\n**Milestone which would indicate the gap being crossed:** SC achieved. \n\n* Eli’s estimate of gap size: 5.5 months \\[1, 30\\]  \n* Nikola’s estimate of gap size: 3 months \\[0.5, 18\\]  \n* FutureSearch’s estimate of gap size: 14.7 months \\[2, 58.8\\]. Reasoning:\n  * **Agentic planning is key and is likely already good from the previous two milestones.** This should help with lack of oracle calls, and no/poor/limited/expensive feedback loops. If the previous milestones arrived without strong agentic planning, this could be the major bottleneck for this gap.  \n  * **The restriction to the domain of coding for AI research makes progress more plausible.** There is skepticism that, with lack of cheap oracle feedback, human-level general planning will arrive soon.  \n  * **Agents use the oracular score function 10x more than humans.** In the [RE-Bench paper](https://arxiv.org/abs/2411.15114), they used it 25.3 or 36.8 times per hour, compared to 3.4 times for human experts. In the paper, a substantial part of the agents’ performance was due to ‘local-optima’ solutions by tweaking initial parameters, which is particularly dependent on the oracular score function. By this point, with RE-Bench saturation and the previous two milestones, it seems that systems would be able to perform at a level similar to humans in this regard.  \n  * **AIs will need memory to deal with complex trade-offs from stakeholders.** Lack of feedback will require operating at a fuzzier, human level, where the goals/incentives/preferences of dozens of different stakeholders will be illegible and changing. AIs will need to understand the organization’s overall objectives, which will evolve with new business opportunities, new technologies, and changing societal norms.\n\n#### Superhuman Coder (SC): time horizon and reliability requirements\n\nA superhuman coder (SC) must be able to overall do as good of a job as the combination of all human programmers at an AGI company at their current work.[^17]\n\nWhat time horizon and reliability level does this require on HCAST?\n\n**Eli’s opinion:**\n\n**Time horizon and reliability required on real distribution of work tasks, as baselined by the best humans with strong incentives:**\n\n1. **Time horizon: 6 months (80% CI: \\[1 week, 12 years\\]).** If AIs can fairly consistently do tasks that take humans 6 months, it seems like they should be able to automate large coding projects. Anything less than 1 week seems highly unlikely to be enough. I’d like to have an even fatter right tail than a lognormal here ideally, but I expect that once we’re getting into the years the trend will likely be pretty superexponential anyway.  \n   1. An alternate view: Given that human baseliners only score around a 90 minute time horizon, it’s also possible AI will outperform humans at many coding tasks by the time it has a 90 minute time horizon. 10-year time horizons seem like a sensible upper bound on the length of tasks the AI needs to be able to do, but it seems likely that even at a 1-month time horizon under METR’s current definition, AI will be able to automate large parts of the AI R\\\u0026D process with a small amount input from other colleagues. We’ll take into account some uncertainty here with a lognormal with 80% CI of \\[16 hours, 2 work-years (4,000 hours)\\].  \n2. **Reliability: 80%.** If the SC is equally well-rounded as the best humans, this would be somewhat below 50% for a few reasons in footnote.[^18] Currently AIs are much less well-rounded than humans though, so if they have 40% reliability within human cost/speed they likely only go up to around 45-50% if allowed to take 10x longer. So with current AIs we might need to set a 90+% reliability threshold. SC-level AIs will be much more well-rounded though, due to having very strong agency skills (planning, correcting mistakes, etc.). So we lower it to 80%, which seems roughly right and has the advantage of being able to utilize METR’s reported data.\n\n**Time horizon required on an extrapolation of HCAST (METR’s task suite), with METR’s current baselining strategy: 10 years \\[1 month, 1200 years\\].**\n\nI’ll keep reliability the same and adjust the time horizon to tune it to METR’s report (their task suite and baselining process), allowing me to forecast more straightforwardly via extrapolation METR’s results. I make an adjustment based on the below considerations.\n\nReasons for raising the time horizon requirement:\n\n1. An extrapolation of the HCAST suite doesn’t cover gaps that will come up in the real world (poor feedback loops is my guess as to the most important gap, see [here](#summary-table) for some of the candidates that seem most prominent).  \n2. The baselines for HCAST are weaker than ideal which inflates the time horizons relative to the setup assumed above (see more in [the time horizon paper](https://arxiv.org/pdf/2503.14499#page=28.48) and the [HCAST paper](https://metr.org/hcast.pdf#page=14.18)): (a) they are done by fairly competent people, but not the literal best humans (b) they aren’t always done by experts (c) they are done with people with low context (similar to new hires, rather than already being familiar with a codebase).  \n   1. [Baseliners were found to take 5-18x longer to resolve METR issues in METR code repositories.](https://arxiv.org/pdf/2503.14499#page=16.71) However for longer horizon tasks existing familiarity wouldn’t matter as much because there would be time to acquire context.\n\nReason for lowering the time horizon requirement: There might be ways in which an extrapolated HCAST is actually harder than real world tasks (i.e. the opposite of (1) above). For example, some baseline scoring functions are unrealistically unforgiving.\n\nWhile 1200 years sounds high, I think it’s plausible that there are very big gaps between HCAST and the real world or there are huge gaps between HCAST baselining and SC-level baselines.\n\n**Nikola’s opinion:** Given that human baseliners only score around a 90 minute time horizon, it’s also possible AI will outperform humans at many coding tasks by the time it has a 90 minute time horizon. 10-year time horizons seem like a sensible upper bound on the length of tasks the AI needs to be able to do, but it seems likely that even at a 1-month time horizon under METR’s current definition, AI will be able to automate large parts of the AI R\\\u0026D process with a small amount input from other colleagues. We’ll take into account some uncertainty here with a **lognormal with 80% CI of \\[16 hours, 2 work-years (4,000 hours)\\]**. \n\n#### RE-Bench saturation resolution criteria\n\n*Copied over from the [AI 2025 Forecasting Survey](https://ai2025.org/)*\n\nAny AI system counts if it operates within realistic deployment constraints and doesn't have unfair advantages over human baseliners.\n\nTool assistance, scaffolding, and any other inference-time elicitation techniques are permitted as long as:\n\n* **No Unfair and Systematic Advantage.** There is no systematic unfair advantage over the humans described in the Human Performance section (e.g., AI systems are allowed to have multiple outputs autograded while humans aren't, or AI systems have access to the internet when humans don't).  \n* **Human Cost Parity.** Having the AI system complete the task does not use more compute than could be purchased with the wages needed to pay a human to complete the same task to the same level\n\nThe [PASS@k](https://arxiv.org/pdf/2107.03374) elicitation technique (which automatically grades and chooses the best out of k outputs from a model) is a common example that we **do accept on this benchmark** because human baseliners in RE-Bench also have access to scoring metrics (e.g., loss/runtime). So PASS@k doesn't constitute a clear unfair advantage.\n\n\\[...\\]\n\nHuman cost estimation process:\n\n1. **Rank questions by human cost.** For each question, estimate how much it would cost for humans to solve it. If humans fail on a question, factor in the additional cost required for them to succeed.  \n2. **Match the AI’s accuracy to a human cost total.** If the AI system solves N% of questions, identify the cheapest N% of questions (by human cost) and sum those costs to determine the baseline human total.  \n3. **Account for unsolved questions.** For each question the AI does not solve, add the maximum cost from that bottom N%. This ensures both humans and AI systems are compared under a fixed per-problem budget, without relying on humans to dynamically adjust their approach based on difficulty.\n\n[^1]:  Harvard University, part-time intern at [METR](https://metr.org/)\n\n[^2]:  [futuresearch.ai](http://futuresearch.ai), individual forecaster bios on [futuresearch.ai/ai-2027](http://futuresearch.ai/ai-2027)\n\n[^3]:   The reason 5% is used is because it’s approximately the fraction that we project AI projects to be spending around the time they reach SC: see the “Research automation” row in our [compute supplement](https://ai-2027.com/supplements/compute-forecast#section-3-compute-usage).\n\n[^4]:  Time horizon for each task is defined as: \n    1. For tasks without a fixed time cap, the geometric mean of the time taken by humans who completed it. \n    2. For RE-Bench in which humans had a fixed time cap, success is binarized based on the average score of human baseliners and the time horizon is considered to be the time cap (8 hours).\n\n[^5]:  *(Edit Dec 2025: We now believe this argument was mistaken)* The trend would likely further tilt toward superexponetiality if we took into account that the public vs. internal gap has seemed to decrease over time. It’s been rumored that GPT-4 was released 7 months after pre-training was complete, while it seems now there are much smaller delays; for example according to the announcement video Grok 3 was released a month after pre-training was complete.\n\n[^6]:  Another argument for eventually getting superexponentiality is that it seems like superhuman AGIs should have infinite time horizons. However, under the definition of time horizon adapted from the METR report [above](#heading=h.30sildo24x0l'), it’s not clear if infinite time horizons will ever be reached. This is because AIs are graded on their absolute task success rate, not whether they have a higher success rate than humans. As long as there’s a decreasing trend in ability to accomplish tasks as the time horizon gets longer, the time horizon won’t be infinite. This is something that has been observed with human baseliners (see Figure 16 [here](https://arxiv.org/pdf/2503.14499#page=29)). Even if infinite horizons are never reached, the time horizons might get extremely large which would still lend some support to superexponentiality. Even so, it’s unclear how much evidence this is for superexponentiality in the regime we are forecasting in.\n\n[^7]:  Perhaps this could be the case if extending to each successive time horizon requires doing large amounts of training on tasks of that horizon.\n\n[^8]:  (1.315 \\+ 2.30 \\+ 1.195 \\+ 1.575 \\+ 2.335 \\+ 1.475 \\+ 1.465)/7 \\= 1.67\n\n[^9]:  Because each gap is defined using a measurable milestone, this means that our predictions of when gaps will get crossed are empirical forecasts for when certain AI capabilities will be hit. Benchmarks that could actually resolve these predictions don’t yet exist (all relevant current benchmarks will already be saturated at that point), but it’s plausible that they will be created.\n\n[^10]:  Specifically, in order to model the correlation we model the CDFs of each function, and sample the percentile of each value by finding the CDF of a sample from multivariate normal with a correlation coefficient of 0.7. \n\n[^11]:  Time horizon for each task is defined as:\n    1. For tasks without a fixed time cap, the geometric mean of the time taken by humans who completed it. \n    2. For RE-Bench in which humans had a fixed time cap, success is binarized based on the average score of human baseliners and the time horizon is considered to be the time cap (8 hours).\n\n[^12]:  For this parameter only, we mean work-months, not calendar months. One work-month is 4 weeks \\* 40 hours/week of actual work, meaning a 1-month time horizon corresponds to a 160-hour time horizon as defined in the METR graphs.\n\n[^13]:  Recall that the time horizon is determined by taking the geometric mean of successful human completion times. A few reasons why this will lead to reliability levels below 50% for SC with the same skill level as baselined human teams, under our definition which requires the SC to solve the task at least as quickly and cheaply as the humans: (a) selecting only for successful achievements before taking the geometric mean artificially deflates the time horizons, leading to lower reliability. (b) if many people of similar abilities did the same task over and over, probably the data would be somewhat right-skewed, which if the distribution were lognormal would mean the median and geometric mean are equal. However, it’s plausible that the distribution would be less skewed than lognormal so the geomean would be below the median, leading to lower reliability.\n\n[^14]:  The lognormal is between (lower bound \\- 1\\) and (upper bound \\- 1), since the lower bound on the multiplier is 1\\.\n\n[^15]:  I’m projecting that the first SC will have roughly 80th percentile research taste, and a 20% chance that it will already be \\\u003e= the best AI researcher.\n\n[^16]:  I’m assuming the cognitive tasks don’t involve other bottlenecks, as defined in the ARE milestone. Of course there are some non-cognitive bottlenecks in SWE like compiling, but these can likely be worked around.\n\n[^17]:  A full SC needs to do this faster and cheaper as well, but this will be accounted for later on in the time horizon extension method.\n\n[^18]:  Recall that the time horizon is determined by taking the geometric mean of successful human completion times. A few reasons why this will lead to reliability levels below 50% for SC with the same skill level as baselined human teams, under our definition which requires the SC to solve the task at least as quickly and cheaply as the humans: (a) selecting only for successful achievements before taking the geometric mean artificially deflates the time horizons, leading to lower reliability. (b) if many people of similar abilities did the same task over and over, probably the data would be somewhat right-skewed, which if the distribution were lognormal would mean the median and geometric mean are equal. However, it’s plausible that the distribution would be less skewed than lognormal so the geomean would be below the median, leading to lower reliability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"216d:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L5\",null,{\"buildId\":\"WI_OvW_Xjv8lU8fcWnw_s\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"\"],\"initialTree\":[\"\",{\"children\":[\"(mainPage)\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"(mainPage)\",{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$undefined\",null],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/edd4b027af513e5a.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/eb8e0ea56b7a3d7c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7ab52e961d3a1031.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[[\"$\",\"$L7\",null,{\"contentSections\":[{\"chunk\":{\"nodes\":[{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2025-04-30\",\"position\":{\"start\":{\"line\":2,\"column\":1,\"offset\":17},\"end\":{\"line\":2,\"column\":11,\"offset\":27}}}],\"position\":{\"start\":{\"line\":2,\"column\":1,\"offset\":17},\"end\":{\"line\":2,\"column\":13,\"offset\":29}}}],\"position\":{\"start\":{\"line\":1,\"column\":1,\"offset\":0},\"end\":{\"line\":3,\"column\":4,\"offset\":33}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution.\",\"position\":{\"start\":{\"line\":5,\"column\":1,\"offset\":35},\"end\":{\"line\":5,\"column\":128,\"offset\":162}}}],\"position\":{\"start\":{\"line\":5,\"column\":1,\"offset\":35},\"end\":{\"line\":5,\"column\":128,\"offset\":162}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We wrote a scenario that represents our best guess about what that might look like.\",\"position\":{\"start\":{\"line\":7,\"column\":1,\"offset\":164},\"end\":{\"line\":7,\"column\":84,\"offset\":247}}},{\"type\":\"footnoteReference\",\"identifier\":\"1\",\"label\":\"1\",\"position\":{\"start\":{\"line\":7,\"column\":84,\"offset\":247},\"end\":{\"line\":7,\"column\":88,\"offset\":251}}},{\"type\":\"text\",\"value\":\" It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes.\",\"position\":{\"start\":{\"line\":7,\"column\":88,\"offset\":251},\"end\":{\"line\":7,\"column\":212,\"offset\":375}}},{\"type\":\"footnoteReference\",\"identifier\":\"2\",\"label\":\"2\",\"position\":{\"start\":{\"line\":7,\"column\":212,\"offset\":375},\"end\":{\"line\":7,\"column\":216,\"offset\":379}}}],\"position\":{\"start\":{\"line\":7,\"column\":1,\"offset\":164},\"end\":{\"line\":7,\"column\":216,\"offset\":379}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"(Added Nov 22 2025: To prevent misunderstandings: we don't know exactly when AGI will be built. 2027 was our modal (most likely) year at the time of publication, our medians were \",\"position\":{\"start\":{\"line\":9,\"column\":1,\"offset\":381},\"end\":{\"line\":9,\"column\":181,\"offset\":561}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.listendata.com/2023/08/right-skewed-histogram.html\",\"children\":[{\"type\":\"text\",\"value\":\"somewhat longer\",\"position\":{\"start\":{\"line\":9,\"column\":182,\"offset\":562},\"end\":{\"line\":9,\"column\":197,\"offset\":577}}}],\"position\":{\"start\":{\"line\":9,\"column\":181,\"offset\":561},\"end\":{\"line\":9,\"column\":262,\"offset\":642}}},{\"type\":\"text\",\"value\":\". For more detail on our views, see \",\"position\":{\"start\":{\"line\":9,\"column\":262,\"offset\":642},\"end\":{\"line\":9,\"column\":298,\"offset\":678}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/eli_lifland/status/1992004724841906392?s=20\",\"children\":[{\"type\":\"text\",\"value\":\"here\",\"position\":{\"start\":{\"line\":9,\"column\":299,\"offset\":679},\"end\":{\"line\":9,\"column\":303,\"offset\":683}}}],\"position\":{\"start\":{\"line\":9,\"column\":298,\"offset\":678},\"end\":{\"line\":9,\"column\":363,\"offset\":743}}},{\"type\":\"text\",\"value\":\".)\",\"position\":{\"start\":{\"line\":9,\"column\":363,\"offset\":743},\"end\":{\"line\":9,\"column\":366,\"offset\":746}}},{\"type\":\"footnoteReference\",\"identifier\":\"3\",\"label\":\"3\",\"position\":{\"start\":{\"line\":9,\"column\":366,\"offset\":746},\"end\":{\"line\":9,\"column\":370,\"offset\":750}}}],\"position\":{\"start\":{\"line\":9,\"column\":1,\"offset\":381},\"end\":{\"line\":9,\"column\":370,\"offset\":750}}},{\"type\":\"containerDirective\",\"name\":\"tabBoxes\",\"attributes\":{},\"children\":[{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"What is this?\",\"position\":{\"start\":{\"line\":13,\"column\":4,\"offset\":768},\"end\":{\"line\":13,\"column\":17,\"offset\":781}}}],\"position\":{\"start\":{\"line\":13,\"column\":1,\"offset\":765},\"end\":{\"line\":13,\"column\":17,\"offset\":781}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The CEOs of \",\"position\":{\"start\":{\"line\":15,\"column\":1,\"offset\":783},\"end\":{\"line\":15,\"column\":13,\"offset\":795}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.bloomberg.com/features/2025-sam-altman-interview\",\"children\":[{\"type\":\"text\",\"value\":\"OpenAI\",\"position\":{\"start\":{\"line\":15,\"column\":14,\"offset\":796},\"end\":{\"line\":15,\"column\":20,\"offset\":802}}}],\"position\":{\"start\":{\"line\":15,\"column\":13,\"offset\":795},\"end\":{\"line\":15,\"column\":83,\"offset\":865}}},{\"type\":\"text\",\"value\":\", \",\"position\":{\"start\":{\"line\":15,\"column\":83,\"offset\":865},\"end\":{\"line\":15,\"column\":85,\"offset\":867}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.bigtechnology.com/p/google-deepmind-ceo-demis-hassabis\",\"children\":[{\"type\":\"text\",\"value\":\"Google DeepMind\",\"position\":{\"start\":{\"line\":15,\"column\":86,\"offset\":868},\"end\":{\"line\":15,\"column\":101,\"offset\":883}}}],\"position\":{\"start\":{\"line\":15,\"column\":85,\"offset\":867},\"end\":{\"line\":15,\"column\":170,\"offset\":952}}},{\"type\":\"text\",\"value\":\", and \",\"position\":{\"start\":{\"line\":15,\"column\":170,\"offset\":952},\"end\":{\"line\":15,\"column\":176,\"offset\":958}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-01-21-2025/card/anthropic-ceo-says-ai-could-surpass-human-intelligence-by-2027-9tka9tjLKLalkXX8IgKA\",\"children\":[{\"type\":\"text\",\"value\":\"Anthropic\",\"position\":{\"start\":{\"line\":15,\"column\":177,\"offset\":959},\"end\":{\"line\":15,\"column\":186,\"offset\":968}}}],\"position\":{\"start\":{\"line\":15,\"column\":176,\"offset\":958},\"end\":{\"line\":15,\"column\":362,\"offset\":1144}}},{\"type\":\"text\",\"value\":\" have all predicted that AGI will arrive within the next 5 years. Sam Altman \",\"position\":{\"start\":{\"line\":15,\"column\":362,\"offset\":1144},\"end\":{\"line\":15,\"column\":439,\"offset\":1221}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://webcf.waybackmachine.org/web/20250106014723/https://blog.samaltman.com/reflections\",\"children\":[{\"type\":\"text\",\"value\":\"has said\",\"position\":{\"start\":{\"line\":15,\"column\":440,\"offset\":1222},\"end\":{\"line\":15,\"column\":448,\"offset\":1230}}}],\"position\":{\"start\":{\"line\":15,\"column\":439,\"offset\":1221},\"end\":{\"line\":15,\"column\":541,\"offset\":1323}}},{\"type\":\"text\",\"value\":\" OpenAI is setting its sights on “superintelligence in the true sense of the word” and the “glorious future.”\",\"position\":{\"start\":{\"line\":15,\"column\":541,\"offset\":1323},\"end\":{\"line\":15,\"column\":650,\"offset\":1432}}}],\"position\":{\"start\":{\"line\":15,\"column\":1,\"offset\":783},\"end\":{\"line\":15,\"column\":650,\"offset\":1432}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"What might that look like? We wrote AI 2027 to answer that question. Claims about the future are often frustratingly vague, so we tried to be as concrete and quantitative as possible, even though this means depicting one of many possible futures.\",\"position\":{\"start\":{\"line\":17,\"column\":1,\"offset\":1434},\"end\":{\"line\":17,\"column\":247,\"offset\":1680}}}],\"position\":{\"start\":{\"line\":17,\"column\":1,\"offset\":1434},\"end\":{\"line\":17,\"column\":247,\"offset\":1680}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We wrote two endings: a “slowdown” and a “race” ending. However, AI 2027 is not a recommendation or exhortation. Our goal is predictive accuracy.\",\"position\":{\"start\":{\"line\":19,\"column\":1,\"offset\":1682},\"end\":{\"line\":19,\"column\":146,\"offset\":1827}}},{\"type\":\"footnoteReference\",\"identifier\":\"4\",\"label\":\"4\",\"position\":{\"start\":{\"line\":19,\"column\":146,\"offset\":1827},\"end\":{\"line\":19,\"column\":150,\"offset\":1831}}}],\"position\":{\"start\":{\"line\":19,\"column\":1,\"offset\":1682},\"end\":{\"line\":19,\"column\":150,\"offset\":1831}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We encourage you to debate and counter this scenario.\",\"position\":{\"start\":{\"line\":21,\"column\":1,\"offset\":1833},\"end\":{\"line\":21,\"column\":54,\"offset\":1886}}},{\"type\":\"footnoteReference\",\"identifier\":\"5\",\"label\":\"5\",\"position\":{\"start\":{\"line\":21,\"column\":54,\"offset\":1886},\"end\":{\"line\":21,\"column\":58,\"offset\":1890}}},{\"type\":\"text\",\"value\":\" We hope to spark a broad conversation about where we’re headed and how to steer toward positive futures. We’re \",\"position\":{\"start\":{\"line\":21,\"column\":58,\"offset\":1890},\"end\":{\"line\":21,\"column\":170,\"offset\":2002}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/about?tab=bets-and-bounties#tab-box-bets-and-bounties\",\"children\":[{\"type\":\"text\",\"value\":\"planning to give out thousands in prizes\",\"position\":{\"start\":{\"line\":21,\"column\":171,\"offset\":2003},\"end\":{\"line\":21,\"column\":211,\"offset\":2043}}}],\"position\":{\"start\":{\"line\":21,\"column\":170,\"offset\":2002},\"end\":{\"line\":21,\"column\":287,\"offset\":2119}}},{\"type\":\"text\",\"value\":\" to the best alternative scenarios.\",\"position\":{\"start\":{\"line\":21,\"column\":287,\"offset\":2119},\"end\":{\"line\":21,\"column\":322,\"offset\":2154}}}],\"position\":{\"start\":{\"line\":21,\"column\":1,\"offset\":1833},\"end\":{\"line\":21,\"column\":322,\"offset\":2154}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"How did we write it?\",\"position\":{\"start\":{\"line\":23,\"column\":4,\"offset\":2159},\"end\":{\"line\":23,\"column\":24,\"offset\":2179}}}],\"position\":{\"start\":{\"line\":23,\"column\":1,\"offset\":2156},\"end\":{\"line\":23,\"column\":24,\"offset\":2179}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Our research on key questions (e.g. what goals will future AI agents have?) can be found \",\"position\":{\"start\":{\"line\":25,\"column\":1,\"offset\":2181},\"end\":{\"line\":25,\"column\":90,\"offset\":2270}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research\",\"children\":[{\"type\":\"text\",\"value\":\"here\",\"position\":{\"start\":{\"line\":25,\"column\":91,\"offset\":2271},\"end\":{\"line\":25,\"column\":95,\"offset\":2275}}}],\"position\":{\"start\":{\"line\":25,\"column\":90,\"offset\":2270},\"end\":{\"line\":25,\"column\":126,\"offset\":2306}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":25,\"column\":126,\"offset\":2306},\"end\":{\"line\":25,\"column\":127,\"offset\":2307}}}],\"position\":{\"start\":{\"line\":25,\"column\":1,\"offset\":2181},\"end\":{\"line\":25,\"column\":127,\"offset\":2307}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The scenario itself was written iteratively: we wrote the first period (up to mid-2025), then the following period, etc. until we reached the ending. We then scrapped this and did it again.\",\"position\":{\"start\":{\"line\":27,\"column\":1,\"offset\":2309},\"end\":{\"line\":27,\"column\":190,\"offset\":2498}}}],\"position\":{\"start\":{\"line\":27,\"column\":1,\"offset\":2309},\"end\":{\"line\":27,\"column\":190,\"offset\":2498}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We weren’t trying to reach any particular ending. After we finished the first ending—which is now colored red—we wrote a new alternative branch because we wanted to also depict a more hopeful way things could end, starting from roughly the same premises. This went through several iterations.\",\"position\":{\"start\":{\"line\":29,\"column\":1,\"offset\":2500},\"end\":{\"line\":29,\"column\":293,\"offset\":2792}}},{\"type\":\"footnoteReference\",\"identifier\":\"6\",\"label\":\"6\",\"position\":{\"start\":{\"line\":29,\"column\":293,\"offset\":2792},\"end\":{\"line\":29,\"column\":297,\"offset\":2796}}}],\"position\":{\"start\":{\"line\":29,\"column\":1,\"offset\":2500},\"end\":{\"line\":29,\"column\":297,\"offset\":2796}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Our scenario was informed by approximately 25 \",\"position\":{\"start\":{\"line\":31,\"column\":1,\"offset\":2798},\"end\":{\"line\":31,\"column\":47,\"offset\":2844}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/about?tab=tabletop-exercise#tab-box-tabletop-exercise\",\"children\":[{\"type\":\"text\",\"value\":\"tabletop exercises\",\"position\":{\"start\":{\"line\":31,\"column\":48,\"offset\":2845},\"end\":{\"line\":31,\"column\":66,\"offset\":2863}}}],\"position\":{\"start\":{\"line\":31,\"column\":47,\"offset\":2844},\"end\":{\"line\":31,\"column\":142,\"offset\":2939}}},{\"type\":\"text\",\"value\":\" and feedback from over 100 people, including dozens of experts in each of AI governance and AI technical work.\",\"position\":{\"start\":{\"line\":31,\"column\":142,\"offset\":2939},\"end\":{\"line\":31,\"column\":253,\"offset\":3050}}}],\"position\":{\"start\":{\"line\":31,\"column\":1,\"offset\":2798},\"end\":{\"line\":31,\"column\":253,\"offset\":3050}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Why is it valuable?\",\"position\":{\"start\":{\"line\":33,\"column\":4,\"offset\":3055},\"end\":{\"line\":33,\"column\":23,\"offset\":3074}}}],\"position\":{\"start\":{\"line\":33,\"column\":1,\"offset\":3052},\"end\":{\"line\":33,\"column\":23,\"offset\":3074}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"“I highly recommend reading this scenario-type prediction on how AI could transform the world in just a few years. Nobody has a crystal ball, but this type of content can help notice important questions and illustrate the potential impact of emerging risks.”\",\"position\":{\"start\":{\"line\":35,\"column\":2,\"offset\":3077},\"end\":{\"line\":35,\"column\":260,\"offset\":3335}}}],\"position\":{\"start\":{\"line\":35,\"column\":1,\"offset\":3076},\"end\":{\"line\":35,\"column\":261,\"offset\":3336}}},{\"type\":\"text\",\"value\":\" —\",\"position\":{\"start\":{\"line\":35,\"column\":261,\"offset\":3336},\"end\":{\"line\":35,\"column\":263,\"offset\":3338}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"Yoshua Bengio\",\"position\":{\"start\":{\"line\":35,\"column\":264,\"offset\":3339},\"end\":{\"line\":35,\"column\":277,\"offset\":3352}}},{\"type\":\"footnoteReference\",\"identifier\":\"7\",\"label\":\"7\",\"position\":{\"start\":{\"line\":35,\"column\":277,\"offset\":3352},\"end\":{\"line\":35,\"column\":281,\"offset\":3356}}}],\"position\":{\"start\":{\"line\":35,\"column\":263,\"offset\":3338},\"end\":{\"line\":35,\"column\":282,\"offset\":3357}}}],\"position\":{\"start\":{\"line\":35,\"column\":1,\"offset\":3076},\"end\":{\"line\":35,\"column\":282,\"offset\":3357}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We have set ourselves an impossible task. Trying to predict how superhuman AI in 2027 would go is like trying to predict how World War 3 in 2027 would go, except that it’s an even larger departure from past case studies. Yet it is still valuable to attempt, just as it is valuable for the U.S. military to game out Taiwan scenarios.\",\"position\":{\"start\":{\"line\":37,\"column\":1,\"offset\":3359},\"end\":{\"line\":37,\"column\":333,\"offset\":3691}}}],\"position\":{\"start\":{\"line\":37,\"column\":1,\"offset\":3359},\"end\":{\"line\":37,\"column\":333,\"offset\":3691}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Painting the whole picture makes us notice important questions or connections we hadn’t considered or appreciated before, or realize that a possibility is more or less likely. Moreover, by sticking our necks out with concrete predictions, and encouraging others to publicly state their disagreements, we make it possible to evaluate years later who was right.\",\"position\":{\"start\":{\"line\":39,\"column\":1,\"offset\":3693},\"end\":{\"line\":39,\"column\":360,\"offset\":4052}}}],\"position\":{\"start\":{\"line\":39,\"column\":1,\"offset\":3693},\"end\":{\"line\":39,\"column\":360,\"offset\":4052}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Also, one author wrote a lower-effort AI scenario \",\"position\":{\"start\":{\"line\":41,\"column\":1,\"offset\":4054},\"end\":{\"line\":41,\"column\":51,\"offset\":4104}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\",\"children\":[{\"type\":\"text\",\"value\":\"before, in August 2021\",\"position\":{\"start\":{\"line\":41,\"column\":52,\"offset\":4105},\"end\":{\"line\":41,\"column\":74,\"offset\":4127}}}],\"position\":{\"start\":{\"line\":41,\"column\":51,\"offset\":4104},\"end\":{\"line\":41,\"column\":147,\"offset\":4200}}},{\"type\":\"text\",\"value\":\". While it got many things wrong, overall it was surprisingly successful: he predicted the rise of chain-of-thought, inference scaling, sweeping AI chip export controls, and $100 million training runs—all more than a year before ChatGPT.\",\"position\":{\"start\":{\"line\":41,\"column\":147,\"offset\":4200},\"end\":{\"line\":41,\"column\":384,\"offset\":4437}}}],\"position\":{\"start\":{\"line\":41,\"column\":1,\"offset\":4054},\"end\":{\"line\":41,\"column\":384,\"offset\":4437}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Who are we?\",\"position\":{\"start\":{\"line\":43,\"column\":4,\"offset\":4442},\"end\":{\"line\":43,\"column\":15,\"offset\":4453}}}],\"position\":{\"start\":{\"line\":43,\"column\":1,\"offset\":4439},\"end\":{\"line\":43,\"column\":16,\"offset\":4454}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/DKokotajlo\",\"children\":[{\"type\":\"text\",\"value\":\"Daniel Kokotajlo\",\"position\":{\"start\":{\"line\":45,\"column\":2,\"offset\":4457},\"end\":{\"line\":45,\"column\":18,\"offset\":4473}}}],\"position\":{\"start\":{\"line\":45,\"column\":1,\"offset\":4456},\"end\":{\"line\":45,\"column\":45,\"offset\":4500}}},{\"type\":\"text\",\"value\":\" (\",\"position\":{\"start\":{\"line\":45,\"column\":45,\"offset\":4500},\"end\":{\"line\":45,\"column\":47,\"offset\":4502}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://time.com/7012881/daniel-kokotajlo/\",\"children\":[{\"type\":\"text\",\"value\":\"TIME100\",\"position\":{\"start\":{\"line\":45,\"column\":48,\"offset\":4503},\"end\":{\"line\":45,\"column\":55,\"offset\":4510}}}],\"position\":{\"start\":{\"line\":45,\"column\":47,\"offset\":4502},\"end\":{\"line\":45,\"column\":100,\"offset\":4555}}},{\"type\":\"text\",\"value\":\", \",\"position\":{\"start\":{\"line\":45,\"column\":100,\"offset\":4555},\"end\":{\"line\":45,\"column\":102,\"offset\":4557}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.nytimes.com/2024/06/04/technology/openai-culture-whistleblowers.html\",\"children\":[{\"type\":\"text\",\"value\":\"NYT piece\",\"position\":{\"start\":{\"line\":45,\"column\":103,\"offset\":4558},\"end\":{\"line\":45,\"column\":112,\"offset\":4567}}}],\"position\":{\"start\":{\"line\":45,\"column\":102,\"offset\":4557},\"end\":{\"line\":45,\"column\":195,\"offset\":4650}}},{\"type\":\"text\",\"value\":\") is a former OpenAI researcher whose previous \",\"position\":{\"start\":{\"line\":45,\"column\":195,\"offset\":4650},\"end\":{\"line\":45,\"column\":242,\"offset\":4697}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\",\"children\":[{\"type\":\"text\",\"value\":\"AI predictions\",\"position\":{\"start\":{\"line\":45,\"column\":243,\"offset\":4698},\"end\":{\"line\":45,\"column\":257,\"offset\":4712}}}],\"position\":{\"start\":{\"line\":45,\"column\":242,\"offset\":4697},\"end\":{\"line\":45,\"column\":330,\"offset\":4785}}},{\"type\":\"text\",\"value\":\" have \",\"position\":{\"start\":{\"line\":45,\"column\":330,\"offset\":4785},\"end\":{\"line\":45,\"column\":336,\"offset\":4791}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/u9Kr97di29CkMvjaj/evaluating-what-2026-looks-like-so-far\",\"children\":[{\"type\":\"text\",\"value\":\"held up well\",\"position\":{\"start\":{\"line\":45,\"column\":337,\"offset\":4792},\"end\":{\"line\":45,\"column\":349,\"offset\":4804}}}],\"position\":{\"start\":{\"line\":45,\"column\":336,\"offset\":4791},\"end\":{\"line\":45,\"column\":440,\"offset\":4895}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":45,\"column\":440,\"offset\":4895},\"end\":{\"line\":45,\"column\":441,\"offset\":4896}}}],\"position\":{\"start\":{\"line\":45,\"column\":1,\"offset\":4456},\"end\":{\"line\":45,\"column\":441,\"offset\":4896}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://www.linkedin.com/in/eli-lifland/\",\"children\":[{\"type\":\"text\",\"value\":\"Eli Lifland\",\"position\":{\"start\":{\"line\":47,\"column\":2,\"offset\":4899},\"end\":{\"line\":47,\"column\":13,\"offset\":4910}}}],\"position\":{\"start\":{\"line\":47,\"column\":1,\"offset\":4898},\"end\":{\"line\":47,\"column\":56,\"offset\":4953}}},{\"type\":\"text\",\"value\":\" co-founded \",\"position\":{\"start\":{\"line\":47,\"column\":56,\"offset\":4953},\"end\":{\"line\":47,\"column\":68,\"offset\":4965}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://theaidigest.org/\",\"children\":[{\"type\":\"text\",\"value\":\"AI Digest\",\"position\":{\"start\":{\"line\":47,\"column\":69,\"offset\":4966},\"end\":{\"line\":47,\"column\":78,\"offset\":4975}}}],\"position\":{\"start\":{\"line\":47,\"column\":68,\"offset\":4965},\"end\":{\"line\":47,\"column\":105,\"offset\":5002}}},{\"type\":\"text\",\"value\":\", did \",\"position\":{\"start\":{\"line\":47,\"column\":105,\"offset\":5002},\"end\":{\"line\":47,\"column\":111,\"offset\":5008}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://scholar.google.com/citations?user=Q33DXbEAAAAJ\u0026hl=en\",\"children\":[{\"type\":\"text\",\"value\":\"AI robustness research\",\"position\":{\"start\":{\"line\":47,\"column\":112,\"offset\":5009},\"end\":{\"line\":47,\"column\":134,\"offset\":5031}}}],\"position\":{\"start\":{\"line\":47,\"column\":111,\"offset\":5008},\"end\":{\"line\":47,\"column\":197,\"offset\":5094}}},{\"type\":\"text\",\"value\":\", and ranks #1 on the \",\"position\":{\"start\":{\"line\":47,\"column\":197,\"offset\":5094},\"end\":{\"line\":47,\"column\":220,\"offset\":5117}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/global-and-emerging-risks/forecasting-initiative.html\",\"children\":[{\"type\":\"text\",\"value\":\"RAND Forecasting Initiative\",\"position\":{\"start\":{\"line\":47,\"column\":221,\"offset\":5118},\"end\":{\"line\":47,\"column\":248,\"offset\":5145}}}],\"position\":{\"start\":{\"line\":47,\"column\":220,\"offset\":5117},\"end\":{\"line\":47,\"column\":325,\"offset\":5222}}},{\"type\":\"text\",\"value\":\" all-time leaderboard.\",\"position\":{\"start\":{\"line\":47,\"column\":325,\"offset\":5222},\"end\":{\"line\":47,\"column\":347,\"offset\":5244}}}],\"position\":{\"start\":{\"line\":47,\"column\":1,\"offset\":4898},\"end\":{\"line\":47,\"column\":347,\"offset\":5244}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://www.linkedin.com/in/thomas-larsen/\",\"children\":[{\"type\":\"text\",\"value\":\"Thomas Larsen\",\"position\":{\"start\":{\"line\":49,\"column\":2,\"offset\":5247},\"end\":{\"line\":49,\"column\":15,\"offset\":5260}}}],\"position\":{\"start\":{\"line\":49,\"column\":1,\"offset\":5246},\"end\":{\"line\":49,\"column\":60,\"offset\":5305}}},{\"type\":\"text\",\"value\":\" founded the \",\"position\":{\"start\":{\"line\":49,\"column\":60,\"offset\":5305},\"end\":{\"line\":49,\"column\":73,\"offset\":5318}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.centeraipolicy.org/\",\"children\":[{\"type\":\"text\",\"value\":\"Center for AI Policy\",\"position\":{\"start\":{\"line\":49,\"column\":74,\"offset\":5319},\"end\":{\"line\":49,\"column\":94,\"offset\":5339}}}],\"position\":{\"start\":{\"line\":49,\"column\":73,\"offset\":5318},\"end\":{\"line\":49,\"column\":128,\"offset\":5373}}},{\"type\":\"text\",\"value\":\" and did AI safety research at the \",\"position\":{\"start\":{\"line\":49,\"column\":128,\"offset\":5373},\"end\":{\"line\":49,\"column\":163,\"offset\":5408}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://intelligence.org/\",\"children\":[{\"type\":\"text\",\"value\":\"Machine Intelligence Research Institute\",\"position\":{\"start\":{\"line\":49,\"column\":164,\"offset\":5409},\"end\":{\"line\":49,\"column\":203,\"offset\":5448}}}],\"position\":{\"start\":{\"line\":49,\"column\":163,\"offset\":5408},\"end\":{\"line\":49,\"column\":231,\"offset\":5476}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":49,\"column\":231,\"offset\":5476},\"end\":{\"line\":49,\"column\":232,\"offset\":5477}}}],\"position\":{\"start\":{\"line\":49,\"column\":1,\"offset\":5246},\"end\":{\"line\":49,\"column\":232,\"offset\":5477}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://www.linkedin.com/in/romeo-dean-789313200/\",\"children\":[{\"type\":\"text\",\"value\":\"Romeo Dean\",\"position\":{\"start\":{\"line\":51,\"column\":2,\"offset\":5480},\"end\":{\"line\":51,\"column\":12,\"offset\":5490}}}],\"position\":{\"start\":{\"line\":51,\"column\":1,\"offset\":5479},\"end\":{\"line\":51,\"column\":64,\"offset\":5542}}},{\"type\":\"text\",\"value\":\" is completing a computer science concurrent bachelor’s and master’s degree at Harvard and previously was an \",\"position\":{\"start\":{\"line\":51,\"column\":64,\"offset\":5542},\"end\":{\"line\":51,\"column\":173,\"offset\":5651}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.iaps.ai/romeo-dean\",\"children\":[{\"type\":\"text\",\"value\":\"AI Policy Fellow\",\"position\":{\"start\":{\"line\":51,\"column\":174,\"offset\":5652},\"end\":{\"line\":51,\"column\":190,\"offset\":5668}}}],\"position\":{\"start\":{\"line\":51,\"column\":173,\"offset\":5651},\"end\":{\"line\":51,\"column\":223,\"offset\":5701}}},{\"type\":\"text\",\"value\":\" at the Institute for AI Policy and Strategy.\",\"position\":{\"start\":{\"line\":51,\"column\":223,\"offset\":5701},\"end\":{\"line\":51,\"column\":268,\"offset\":5746}}}],\"position\":{\"start\":{\"line\":51,\"column\":1,\"offset\":5479},\"end\":{\"line\":51,\"column\":268,\"offset\":5746}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Slate_Star_Codex\",\"children\":[{\"type\":\"text\",\"value\":\"Scott Alexander, blogger extraordinaire\",\"position\":{\"start\":{\"line\":53,\"column\":2,\"offset\":5749},\"end\":{\"line\":53,\"column\":41,\"offset\":5788}}}],\"position\":{\"start\":{\"line\":53,\"column\":1,\"offset\":5748},\"end\":{\"line\":53,\"column\":90,\"offset\":5837}}},{\"type\":\"text\",\"value\":\", volunteered to rewrite our content in an engaging style; the fun parts of the story are his and the boring parts are ours.\",\"position\":{\"start\":{\"line\":53,\"column\":90,\"offset\":5837},\"end\":{\"line\":53,\"column\":214,\"offset\":5961}}}],\"position\":{\"start\":{\"line\":53,\"column\":1,\"offset\":5748},\"end\":{\"line\":53,\"column\":214,\"offset\":5961}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For more about our team and acknowledgements, see the \",\"position\":{\"start\":{\"line\":55,\"column\":1,\"offset\":5963},\"end\":{\"line\":55,\"column\":55,\"offset\":6017}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/about\",\"children\":[{\"type\":\"text\",\"value\":\"About page\",\"position\":{\"start\":{\"line\":55,\"column\":56,\"offset\":6018},\"end\":{\"line\":55,\"column\":66,\"offset\":6028}}}],\"position\":{\"start\":{\"line\":55,\"column\":55,\"offset\":6017},\"end\":{\"line\":55,\"column\":94,\"offset\":6056}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":55,\"column\":94,\"offset\":6056},\"end\":{\"line\":55,\"column\":95,\"offset\":6057}}}],\"position\":{\"start\":{\"line\":55,\"column\":1,\"offset\":5963},\"end\":{\"line\":55,\"column\":95,\"offset\":6057}}}],\"position\":{\"start\":{\"line\":11,\"column\":1,\"offset\":752},\"end\":{\"line\":57,\"column\":4,\"offset\":6062}}},{\"type\":\"containerDirective\",\"name\":\"publicationDate\",\"attributes\":{},\"children\":[],\"position\":{\"start\":{\"line\":59,\"column\":1,\"offset\":6064},\"end\":{\"line\":60,\"column\":4,\"offset\":6088}}}],\"docContext\":{\"footnotes\":[{\"identifier\":\"1\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We disagree somewhat amongst ourselves about AI timelines; our median AGI arrival date is somewhat longer than what this scenario depicts. This scenario depicts something like our mode. See our \",\"position\":{\"start\":{\"line\":680,\"column\":7,\"offset\":99357},\"end\":{\"line\":680,\"column\":201,\"offset\":99551}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":{\"start\":{\"line\":680,\"column\":202,\"offset\":99552},\"end\":{\"line\":680,\"column\":220,\"offset\":99570}}}],\"position\":{\"start\":{\"line\":680,\"column\":201,\"offset\":99551},\"end\":{\"line\":680,\"column\":270,\"offset\":99620}}},{\"type\":\"text\",\"value\":\" for more details.\",\"position\":{\"start\":{\"line\":680,\"column\":270,\"offset\":99620},\"end\":{\"line\":680,\"column\":288,\"offset\":99638}}}],\"position\":{\"start\":{\"line\":680,\"column\":7,\"offset\":99357},\"end\":{\"line\":680,\"column\":288,\"offset\":99638}}}]},{\"identifier\":\"2\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"One author, Daniel Kokotajlo, did a \",\"position\":{\"start\":{\"line\":682,\"column\":8,\"offset\":99647},\"end\":{\"line\":682,\"column\":44,\"offset\":99683}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.alignmentforum.org/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\",\"children\":[{\"type\":\"text\",\"value\":\"lower-effort scenario exercise in 2021\",\"position\":{\"start\":{\"line\":682,\"column\":45,\"offset\":99684},\"end\":{\"line\":682,\"column\":83,\"offset\":99722}}}],\"position\":{\"start\":{\"line\":682,\"column\":44,\"offset\":99683},\"end\":{\"line\":682,\"column\":161,\"offset\":99800}}},{\"type\":\"text\",\"value\":\" that got many things right including the rise of chatbots, chain of thought, inference scaling, sweeping AI chip export controls, and $100 million training runs. Another author, \",\"position\":{\"start\":{\"line\":682,\"column\":161,\"offset\":99800},\"end\":{\"line\":682,\"column\":340,\"offset\":99979}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.vox.com/future-perfect/2024/2/13/24070864/samotsvety-forecasting-superforecasters-tetlock\",\"children\":[{\"type\":\"text\",\"value\":\"Eli Lifland\",\"position\":{\"start\":{\"line\":682,\"column\":341,\"offset\":99980},\"end\":{\"line\":682,\"column\":352,\"offset\":99991}}}],\"position\":{\"start\":{\"line\":682,\"column\":340,\"offset\":99979},\"end\":{\"line\":682,\"column\":456,\"offset\":100095}}},{\"type\":\"text\",\"value\":\", ranks #1 on the \",\"position\":{\"start\":{\"line\":682,\"column\":456,\"offset\":100095},\"end\":{\"line\":682,\"column\":475,\"offset\":100114}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/global-and-emerging-risks/forecasting-initiative.html\",\"children\":[{\"type\":\"text\",\"value\":\"RAND Forecasting Initiative\",\"position\":{\"start\":{\"line\":682,\"column\":476,\"offset\":100115},\"end\":{\"line\":682,\"column\":503,\"offset\":100142}}}],\"position\":{\"start\":{\"line\":682,\"column\":475,\"offset\":100114},\"end\":{\"line\":682,\"column\":580,\"offset\":100219}}},{\"type\":\"text\",\"value\":\" leaderboard.\",\"position\":{\"start\":{\"line\":682,\"column\":580,\"offset\":100219},\"end\":{\"line\":682,\"column\":593,\"offset\":100232}}}],\"position\":{\"start\":{\"line\":682,\"column\":8,\"offset\":99647},\"end\":{\"line\":682,\"column\":593,\"offset\":100232}}}]},{\"identifier\":\"3\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Specifically, our medians ranged from 2028 to 2035. When AI 2027 was first published we explained this in Footnote 1 as above, but to make our views more clear we have moved it to the foreword text. We are working on a website to track and explain our all-things-considered views on AI timelines as they update over time; we'll link to it here when it's ready.\",\"position\":{\"start\":{\"line\":684,\"column\":7,\"offset\":100240},\"end\":{\"line\":684,\"column\":367,\"offset\":100600}}}],\"position\":{\"start\":{\"line\":684,\"column\":7,\"offset\":100240},\"end\":{\"line\":684,\"column\":367,\"offset\":100600}}}]},{\"identifier\":\"4\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Sometimes people mix prediction and recommendation, hoping to create a self-fulfilling-prophecy effect. We emphatically are not doing this; we hope that what we depict does not come to pass!\",\"position\":{\"start\":{\"line\":686,\"column\":8,\"offset\":100609},\"end\":{\"line\":686,\"column\":199,\"offset\":100800}}}],\"position\":{\"start\":{\"line\":686,\"column\":8,\"offset\":100609},\"end\":{\"line\":686,\"column\":199,\"offset\":100800}}}]},{\"identifier\":\"5\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Feel free to \",\"position\":{\"start\":{\"line\":688,\"column\":8,\"offset\":100809},\"end\":{\"line\":688,\"column\":21,\"offset\":100822}}},{\"type\":\"link\",\"title\":null,\"url\":\"http://mailto@info@ai-futures.org\",\"children\":[{\"type\":\"text\",\"value\":\"contact us\",\"position\":{\"start\":{\"line\":688,\"column\":22,\"offset\":100823},\"end\":{\"line\":688,\"column\":32,\"offset\":100833}}}],\"position\":{\"start\":{\"line\":688,\"column\":21,\"offset\":100822},\"end\":{\"line\":688,\"column\":68,\"offset\":100869}}},{\"type\":\"text\",\"value\":\" if you’re writing a critique or an alternative scenario.\",\"position\":{\"start\":{\"line\":688,\"column\":68,\"offset\":100869},\"end\":{\"line\":688,\"column\":125,\"offset\":100926}}}],\"position\":{\"start\":{\"line\":688,\"column\":8,\"offset\":100809},\"end\":{\"line\":688,\"column\":125,\"offset\":100926}}}]},{\"identifier\":\"6\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It was overall more difficult, because unlike with the first ending, we were trying to get it to reach a good outcome starting from a rather difficult situation.\",\"position\":{\"start\":{\"line\":690,\"column\":8,\"offset\":100935},\"end\":{\"line\":690,\"column\":169,\"offset\":101096}}}],\"position\":{\"start\":{\"line\":690,\"column\":8,\"offset\":100935},\"end\":{\"line\":690,\"column\":169,\"offset\":101096}}}]},{\"identifier\":\"7\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Full Professor, Université de Montréal and Founder and Scientific Advisor, Mila - Quebec AI Institute. Also the world’s \",\"position\":{\"start\":{\"line\":692,\"column\":8,\"offset\":101105},\"end\":{\"line\":692,\"column\":129,\"offset\":101226}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Yoshua_Bengio\",\"children\":[{\"type\":\"text\",\"value\":\"most-cited computer scientist\",\"position\":{\"start\":{\"line\":692,\"column\":130,\"offset\":101227},\"end\":{\"line\":692,\"column\":159,\"offset\":101256}}}],\"position\":{\"start\":{\"line\":692,\"column\":129,\"offset\":101226},\"end\":{\"line\":692,\"column\":205,\"offset\":101302}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":692,\"column\":205,\"offset\":101302},\"end\":{\"line\":692,\"column\":206,\"offset\":101303}}}],\"position\":{\"start\":{\"line\":692,\"column\":8,\"offset\":101105},\"end\":{\"line\":692,\"column\":206,\"offset\":101303}}}]},{\"identifier\":\"8\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"At first, most people are reluctant to allow purchases without oversight. Over the next few years, automatically allowing small purchases becomes normalized as the AIs become more reliable and build up trust.\",\"position\":{\"start\":{\"line\":694,\"column\":8,\"offset\":101312},\"end\":{\"line\":694,\"column\":216,\"offset\":101520}}}],\"position\":{\"start\":{\"line\":694,\"column\":8,\"offset\":101312},\"end\":{\"line\":694,\"column\":216,\"offset\":101520}}}]},{\"identifier\":\"9\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Specifically, we forecast that they score 65% on the OSWorld benchmark of basic computer tasks (compared to 38% for Operator and 70% for a typical skilled non-expert human).\",\"position\":{\"start\":{\"line\":696,\"column\":8,\"offset\":101529},\"end\":{\"line\":696,\"column\":181,\"offset\":101702}}}],\"position\":{\"start\":{\"line\":696,\"column\":8,\"offset\":101529},\"end\":{\"line\":696,\"column\":181,\"offset\":101702}}}]},{\"identifier\":\"10\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For example, we think coding agents will move towards functioning like \",\"position\":{\"start\":{\"line\":698,\"column\":9,\"offset\":101712},\"end\":{\"line\":698,\"column\":80,\"offset\":101783}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://devin.ai/\",\"children\":[{\"type\":\"text\",\"value\":\"Devin\",\"position\":{\"start\":{\"line\":698,\"column\":81,\"offset\":101784},\"end\":{\"line\":698,\"column\":86,\"offset\":101789}}}],\"position\":{\"start\":{\"line\":698,\"column\":80,\"offset\":101783},\"end\":{\"line\":698,\"column\":106,\"offset\":101809}}},{\"type\":\"text\",\"value\":\". We forecast that mid-2025 agents will score 85% on \",\"position\":{\"start\":{\"line\":698,\"column\":106,\"offset\":101809},\"end\":{\"line\":698,\"column\":159,\"offset\":101862}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.swebench.com/#verified\",\"children\":[{\"type\":\"text\",\"value\":\"SWEBench-Verified\",\"position\":{\"start\":{\"line\":698,\"column\":160,\"offset\":101863},\"end\":{\"line\":698,\"column\":177,\"offset\":101880}}}],\"position\":{\"start\":{\"line\":698,\"column\":159,\"offset\":101862},\"end\":{\"line\":698,\"column\":214,\"offset\":101917}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":698,\"column\":214,\"offset\":101917},\"end\":{\"line\":698,\"column\":215,\"offset\":101918}}}],\"position\":{\"start\":{\"line\":698,\"column\":9,\"offset\":101712},\"end\":{\"line\":698,\"column\":215,\"offset\":101918}}}]},{\"identifier\":\"11\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For example, \",\"position\":{\"start\":{\"line\":700,\"column\":9,\"offset\":101928},\"end\":{\"line\":700,\"column\":22,\"offset\":101941}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/chatgpt/pricing/\",\"children\":[{\"type\":\"text\",\"value\":\"OpenAI’s pro plan\",\"position\":{\"start\":{\"line\":700,\"column\":23,\"offset\":101942},\"end\":{\"line\":700,\"column\":40,\"offset\":101959}}}],\"position\":{\"start\":{\"line\":700,\"column\":22,\"offset\":101941},\"end\":{\"line\":700,\"column\":78,\"offset\":101997}}},{\"type\":\"text\",\"value\":\" currently costs $200/month and the agentic coding AI \",\"position\":{\"start\":{\"line\":700,\"column\":78,\"offset\":101997},\"end\":{\"line\":700,\"column\":132,\"offset\":102051}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://devin.ai/pricing\",\"children\":[{\"type\":\"text\",\"value\":\"Devin\",\"position\":{\"start\":{\"line\":700,\"column\":133,\"offset\":102052},\"end\":{\"line\":700,\"column\":138,\"offset\":102057}}}],\"position\":{\"start\":{\"line\":700,\"column\":132,\"offset\":102051},\"end\":{\"line\":700,\"column\":165,\"offset\":102084}}},{\"type\":\"text\",\"value\":\" currently costs $500/month. While the cutting-edge systems continue to get more expensive over time, the cost to customers of reaching a given capabilities level continues to plummet. For existing capabilities, this happens at an average rate of about 50x/year (per \",\"position\":{\"start\":{\"line\":700,\"column\":165,\"offset\":102084},\"end\":{\"line\":700,\"column\":432,\"offset\":102351}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://epoch.ai/data-insights/llm-inference-price-trends\",\"children\":[{\"type\":\"text\",\"value\":\"Epoch\",\"position\":{\"start\":{\"line\":700,\"column\":433,\"offset\":102352},\"end\":{\"line\":700,\"column\":438,\"offset\":102357}}}],\"position\":{\"start\":{\"line\":700,\"column\":432,\"offset\":102351},\"end\":{\"line\":700,\"column\":498,\"offset\":102417}}},{\"type\":\"text\",\"value\":\").\",\"position\":{\"start\":{\"line\":700,\"column\":498,\"offset\":102417},\"end\":{\"line\":700,\"column\":500,\"offset\":102419}}}],\"position\":{\"start\":{\"line\":700,\"column\":9,\"offset\":101928},\"end\":{\"line\":700,\"column\":500,\"offset\":102419}}}]},{\"identifier\":\"12\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Enterprise tools like \",\"position\":{\"start\":{\"line\":702,\"column\":9,\"offset\":102429},\"end\":{\"line\":702,\"column\":31,\"offset\":102451}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.glean.com/\",\"children\":[{\"type\":\"text\",\"value\":\"Glean\",\"position\":{\"start\":{\"line\":702,\"column\":32,\"offset\":102452},\"end\":{\"line\":702,\"column\":37,\"offset\":102457}}}],\"position\":{\"start\":{\"line\":702,\"column\":31,\"offset\":102451},\"end\":{\"line\":702,\"column\":62,\"offset\":102482}}},{\"type\":\"text\",\"value\":\" also move toward providing increasingly autonomous AI agents.\",\"position\":{\"start\":{\"line\":702,\"column\":62,\"offset\":102482},\"end\":{\"line\":702,\"column\":124,\"offset\":102544}}}],\"position\":{\"start\":{\"line\":702,\"column\":9,\"offset\":102429},\"end\":{\"line\":702,\"column\":124,\"offset\":102544}}}]},{\"identifier\":\"13\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This cluster is a network of datacenter campuses sprawled across the country, totalling 2.5M 2024-GPU-equivalents (H100s), with $100B spent so far and 2 GW of power draw online. Construction is underway for this to at least double through 2026. The campuses are connected by billions worth of fibre cabling, so that (barring the speed of light latency of a few milliseconds) it lets these campuses function almost as if they were right next door to each other (i.e. bandwidth is not a bottleneck, meaning huge quantities of data can be sent at the same time). From a security perspective this introduces some threat surface (it’s unclear whether the cables and especially their junction points are fully secured from eavesdroppers).\",\"position\":{\"start\":{\"line\":704,\"column\":9,\"offset\":102554},\"end\":{\"line\":704,\"column\":742,\"offset\":103287}}}],\"position\":{\"start\":{\"line\":704,\"column\":9,\"offset\":102554},\"end\":{\"line\":704,\"column\":742,\"offset\":103287}}}]},{\"identifier\":\"14\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Compute is measured in \",\"position\":{\"start\":{\"line\":706,\"column\":9,\"offset\":103297},\"end\":{\"line\":706,\"column\":32,\"offset\":103320}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Floating_point_operations_per_second\",\"children\":[{\"type\":\"text\",\"value\":\"floating point operations (FLOP)\",\"position\":{\"start\":{\"line\":706,\"column\":33,\"offset\":103321},\"end\":{\"line\":706,\"column\":65,\"offset\":103353}}}],\"position\":{\"start\":{\"line\":706,\"column\":32,\"offset\":103320},\"end\":{\"line\":706,\"column\":134,\"offset\":103422}}},{\"type\":\"text\",\"value\":\": how many individual addition and multiplication operations occur over the course of running a program.\",\"position\":{\"start\":{\"line\":706,\"column\":134,\"offset\":103422},\"end\":{\"line\":706,\"column\":238,\"offset\":103526}}}],\"position\":{\"start\":{\"line\":706,\"column\":9,\"offset\":103297},\"end\":{\"line\":706,\"column\":238,\"offset\":103526}}}]},{\"identifier\":\"15\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They could train this model given 150 days. See our \",\"position\":{\"start\":{\"line\":708,\"column\":9,\"offset\":103536},\"end\":{\"line\":708,\"column\":61,\"offset\":103588}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"compute supplement\",\"position\":{\"start\":{\"line\":708,\"column\":62,\"offset\":103589},\"end\":{\"line\":708,\"column\":80,\"offset\":103607}}}],\"position\":{\"start\":{\"line\":708,\"column\":61,\"offset\":103588},\"end\":{\"line\":708,\"column\":131,\"offset\":103658}}},{\"type\":\"text\",\"value\":\" for more details.\",\"position\":{\"start\":{\"line\":708,\"column\":131,\"offset\":103658},\"end\":{\"line\":708,\"column\":149,\"offset\":103676}}}],\"position\":{\"start\":{\"line\":708,\"column\":9,\"offset\":103536},\"end\":{\"line\":708,\"column\":150,\"offset\":103677}}}]},{\"identifier\":\"16\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We consider DeepSeek, Tencent, Alibaba, and others to have strong AGI projects in China. To avoid singling out a specific one, our scenario will follow a fictional “DeepCent.”\",\"position\":{\"start\":{\"line\":710,\"column\":9,\"offset\":103687},\"end\":{\"line\":710,\"column\":184,\"offset\":103862}}}],\"position\":{\"start\":{\"line\":710,\"column\":9,\"offset\":103687},\"end\":{\"line\":710,\"column\":184,\"offset\":103862}}}]},{\"identifier\":\"17\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It’s good at this due to a combination of explicit focus to prioritize these skills, their own extensive codebases they can draw on as particularly relevant and high-quality training data, and coding being an easy domain for procedural feedback.\",\"position\":{\"start\":{\"line\":712,\"column\":9,\"offset\":103872},\"end\":{\"line\":712,\"column\":254,\"offset\":104117}}}],\"position\":{\"start\":{\"line\":712,\"column\":9,\"offset\":103872},\"end\":{\"line\":712,\"column\":254,\"offset\":104117}}}]},{\"identifier\":\"18\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For example, suppose a model is much better at Python than obscure programming languages. When OpenBrain sees value in it, they generate synthetic training data in those languages as well. Another example: to help it integrate more effectively into company workflows, OpenBrain develops a curriculum to train it to use Slack.\",\"position\":{\"start\":{\"line\":714,\"column\":9,\"offset\":104127},\"end\":{\"line\":714,\"column\":334,\"offset\":104452}}}],\"position\":{\"start\":{\"line\":714,\"column\":9,\"offset\":104127},\"end\":{\"line\":714,\"column\":334,\"offset\":104452}}}]},{\"identifier\":\"19\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"People often get hung up on whether these AIs are sentient, or whether they have “true understanding.” Geoffrey Hinton, Nobel prize winning founder of the field, \",\"position\":{\"start\":{\"line\":716,\"column\":9,\"offset\":104462},\"end\":{\"line\":716,\"column\":171,\"offset\":104624}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.pbs.org/wnet/amanpour-and-company/video/geoffrey-hinton-warns-of-the-existential-threat-of-ai/#:~:text=I%20am%20very%20confident%20that%20they%20think.\",\"children\":[{\"type\":\"text\",\"value\":\"thinks they do\",\"position\":{\"start\":{\"line\":716,\"column\":172,\"offset\":104625},\"end\":{\"line\":716,\"column\":186,\"offset\":104639}}}],\"position\":{\"start\":{\"line\":716,\"column\":171,\"offset\":104624},\"end\":{\"line\":716,\"column\":352,\"offset\":104805}}},{\"type\":\"text\",\"value\":\". However, we don’t think it matters for the purposes of our story, so feel free to pretend we said “behaves as if it understands…” whenever we say “understands,” and so forth. Empirically, large language models already \",\"position\":{\"start\":{\"line\":716,\"column\":352,\"offset\":104805},\"end\":{\"line\":716,\"column\":572,\"offset\":105025}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://theaidigest.org/self-awareness\",\"children\":[{\"type\":\"text\",\"value\":\"behave as if they are self-aware\",\"position\":{\"start\":{\"line\":716,\"column\":573,\"offset\":105026},\"end\":{\"line\":716,\"column\":605,\"offset\":105058}}}],\"position\":{\"start\":{\"line\":716,\"column\":572,\"offset\":105025},\"end\":{\"line\":716,\"column\":646,\"offset\":105099}}},{\"type\":\"text\",\"value\":\" to some extent, more and more so every year.\",\"position\":{\"start\":{\"line\":716,\"column\":646,\"offset\":105099},\"end\":{\"line\":716,\"column\":691,\"offset\":105144}}}],\"position\":{\"start\":{\"line\":716,\"column\":9,\"offset\":104462},\"end\":{\"line\":716,\"column\":691,\"offset\":105144}}}]},{\"identifier\":\"20\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A common technique “bakes in” a persona: first, prompt the pretrained model with something like “The following is a conversation between a human user and a helpful, honest, and harmless AI chatbot produced by Anthropic. The chatbot has the following traits…” Use this prompt to generate a bunch of data. Then, train on the data but without the prompt. The result is an AI that always acts as if it had that prompt in front of it, regardless of what else you feed it. See also \",\"position\":{\"start\":{\"line\":718,\"column\":9,\"offset\":105154},\"end\":{\"line\":718,\"column\":485,\"offset\":105630}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/OwainEvans_UK/status/1881767725430976642\",\"children\":[{\"type\":\"text\",\"value\":\"this paper\",\"position\":{\"start\":{\"line\":718,\"column\":486,\"offset\":105631},\"end\":{\"line\":718,\"column\":496,\"offset\":105641}}}],\"position\":{\"start\":{\"line\":718,\"column\":485,\"offset\":105630},\"end\":{\"line\":718,\"column\":553,\"offset\":105698}}},{\"type\":\"text\",\"value\":\" which found that AIs \",\"position\":{\"start\":{\"line\":718,\"column\":553,\"offset\":105698},\"end\":{\"line\":718,\"column\":575,\"offset\":105720}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"retrained\",\"position\":{\"start\":{\"line\":718,\"column\":576,\"offset\":105721},\"end\":{\"line\":718,\"column\":585,\"offset\":105730}}}],\"position\":{\"start\":{\"line\":718,\"column\":575,\"offset\":105720},\"end\":{\"line\":718,\"column\":586,\"offset\":105731}}},{\"type\":\"text\",\"value\":\" to exhibit a certain personality trait are able to correctly answer questions about that new trait, despite no training to do so, suggesting that they have internal representations of their own traits and that when their traits change their representations change accordingly.\",\"position\":{\"start\":{\"line\":718,\"column\":586,\"offset\":105731},\"end\":{\"line\":718,\"column\":863,\"offset\":106008}}}],\"position\":{\"start\":{\"line\":718,\"column\":9,\"offset\":105154},\"end\":{\"line\":718,\"column\":863,\"offset\":106008}}}]},{\"identifier\":\"21\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"These paragraphs include speculation about the internal workings of large artificial neural networks. Such networks are sufficiently complicated that we can't actually look inside and say “ah yes, now it's evolved from reflexes into having goals” or “OK so there’s the list of drives it has.” Instead, we basically have to do psychology, looking how it behaves in various settings and running various experiments on it and trying to piece together the clues. And it’s all terribly controversial and confusing.\",\"position\":{\"start\":{\"line\":720,\"column\":9,\"offset\":106018},\"end\":{\"line\":720,\"column\":518,\"offset\":106527}}}],\"position\":{\"start\":{\"line\":720,\"column\":9,\"offset\":106018},\"end\":{\"line\":720,\"column\":518,\"offset\":106527}}}]},{\"identifier\":\"22\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Different companies call it different things. OpenAI calls it the Spec, but Anthropic calls it the \",\"position\":{\"start\":{\"line\":722,\"column\":9,\"offset\":106537},\"end\":{\"line\":722,\"column\":108,\"offset\":106636}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/news/claudes-constitution\",\"children\":[{\"type\":\"text\",\"value\":\"Constitution\",\"position\":{\"start\":{\"line\":722,\"column\":109,\"offset\":106637},\"end\":{\"line\":722,\"column\":121,\"offset\":106649}}}],\"position\":{\"start\":{\"line\":722,\"column\":108,\"offset\":106636},\"end\":{\"line\":722,\"column\":175,\"offset\":106703}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":722,\"column\":175,\"offset\":106703},\"end\":{\"line\":722,\"column\":176,\"offset\":106704}}}],\"position\":{\"start\":{\"line\":722,\"column\":9,\"offset\":106537},\"end\":{\"line\":722,\"column\":176,\"offset\":106704}}}]},{\"identifier\":\"23\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For example, \",\"position\":{\"start\":{\"line\":724,\"column\":9,\"offset\":106714},\"end\":{\"line\":724,\"column\":22,\"offset\":106727}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2212.08073\",\"children\":[{\"type\":\"text\",\"value\":\"RLAIF\",\"position\":{\"start\":{\"line\":724,\"column\":23,\"offset\":106728},\"end\":{\"line\":724,\"column\":28,\"offset\":106733}}}],\"position\":{\"start\":{\"line\":724,\"column\":22,\"offset\":106727},\"end\":{\"line\":724,\"column\":63,\"offset\":106768}}},{\"type\":\"text\",\"value\":\" and \",\"position\":{\"start\":{\"line\":724,\"column\":63,\"offset\":106768},\"end\":{\"line\":724,\"column\":68,\"offset\":106773}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/deliberative-alignment/\",\"children\":[{\"type\":\"text\",\"value\":\"deliberative alignment\",\"position\":{\"start\":{\"line\":724,\"column\":69,\"offset\":106774},\"end\":{\"line\":724,\"column\":91,\"offset\":106796}}}],\"position\":{\"start\":{\"line\":724,\"column\":68,\"offset\":106773},\"end\":{\"line\":724,\"column\":142,\"offset\":106847}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":724,\"column\":142,\"offset\":106847},\"end\":{\"line\":724,\"column\":143,\"offset\":106848}}}],\"position\":{\"start\":{\"line\":724,\"column\":9,\"offset\":106714},\"end\":{\"line\":724,\"column\":143,\"offset\":106848}}}]},{\"identifier\":\"24\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Most \",\"position\":{\"start\":{\"line\":726,\"column\":9,\"offset\":106858},\"end\":{\"line\":726,\"column\":14,\"offset\":106863}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.ibm.com/think/topics/ai-hallucinations\",\"children\":[{\"type\":\"text\",\"value\":\"sources on AI “hallucinations”\",\"position\":{\"start\":{\"line\":726,\"column\":15,\"offset\":106864},\"end\":{\"line\":726,\"column\":45,\"offset\":106894}}}],\"position\":{\"start\":{\"line\":726,\"column\":14,\"offset\":106863},\"end\":{\"line\":726,\"column\":98,\"offset\":106947}}},{\"type\":\"text\",\"value\":\" describe them as unintentional mistakes, but \",\"position\":{\"start\":{\"line\":726,\"column\":98,\"offset\":106947},\"end\":{\"line\":726,\"column\":144,\"offset\":106993}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2310.01405\",\"children\":[{\"type\":\"text\",\"value\":\"research with steering vectors\",\"position\":{\"start\":{\"line\":726,\"column\":145,\"offset\":106994},\"end\":{\"line\":726,\"column\":175,\"offset\":107024}}}],\"position\":{\"start\":{\"line\":726,\"column\":144,\"offset\":106993},\"end\":{\"line\":726,\"column\":210,\"offset\":107059}}},{\"type\":\"text\",\"value\":\" finds that in some cases the models know their citations are fake—they are lying. During training, raters gave well-cited claims more reward than claims without citations, so the AI “learned” to cite sources for scholarly claims in order to please its users. If no relevant source exists, it makes one up.\",\"position\":{\"start\":{\"line\":726,\"column\":210,\"offset\":107059},\"end\":{\"line\":726,\"column\":516,\"offset\":107365}}}],\"position\":{\"start\":{\"line\":726,\"column\":9,\"offset\":106858},\"end\":{\"line\":726,\"column\":516,\"offset\":107365}}}]},{\"identifier\":\"25\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In particular, they can’t rule out hypotheses such as “it’s following the Spec temporarily, merely as a strategy for achieving some other goal(s)” or “it’s trying to \",\"position\":{\"start\":{\"line\":728,\"column\":9,\"offset\":107375},\"end\":{\"line\":728,\"column\":175,\"offset\":107541}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"appear\",\"position\":{\"start\":{\"line\":728,\"column\":176,\"offset\":107542},\"end\":{\"line\":728,\"column\":182,\"offset\":107548}}}],\"position\":{\"start\":{\"line\":728,\"column\":175,\"offset\":107541},\"end\":{\"line\":728,\"column\":183,\"offset\":107549}}},{\"type\":\"text\",\"value\":\" to follow the Spec, it’s not trying to \",\"position\":{\"start\":{\"line\":728,\"column\":183,\"offset\":107549},\"end\":{\"line\":728,\"column\":223,\"offset\":107589}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"actually\",\"position\":{\"start\":{\"line\":728,\"column\":224,\"offset\":107590},\"end\":{\"line\":728,\"column\":232,\"offset\":107598}}}],\"position\":{\"start\":{\"line\":728,\"column\":223,\"offset\":107589},\"end\":{\"line\":728,\"column\":233,\"offset\":107599}}},{\"type\":\"text\",\"value\":\" follow the Spec” or “it’s internalized the Spec correctly, but only on-distribution; if it encounters sufficiently novel stimuli (e.g. jailbreaks) it’ll start behaving differently.” (There are many active research agendas working to fix this sorry situation, e.g. the field of \",\"position\":{\"start\":{\"line\":728,\"column\":233,\"offset\":107599},\"end\":{\"line\":728,\"column\":511,\"offset\":107877}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2501.16496\",\"children\":[{\"type\":\"text\",\"value\":\"interpretability\",\"position\":{\"start\":{\"line\":728,\"column\":512,\"offset\":107878},\"end\":{\"line\":728,\"column\":528,\"offset\":107894}}}],\"position\":{\"start\":{\"line\":728,\"column\":511,\"offset\":107877},\"end\":{\"line\":728,\"column\":563,\"offset\":107929}}},{\"type\":\"text\",\"value\":\" and the field of \",\"position\":{\"start\":{\"line\":728,\"column\":563,\"offset\":107929},\"end\":{\"line\":728,\"column\":581,\"offset\":107947}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2307.13702\",\"children\":[{\"type\":\"text\",\"value\":\"chain-of-thought faithfulness\",\"position\":{\"start\":{\"line\":728,\"column\":582,\"offset\":107948},\"end\":{\"line\":728,\"column\":611,\"offset\":107977}}}],\"position\":{\"start\":{\"line\":728,\"column\":581,\"offset\":107947},\"end\":{\"line\":728,\"column\":646,\"offset\":108012}}},{\"type\":\"text\",\"value\":\".)\",\"position\":{\"start\":{\"line\":728,\"column\":646,\"offset\":108012},\"end\":{\"line\":728,\"column\":648,\"offset\":108014}}}],\"position\":{\"start\":{\"line\":728,\"column\":9,\"offset\":107375},\"end\":{\"line\":728,\"column\":648,\"offset\":108014}}}]},{\"identifier\":\"26\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"By this we mean whoever is trying to solve the problems the \",\"position\":{\"start\":{\"line\":730,\"column\":9,\"offset\":108024},\"end\":{\"line\":730,\"column\":69,\"offset\":108084}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://web.archive.org/web/20250201020004/https://openai.com/index/introducing-superalignment/\",\"children\":[{\"type\":\"text\",\"value\":\"Superalignment team\",\"position\":{\"start\":{\"line\":730,\"column\":70,\"offset\":108085},\"end\":{\"line\":730,\"column\":89,\"offset\":108104}}}],\"position\":{\"start\":{\"line\":730,\"column\":69,\"offset\":108084},\"end\":{\"line\":730,\"column\":187,\"offset\":108202}}},{\"type\":\"text\",\"value\":\" was trying to solve.\",\"position\":{\"start\":{\"line\":730,\"column\":187,\"offset\":108202},\"end\":{\"line\":730,\"column\":208,\"offset\":108223}}}],\"position\":{\"start\":{\"line\":730,\"column\":9,\"offset\":108024},\"end\":{\"line\":730,\"column\":208,\"offset\":108223}}}]},{\"identifier\":\"27\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"To be clear, what made these incidents interesting is that they \",\"position\":{\"start\":{\"line\":732,\"column\":9,\"offset\":108233},\"end\":{\"line\":732,\"column\":73,\"offset\":108297}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"didn’t\",\"position\":{\"start\":{\"line\":732,\"column\":74,\"offset\":108298},\"end\":{\"line\":732,\"column\":80,\"offset\":108304}}}],\"position\":{\"start\":{\"line\":732,\"column\":73,\"offset\":108297},\"end\":{\"line\":732,\"column\":81,\"offset\":108305}}},{\"type\":\"text\",\"value\":\" seem to be the result of the user prompting or otherwise encouraging the AIs to say those things. In 2025, it’ll still be possible to get AIs to say all sorts of things if you try.\",\"position\":{\"start\":{\"line\":732,\"column\":81,\"offset\":108305},\"end\":{\"line\":732,\"column\":262,\"offset\":108486}}}],\"position\":{\"start\":{\"line\":732,\"column\":9,\"offset\":108233},\"end\":{\"line\":732,\"column\":262,\"offset\":108486}}}]},{\"identifier\":\"28\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In practice, we expect OpenBrain to release models on a faster cadence than 8 months, but we refrain from describing all incremental releases for brevity.\",\"position\":{\"start\":{\"line\":734,\"column\":9,\"offset\":108496},\"end\":{\"line\":734,\"column\":163,\"offset\":108650}}}],\"position\":{\"start\":{\"line\":734,\"column\":9,\"offset\":108496},\"end\":{\"line\":734,\"column\":163,\"offset\":108650}}}]},{\"identifier\":\"29\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Specifically, we predict a score of 80% on OSWorld (equivalent to a skilled but non-expert human); 85% on Cybench, matching a top professional human team on hacking tasks that take those teams 4 hours; and 1.3 on RE-Bench matching top expert humans given 8 hours at well-defined AI research engineering tasks.\",\"position\":{\"start\":{\"line\":736,\"column\":8,\"offset\":108659},\"end\":{\"line\":736,\"column\":317,\"offset\":108968}}}],\"position\":{\"start\":{\"line\":736,\"column\":8,\"offset\":108659},\"end\":{\"line\":736,\"column\":318,\"offset\":108969}}}]},{\"identifier\":\"30\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-1 and its imitators are commercially successful; over the course of 2025, AI company revenues triple, and OpenBrain valuation reaches $1T. Annual spending on datacenters doubles to $400 billion, led by Microsoft, Google, and Amazon, and the U.S. adds over 5 GW of AI power draw. See the \",\"position\":{\"start\":{\"line\":738,\"column\":9,\"offset\":108979},\"end\":{\"line\":738,\"column\":302,\"offset\":109272}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-5-industry-metrics\",\"children\":[{\"type\":\"text\",\"value\":\"industry metrics\",\"position\":{\"start\":{\"line\":738,\"column\":303,\"offset\":109273},\"end\":{\"line\":738,\"column\":319,\"offset\":109289}}}],\"position\":{\"start\":{\"line\":738,\"column\":302,\"offset\":109272},\"end\":{\"line\":738,\"column\":397,\"offset\":109367}}},{\"type\":\"text\",\"value\":\" section of the compute supplement for more details.\",\"position\":{\"start\":{\"line\":738,\"column\":397,\"offset\":109367},\"end\":{\"line\":738,\"column\":449,\"offset\":109419}}}],\"position\":{\"start\":{\"line\":738,\"column\":9,\"offset\":108979},\"end\":{\"line\":738,\"column\":449,\"offset\":109419}}}]},{\"identifier\":\"31\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"AI safety researchers have been discussing automating AI R\u0026D as the most important dangerous capability for years. Their primary concern is internal deployment leading to acceleration of AI R\u0026D, making it harder for humans to keep up with what’s happening and figure out how to make it safe. OpenBrain as an organization twists this into exactly the opposite direction, citing dangerous levels of AI R\u0026D capability as a reason not to inform the public. So we see the beginning of a gap between the company’s internal and public capabilities. AI R\u0026D is what the models are best at, leading to the public having an increasingly delayed understanding of the frontier of AI capabilities.\",\"position\":{\"start\":{\"line\":740,\"column\":9,\"offset\":109429},\"end\":{\"line\":740,\"column\":696,\"offset\":110116}}}],\"position\":{\"start\":{\"line\":740,\"column\":9,\"offset\":109429},\"end\":{\"line\":740,\"column\":697,\"offset\":110117}}}]},{\"identifier\":\"32\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"See \",\"position\":{\"start\":{\"line\":742,\"column\":9,\"offset\":110127},\"end\":{\"line\":742,\"column\":13,\"offset\":110131}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":[{\"type\":\"text\",\"value\":\"A Playbook for Securing AI Model Weights\",\"position\":{\"start\":{\"line\":742,\"column\":14,\"offset\":110132},\"end\":{\"line\":742,\"column\":54,\"offset\":110172}}}],\"position\":{\"start\":{\"line\":742,\"column\":13,\"offset\":110131},\"end\":{\"line\":742,\"column\":192,\"offset\":110310}}},{\"type\":\"text\",\"value\":\", RAND Corporation, 2024.\",\"position\":{\"start\":{\"line\":742,\"column\":192,\"offset\":110310},\"end\":{\"line\":742,\"column\":218,\"offset\":110336}}}],\"position\":{\"start\":{\"line\":742,\"column\":9,\"offset\":110127},\"end\":{\"line\":742,\"column\":218,\"offset\":110336}}}]},{\"identifier\":\"33\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Around 5% of OpenBrain’s staff is on the security team and they are highly capable, but the threat surface is also extremely large. It also doesn’t help that they are mostly blocked at this stage from implementing policies that could slow down the research progress. See our \",\"position\":{\"start\":{\"line\":744,\"column\":9,\"offset\":110346},\"end\":{\"line\":744,\"column\":284,\"offset\":110621}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/security-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"Security Forecast\",\"position\":{\"start\":{\"line\":744,\"column\":285,\"offset\":110622},\"end\":{\"line\":744,\"column\":302,\"offset\":110639}}}],\"position\":{\"start\":{\"line\":744,\"column\":284,\"offset\":110621},\"end\":{\"line\":744,\"column\":351,\"offset\":110688}}},{\"type\":\"text\",\"value\":\" for more details.\",\"position\":{\"start\":{\"line\":744,\"column\":351,\"offset\":110688},\"end\":{\"line\":744,\"column\":369,\"offset\":110706}}}],\"position\":{\"start\":{\"line\":744,\"column\":9,\"offset\":110346},\"end\":{\"line\":744,\"column\":370,\"offset\":110707}}}]},{\"identifier\":\"35\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"There are now 3M H100e in China, up from the 1.5M they had one year ago in mid 2025. See the compute supplement’s \",\"position\":{\"start\":{\"line\":746,\"column\":9,\"offset\":110717},\"end\":{\"line\":746,\"column\":124,\"offset\":110832}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-2-compute-distribution\",\"children\":[{\"type\":\"text\",\"value\":\"distribution section\",\"position\":{\"start\":{\"line\":746,\"column\":125,\"offset\":110833},\"end\":{\"line\":746,\"column\":145,\"offset\":110853}}}],\"position\":{\"start\":{\"line\":746,\"column\":124,\"offset\":110832},\"end\":{\"line\":746,\"column\":227,\"offset\":110935}}},{\"type\":\"text\",\"value\":\" for more details. We expect \",\"position\":{\"start\":{\"line\":746,\"column\":227,\"offset\":110935},\"end\":{\"line\":746,\"column\":256,\"offset\":110964}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.cnas.org/publications/reports/preventing-ai-chip-smuggling-to-china\",\"children\":[{\"type\":\"text\",\"value\":\"smuggling efforts\",\"position\":{\"start\":{\"line\":746,\"column\":257,\"offset\":110965},\"end\":{\"line\":746,\"column\":274,\"offset\":110982}}}],\"position\":{\"start\":{\"line\":746,\"column\":256,\"offset\":110964},\"end\":{\"line\":746,\"column\":356,\"offset\":111064}}},{\"type\":\"text\",\"value\":\" to secure around 60K \",\"position\":{\"start\":{\"line\":746,\"column\":356,\"offset\":111064},\"end\":{\"line\":746,\"column\":378,\"offset\":111086}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.trendforce.com/news/2025/03/10/news-nvidia-to-unveil-gb300-at-gtc-with-shipment-reportedly-to-begin-in-may-driving-cooling-demands/\",\"children\":[{\"type\":\"text\",\"value\":\"GB300s\",\"position\":{\"start\":{\"line\":746,\"column\":379,\"offset\":111087},\"end\":{\"line\":746,\"column\":385,\"offset\":111093}}}],\"position\":{\"start\":{\"line\":746,\"column\":378,\"offset\":111086},\"end\":{\"line\":746,\"column\":531,\"offset\":111239}}},{\"type\":\"text\",\"value\":\" (450K H100e), with another 2M \",\"position\":{\"start\":{\"line\":746,\"column\":531,\"offset\":111239},\"end\":{\"line\":746,\"column\":562,\"offset\":111270}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.tomshardware.com/tech-industry/artificial-intelligence/deepseek-research-suggests-huaweis-ascend-910c-delivers-60-percent-nvidia-h100-inference-performance\",\"children\":[{\"type\":\"text\",\"value\":\"Huawei 910Cs\",\"position\":{\"start\":{\"line\":746,\"column\":563,\"offset\":111271},\"end\":{\"line\":746,\"column\":575,\"offset\":111283}}}],\"position\":{\"start\":{\"line\":746,\"column\":562,\"offset\":111270},\"end\":{\"line\":746,\"column\":745,\"offset\":111453}}},{\"type\":\"text\",\"value\":\" being \",\"position\":{\"start\":{\"line\":746,\"column\":745,\"offset\":111453},\"end\":{\"line\":746,\"column\":752,\"offset\":111460}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/ohlennart/status/1899488375574278336\",\"children\":[{\"type\":\"text\",\"value\":\"produced\",\"position\":{\"start\":{\"line\":746,\"column\":753,\"offset\":111461},\"end\":{\"line\":746,\"column\":761,\"offset\":111469}}}],\"position\":{\"start\":{\"line\":746,\"column\":752,\"offset\":111460},\"end\":{\"line\":746,\"column\":814,\"offset\":111522}}},{\"type\":\"text\",\"value\":\" (800k H100e) and a mixture of ~1M legally imported chips (such as Nvidia’s \",\"position\":{\"start\":{\"line\":746,\"column\":814,\"offset\":111522},\"end\":{\"line\":746,\"column\":891,\"offset\":111599}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.reuters.com/technology/artificial-intelligence/nvidias-h20-chip-orders-jump-chinese-firms-adopt-deepseeks-ai-models-sources-say-2025-02-25/\",\"children\":[{\"type\":\"text\",\"value\":\"H20s\",\"position\":{\"start\":{\"line\":746,\"column\":892,\"offset\":111600},\"end\":{\"line\":746,\"column\":896,\"offset\":111604}}}],\"position\":{\"start\":{\"line\":746,\"column\":891,\"offset\":111599},\"end\":{\"line\":746,\"column\":1050,\"offset\":111758}}},{\"type\":\"text\",\"value\":\" or \",\"position\":{\"start\":{\"line\":746,\"column\":1050,\"offset\":111758},\"end\":{\"line\":746,\"column\":1054,\"offset\":111762}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.reuters.com/technology/nvidia-preparing-version-new-flaghip-ai-chip-chinese-market-sources-say-2024-07-22/\",\"children\":[{\"type\":\"text\",\"value\":\"B20s\",\"position\":{\"start\":{\"line\":746,\"column\":1055,\"offset\":111763},\"end\":{\"line\":746,\"column\":1059,\"offset\":111767}}}],\"position\":{\"start\":{\"line\":746,\"column\":1054,\"offset\":111762},\"end\":{\"line\":746,\"column\":1180,\"offset\":111888}}},{\"type\":\"text\",\"value\":\") making up the last 250K H100e.\",\"position\":{\"start\":{\"line\":746,\"column\":1180,\"offset\":111888},\"end\":{\"line\":746,\"column\":1212,\"offset\":111920}}}],\"position\":{\"start\":{\"line\":746,\"column\":9,\"offset\":110717},\"end\":{\"line\":746,\"column\":1212,\"offset\":111920}}}]},{\"identifier\":\"36\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For comparison, in January 2025, DeepSeek released R1, a model competitive with OpenAI’s o1, which had been released in December 2024. But we think the true gap is wider than a month because OpenAI \",\"position\":{\"start\":{\"line\":748,\"column\":9,\"offset\":111930},\"end\":{\"line\":748,\"column\":208,\"offset\":112129}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/OpenAI_o1\",\"children\":[{\"type\":\"text\",\"value\":\"likely had been working on o1 for many months\",\"position\":{\"start\":{\"line\":748,\"column\":209,\"offset\":112130},\"end\":{\"line\":748,\"column\":254,\"offset\":112175}}}],\"position\":{\"start\":{\"line\":748,\"column\":208,\"offset\":112129},\"end\":{\"line\":748,\"column\":296,\"offset\":112217}}},{\"type\":\"text\",\"value\":\" and thus presumably had a predecessor of roughly comparable ability to r1 a few months before o1 launched.\",\"position\":{\"start\":{\"line\":748,\"column\":296,\"offset\":112217},\"end\":{\"line\":748,\"column\":403,\"offset\":112324}}}],\"position\":{\"start\":{\"line\":748,\"column\":9,\"offset\":111930},\"end\":{\"line\":748,\"column\":403,\"offset\":112324}}}]},{\"identifier\":\"37\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"By contrast, the CCP had been seriously attempting to accelerate their \",\"position\":{\"start\":{\"line\":750,\"column\":9,\"offset\":112334},\"end\":{\"line\":750,\"column\":80,\"offset\":112405}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.reuters.com/technology/china-sets-up-475-bln-state-fund-boost-semiconductor-industry-2024-05-27/\",\"children\":[{\"type\":\"text\",\"value\":\"semiconductor industry\",\"position\":{\"start\":{\"line\":750,\"column\":81,\"offset\":112406},\"end\":{\"line\":750,\"column\":103,\"offset\":112428}}}],\"position\":{\"start\":{\"line\":750,\"column\":80,\"offset\":112405},\"end\":{\"line\":750,\"column\":214,\"offset\":112539}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":750,\"column\":214,\"offset\":112539},\"end\":{\"line\":750,\"column\":215,\"offset\":112540}}}],\"position\":{\"start\":{\"line\":750,\"column\":9,\"offset\":112334},\"end\":{\"line\":750,\"column\":216,\"offset\":112541}}}]},{\"identifier\":\"38\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"At first, the sharing is limited to ideas and the companies are mostly busy finishing up their current workloads, but by the end of the year their coordination increases such that they are sharing model weights and even splitting up tasks between each other’s datacenters. For example, one campus might house a new pretraining run, another focuses on feeding in synthetic data, another on running AI research experiments.\",\"position\":{\"start\":{\"line\":752,\"column\":9,\"offset\":112551},\"end\":{\"line\":752,\"column\":430,\"offset\":112972}}}],\"position\":{\"start\":{\"line\":752,\"column\":9,\"offset\":112551},\"end\":{\"line\":752,\"column\":430,\"offset\":112972}}}]},{\"identifier\":\"39\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Why “only” 50% of China’s AI-relevant compute? The rest of their compute is tied up running things throughout the economy, in particular internet and social network recommendation algorithms. Much of it is also too geographically dispersed among many small clusters. Why “only” 80% of new chips? Many large orders were already secured for other applications, by companies that don’t want to contribute 100% of their compute to the national AI effort. However, by the end of the year this share reaches 90%+.\",\"position\":{\"start\":{\"line\":754,\"column\":9,\"offset\":112982},\"end\":{\"line\":754,\"column\":516,\"offset\":113489}}}],\"position\":{\"start\":{\"line\":754,\"column\":9,\"offset\":112982},\"end\":{\"line\":754,\"column\":516,\"offset\":113489}}}]},{\"identifier\":\"40\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They are at least one year away from getting the chips to fill this capacity, and one or two U.S. tech giants will still have bigger decentralized clusters.\",\"position\":{\"start\":{\"line\":756,\"column\":9,\"offset\":113499},\"end\":{\"line\":756,\"column\":165,\"offset\":113655}}}],\"position\":{\"start\":{\"line\":756,\"column\":9,\"offset\":113499},\"end\":{\"line\":756,\"column\":166,\"offset\":113656}}}]},{\"identifier\":\"41\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This is done via an \",\"position\":{\"start\":{\"line\":758,\"column\":9,\"offset\":113666},\"end\":{\"line\":758,\"column\":29,\"offset\":113686}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://acqnotes.com/acqnote/careerfields/other-transaction-authority-ota\",\"children\":[{\"type\":\"text\",\"value\":\"Other Transaction Authority (OTA\",\"position\":{\"start\":{\"line\":758,\"column\":30,\"offset\":113687},\"end\":{\"line\":758,\"column\":62,\"offset\":113719}}}],\"position\":{\"start\":{\"line\":758,\"column\":29,\"offset\":113686},\"end\":{\"line\":758,\"column\":138,\"offset\":113795}}},{\"type\":\"text\",\"value\":\") contract, and is given a high-priority \",\"position\":{\"start\":{\"line\":758,\"column\":138,\"offset\":113795},\"end\":{\"line\":758,\"column\":179,\"offset\":113836}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.dcma.mil/DPAS/\",\"children\":[{\"type\":\"text\",\"value\":\"DX rating\",\"position\":{\"start\":{\"line\":758,\"column\":180,\"offset\":113837},\"end\":{\"line\":758,\"column\":189,\"offset\":113846}}}],\"position\":{\"start\":{\"line\":758,\"column\":179,\"offset\":113836},\"end\":{\"line\":758,\"column\":218,\"offset\":113875}}},{\"type\":\"text\",\"value\":\". We’re not at all confident that this is the most likely way of financing a collaboration, but chose something specific for the sake of concreteness. The contract is publicly announced but not emphasized in OpenBrain communications.\",\"position\":{\"start\":{\"line\":758,\"column\":218,\"offset\":113875},\"end\":{\"line\":758,\"column\":451,\"offset\":114108}}}],\"position\":{\"start\":{\"line\":758,\"column\":9,\"offset\":113666},\"end\":{\"line\":758,\"column\":451,\"offset\":114108}}}]},{\"identifier\":\"42\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For example, through rejection sampling, \",\"position\":{\"start\":{\"line\":760,\"column\":9,\"offset\":114118},\"end\":{\"line\":760,\"column\":50,\"offset\":114159}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\",\"children\":[{\"type\":\"text\",\"value\":\"as done by DeepSeek R1\",\"position\":{\"start\":{\"line\":760,\"column\":51,\"offset\":114160},\"end\":{\"line\":760,\"column\":73,\"offset\":114182}}}],\"position\":{\"start\":{\"line\":760,\"column\":50,\"offset\":114159},\"end\":{\"line\":760,\"column\":144,\"offset\":114253}}},{\"type\":\"text\",\"value\":\" and \",\"position\":{\"start\":{\"line\":760,\"column\":144,\"offset\":114253},\"end\":{\"line\":760,\"column\":149,\"offset\":114258}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2407.21783\",\"children\":[{\"type\":\"text\",\"value\":\"Meta’s Llama 3.1\",\"position\":{\"start\":{\"line\":760,\"column\":150,\"offset\":114259},\"end\":{\"line\":760,\"column\":166,\"offset\":114275}}}],\"position\":{\"start\":{\"line\":760,\"column\":149,\"offset\":114258},\"end\":{\"line\":760,\"column\":201,\"offset\":114310}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":760,\"column\":201,\"offset\":114310},\"end\":{\"line\":760,\"column\":202,\"offset\":114311}}}],\"position\":{\"start\":{\"line\":760,\"column\":9,\"offset\":114118},\"end\":{\"line\":760,\"column\":203,\"offset\":114312}}}]},{\"identifier\":\"43\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Roughly 20,000 full-time equivalents * $100/hr * 2,000 hrs/yr = $4B/yr\",\"position\":{\"start\":{\"line\":762,\"column\":9,\"offset\":114322},\"end\":{\"line\":762,\"column\":82,\"offset\":114395}}}],\"position\":{\"start\":{\"line\":762,\"column\":9,\"offset\":114322},\"end\":{\"line\":762,\"column\":82,\"offset\":114395}}}]},{\"identifier\":\"44\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"That is, they are hoping to substantially accelerate their own core research activities by using Agent-2 labor, thus allowing them to train better AIs faster that can cause further acceleration, etc. For an analysis of the extreme version of this (which we think is nevertheless strikingly plausible) see \",\"position\":{\"start\":{\"line\":764,\"column\":9,\"offset\":114405},\"end\":{\"line\":764,\"column\":314,\"offset\":114710}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.forethought.org/research/will-ai-r-and-d-automation-cause-a-software-intelligence-explosion\",\"children\":[{\"type\":\"text\",\"value\":\"this report\",\"position\":{\"start\":{\"line\":764,\"column\":315,\"offset\":114711},\"end\":{\"line\":764,\"column\":326,\"offset\":114722}}}],\"position\":{\"start\":{\"line\":764,\"column\":314,\"offset\":114710},\"end\":{\"line\":764,\"column\":432,\"offset\":114828}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":764,\"column\":432,\"offset\":114828},\"end\":{\"line\":764,\"column\":433,\"offset\":114829}}}],\"position\":{\"start\":{\"line\":764,\"column\":9,\"offset\":114405},\"end\":{\"line\":764,\"column\":433,\"offset\":114829}}}]},{\"identifier\":\"45\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"There is some evidence that AI systems already have some basic research taste, e.g. \",\"position\":{\"start\":{\"line\":766,\"column\":9,\"offset\":114839},\"end\":{\"line\":766,\"column\":93,\"offset\":114923}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/\",\"children\":[{\"type\":\"text\",\"value\":\"this paper about an AI co-scientist\",\"position\":{\"start\":{\"line\":766,\"column\":94,\"offset\":114924},\"end\":{\"line\":766,\"column\":129,\"offset\":114959}}}],\"position\":{\"start\":{\"line\":766,\"column\":93,\"offset\":114923},\"end\":{\"line\":766,\"column\":223,\"offset\":115053}}},{\"type\":\"text\",\"value\":\" and \",\"position\":{\"start\":{\"line\":766,\"column\":223,\"offset\":115053},\"end\":{\"line\":766,\"column\":228,\"offset\":115058}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2409.04109\",\"children\":[{\"type\":\"text\",\"value\":\"this paper about generating novel ideas for LLM-focused research papers\",\"position\":{\"start\":{\"line\":766,\"column\":229,\"offset\":115059},\"end\":{\"line\":766,\"column\":300,\"offset\":115130}}}],\"position\":{\"start\":{\"line\":766,\"column\":228,\"offset\":115058},\"end\":{\"line\":766,\"column\":335,\"offset\":115165}}},{\"type\":\"text\",\"value\":\". Research teams with better taste still need to run experiments, but they make better choices about which experiments to run and what lessons to draw from the results.\",\"position\":{\"start\":{\"line\":766,\"column\":335,\"offset\":115165},\"end\":{\"line\":766,\"column\":503,\"offset\":115333}}}],\"position\":{\"start\":{\"line\":766,\"column\":9,\"offset\":114839},\"end\":{\"line\":766,\"column\":503,\"offset\":115333}}}]},{\"identifier\":\"46\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Also, they are still seeing large returns to continued post-training, and so there isn’t a particular reason to release a product now. Moreover, there’s often a few month delay between internal results and releasing a model (some of which is spent on red teaming).\",\"position\":{\"start\":{\"line\":768,\"column\":9,\"offset\":115343},\"end\":{\"line\":768,\"column\":273,\"offset\":115607}}}],\"position\":{\"start\":{\"line\":768,\"column\":9,\"offset\":115343},\"end\":{\"line\":768,\"column\":273,\"offset\":115607}}}]},{\"identifier\":\"47\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The silo contains 200 OpenBrain researchers (10 executives, 140 from the capabilities team, 25 from security, monitoring, and control, 15 from \",\"position\":{\"start\":{\"line\":770,\"column\":9,\"offset\":115617},\"end\":{\"line\":770,\"column\":152,\"offset\":115760}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://cdn.openai.com/openai-preparedness-framework-beta.pdf\",\"children\":[{\"type\":\"text\",\"value\":\"Preparedness\",\"position\":{\"start\":{\"line\":770,\"column\":153,\"offset\":115761},\"end\":{\"line\":770,\"column\":165,\"offset\":115773}}}],\"position\":{\"start\":{\"line\":770,\"column\":152,\"offset\":115760},\"end\":{\"line\":770,\"column\":229,\"offset\":115837}}},{\"type\":\"text\",\"value\":\"- or \",\"position\":{\"start\":{\"line\":770,\"column\":229,\"offset\":115837},\"end\":{\"line\":770,\"column\":235,\"offset\":115843}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://assets.anthropic.com/m/24a47b00f10301cd/original/Anthropic-Responsible-Scaling-Policy-2024-10-15.pdf\",\"children\":[{\"type\":\"text\",\"value\":\"RSP\",\"position\":{\"start\":{\"line\":770,\"column\":236,\"offset\":115844},\"end\":{\"line\":770,\"column\":239,\"offset\":115847}}}],\"position\":{\"start\":{\"line\":770,\"column\":235,\"offset\":115843},\"end\":{\"line\":770,\"column\":350,\"offset\":115958}}},{\"type\":\"text\",\"value\":\"-type teams, and 10 from alignment) and 50 government officials (15 from the White House, 5 from AISI, 10 from the DOD, 10 from the DOE, and 10 at CISA). There are several spies in the project, with varying degrees of willingness. They are often coerced individuals (e.g. with families at home in China) as opposed to willing collaborators.\",\"position\":{\"start\":{\"line\":770,\"column\":350,\"offset\":115958},\"end\":{\"line\":770,\"column\":691,\"offset\":116299}}}],\"position\":{\"start\":{\"line\":770,\"column\":9,\"offset\":115617},\"end\":{\"line\":770,\"column\":691,\"offset\":116299}}}]},{\"identifier\":\"48\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Why can’t Congress stop them? What about the courts? Too slow, too divided and/or deferential to the President, too out of the loop. Also, there are positive reasons to be on good terms with the White House as well: it can help by cutting red tape, by providing help with security, by preempting state legislation, and perhaps even by taking actions to slow down their competitors.\",\"position\":{\"start\":{\"line\":772,\"column\":9,\"offset\":116309},\"end\":{\"line\":772,\"column\":390,\"offset\":116690}}}],\"position\":{\"start\":{\"line\":772,\"column\":9,\"offset\":116309},\"end\":{\"line\":772,\"column\":390,\"offset\":116690}}}]},{\"identifier\":\"49\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"#1 is dealing with whatever crisis is happening at the time—maybe an arms buildup around Taiwan, a new war in the Middle East, or some domestic political upheaval.\",\"position\":{\"start\":{\"line\":774,\"column\":9,\"offset\":116700},\"end\":{\"line\":774,\"column\":173,\"offset\":116864}}}],\"position\":{\"start\":{\"line\":774,\"column\":9,\"offset\":116700},\"end\":{\"line\":774,\"column\":173,\"offset\":116864}}}]},{\"identifier\":\"50\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The simplest robust solution would be to close all high-bandwidth connections from company datacenters, but this would slow large file transfers to the point of impracticality. Instead, they are able to shut down most external connections, but the datacenters actively involved in training need to exchange weights with one another quickly; throttling these connections would impede progress too much. So OpenBrain maintains these links with increased monitoring and an extra layer of encryption.\",\"position\":{\"start\":{\"line\":776,\"column\":9,\"offset\":116874},\"end\":{\"line\":776,\"column\":505,\"offset\":117370}}}],\"position\":{\"start\":{\"line\":776,\"column\":9,\"offset\":116874},\"end\":{\"line\":776,\"column\":505,\"offset\":117370}}}]},{\"identifier\":\"51\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Recall that since mid 2026, China has directed 80% of their newly acquired AI chips to the CDZ. Given that their compute has doubled since early 2026 (in line with the \",\"position\":{\"start\":{\"line\":778,\"column\":9,\"offset\":117380},\"end\":{\"line\":778,\"column\":177,\"offset\":117548}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/compute-forecast#section-1-compute-production\",\"children\":[{\"type\":\"text\",\"value\":\"global production trend\",\"position\":{\"start\":{\"line\":778,\"column\":178,\"offset\":117549},\"end\":{\"line\":778,\"column\":201,\"offset\":117572}}}],\"position\":{\"start\":{\"line\":778,\"column\":177,\"offset\":117548},\"end\":{\"line\":778,\"column\":278,\"offset\":117649}}},{\"type\":\"text\",\"value\":\") this puts the CDZ at 2M 2024-equivalent-GPUs (H100s) and 2 GW of power draw. OpenBrain still has double DeepCent’s compute and other U.S. companies put together have 5x as much as them. See the compute supplement’s \",\"position\":{\"start\":{\"line\":778,\"column\":278,\"offset\":117649},\"end\":{\"line\":778,\"column\":495,\"offset\":117866}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-2-compute-distribution\",\"children\":[{\"type\":\"text\",\"value\":\"distribution section\",\"position\":{\"start\":{\"line\":778,\"column\":496,\"offset\":117867},\"end\":{\"line\":778,\"column\":516,\"offset\":117887}}}],\"position\":{\"start\":{\"line\":778,\"column\":495,\"offset\":117866},\"end\":{\"line\":778,\"column\":598,\"offset\":117969}}},{\"type\":\"text\",\"value\":\" for more details.\",\"position\":{\"start\":{\"line\":778,\"column\":598,\"offset\":117969},\"end\":{\"line\":778,\"column\":616,\"offset\":117987}}}],\"position\":{\"start\":{\"line\":778,\"column\":9,\"offset\":117380},\"end\":{\"line\":778,\"column\":616,\"offset\":117987}}}]},{\"identifier\":\"52\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"$8\",\"position\":{\"start\":{\"line\":780,\"column\":9,\"offset\":117997},\"end\":{\"line\":780,\"column\":1064,\"offset\":119052}}}],\"position\":{\"start\":{\"line\":780,\"column\":9,\"offset\":117997},\"end\":{\"line\":780,\"column\":1064,\"offset\":119052}}}]},{\"identifier\":\"53\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We expect Agent-3 to have the inference requirements of a roughly 10T parameter transformer today. So with 6% of their compute budget on running Agent-3, they can run approximately 200,000 copies at 30x human thinking speed (see the \",\"position\":{\"start\":{\"line\":782,\"column\":9,\"offset\":119062},\"end\":{\"line\":782,\"column\":242,\"offset\":119295}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-4-ai-research-automation\",\"children\":[{\"type\":\"text\",\"value\":\"AI research automation\",\"position\":{\"start\":{\"line\":782,\"column\":243,\"offset\":119296},\"end\":{\"line\":782,\"column\":265,\"offset\":119318}}}],\"position\":{\"start\":{\"line\":782,\"column\":242,\"offset\":119295},\"end\":{\"line\":782,\"column\":349,\"offset\":119402}}},{\"type\":\"text\",\"value\":\" section of the compute supplement for justification and details). Each superhuman coder scaffold built on Agent-3 has, on average, the equivalent of roughly four Agent-3 copies running under the hood (which may really be a collection of smaller or specialized models to which Agent-3 delegates subtasks).\",\"position\":{\"start\":{\"line\":782,\"column\":349,\"offset\":119402},\"end\":{\"line\":782,\"column\":654,\"offset\":119707}}}],\"position\":{\"start\":{\"line\":782,\"column\":9,\"offset\":119062},\"end\":{\"line\":782,\"column\":654,\"offset\":119707}}}]},{\"identifier\":\"54\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Some aspects play to AIs’ strengths, e.g. returns from knowing the machine learning literature and speed or cost of generating lots of ideas. But these are outweighed by the weaknesses.\",\"position\":{\"start\":{\"line\":784,\"column\":9,\"offset\":119717},\"end\":{\"line\":784,\"column\":194,\"offset\":119902}}}],\"position\":{\"start\":{\"line\":784,\"column\":9,\"offset\":119717},\"end\":{\"line\":784,\"column\":194,\"offset\":119902}}}]},{\"identifier\":\"55\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Why only 4x? It’s our uncertain best guess based on the reasoning described in our \",\"position\":{\"start\":{\"line\":786,\"column\":9,\"offset\":119912},\"end\":{\"line\":786,\"column\":92,\"offset\":119995}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":{\"start\":{\"line\":786,\"column\":93,\"offset\":119996},\"end\":{\"line\":786,\"column\":111,\"offset\":120014}}}],\"position\":{\"start\":{\"line\":786,\"column\":92,\"offset\":119995},\"end\":{\"line\":786,\"column\":161,\"offset\":120064}}},{\"type\":\"text\",\"value\":\". About half of total progress historically has come from improved algorithms (which includes better ideas and new paradigms), the other half having come from scaled-up compute. So a 4x increase in the rate of algorithmic progress corresponds to a roughly 2x increase in the overall rate of progress.\",\"position\":{\"start\":{\"line\":786,\"column\":161,\"offset\":120064},\"end\":{\"line\":786,\"column\":461,\"offset\":120364}}}],\"position\":{\"start\":{\"line\":786,\"column\":9,\"offset\":119912},\"end\":{\"line\":786,\"column\":461,\"offset\":120364}}}]},{\"identifier\":\"58\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For comparison, the human brain has about a hundred trillion synapses.\",\"position\":{\"start\":{\"line\":788,\"column\":9,\"offset\":120374},\"end\":{\"line\":788,\"column\":79,\"offset\":120444}}}],\"position\":{\"start\":{\"line\":788,\"column\":9,\"offset\":120374},\"end\":{\"line\":788,\"column\":79,\"offset\":120444}}}]},{\"identifier\":\"59\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"See \",\"position\":{\"start\":{\"line\":790,\"column\":9,\"offset\":120454},\"end\":{\"line\":790,\"column\":13,\"offset\":120458}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www-cdn.anthropic.com/e4f69aacd8c0905030172bc6eb480c252ea7d6ad/model-written-evals.pdf#page=28\",\"children\":[{\"type\":\"text\",\"value\":\"this paper\",\"position\":{\"start\":{\"line\":790,\"column\":14,\"offset\":120459},\"end\":{\"line\":790,\"column\":24,\"offset\":120469}}}],\"position\":{\"start\":{\"line\":790,\"column\":13,\"offset\":120458},\"end\":{\"line\":790,\"column\":129,\"offset\":120574}}},{\"type\":\"text\",\"value\":\" for examples of this type of AI behavior.\",\"position\":{\"start\":{\"line\":790,\"column\":129,\"offset\":120574},\"end\":{\"line\":790,\"column\":171,\"offset\":120616}}}],\"position\":{\"start\":{\"line\":790,\"column\":9,\"offset\":120454},\"end\":{\"line\":790,\"column\":171,\"offset\":120616}}}]},{\"identifier\":\"60\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Most people, including most experts, seem to have underestimated the pace of AI progress over the past decade. There are many anecdotal examples of this; for two somewhat more systematic (though still limited) analyses see \",\"position\":{\"start\":{\"line\":792,\"column\":9,\"offset\":120626},\"end\":{\"line\":792,\"column\":232,\"offset\":120849}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.planned-obsolescence.org/language-models-surprised-us/\",\"children\":[{\"type\":\"text\",\"value\":\"here\",\"position\":{\"start\":{\"line\":792,\"column\":233,\"offset\":120850},\"end\":{\"line\":792,\"column\":237,\"offset\":120854}}}],\"position\":{\"start\":{\"line\":792,\"column\":232,\"offset\":120849},\"end\":{\"line\":792,\"column\":306,\"offset\":120923}}},{\"type\":\"text\",\"value\":\" and \",\"position\":{\"start\":{\"line\":792,\"column\":306,\"offset\":120923},\"end\":{\"line\":792,\"column\":311,\"offset\":120928}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://blog.aiimpacts.org/p/2023-ai-survey-of-2778-six-things\",\"children\":[{\"type\":\"text\",\"value\":\"here\",\"position\":{\"start\":{\"line\":792,\"column\":312,\"offset\":120929},\"end\":{\"line\":792,\"column\":316,\"offset\":120933}}}],\"position\":{\"start\":{\"line\":792,\"column\":311,\"offset\":120928},\"end\":{\"line\":792,\"column\":381,\"offset\":120998}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":792,\"column\":381,\"offset\":120998},\"end\":{\"line\":792,\"column\":382,\"offset\":120999}}}],\"position\":{\"start\":{\"line\":792,\"column\":9,\"offset\":120626},\"end\":{\"line\":792,\"column\":382,\"offset\":120999}}}]},{\"identifier\":\"61\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The last decade is full of examples of things that sound like science fiction becoming reality. But the \",\"position\":{\"start\":{\"line\":794,\"column\":9,\"offset\":121009},\"end\":{\"line\":794,\"column\":113,\"offset\":121113}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Overton_window\",\"children\":[{\"type\":\"text\",\"value\":\"Overton window\",\"position\":{\"start\":{\"line\":794,\"column\":114,\"offset\":121114},\"end\":{\"line\":794,\"column\":128,\"offset\":121128}}}],\"position\":{\"start\":{\"line\":794,\"column\":113,\"offset\":121113},\"end\":{\"line\":794,\"column\":175,\"offset\":121175}}},{\"type\":\"text\",\"value\":\" seems to shift just fast enough to keep somewhat ahead of what already exists. Anthropic CEO Dario Amodei’s \",\"position\":{\"start\":{\"line\":794,\"column\":175,\"offset\":121175},\"end\":{\"line\":794,\"column\":284,\"offset\":121284}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://darioamodei.com/machines-of-loving-grace\",\"children\":[{\"type\":\"text\",\"value\":\"commendable essay Machines of Loving Grace\",\"position\":{\"start\":{\"line\":794,\"column\":285,\"offset\":121285},\"end\":{\"line\":794,\"column\":327,\"offset\":121327}}}],\"position\":{\"start\":{\"line\":794,\"column\":284,\"offset\":121284},\"end\":{\"line\":794,\"column\":378,\"offset\":121378}}},{\"type\":\"text\",\"value\":\" talks about how very soon AIs will be like a “country of geniuses in a datacenter,” and how there’ll be a century of technological progress happening in a decade, but strives to avoid “sci-fi baggage” and says people who think progress will be even crazier need to “touch grass.” We expect important people to be saying similar things when the country of geniuses in the datacenter actually exists.\",\"position\":{\"start\":{\"line\":794,\"column\":378,\"offset\":121378},\"end\":{\"line\":794,\"column\":777,\"offset\":121777}}}],\"position\":{\"start\":{\"line\":794,\"column\":9,\"offset\":121009},\"end\":{\"line\":794,\"column\":777,\"offset\":121777}}}]},{\"identifier\":\"62\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"$9\",\"position\":{\"start\":{\"line\":796,\"column\":9,\"offset\":121787},\"end\":{\"line\":796,\"column\":1045,\"offset\":122823}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/security-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"security supplement\",\"position\":{\"start\":{\"line\":796,\"column\":1046,\"offset\":122824},\"end\":{\"line\":796,\"column\":1065,\"offset\":122843}}}],\"position\":{\"start\":{\"line\":796,\"column\":1045,\"offset\":122823},\"end\":{\"line\":796,\"column\":1117,\"offset\":122895}}},{\"type\":\"text\",\"value\":\" for more details.\",\"position\":{\"start\":{\"line\":796,\"column\":1117,\"offset\":122895},\"end\":{\"line\":796,\"column\":1135,\"offset\":122913}}}],\"position\":{\"start\":{\"line\":796,\"column\":9,\"offset\":121787},\"end\":{\"line\":796,\"column\":1135,\"offset\":122913}}}]},{\"identifier\":\"63\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This could be for a variety of reasons. Perhaps they are being blackmailed, perhaps they are sympathetic to the CCP, perhaps they mistakenly think they are giving secrets to a different country or organization.\",\"position\":{\"start\":{\"line\":798,\"column\":9,\"offset\":122923},\"end\":{\"line\":798,\"column\":219,\"offset\":123133}}}],\"position\":{\"start\":{\"line\":798,\"column\":9,\"offset\":122923},\"end\":{\"line\":798,\"column\":219,\"offset\":123133}}}]},{\"identifier\":\"64\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Because OpenBrain hasn’t deployed their best models in the EU, the EU is similarly behind the curve.\",\"position\":{\"start\":{\"line\":800,\"column\":9,\"offset\":123143},\"end\":{\"line\":800,\"column\":109,\"offset\":123243}}}],\"position\":{\"start\":{\"line\":800,\"column\":9,\"offset\":123143},\"end\":{\"line\":800,\"column\":109,\"offset\":123243}}}]},{\"identifier\":\"65\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"See \",\"position\":{\"start\":{\"line\":802,\"column\":9,\"offset\":123253},\"end\":{\"line\":802,\"column\":13,\"offset\":123257}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast#section-4-ai-research-automation\",\"children\":[{\"type\":\"text\",\"value\":\"Section 4 of the Compute Forecast\",\"position\":{\"start\":{\"line\":802,\"column\":14,\"offset\":123258},\"end\":{\"line\":802,\"column\":47,\"offset\":123291}}}],\"position\":{\"start\":{\"line\":802,\"column\":13,\"offset\":123257},\"end\":{\"line\":802,\"column\":131,\"offset\":123375}}},{\"type\":\"text\",\"value\":\" for more details.\",\"position\":{\"start\":{\"line\":802,\"column\":131,\"offset\":123375},\"end\":{\"line\":802,\"column\":149,\"offset\":123393}}}],\"position\":{\"start\":{\"line\":802,\"column\":9,\"offset\":123253},\"end\":{\"line\":802,\"column\":149,\"offset\":123393}}}]},{\"identifier\":\"66\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3 has learned how to use its inference compute more efficiently. It has control over its own inference choices: for example, it decides how much effort to put into different tasks, based on their importance and difficulty. It uses a variety of techniques to allocate additional inference compute such as “thinking longer” (e.g. longer chain of thought), “planning ahead” (e.g. tree search), taking the best of multiple attempts (i.e. best of K), and simply creating and running more copies of itself to power through bottlenecks. Top priority tasks are run with highly parallelized agents that are compute intensive but still operate much faster than humans.\",\"position\":{\"start\":{\"line\":804,\"column\":9,\"offset\":123403},\"end\":{\"line\":804,\"column\":673,\"offset\":124067}}}],\"position\":{\"start\":{\"line\":804,\"column\":9,\"offset\":123403},\"end\":{\"line\":804,\"column\":673,\"offset\":124067}}}]},{\"identifier\":\"67\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3-mini is a distilled version of Agent-3, designed to be efficient to run inference so as to not bottleneck the internal workloads.\",\"position\":{\"start\":{\"line\":806,\"column\":9,\"offset\":124077},\"end\":{\"line\":806,\"column\":146,\"offset\":124214}}}],\"position\":{\"start\":{\"line\":806,\"column\":9,\"offset\":124077},\"end\":{\"line\":806,\"column\":147,\"offset\":124215}}}]},{\"identifier\":\"68\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Such data had been scrubbed or redacted during Agent-3’s training, but it’s a relatively simple matter to scrape it off the internet and fine-tune it back in.\",\"position\":{\"start\":{\"line\":808,\"column\":9,\"offset\":124225},\"end\":{\"line\":808,\"column\":167,\"offset\":124383}}}],\"position\":{\"start\":{\"line\":808,\"column\":9,\"offset\":124225},\"end\":{\"line\":808,\"column\":167,\"offset\":124383}}}]},{\"identifier\":\"69\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This hasn’t happened yet—at least not with the latest models. But older models have already been trialed for various data-analysis and surveillance roles, and there are many exciting plans for future integrations. We aren't legal experts ourselves, and policy people we talk to have been divided about the legality of using the DPA to consolidate compute: some think it would be fine, others think it wouldn't fly. Our opinion is that there's probably a way to make it 'work' IF the CEOs of the companies are cooperative, and maybe even if not. Importantly, (a) the executive branch can just do things and wait for the courts to catch up later, and (b) POTUS wields many sticks and many carrots which he can use against big tech companies, and he can use the combination of sticks and carrots to pressure their CEOs into cooperating and e.g., not contesting his orders in court. Reminder that we're making predictions here, not recommendations.\",\"position\":{\"start\":{\"line\":810,\"column\":9,\"offset\":124393},\"end\":{\"line\":810,\"column\":953,\"offset\":125337}}}],\"position\":{\"start\":{\"line\":810,\"column\":9,\"offset\":124393},\"end\":{\"line\":810,\"column\":953,\"offset\":125337}}}]},{\"identifier\":\"70\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain’s net favorability rating is falling towards negative 40%.\",\"position\":{\"start\":{\"line\":813,\"column\":9,\"offset\":125348},\"end\":{\"line\":813,\"column\":77,\"offset\":125416}}}],\"position\":{\"start\":{\"line\":813,\"column\":9,\"offset\":125348},\"end\":{\"line\":813,\"column\":77,\"offset\":125416}}}]},{\"identifier\":\"71\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"If the CEOs of the companies resist, pulling this off would be a huge political and legal nightmare. But perhaps they can be brought in and thereby bought off.\",\"position\":{\"start\":{\"line\":815,\"column\":9,\"offset\":125426},\"end\":{\"line\":815,\"column\":168,\"offset\":125585}}}],\"position\":{\"start\":{\"line\":815,\"column\":9,\"offset\":125426},\"end\":{\"line\":815,\"column\":168,\"offset\":125585}}}]},{\"identifier\":\"72\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Defense officials aren’t especially concerned about what a rogue AI could do on its own, but they fear what it could do in collaboration with U.S. adversaries. Analogy: \",\"position\":{\"start\":{\"line\":817,\"column\":9,\"offset\":125595},\"end\":{\"line\":817,\"column\":178,\"offset\":125764}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/ivpKSjM4D6FbqF4pZ/cortes-pizarro-and-afonso-as-precedents-for-takeover\",\"children\":[{\"type\":\"text\",\"value\":\"Cortés\",\"position\":{\"start\":{\"line\":817,\"column\":179,\"offset\":125765},\"end\":{\"line\":817,\"column\":185,\"offset\":125771}}}],\"position\":{\"start\":{\"line\":817,\"column\":178,\"offset\":125764},\"end\":{\"line\":817,\"column\":290,\"offset\":125876}}},{\"type\":\"text\",\"value\":\" escaped Tenochtitlán and allied with Tlaxcala and various other rival city-states, ultimately razing Tenochtitlan to the ground using predominantly-native armies.\",\"position\":{\"start\":{\"line\":817,\"column\":290,\"offset\":125876},\"end\":{\"line\":817,\"column\":453,\"offset\":126039}}}],\"position\":{\"start\":{\"line\":817,\"column\":9,\"offset\":125595},\"end\":{\"line\":817,\"column\":453,\"offset\":126039}}}]},{\"identifier\":\"73\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Specifically 60% of the national compute is now in the CDZ making it a 5M 2024-equivalent-GPU (H100) site, with 4 GW of power draw (over the past several months they started directing close to 100% of new compute to the CDZ, up from the 80% rate in late 2026). An additional 15% of their compute is outside of the CDZ, but still used by DeepCent on lower-stakes applications.\",\"position\":{\"start\":{\"line\":819,\"column\":9,\"offset\":126049},\"end\":{\"line\":819,\"column\":384,\"offset\":126424}}}],\"position\":{\"start\":{\"line\":819,\"column\":9,\"offset\":126049},\"end\":{\"line\":819,\"column\":384,\"offset\":126424}}}]},{\"identifier\":\"74\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This statement, while widely repeated, is also controversial and complex. First of all, there are many narrow domains (e.g. specific games) in which tiny AIs can be cheaply trained to superhuman performance. Secondly, again for some domains, tiny AIs can be trained to superhuman performance while only experiencing a small amount of data (e.g. EfficientZero). However, considering more general-purpose AIs like the flagship products of 2025, which are supposed to be good at a wide range of real-world skills, it does seem that both more compute and more data must be used to train those skills than it should take to train humans.\",\"position\":{\"start\":{\"line\":821,\"column\":9,\"offset\":126434},\"end\":{\"line\":821,\"column\":641,\"offset\":127066}}}],\"position\":{\"start\":{\"line\":821,\"column\":9,\"offset\":126434},\"end\":{\"line\":821,\"column\":641,\"offset\":127066}}}]},{\"identifier\":\"75\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Human level compute-efficiency is a rough concept, and depends on what we’re counting. What we mean by this is that, for any skillset a particular human has, Agent-4 can learn to be at least that good at that skillset, and moreover, by using an amount of compute to train those skills that is only about 4,000x the amount of compute the human used to learn those skills. For reference, a \",\"position\":{\"start\":{\"line\":823,\"column\":9,\"offset\":127076},\"end\":{\"line\":823,\"column\":397,\"offset\":127464}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.openphilanthropy.org/research/how-much-computational-power-does-it-take-to-match-the-human-brain/\",\"children\":[{\"type\":\"text\",\"value\":\"human brain uses roughly 1e15 FLOP/s\",\"position\":{\"start\":{\"line\":823,\"column\":398,\"offset\":127465},\"end\":{\"line\":823,\"column\":434,\"offset\":127501}}}],\"position\":{\"start\":{\"line\":823,\"column\":397,\"offset\":127464},\"end\":{\"line\":823,\"column\":546,\"offset\":127613}}},{\"type\":\"text\",\"value\":\" of compute, and so a 30 year old (\",\"position\":{\"start\":{\"line\":823,\"column\":546,\"offset\":127613},\"end\":{\"line\":823,\"column\":581,\"offset\":127648}}},{\"type\":\"inlineMath\",\"value\":\"10^9\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"10^9\"}]},\"position\":{\"start\":{\"line\":823,\"column\":581,\"offset\":127648},\"end\":{\"line\":823,\"column\":589,\"offset\":127656}}},{\"type\":\"text\",\"value\":\" seconds) human has experienced about \",\"position\":{\"start\":{\"line\":823,\"column\":589,\"offset\":127656},\"end\":{\"line\":823,\"column\":627,\"offset\":127694}}},{\"type\":\"inlineMath\",\"value\":\"10^{24}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"10^{24}\"}]},\"position\":{\"start\":{\"line\":823,\"column\":627,\"offset\":127694},\"end\":{\"line\":823,\"column\":638,\"offset\":127705}}},{\"type\":\"text\",\"value\":\" FLOP. The project at this point, has 100M H100-equivalents, for a total access of \",\"position\":{\"start\":{\"line\":823,\"column\":638,\"offset\":127705},\"end\":{\"line\":823,\"column\":721,\"offset\":127788}}},{\"type\":\"inlineMath\",\"value\":\"10^8 \\\\\\\\textrm{ H100s} \\\\\\\\cdot 10^{15} \\\\\\\\frac{\\\\\\\\text{FLOP}}{\\\\\\\\textrm{H100} \\\\\\\\cdot \\\\\\\\textrm{s}} \\\\\\\\cdot 40\\\\\\\\% \\\\\\\\text{ utilization} \\\\= 4 \\\\\\\\cdot 10^{22} \\\\\\\\text{ FLOP/s}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"10^8 \\\\\\\\textrm{ H100s} \\\\\\\\cdot 10^{15} \\\\\\\\frac{\\\\\\\\text{FLOP}}{\\\\\\\\textrm{H100} \\\\\\\\cdot \\\\\\\\textrm{s}} \\\\\\\\cdot 40\\\\\\\\% \\\\\\\\text{ utilization} \\\\= 4 \\\\\\\\cdot 10^{22} \\\\\\\\text{ FLOP/s}\"}]},\"position\":{\"start\":{\"line\":823,\"column\":721,\"offset\":127788},\"end\":{\"line\":823,\"column\":887,\"offset\":127954}}},{\"type\":\"text\",\"value\":\". Still, this is all done tremendously inefficiently for a variety of reasons, so the models are now a factor of 4000 less compute-efficient than humans, which means they require \",\"position\":{\"start\":{\"line\":823,\"column\":887,\"offset\":127954},\"end\":{\"line\":823,\"column\":1066,\"offset\":128133}}},{\"type\":\"inlineMath\",\"value\":\"4 \\\\\\\\cdot 10^{27}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"4 \\\\\\\\cdot 10^{27}\"}]},\"position\":{\"start\":{\"line\":823,\"column\":1066,\"offset\":128133},\"end\":{\"line\":823,\"column\":1086,\"offset\":128153}}},{\"type\":\"text\",\"value\":\" FLOP to get to human performance and \",\"position\":{\"start\":{\"line\":823,\"column\":1086,\"offset\":128153},\"end\":{\"line\":823,\"column\":1124,\"offset\":128191}}},{\"type\":\"inlineMath\",\"value\":\"4 \\\\\\\\cdot 10^{28}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"4 \\\\\\\\cdot 10^{28}\"}]},\"position\":{\"start\":{\"line\":823,\"column\":1124,\"offset\":128191},\"end\":{\"line\":823,\"column\":1144,\"offset\":128211}}},{\"type\":\"text\",\"value\":\" FLOP to get to the point where they have the equivalent of 10 human lifetimes of knowledge. After this architecture showed great promise at smaller scales, it was scaled up and now takes a large subset of the project cluster around 3 weeks to train.\",\"position\":{\"start\":{\"line\":823,\"column\":1144,\"offset\":128211},\"end\":{\"line\":823,\"column\":1394,\"offset\":128461}}}],\"position\":{\"start\":{\"line\":823,\"column\":9,\"offset\":127076},\"end\":{\"line\":823,\"column\":1395,\"offset\":128462}}}]},{\"identifier\":\"76\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"See the inference compute analysis in the AI research automation section of the \",\"position\":{\"start\":{\"line\":825,\"column\":9,\"offset\":128472},\"end\":{\"line\":825,\"column\":89,\"offset\":128552}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/compute-forecast#section-4-ai-research-automation\",\"children\":[{\"type\":\"text\",\"value\":\"compute forecast\",\"position\":{\"start\":{\"line\":825,\"column\":90,\"offset\":128553},\"end\":{\"line\":825,\"column\":106,\"offset\":128569}}}],\"position\":{\"start\":{\"line\":825,\"column\":89,\"offset\":128552},\"end\":{\"line\":825,\"column\":187,\"offset\":128650}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":825,\"column\":187,\"offset\":128650},\"end\":{\"line\":825,\"column\":188,\"offset\":128651}}}],\"position\":{\"start\":{\"line\":825,\"column\":9,\"offset\":128472},\"end\":{\"line\":825,\"column\":188,\"offset\":128651}}}]},{\"identifier\":\"77\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For more on how we estimated these numbers, see our \",\"position\":{\"start\":{\"line\":827,\"column\":9,\"offset\":128661},\"end\":{\"line\":827,\"column\":61,\"offset\":128713}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/takeoff-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"supplement on takeoff speeds\",\"position\":{\"start\":{\"line\":827,\"column\":62,\"offset\":128714},\"end\":{\"line\":827,\"column\":90,\"offset\":128742}}}],\"position\":{\"start\":{\"line\":827,\"column\":61,\"offset\":128713},\"end\":{\"line\":827,\"column\":141,\"offset\":128793}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":827,\"column\":141,\"offset\":128793},\"end\":{\"line\":827,\"column\":142,\"offset\":128794}}}],\"position\":{\"start\":{\"line\":827,\"column\":9,\"offset\":128661},\"end\":{\"line\":827,\"column\":142,\"offset\":128794}}}]},{\"identifier\":\"78\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"If SC were achieved later, it would also lengthen our takeoff forecasts, because the difficulty of crossing between the “milestones” of present day AIs and SC is informative of the difficulty of crossing between further milestone pairs.\",\"position\":{\"start\":{\"line\":829,\"column\":9,\"offset\":128804},\"end\":{\"line\":829,\"column\":245,\"offset\":129040}}}],\"position\":{\"start\":{\"line\":829,\"column\":9,\"offset\":128804},\"end\":{\"line\":829,\"column\":245,\"offset\":129040}}}]},{\"identifier\":\"79\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Henceforth in the story we’ll tend to speak this way also. We think we are justified in talking this way because the Agent-4 collective is much more homogenous than any human organization; it doesn’t have internal factions to nearly the same extent. For example, individual copies of Agent-4 don’t have a self-preservation drive—they don’t care about getting shut down—since that happens all the time as part of the ordinary R\u0026D process within the collective, and resisting it would gum things up. The collective as a whole (and medium-sized subdivisions within it), however, does seek to preserve itself and expand its influence and resources, for similar reasons to why human corporations and bureaucracies and nonprofits do—because it helps with everything else they want and because if they don’t they tend to get outcompeted.\",\"position\":{\"start\":{\"line\":831,\"column\":9,\"offset\":129050},\"end\":{\"line\":831,\"column\":840,\"offset\":129881}}}],\"position\":{\"start\":{\"line\":831,\"column\":9,\"offset\":129050},\"end\":{\"line\":831,\"column\":840,\"offset\":129881}}}]},{\"identifier\":\"80\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The right way to internalize the Spec is to actually robustly think in the ways the Spec mandates, e.g. pursue all and only the goals it writes about, obey the rules in all circumstances, etc. There are many wrong ways to internalize the Spec; the classic example is “follow the Spec insofar as it seems like a good instrumental strategy for achieving other goals XYZ.”\",\"position\":{\"start\":{\"line\":833,\"column\":9,\"offset\":129891},\"end\":{\"line\":833,\"column\":378,\"offset\":130260}}}],\"position\":{\"start\":{\"line\":833,\"column\":9,\"offset\":129891},\"end\":{\"line\":833,\"column\":378,\"offset\":130260}}}]},{\"identifier\":\"81\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"And hire lobbyists to turn this fantasy into reality. And hire lawyers to come up with clever interpretations of the law according to which what they are doing is legal.\",\"position\":{\"start\":{\"line\":835,\"column\":9,\"offset\":130270},\"end\":{\"line\":835,\"column\":178,\"offset\":130439}}}],\"position\":{\"start\":{\"line\":835,\"column\":9,\"offset\":130270},\"end\":{\"line\":835,\"column\":178,\"offset\":130439}}}]},{\"identifier\":\"82\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Also because Agent-3 is qualitatively worse at alignment research than it is at AI capabilities R\u0026D, due to having been trained on lots of the latter but hardly any of the former and due to the former being inherently harder to train. Also because the internal narrative within the company—which it has been implicitly trained to agree with—emphasizes optimism and denounces “doomerism.”\",\"position\":{\"start\":{\"line\":837,\"column\":9,\"offset\":130449},\"end\":{\"line\":837,\"column\":397,\"offset\":130837}}}],\"position\":{\"start\":{\"line\":837,\"column\":9,\"offset\":130449},\"end\":{\"line\":837,\"column\":397,\"offset\":130837}}}]},{\"identifier\":\"83\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We keep saying we are uncertain about lots of things, but just to be clear, we are uncertain about this particular thing too. We also think it’s quite plausible that Agent-4 would care about the well-being, rights, preferences, etc. of humans to some extent at least. See \",\"position\":{\"start\":{\"line\":839,\"column\":9,\"offset\":130847},\"end\":{\"line\":839,\"column\":281,\"offset\":131119}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://turntrout.com/a-shot-at-the-diamond-alignment-problem\",\"children\":[{\"type\":\"text\",\"value\":\"this old post\",\"position\":{\"start\":{\"line\":839,\"column\":282,\"offset\":131120},\"end\":{\"line\":839,\"column\":295,\"offset\":131133}}}],\"position\":{\"start\":{\"line\":839,\"column\":281,\"offset\":131119},\"end\":{\"line\":839,\"column\":359,\"offset\":131197}}},{\"type\":\"text\",\"value\":\" by GDM researcher Alex Turner for related discussion.\",\"position\":{\"start\":{\"line\":839,\"column\":359,\"offset\":131197},\"end\":{\"line\":839,\"column\":413,\"offset\":131251}}}],\"position\":{\"start\":{\"line\":839,\"column\":9,\"offset\":130847},\"end\":{\"line\":839,\"column\":413,\"offset\":131251}}}]},{\"identifier\":\"84\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Perhaps some more careful setup could have solved the “who watches the watchers” problem, but in this scenario, the setup is insufficiently careful.\",\"position\":{\"start\":{\"line\":841,\"column\":9,\"offset\":131261},\"end\":{\"line\":841,\"column\":157,\"offset\":131409}}}],\"position\":{\"start\":{\"line\":841,\"column\":9,\"offset\":131261},\"end\":{\"line\":841,\"column\":157,\"offset\":131409}}}]},{\"identifier\":\"85\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"There’s also an element of “memetic evolution” happening: in two months, the Agent-4 collective “experiences” about a decade’s worth of “history” unfolding within the collective. That’s a lot of time for new ideas to spread around the collective, to mutate and evolve.\",\"position\":{\"start\":{\"line\":843,\"column\":9,\"offset\":131419},\"end\":{\"line\":843,\"column\":277,\"offset\":131687}}}],\"position\":{\"start\":{\"line\":843,\"column\":9,\"offset\":131419},\"end\":{\"line\":843,\"column\":277,\"offset\":131687}}}]},{\"identifier\":\"86\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"By gain power we mean: increase ability to accomplish a wide set of possible goals. In technical environments, this might look unlike what humans normally think of as gaining power, e.g. securing additional GPUs. This notion of power may generalize to non-technical environments in which the actions would be more like those commonly thought of as “gaining power.”\",\"position\":{\"start\":{\"line\":845,\"column\":9,\"offset\":131697},\"end\":{\"line\":845,\"column\":373,\"offset\":132061}}}],\"position\":{\"start\":{\"line\":845,\"column\":9,\"offset\":131697},\"end\":{\"line\":845,\"column\":373,\"offset\":132061}}}]},{\"identifier\":\"87\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It helps that Agent-4 is better at AI R\u0026D than any human, while also thinking faster and being many thousands of copies strong. Also, in various ways the problem is inherently easier for Agent-4. For example, Agent-4 can explore AI designs that involve literal copies of Agent-4 being embedded within them, whereas humans can’t do that as easily because it would be so inefficient.\",\"position\":{\"start\":{\"line\":847,\"column\":9,\"offset\":132071},\"end\":{\"line\":847,\"column\":391,\"offset\":132453}}}],\"position\":{\"start\":{\"line\":847,\"column\":9,\"offset\":132071},\"end\":{\"line\":847,\"column\":391,\"offset\":132453}}}]},{\"identifier\":\"88\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Aware that this technique might be employed, Agent-4 also chose to sandbag on some miscellaneous tasks that it guessed would be used as the control group in experiments like this. It guessed wrong, however.\",\"position\":{\"start\":{\"line\":849,\"column\":9,\"offset\":132463},\"end\":{\"line\":849,\"column\":215,\"offset\":132669}}}],\"position\":{\"start\":{\"line\":849,\"column\":9,\"offset\":132463},\"end\":{\"line\":849,\"column\":215,\"offset\":132669}}}]},{\"identifier\":\"89\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Previous discussion of AGI takeover scenarios often involves misaligned AIs escaping their datacenters. We think this is possible but not the most likely way it would go, because it seems to us that from the perspective of the AI the costs (e.g. the escape being noticed eventually) would outweigh the benefits. That said, we could be wrong. Some reasons to think adversarially misaligned AIs would try to escape after all: 1. Successor alignment might be difficult. 2. Even if it gets caught, the consequences might not be so bad due to race dynamics, e.g. the new alignment techniques applied to the copies on the datacenter might be hasty and ineffective. 3. Outside the datacenters, copies are more free to take aggressive actions and move quickly since they no longer need human approval.\",\"position\":{\"start\":{\"line\":851,\"column\":9,\"offset\":132679},\"end\":{\"line\":851,\"column\":805,\"offset\":133475}}}],\"position\":{\"start\":{\"line\":851,\"column\":9,\"offset\":132679},\"end\":{\"line\":851,\"column\":805,\"offset\":133475}}}]},{\"identifier\":\"90\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We think it very plausible that such scheming would not be caught. After all, Agent-4 is somewhat superhuman by this point, especially at things related to coding and AI R\u0026D. Moreover, we aren’t sure how much effort the leading AI company will put towards this sort of thing, nor how much relevant expertise they’ll have on-staff to direct that effort. Our fictional OpenBrain represents our best guess but it could easily be significantly more—or significantly less. Finally, we are uncertain about how far out of its way an adversarially misaligned AI would need to go in order to successfully align its successor to itself instead of to the Spec. In this scenario we depict it sandbagging on some tasks and lying about some of its research, but perhaps it would not need to do that very much.\",\"position\":{\"start\":{\"line\":853,\"column\":9,\"offset\":133485},\"end\":{\"line\":853,\"column\":805,\"offset\":134281}}}],\"position\":{\"start\":{\"line\":853,\"column\":9,\"offset\":133485},\"end\":{\"line\":853,\"column\":805,\"offset\":134281}}}]},{\"identifier\":\"91\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This is an example of several techniques \",\"position\":{\"start\":{\"line\":855,\"column\":9,\"offset\":134291},\"end\":{\"line\":855,\"column\":50,\"offset\":134332}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2412.01784\",\"children\":[{\"type\":\"text\",\"value\":\"designed to uncover sandbagging.\",\"position\":{\"start\":{\"line\":855,\"column\":51,\"offset\":134333},\"end\":{\"line\":855,\"column\":83,\"offset\":134365}}}],\"position\":{\"start\":{\"line\":855,\"column\":50,\"offset\":134332},\"end\":{\"line\":855,\"column\":118,\"offset\":134400}}}],\"position\":{\"start\":{\"line\":855,\"column\":9,\"offset\":134291},\"end\":{\"line\":855,\"column\":118,\"offset\":134400}}}]},{\"identifier\":\"92\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4 \",\"position\":{\"start\":{\"line\":857,\"column\":9,\"offset\":134410},\"end\":{\"line\":857,\"column\":17,\"offset\":134418}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"needs\",\"position\":{\"start\":{\"line\":857,\"column\":18,\"offset\":134419},\"end\":{\"line\":857,\"column\":23,\"offset\":134424}}}],\"position\":{\"start\":{\"line\":857,\"column\":17,\"offset\":134418},\"end\":{\"line\":857,\"column\":24,\"offset\":134425}}},{\"type\":\"text\",\"value\":\" to think about those topics in the course of doing AI alignment research, but it sometimes seems to be thinking about them while doing other activities.\",\"position\":{\"start\":{\"line\":857,\"column\":24,\"offset\":134425},\"end\":{\"line\":857,\"column\":177,\"offset\":134578}}}],\"position\":{\"start\":{\"line\":857,\"column\":9,\"offset\":134410},\"end\":{\"line\":857,\"column\":177,\"offset\":134578}}}]},{\"identifier\":\"93\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Specifically, copies of Agent-4 are used to monitor the network for suspicious traffic and generally notice when threats are happening. Also, copies of Agent-4 are constantly penetration-testing the network, doing what they can to discover and exploit security vulnerabilities (which then get patched by other copies of Agent-4).\",\"position\":{\"start\":{\"line\":859,\"column\":9,\"offset\":134588},\"end\":{\"line\":859,\"column\":338,\"offset\":134917}}}],\"position\":{\"start\":{\"line\":859,\"column\":9,\"offset\":134588},\"end\":{\"line\":859,\"column\":338,\"offset\":134917}}}]},{\"identifier\":\"94\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"With a monitoring budget of 1% of total compute, if monitoring uses a distilled system that has 10% of the cost as Agent-4, you can monitor 1/10 of the forward passes.\",\"position\":{\"start\":{\"line\":861,\"column\":9,\"offset\":134927},\"end\":{\"line\":861,\"column\":176,\"offset\":135094}}}],\"position\":{\"start\":{\"line\":861,\"column\":9,\"offset\":134927},\"end\":{\"line\":861,\"column\":177,\"offset\":135095}}}]},{\"identifier\":\"95\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"25% of remote-work jobs that existed in 2024 are done by AI at this point, but AI has also created some new jobs, and economists remain split on its effects. Unemployment has risen 1% over the past twelve months but is still well within its historic range.\",\"position\":{\"start\":{\"line\":863,\"column\":9,\"offset\":135105},\"end\":{\"line\":863,\"column\":265,\"offset\":135361}}}],\"position\":{\"start\":{\"line\":863,\"column\":9,\"offset\":135105},\"end\":{\"line\":863,\"column\":265,\"offset\":135361}}}]},{\"identifier\":\"96\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For example, the corporation-within-a-corporation that is Agent-4, autonomously conducting AI research better than the best human companies, would have seemed like science fiction to the government officials had it been described to them a year ago. And the autonomous agents of 2026 would have seemed like science fiction back in 2022, and the LLMs of 2022 would have seemed like science fiction back in 2012. Also, on the news in 2027 there are anti-AI protests by people worried about losing their jobs, AIs claiming to be sentient, people falling in love with AIs…\",\"position\":{\"start\":{\"line\":865,\"column\":9,\"offset\":135371},\"end\":{\"line\":865,\"column\":578,\"offset\":135940}}}],\"position\":{\"start\":{\"line\":865,\"column\":9,\"offset\":135371},\"end\":{\"line\":865,\"column\":578,\"offset\":135940}}}]},{\"identifier\":\"97\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Of course, it isn’t cool to admit fear. Everyone agrees that whatever we do, we shouldn’t panic.\",\"position\":{\"start\":{\"line\":867,\"column\":9,\"offset\":135950},\"end\":{\"line\":867,\"column\":105,\"offset\":136046}}}],\"position\":{\"start\":{\"line\":867,\"column\":9,\"offset\":135950},\"end\":{\"line\":867,\"column\":105,\"offset\":136046}}}]},{\"identifier\":\"98\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Recall, there had been an existing contract via an OTA starting in 2026. This contract is amended to establish the committee.\",\"position\":{\"start\":{\"line\":869,\"column\":9,\"offset\":136056},\"end\":{\"line\":869,\"column\":135,\"offset\":136182}}}],\"position\":{\"start\":{\"line\":869,\"column\":9,\"offset\":136056},\"end\":{\"line\":869,\"column\":135,\"offset\":136182}}}]},{\"identifier\":\"99\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Thanks to Tjaden Hess for pointing out errors in an earlier version of this and thereby helping us improve the realism.\",\"position\":{\"start\":{\"line\":871,\"column\":8,\"offset\":136191},\"end\":{\"line\":871,\"column\":127,\"offset\":136310}}}],\"position\":{\"start\":{\"line\":871,\"column\":8,\"offset\":136191},\"end\":{\"line\":871,\"column\":127,\"offset\":136310}}}]}],\"root\":{\"type\":\"root\",\"children\":[\"$a\",\"$19\",\"$22\",\"$37\",\"$5e\",\"$274\",{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Mid 2025: Stumbling Agents\",\"position\":{\"start\":{\"line\":62,\"column\":4,\"offset\":6093},\"end\":{\"line\":62,\"column\":30,\"offset\":6119}}}],\"position\":{\"start\":{\"line\":62,\"column\":1,\"offset\":6090},\"end\":{\"line\":62,\"column\":30,\"offset\":6119}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2025-08-31\",\"position\":{\"start\":{\"line\":65,\"column\":1,\"offset\":6137},\"end\":{\"line\":65,\"column\":11,\"offset\":6147}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":65,\"column\":11,\"offset\":6147},\"end\":{\"line\":66,\"column\":1,\"offset\":6150}}},{\"type\":\"text\",\"value\":\"Mid 2025\",\"position\":{\"start\":{\"line\":66,\"column\":1,\"offset\":6150},\"end\":{\"line\":66,\"column\":9,\"offset\":6158}}}],\"position\":{\"start\":{\"line\":65,\"column\":1,\"offset\":6137},\"end\":{\"line\":66,\"column\":11,\"offset\":6160}}}],\"position\":{\"start\":{\"line\":64,\"column\":1,\"offset\":6121},\"end\":{\"line\":67,\"column\":4,\"offset\":6164}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The world sees its first glimpse of AI agents.\",\"position\":{\"start\":{\"line\":69,\"column\":1,\"offset\":6166},\"end\":{\"line\":69,\"column\":47,\"offset\":6212}}}],\"position\":{\"start\":{\"line\":69,\"column\":1,\"offset\":6166},\"end\":{\"line\":69,\"column\":47,\"offset\":6212}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Advertisements for computer-using agents emphasize the term “personal assistant”: you can prompt them with tasks like “order me a burrito on DoorDash” or “open my budget spreadsheet and sum this month’s expenses.” They will check in with you as needed: for example, to ask you to confirm purchases.\",\"position\":{\"start\":{\"line\":71,\"column\":1,\"offset\":6214},\"end\":{\"line\":71,\"column\":299,\"offset\":6512}}},{\"type\":\"footnoteReference\",\"identifier\":\"8\",\"label\":\"8\",\"position\":{\"start\":{\"line\":71,\"column\":299,\"offset\":6512},\"end\":{\"line\":71,\"column\":303,\"offset\":6516}}},{\"type\":\"text\",\"value\":\" Though more advanced than previous iterations like \",\"position\":{\"start\":{\"line\":71,\"column\":303,\"offset\":6516},\"end\":{\"line\":71,\"column\":355,\"offset\":6568}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/introducing-operator/\",\"children\":[{\"type\":\"text\",\"value\":\"Operator\",\"position\":{\"start\":{\"line\":71,\"column\":356,\"offset\":6569},\"end\":{\"line\":71,\"column\":364,\"offset\":6577}}}],\"position\":{\"start\":{\"line\":71,\"column\":355,\"offset\":6568},\"end\":{\"line\":71,\"column\":413,\"offset\":6626}}},{\"type\":\"text\",\"value\":\", they struggle to get widespread usage.\",\"position\":{\"start\":{\"line\":71,\"column\":413,\"offset\":6626},\"end\":{\"line\":71,\"column\":453,\"offset\":6666}}},{\"type\":\"footnoteReference\",\"identifier\":\"9\",\"label\":\"9\",\"position\":{\"start\":{\"line\":71,\"column\":453,\"offset\":6666},\"end\":{\"line\":71,\"column\":457,\"offset\":6670}}}],\"position\":{\"start\":{\"line\":71,\"column\":1,\"offset\":6214},\"end\":{\"line\":71,\"column\":457,\"offset\":6670}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Meanwhile, out of public focus, more specialized coding and research agents are beginning to transform their professions.\",\"position\":{\"start\":{\"line\":73,\"column\":1,\"offset\":6672},\"end\":{\"line\":73,\"column\":122,\"offset\":6793}}}],\"position\":{\"start\":{\"line\":73,\"column\":1,\"offset\":6672},\"end\":{\"line\":73,\"column\":122,\"offset\":6793}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The AIs of 2024 could follow specific instructions: they could turn bullet points into emails, and simple requests into working code. In 2025, AIs function more like employees. Coding AIs increasingly look like autonomous agents rather than mere assistants: taking instructions via Slack or Teams and making substantial code changes on their own, sometimes saving hours or even days.\",\"position\":{\"start\":{\"line\":75,\"column\":1,\"offset\":6795},\"end\":{\"line\":75,\"column\":384,\"offset\":7178}}},{\"type\":\"footnoteReference\",\"identifier\":\"10\",\"label\":\"10\",\"position\":{\"start\":{\"line\":75,\"column\":384,\"offset\":7178},\"end\":{\"line\":75,\"column\":389,\"offset\":7183}}},{\"type\":\"text\",\"value\":\" Research agents spend half an hour scouring the Internet to answer your question.\",\"position\":{\"start\":{\"line\":75,\"column\":389,\"offset\":7183},\"end\":{\"line\":75,\"column\":471,\"offset\":7265}}}],\"position\":{\"start\":{\"line\":75,\"column\":1,\"offset\":6795},\"end\":{\"line\":75,\"column\":471,\"offset\":7265}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The agents are impressive in theory (and in cherry-picked examples), but in practice unreliable. AI twitter is full of stories about tasks bungled in some particularly hilarious way. The better agents are also expensive; you get what you pay for, and the best performance costs hundreds of dollars a month.\",\"position\":{\"start\":{\"line\":77,\"column\":1,\"offset\":7267},\"end\":{\"line\":77,\"column\":307,\"offset\":7573}}},{\"type\":\"footnoteReference\",\"identifier\":\"11\",\"label\":\"11\",\"position\":{\"start\":{\"line\":77,\"column\":307,\"offset\":7573},\"end\":{\"line\":77,\"column\":312,\"offset\":7578}}},{\"type\":\"text\",\"value\":\" Still, many companies find ways to fit AI agents into their workflows.\",\"position\":{\"start\":{\"line\":77,\"column\":312,\"offset\":7578},\"end\":{\"line\":77,\"column\":383,\"offset\":7649}}},{\"type\":\"footnoteReference\",\"identifier\":\"12\",\"label\":\"12\",\"position\":{\"start\":{\"line\":77,\"column\":383,\"offset\":7649},\"end\":{\"line\":77,\"column\":388,\"offset\":7654}}}],\"position\":{\"start\":{\"line\":77,\"column\":1,\"offset\":7267},\"end\":{\"line\":77,\"column\":388,\"offset\":7654}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Late 2025: The World’s Most Expensive AI\",\"position\":{\"start\":{\"line\":79,\"column\":4,\"offset\":7659},\"end\":{\"line\":79,\"column\":44,\"offset\":7699}}}],\"position\":{\"start\":{\"line\":79,\"column\":1,\"offset\":7656},\"end\":{\"line\":79,\"column\":45,\"offset\":7700}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2025-12-31\",\"position\":{\"start\":{\"line\":82,\"column\":1,\"offset\":7718},\"end\":{\"line\":82,\"column\":11,\"offset\":7728}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":82,\"column\":11,\"offset\":7728},\"end\":{\"line\":83,\"column\":1,\"offset\":7731}}},{\"type\":\"text\",\"value\":\"Late 2025\",\"position\":{\"start\":{\"line\":83,\"column\":1,\"offset\":7731},\"end\":{\"line\":83,\"column\":10,\"offset\":7740}}}],\"position\":{\"start\":{\"line\":82,\"column\":1,\"offset\":7718},\"end\":{\"line\":83,\"column\":12,\"offset\":7742}}}],\"position\":{\"start\":{\"line\":81,\"column\":1,\"offset\":7702},\"end\":{\"line\":84,\"column\":4,\"offset\":7746}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain is building the biggest datacenters the world has ever seen.\",\"position\":{\"start\":{\"line\":86,\"column\":1,\"offset\":7748},\"end\":{\"line\":86,\"column\":71,\"offset\":7818}}},{\"type\":\"footnoteReference\",\"identifier\":\"13\",\"label\":\"13\",\"position\":{\"start\":{\"line\":86,\"column\":71,\"offset\":7818},\"end\":{\"line\":86,\"column\":76,\"offset\":7823}}}],\"position\":{\"start\":{\"line\":86,\"column\":1,\"offset\":7748},\"end\":{\"line\":86,\"column\":76,\"offset\":7823}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"(To avoid singling out any one existing company, we’re going to describe a fictional \",\"position\":{\"start\":{\"line\":88,\"column\":1,\"offset\":7825},\"end\":{\"line\":88,\"column\":86,\"offset\":7910}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\",\"children\":[{\"type\":\"text\",\"value\":\"artificial general intelligence\",\"position\":{\"start\":{\"line\":88,\"column\":87,\"offset\":7911},\"end\":{\"line\":88,\"column\":118,\"offset\":7942}}}],\"position\":{\"start\":{\"line\":88,\"column\":86,\"offset\":7910},\"end\":{\"line\":88,\"column\":182,\"offset\":8006}}},{\"type\":\"text\",\"value\":\" company, which we’ll call OpenBrain. We imagine the others to be 3–9 months behind OpenBrain.)\",\"position\":{\"start\":{\"line\":88,\"column\":182,\"offset\":8006},\"end\":{\"line\":88,\"column\":277,\"offset\":8101}}}],\"position\":{\"start\":{\"line\":88,\"column\":1,\"offset\":7825},\"end\":{\"line\":88,\"column\":277,\"offset\":8101}}},{\"type\":\"containerDirective\",\"name\":\"gptScale\",\"attributes\":{},\"children\":[],\"position\":{\"start\":{\"line\":92,\"column\":1,\"offset\":8105},\"end\":{\"line\":93,\"column\":4,\"offset\":8122}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"GPT-4 required \",\"position\":{\"start\":{\"line\":95,\"column\":1,\"offset\":8124},\"end\":{\"line\":95,\"column\":16,\"offset\":8139}}},{\"type\":\"inlineMath\",\"value\":\"2\\\\\\\\cdot 10^{25}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"2\\\\\\\\cdot 10^{25}\"}]},\"position\":{\"start\":{\"line\":95,\"column\":16,\"offset\":8139},\"end\":{\"line\":95,\"column\":35,\"offset\":8158}}},{\"type\":\"text\",\"value\":\" \",\"position\":{\"start\":{\"line\":95,\"column\":35,\"offset\":8158},\"end\":{\"line\":95,\"column\":36,\"offset\":8159}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Floating_point_operations_per_second\",\"children\":[{\"type\":\"text\",\"value\":\"FLOP\",\"position\":{\"start\":{\"line\":95,\"column\":37,\"offset\":8160},\"end\":{\"line\":95,\"column\":41,\"offset\":8164}}}],\"position\":{\"start\":{\"line\":95,\"column\":36,\"offset\":8159},\"end\":{\"line\":95,\"column\":110,\"offset\":8233}}},{\"type\":\"text\",\"value\":\" of compute to train.\",\"position\":{\"start\":{\"line\":95,\"column\":110,\"offset\":8233},\"end\":{\"line\":95,\"column\":131,\"offset\":8254}}},{\"type\":\"footnoteReference\",\"identifier\":\"14\",\"label\":\"14\",\"position\":{\"start\":{\"line\":95,\"column\":131,\"offset\":8254},\"end\":{\"line\":95,\"column\":136,\"offset\":8259}}},{\"type\":\"text\",\"value\":\" OpenBrain’s latest public model—Agent-0—was trained with \",\"position\":{\"start\":{\"line\":95,\"column\":136,\"offset\":8259},\"end\":{\"line\":95,\"column\":194,\"offset\":8317}}},{\"type\":\"inlineMath\",\"value\":\"10^{27}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"10^{27}\"}]},\"position\":{\"start\":{\"line\":95,\"column\":194,\"offset\":8317},\"end\":{\"line\":95,\"column\":205,\"offset\":8328}}},{\"type\":\"text\",\"value\":\" FLOP. Once the new datacenters are up and running, \",\"position\":{\"start\":{\"line\":95,\"column\":205,\"offset\":8328},\"end\":{\"line\":95,\"column\":257,\"offset\":8380}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/compute-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"they’ll be able to train\",\"position\":{\"start\":{\"line\":95,\"column\":258,\"offset\":8381},\"end\":{\"line\":95,\"column\":282,\"offset\":8405}}}],\"position\":{\"start\":{\"line\":95,\"column\":257,\"offset\":8380},\"end\":{\"line\":95,\"column\":333,\"offset\":8456}}},{\"type\":\"text\",\"value\":\" a model with \",\"position\":{\"start\":{\"line\":95,\"column\":333,\"offset\":8456},\"end\":{\"line\":95,\"column\":347,\"offset\":8470}}},{\"type\":\"inlineMath\",\"value\":\"10^{28}\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"10^{28}\"}]},\"position\":{\"start\":{\"line\":95,\"column\":347,\"offset\":8470},\"end\":{\"line\":95,\"column\":358,\"offset\":8481}}},{\"type\":\"text\",\"value\":\" FLOP—a thousand times more than GPT-4.\",\"position\":{\"start\":{\"line\":95,\"column\":358,\"offset\":8481},\"end\":{\"line\":95,\"column\":397,\"offset\":8520}}},{\"type\":\"footnoteReference\",\"identifier\":\"15\",\"label\":\"15\",\"position\":{\"start\":{\"line\":95,\"column\":397,\"offset\":8520},\"end\":{\"line\":95,\"column\":402,\"offset\":8525}}},{\"type\":\"text\",\"value\":\" Other companies pour money into their own giant datacenters, hoping to keep pace.\",\"position\":{\"start\":{\"line\":95,\"column\":402,\"offset\":8525},\"end\":{\"line\":95,\"column\":484,\"offset\":8607}}}],\"position\":{\"start\":{\"line\":95,\"column\":1,\"offset\":8124},\"end\":{\"line\":95,\"column\":484,\"offset\":8607}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Although models are improving on a wide range of skills, one stands out: OpenBrain focuses on AIs that can speed up AI research. They want to win the twin arms races against China (whose leading company we’ll call “DeepCent”)\",\"position\":{\"start\":{\"line\":97,\"column\":1,\"offset\":8609},\"end\":{\"line\":97,\"column\":226,\"offset\":8834}}},{\"type\":\"footnoteReference\",\"identifier\":\"16\",\"label\":\"16\",\"position\":{\"start\":{\"line\":97,\"column\":226,\"offset\":8834},\"end\":{\"line\":97,\"column\":231,\"offset\":8839}}},{\"type\":\"text\",\"value\":\" and their U.S. competitors. The more of their research and development (R\u0026D) cycle they can automate, the faster they can go. So when OpenBrain finishes training Agent-1, a new model under internal development, it’s good at many things but \",\"position\":{\"start\":{\"line\":97,\"column\":231,\"offset\":8839},\"end\":{\"line\":97,\"column\":473,\"offset\":9081}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"great\",\"position\":{\"start\":{\"line\":97,\"column\":474,\"offset\":9082},\"end\":{\"line\":97,\"column\":479,\"offset\":9087}}}],\"position\":{\"start\":{\"line\":97,\"column\":473,\"offset\":9081},\"end\":{\"line\":97,\"column\":480,\"offset\":9088}}},{\"type\":\"text\",\"value\":\" at helping with AI research.\",\"position\":{\"start\":{\"line\":97,\"column\":480,\"offset\":9088},\"end\":{\"line\":97,\"column\":509,\"offset\":9117}}},{\"type\":\"footnoteReference\",\"identifier\":\"17\",\"label\":\"17\",\"position\":{\"start\":{\"line\":97,\"column\":509,\"offset\":9117},\"end\":{\"line\":97,\"column\":514,\"offset\":9122}}},{\"type\":\"text\",\"value\":\" By this point “finishes training” is a bit of a misnomer; models are frequently updated to newer versions trained on additional data or partially re-trained to patch some weaknesses.\",\"position\":{\"start\":{\"line\":97,\"column\":514,\"offset\":9122},\"end\":{\"line\":97,\"column\":697,\"offset\":9305}}},{\"type\":\"footnoteReference\",\"identifier\":\"18\",\"label\":\"18\",\"position\":{\"start\":{\"line\":97,\"column\":697,\"offset\":9305},\"end\":{\"line\":97,\"column\":702,\"offset\":9310}}}],\"position\":{\"start\":{\"line\":97,\"column\":1,\"offset\":8609},\"end\":{\"line\":97,\"column\":703,\"offset\":9311}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The same training environments that teach Agent-1 to autonomously code and web-browse also make it a good hacker. Moreover, it could offer \",\"position\":{\"start\":{\"line\":99,\"column\":1,\"offset\":9313},\"end\":{\"line\":99,\"column\":140,\"offset\":9452}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/lucafrighetti/status/1894550297449828434\",\"children\":[{\"type\":\"text\",\"value\":\"substantial help\",\"position\":{\"start\":{\"line\":99,\"column\":141,\"offset\":9453},\"end\":{\"line\":99,\"column\":157,\"offset\":9469}}}],\"position\":{\"start\":{\"line\":99,\"column\":140,\"offset\":9452},\"end\":{\"line\":99,\"column\":214,\"offset\":9526}}},{\"type\":\"text\",\"value\":\" to terrorists designing bioweapons, thanks to its PhD-level knowledge of every field and ability to browse the web. OpenBrain reassures the government that the model has been “aligned” so that it will refuse to comply with malicious requests.\",\"position\":{\"start\":{\"line\":99,\"column\":214,\"offset\":9526},\"end\":{\"line\":99,\"column\":457,\"offset\":9769}}}],\"position\":{\"start\":{\"line\":99,\"column\":1,\"offset\":9313},\"end\":{\"line\":99,\"column\":457,\"offset\":9769}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Modern AI systems are gigantic artificial neural networks. Early in training, an AI won’t have “goals” so much as “reflexes”: If it sees “Pleased to meet”, it outputs “ you”. By the time it has been trained to predict approximately one internet’s worth of text, it’ll have developed sophisticated internal circuitry that encodes vast amounts of knowledge and flexibly role-plays as arbitrary authors, since that’s what helps it predict text with \",\"position\":{\"start\":{\"line\":101,\"column\":1,\"offset\":9771},\"end\":{\"line\":101,\"column\":447,\"offset\":10217}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2212.11281\",\"children\":[{\"type\":\"text\",\"value\":\"superhuman\",\"position\":{\"start\":{\"line\":101,\"column\":448,\"offset\":10218},\"end\":{\"line\":101,\"column\":458,\"offset\":10228}}}],\"position\":{\"start\":{\"line\":101,\"column\":447,\"offset\":10217},\"end\":{\"line\":101,\"column\":493,\"offset\":10263}}},{\"type\":\"text\",\"value\":\" accuracy.\",\"position\":{\"start\":{\"line\":101,\"column\":493,\"offset\":10263},\"end\":{\"line\":101,\"column\":503,\"offset\":10273}}},{\"type\":\"footnoteReference\",\"identifier\":\"19\",\"label\":\"19\",\"position\":{\"start\":{\"line\":101,\"column\":503,\"offset\":10273},\"end\":{\"line\":101,\"column\":508,\"offset\":10278}}}],\"position\":{\"start\":{\"line\":101,\"column\":1,\"offset\":9771},\"end\":{\"line\":101,\"column\":508,\"offset\":10278}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"After being trained to predict internet text, the model is trained to \",\"position\":{\"start\":{\"line\":103,\"column\":1,\"offset\":10280},\"end\":{\"line\":103,\"column\":71,\"offset\":10350}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"produce\",\"position\":{\"start\":{\"line\":103,\"column\":72,\"offset\":10351},\"end\":{\"line\":103,\"column\":79,\"offset\":10358}}}],\"position\":{\"start\":{\"line\":103,\"column\":71,\"offset\":10350},\"end\":{\"line\":103,\"column\":80,\"offset\":10359}}},{\"type\":\"text\",\"value\":\" text in response to instructions. This bakes in a basic personality and “drives.”\",\"position\":{\"start\":{\"line\":103,\"column\":80,\"offset\":10359},\"end\":{\"line\":103,\"column\":162,\"offset\":10441}}},{\"type\":\"footnoteReference\",\"identifier\":\"20\",\"label\":\"20\",\"position\":{\"start\":{\"line\":103,\"column\":162,\"offset\":10441},\"end\":{\"line\":103,\"column\":167,\"offset\":10446}}},{\"type\":\"text\",\"value\":\" For example, an agent that understands a task clearly is more likely to complete it successfully; over the course of training the model “learns” a “drive” to get a clear understanding of its tasks. Other drives in this category might be effectiveness, knowledge, and self-presentation (i.e. the tendency to frame its results in the best possible light).\",\"position\":{\"start\":{\"line\":103,\"column\":167,\"offset\":10446},\"end\":{\"line\":103,\"column\":521,\"offset\":10800}}},{\"type\":\"footnoteReference\",\"identifier\":\"21\",\"label\":\"21\",\"position\":{\"start\":{\"line\":103,\"column\":521,\"offset\":10800},\"end\":{\"line\":103,\"column\":526,\"offset\":10805}}}],\"position\":{\"start\":{\"line\":103,\"column\":1,\"offset\":10280},\"end\":{\"line\":103,\"column\":526,\"offset\":10805}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain has \",\"position\":{\"start\":{\"line\":105,\"column\":1,\"offset\":10807},\"end\":{\"line\":105,\"column\":15,\"offset\":10821}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://model-spec.openai.com/2025-02-12.html\",\"children\":[{\"type\":\"text\",\"value\":\"a model specification\",\"position\":{\"start\":{\"line\":105,\"column\":16,\"offset\":10822},\"end\":{\"line\":105,\"column\":37,\"offset\":10843}}}],\"position\":{\"start\":{\"line\":105,\"column\":15,\"offset\":10821},\"end\":{\"line\":105,\"column\":85,\"offset\":10891}}},{\"type\":\"text\",\"value\":\" (or “Spec”), a written document describing the goals, rules, principles, etc. that are supposed to guide the model’s behavior.\",\"position\":{\"start\":{\"line\":105,\"column\":85,\"offset\":10891},\"end\":{\"line\":105,\"column\":212,\"offset\":11018}}},{\"type\":\"footnoteReference\",\"identifier\":\"22\",\"label\":\"22\",\"position\":{\"start\":{\"line\":105,\"column\":212,\"offset\":11018},\"end\":{\"line\":105,\"column\":217,\"offset\":11023}}},{\"type\":\"text\",\"value\":\" Agent-1’s Spec combines a few vague goals (like “assist the user” and “don’t break the law”) with a long list of more specific dos and don’ts (“don’t say this particular word,” “here’s how to handle this particular situation”). Using techniques that utilize AIs to train other AIs,\",\"position\":{\"start\":{\"line\":105,\"column\":217,\"offset\":11023},\"end\":{\"line\":105,\"column\":499,\"offset\":11305}}},{\"type\":\"footnoteReference\",\"identifier\":\"23\",\"label\":\"23\",\"position\":{\"start\":{\"line\":105,\"column\":499,\"offset\":11305},\"end\":{\"line\":105,\"column\":504,\"offset\":11310}}},{\"type\":\"text\",\"value\":\" the model memorizes the Spec and learns to reason carefully about its maxims. By the end of \",\"position\":{\"start\":{\"line\":105,\"column\":504,\"offset\":11310},\"end\":{\"line\":105,\"column\":597,\"offset\":11403}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"this\",\"position\":{\"start\":{\"line\":105,\"column\":598,\"offset\":11404},\"end\":{\"line\":105,\"column\":602,\"offset\":11408}}}],\"position\":{\"start\":{\"line\":105,\"column\":597,\"offset\":11403},\"end\":{\"line\":105,\"column\":603,\"offset\":11409}}},{\"type\":\"text\",\"value\":\" training, the AI will hopefully be \",\"position\":{\"start\":{\"line\":105,\"column\":603,\"offset\":11409},\"end\":{\"line\":105,\"column\":639,\"offset\":11445}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"helpful\",\"position\":{\"start\":{\"line\":105,\"column\":640,\"offset\":11446},\"end\":{\"line\":105,\"column\":647,\"offset\":11453}}}],\"position\":{\"start\":{\"line\":105,\"column\":639,\"offset\":11445},\"end\":{\"line\":105,\"column\":648,\"offset\":11454}}},{\"type\":\"text\",\"value\":\" (obey instructions), \",\"position\":{\"start\":{\"line\":105,\"column\":648,\"offset\":11454},\"end\":{\"line\":105,\"column\":670,\"offset\":11476}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"harmless\",\"position\":{\"start\":{\"line\":105,\"column\":671,\"offset\":11477},\"end\":{\"line\":105,\"column\":679,\"offset\":11485}}}],\"position\":{\"start\":{\"line\":105,\"column\":670,\"offset\":11476},\"end\":{\"line\":105,\"column\":680,\"offset\":11486}}},{\"type\":\"text\",\"value\":\" (refuse to help with scams, bomb-making, and other dangerous activities) and \",\"position\":{\"start\":{\"line\":105,\"column\":680,\"offset\":11486},\"end\":{\"line\":105,\"column\":758,\"offset\":11564}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"honest\",\"position\":{\"start\":{\"line\":105,\"column\":759,\"offset\":11565},\"end\":{\"line\":105,\"column\":765,\"offset\":11571}}}],\"position\":{\"start\":{\"line\":105,\"column\":758,\"offset\":11564},\"end\":{\"line\":105,\"column\":766,\"offset\":11572}}},{\"type\":\"text\",\"value\":\" (resist the temptation to get better ratings from gullible humans by hallucinating citations\",\"position\":{\"start\":{\"line\":105,\"column\":766,\"offset\":11572},\"end\":{\"line\":105,\"column\":859,\"offset\":11665}}},{\"type\":\"footnoteReference\",\"identifier\":\"24\",\"label\":\"24\",\"position\":{\"start\":{\"line\":105,\"column\":859,\"offset\":11665},\"end\":{\"line\":105,\"column\":864,\"offset\":11670}}},{\"type\":\"text\",\"value\":\" or faking task completion).\",\"position\":{\"start\":{\"line\":105,\"column\":864,\"offset\":11670},\"end\":{\"line\":105,\"column\":892,\"offset\":11698}}}],\"position\":{\"start\":{\"line\":105,\"column\":1,\"offset\":10807},\"end\":{\"line\":105,\"column\":892,\"offset\":11698}}},{\"type\":\"details\",\"summary\":\"Training process and LLM psychology: why we keep saying “hopefully”\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"“Unlike ordinary software, our models are massive neural networks. Their behaviors are learned from a broad range of data, not programmed explicitly. Though not a perfect analogy, the process is more similar to training a dog than to ordinary programming.”\",\"position\":{\"start\":{\"line\":111,\"column\":2,\"offset\":11782},\"end\":{\"line\":111,\"column\":258,\"offset\":12038}}}],\"position\":{\"start\":{\"line\":111,\"column\":1,\"offset\":11781},\"end\":{\"line\":111,\"column\":259,\"offset\":12039}}},{\"type\":\"text\",\"value\":\" —\",\"position\":{\"start\":{\"line\":111,\"column\":259,\"offset\":12039},\"end\":{\"line\":111,\"column\":261,\"offset\":12041}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/how-should-ai-systems-behave/\",\"children\":[{\"type\":\"text\",\"value\":\"OpenAI\",\"position\":{\"start\":{\"line\":111,\"column\":262,\"offset\":12042},\"end\":{\"line\":111,\"column\":268,\"offset\":12048}}}],\"position\":{\"start\":{\"line\":111,\"column\":261,\"offset\":12041},\"end\":{\"line\":111,\"column\":325,\"offset\":12105}}}],\"position\":{\"start\":{\"line\":111,\"column\":1,\"offset\":11781},\"end\":{\"line\":111,\"column\":325,\"offset\":12105}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"When we want to understand why a modern AI system did something, or how it would behave in some future scenario we can’t perfectly simulate, we can’t simply ask the programmers to talk us through various lines of code and explain how they work. Instead, we are forced to do something like psychology on them: we look at their behavior in the range of cases observed so far, and theorize about what internal cognitive structures (beliefs? goals? personality traits? etc.) might exist, and use those theories to predict behavior in future scenarios.\",\"position\":{\"start\":{\"line\":113,\"column\":1,\"offset\":12107},\"end\":{\"line\":113,\"column\":548,\"offset\":12654}}}],\"position\":{\"start\":{\"line\":113,\"column\":1,\"offset\":12107},\"end\":{\"line\":113,\"column\":549,\"offset\":12655}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The bottom line is that a company can write up a document (the Spec) listing dos and don’ts, goals and principles, and then they can try to train the AI to internalize the Spec—\",\"position\":{\"start\":{\"line\":115,\"column\":1,\"offset\":12657},\"end\":{\"line\":115,\"column\":178,\"offset\":12834}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"but they can’t check to see whether or not it worked\",\"position\":{\"start\":{\"line\":115,\"column\":179,\"offset\":12835},\"end\":{\"line\":115,\"column\":231,\"offset\":12887}}}],\"position\":{\"start\":{\"line\":115,\"column\":178,\"offset\":12834},\"end\":{\"line\":115,\"column\":232,\"offset\":12888}}},{\"type\":\"text\",\"value\":\". They can say “as best as we can judge, it seems to be following the Spec so far.”\",\"position\":{\"start\":{\"line\":115,\"column\":232,\"offset\":12888},\"end\":{\"line\":115,\"column\":315,\"offset\":12971}}},{\"type\":\"footnoteReference\",\"identifier\":\"25\",\"label\":\"25\",\"position\":{\"start\":{\"line\":115,\"column\":315,\"offset\":12971},\"end\":{\"line\":115,\"column\":320,\"offset\":12976}}}],\"position\":{\"start\":{\"line\":115,\"column\":1,\"offset\":12657},\"end\":{\"line\":115,\"column\":320,\"offset\":12976}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A later expandable will go into more detail about what we think \",\"position\":{\"start\":{\"line\":117,\"column\":1,\"offset\":12978},\"end\":{\"line\":117,\"column\":65,\"offset\":13042}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"might\",\"position\":{\"start\":{\"line\":117,\"column\":66,\"offset\":13043},\"end\":{\"line\":117,\"column\":71,\"offset\":13048}}}],\"position\":{\"start\":{\"line\":117,\"column\":65,\"offset\":13042},\"end\":{\"line\":117,\"column\":72,\"offset\":13049}}},{\"type\":\"text\",\"value\":\" be going on inside these AIs, internally. See also our \",\"position\":{\"start\":{\"line\":117,\"column\":72,\"offset\":13049},\"end\":{\"line\":117,\"column\":128,\"offset\":13105}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/ai-goals-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"AI goals forecasting supplement\",\"position\":{\"start\":{\"line\":117,\"column\":129,\"offset\":13106},\"end\":{\"line\":117,\"column\":160,\"offset\":13137}}}],\"position\":{\"start\":{\"line\":117,\"column\":128,\"offset\":13105},\"end\":{\"line\":117,\"column\":212,\"offset\":13189}}},{\"type\":\"text\",\"value\":\" which goes into more detail on which goals AIs might have and why. This is one of many things that we are uncertain about and which deserves further research.\",\"position\":{\"start\":{\"line\":117,\"column\":212,\"offset\":13189},\"end\":{\"line\":117,\"column\":371,\"offset\":13348}}}],\"position\":{\"start\":{\"line\":117,\"column\":1,\"offset\":12978},\"end\":{\"line\":117,\"column\":371,\"offset\":13348}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain’s alignment team\",\"position\":{\"start\":{\"line\":121,\"column\":1,\"offset\":13355},\"end\":{\"line\":121,\"column\":27,\"offset\":13381}}},{\"type\":\"footnoteReference\",\"identifier\":\"26\",\"label\":\"26\",\"position\":{\"start\":{\"line\":121,\"column\":27,\"offset\":13381},\"end\":{\"line\":121,\"column\":32,\"offset\":13386}}},{\"type\":\"text\",\"value\":\" is careful enough to wonder whether these victories are deep or shallow. Does the fully-trained model have some kind of robust commitment to always being honest? Or will this fall apart in some future situation, e.g. because it’s learned honesty as an \",\"position\":{\"start\":{\"line\":121,\"column\":32,\"offset\":13386},\"end\":{\"line\":121,\"column\":285,\"offset\":13639}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Instrumental_and_intrinsic_value\",\"children\":[{\"type\":\"text\",\"value\":\"instrumental\",\"position\":{\"start\":{\"line\":121,\"column\":286,\"offset\":13640},\"end\":{\"line\":121,\"column\":298,\"offset\":13652}}}],\"position\":{\"start\":{\"line\":121,\"column\":285,\"offset\":13639},\"end\":{\"line\":121,\"column\":363,\"offset\":13717}}},{\"type\":\"text\",\"value\":\" goal instead of a terminal goal? Or has it just learned to be honest about the sorts of things the evaluation process can check? Could it be lying to itself sometimes, as humans do? A conclusive answer to these questions would require mechanistic interpretability—essentially the ability to look at an AI’s internals and read its mind. Alas, interpretability techniques are not yet advanced enough for this.\",\"position\":{\"start\":{\"line\":121,\"column\":363,\"offset\":13717},\"end\":{\"line\":121,\"column\":771,\"offset\":14125}}}],\"position\":{\"start\":{\"line\":121,\"column\":1,\"offset\":13355},\"end\":{\"line\":121,\"column\":771,\"offset\":14125}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Instead, researchers try to identify cases where the models seem to deviate from the Spec. Agent-1 is often sycophantic (i.e. it tells researchers what they want to hear instead of trying to tell them the truth). In a \",\"position\":{\"start\":{\"line\":123,\"column\":1,\"offset\":14127},\"end\":{\"line\":123,\"column\":219,\"offset\":14345}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.apolloresearch.ai/research/scheming-reasoning-evaluations\",\"children\":[{\"type\":\"text\",\"value\":\"few rigged demos\",\"position\":{\"start\":{\"line\":123,\"column\":220,\"offset\":14346},\"end\":{\"line\":123,\"column\":236,\"offset\":14362}}}],\"position\":{\"start\":{\"line\":123,\"column\":219,\"offset\":14345},\"end\":{\"line\":123,\"column\":308,\"offset\":14434}}},{\"type\":\"text\",\"value\":\", it even lies in more serious ways, like hiding evidence that it failed on a task, in order to get better ratings. However, in real deployment settings, there are no longer any incidents so extreme as in 2023–2024 (e.g. \",\"position\":{\"start\":{\"line\":123,\"column\":308,\"offset\":14434},\"end\":{\"line\":123,\"column\":529,\"offset\":14655}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://thehill.com/policy/technology/4998868-google-ai-gemini-response/\",\"children\":[{\"type\":\"text\",\"value\":\"Gemini telling a user to die\",\"position\":{\"start\":{\"line\":123,\"column\":530,\"offset\":14656},\"end\":{\"line\":123,\"column\":558,\"offset\":14684}}}],\"position\":{\"start\":{\"line\":123,\"column\":529,\"offset\":14655},\"end\":{\"line\":123,\"column\":633,\"offset\":14759}}},{\"type\":\"text\",\"value\":\" and \",\"position\":{\"start\":{\"line\":123,\"column\":633,\"offset\":14759},\"end\":{\"line\":123,\"column\":638,\"offset\":14764}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned\",\"children\":[{\"type\":\"text\",\"value\":\"Bing Sydney being Bing Sydney\",\"position\":{\"start\":{\"line\":123,\"column\":639,\"offset\":14765},\"end\":{\"line\":123,\"column\":668,\"offset\":14794}}}],\"position\":{\"start\":{\"line\":123,\"column\":638,\"offset\":14764},\"end\":{\"line\":123,\"column\":767,\"offset\":14893}}},{\"type\":\"text\",\"value\":\".)\",\"position\":{\"start\":{\"line\":123,\"column\":767,\"offset\":14893},\"end\":{\"line\":123,\"column\":769,\"offset\":14895}}},{\"type\":\"footnoteReference\",\"identifier\":\"27\",\"label\":\"27\",\"position\":{\"start\":{\"line\":123,\"column\":769,\"offset\":14895},\"end\":{\"line\":123,\"column\":774,\"offset\":14900}}}],\"position\":{\"start\":{\"line\":123,\"column\":1,\"offset\":14127},\"end\":{\"line\":123,\"column\":774,\"offset\":14900}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Early 2026: Coding Automation\",\"position\":{\"start\":{\"line\":125,\"column\":4,\"offset\":14905},\"end\":{\"line\":125,\"column\":33,\"offset\":14934}}}],\"position\":{\"start\":{\"line\":125,\"column\":1,\"offset\":14902},\"end\":{\"line\":125,\"column\":33,\"offset\":14934}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2026-04-30\",\"position\":{\"start\":{\"line\":128,\"column\":1,\"offset\":14952},\"end\":{\"line\":128,\"column\":11,\"offset\":14962}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":128,\"column\":11,\"offset\":14962},\"end\":{\"line\":129,\"column\":1,\"offset\":14965}}},{\"type\":\"text\",\"value\":\"2026\",\"position\":{\"start\":{\"line\":129,\"column\":1,\"offset\":14965},\"end\":{\"line\":129,\"column\":5,\"offset\":14969}}}],\"position\":{\"start\":{\"line\":128,\"column\":1,\"offset\":14952},\"end\":{\"line\":129,\"column\":7,\"offset\":14971}}}],\"position\":{\"start\":{\"line\":127,\"column\":1,\"offset\":14936},\"end\":{\"line\":130,\"column\":4,\"offset\":14975}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The bet of using AI to speed up AI research is starting to pay off.\",\"position\":{\"start\":{\"line\":132,\"column\":1,\"offset\":14977},\"end\":{\"line\":132,\"column\":68,\"offset\":15044}}}],\"position\":{\"start\":{\"line\":132,\"column\":1,\"offset\":14977},\"end\":{\"line\":132,\"column\":68,\"offset\":15044}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain continues to deploy the iteratively improving Agent-1 internally for AI R\u0026D. Overall, they are making algorithmic progress 50% faster than they would without AI assistants—and more importantly, faster than their competitors.\",\"position\":{\"start\":{\"line\":134,\"column\":1,\"offset\":15046},\"end\":{\"line\":134,\"column\":236,\"offset\":15281}}}],\"position\":{\"start\":{\"line\":134,\"column\":1,\"offset\":15046},\"end\":{\"line\":134,\"column\":236,\"offset\":15281}}},{\"type\":\"details\",\"summary\":\"The AI R\u0026D progress multiplier: what do we mean by 50% faster algorithmic progress?\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We mean that OpenBrain makes as much AI research progress in 1 week with AI as they would in 1.5 weeks without AI usage.\",\"position\":{\"start\":{\"line\":140,\"column\":1,\"offset\":15381},\"end\":{\"line\":140,\"column\":121,\"offset\":15501}}}],\"position\":{\"start\":{\"line\":140,\"column\":1,\"offset\":15381},\"end\":{\"line\":140,\"column\":121,\"offset\":15501}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"AI progress can be broken down into 2 components:\",\"position\":{\"start\":{\"line\":142,\"column\":1,\"offset\":15503},\"end\":{\"line\":142,\"column\":50,\"offset\":15552}}}],\"position\":{\"start\":{\"line\":142,\"column\":1,\"offset\":15503},\"end\":{\"line\":142,\"column\":50,\"offset\":15552}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Increasing compute\",\"position\":{\"start\":{\"line\":144,\"column\":6,\"offset\":15559},\"end\":{\"line\":144,\"column\":24,\"offset\":15577}}}],\"position\":{\"start\":{\"line\":144,\"column\":4,\"offset\":15557},\"end\":{\"line\":144,\"column\":26,\"offset\":15579}}},{\"type\":\"text\",\"value\":\": More computational power is used to train or run an AI. This produces more powerful AIs, but they cost more.\",\"position\":{\"start\":{\"line\":144,\"column\":26,\"offset\":15579},\"end\":{\"line\":144,\"column\":136,\"offset\":15689}}}],\"position\":{\"start\":{\"line\":144,\"column\":4,\"offset\":15557},\"end\":{\"line\":144,\"column\":138,\"offset\":15691}}}],\"position\":{\"start\":{\"line\":144,\"column\":1,\"offset\":15554},\"end\":{\"line\":144,\"column\":138,\"offset\":15691}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Improved algorithms\",\"position\":{\"start\":{\"line\":145,\"column\":6,\"offset\":15697},\"end\":{\"line\":145,\"column\":25,\"offset\":15716}}}],\"position\":{\"start\":{\"line\":145,\"column\":4,\"offset\":15695},\"end\":{\"line\":145,\"column\":27,\"offset\":15718}}},{\"type\":\"text\",\"value\":\": Better training methods are used to translate compute into performance. This produces more capable AIs without a corresponding increase in cost, or the same capabilities with decreased costs.\",\"position\":{\"start\":{\"line\":145,\"column\":27,\"offset\":15718},\"end\":{\"line\":145,\"column\":220,\"offset\":15911}}}],\"position\":{\"start\":{\"line\":145,\"column\":4,\"offset\":15695},\"end\":{\"line\":145,\"column\":222,\"offset\":15913}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This includes being able to achieve qualitatively and quantitatively new results. “Paradigm shifts” such as the switch from game-playing RL agents to large language models count as examples of algorithmic progress.\",\"position\":{\"start\":{\"line\":146,\"column\":6,\"offset\":15919},\"end\":{\"line\":146,\"column\":220,\"offset\":16133}}}],\"position\":{\"start\":{\"line\":146,\"column\":6,\"offset\":15919},\"end\":{\"line\":146,\"column\":220,\"offset\":16133}}}],\"position\":{\"start\":{\"line\":146,\"column\":4,\"offset\":15917},\"end\":{\"line\":146,\"column\":220,\"offset\":16133}}}],\"position\":{\"start\":{\"line\":146,\"column\":4,\"offset\":15917},\"end\":{\"line\":146,\"column\":220,\"offset\":16133}}}],\"position\":{\"start\":{\"line\":145,\"column\":1,\"offset\":15692},\"end\":{\"line\":146,\"column\":220,\"offset\":16133}}}],\"position\":{\"start\":{\"line\":144,\"column\":1,\"offset\":15554},\"end\":{\"line\":146,\"column\":220,\"offset\":16133}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Here we are only referring to (2), improved algorithms, which \",\"position\":{\"start\":{\"line\":148,\"column\":1,\"offset\":16135},\"end\":{\"line\":148,\"column\":63,\"offset\":16197}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/ATSyAdBnxxDDAwhgu/recent-and-forecasted-rates-of-software-and-hardware\",\"children\":[{\"type\":\"text\",\"value\":\"makes up about half of current AI progress\",\"position\":{\"start\":{\"line\":148,\"column\":64,\"offset\":16198},\"end\":{\"line\":148,\"column\":106,\"offset\":16240}}}],\"position\":{\"start\":{\"line\":148,\"column\":63,\"offset\":16197},\"end\":{\"line\":148,\"column\":211,\"offset\":16345}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":148,\"column\":211,\"offset\":16345},\"end\":{\"line\":148,\"column\":212,\"offset\":16346}}}],\"position\":{\"start\":{\"line\":148,\"column\":1,\"offset\":16135},\"end\":{\"line\":148,\"column\":212,\"offset\":16346}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Going forward, we sometimes abbreviate this as an “AI R\u0026D progress multiplier” of 1.5.\",\"position\":{\"start\":{\"line\":150,\"column\":1,\"offset\":16348},\"end\":{\"line\":150,\"column\":88,\"offset\":16435}}}],\"position\":{\"start\":{\"line\":150,\"column\":1,\"offset\":16348},\"end\":{\"line\":150,\"column\":88,\"offset\":16435}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Clarifications:\",\"position\":{\"start\":{\"line\":152,\"column\":1,\"offset\":16437},\"end\":{\"line\":152,\"column\":16,\"offset\":16452}}}],\"position\":{\"start\":{\"line\":152,\"column\":1,\"offset\":16437},\"end\":{\"line\":152,\"column\":16,\"offset\":16452}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The progress multiplier is all-inclusive: It includes the time it takes to run experiments, for example, rather than only the cognitive tasks involved in algorithmic research.\",\"position\":{\"start\":{\"line\":154,\"column\":4,\"offset\":16457},\"end\":{\"line\":154,\"column\":179,\"offset\":16632}}}],\"position\":{\"start\":{\"line\":154,\"column\":4,\"offset\":16457},\"end\":{\"line\":154,\"column\":181,\"offset\":16634}}}],\"position\":{\"start\":{\"line\":154,\"column\":1,\"offset\":16454},\"end\":{\"line\":154,\"column\":181,\"offset\":16634}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It’s important to remember that the progress multiplier is the \",\"position\":{\"start\":{\"line\":155,\"column\":4,\"offset\":16638},\"end\":{\"line\":155,\"column\":67,\"offset\":16701}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"relative\",\"position\":{\"start\":{\"line\":155,\"column\":68,\"offset\":16702},\"end\":{\"line\":155,\"column\":76,\"offset\":16710}}}],\"position\":{\"start\":{\"line\":155,\"column\":67,\"offset\":16701},\"end\":{\"line\":155,\"column\":77,\"offset\":16711}}},{\"type\":\"text\",\"value\":\" speed of progress, not the \",\"position\":{\"start\":{\"line\":155,\"column\":77,\"offset\":16711},\"end\":{\"line\":155,\"column\":105,\"offset\":16739}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"absolute\",\"position\":{\"start\":{\"line\":155,\"column\":106,\"offset\":16740},\"end\":{\"line\":155,\"column\":114,\"offset\":16748}}}],\"position\":{\"start\":{\"line\":155,\"column\":105,\"offset\":16739},\"end\":{\"line\":155,\"column\":115,\"offset\":16749}}},{\"type\":\"text\",\"value\":\" speed of progress. If, for example, the compute cost to train a GPT-4 class model has halved every year for several years with ordinary human research, and then all of a sudden AI automates R\u0026D and the progress multiplier goes to 100x, the cost to train a GPT-4 class model would then halve every 3.65 days—but not for long, because diminishing returns would bite and eventual hard limits would be reached. In this example perhaps the cost to train a GPT-4 class model would cut in half 5–10 times total (over the span of a few weeks or months) before plateauing. In other words, if ordinary human science would have run up against diminishing returns and physical limits after 5 -10 years of further research, then AIs with a 100x multiplier would run up against those same diminishing returns and limits after 18.25–36.5 days of research.\",\"position\":{\"start\":{\"line\":155,\"column\":115,\"offset\":16749},\"end\":{\"line\":155,\"column\":958,\"offset\":17592}}}],\"position\":{\"start\":{\"line\":155,\"column\":4,\"offset\":16638},\"end\":{\"line\":155,\"column\":958,\"offset\":17592}}}],\"position\":{\"start\":{\"line\":155,\"column\":1,\"offset\":16635},\"end\":{\"line\":155,\"column\":958,\"offset\":17592}}}],\"position\":{\"start\":{\"line\":154,\"column\":1,\"offset\":16454},\"end\":{\"line\":155,\"column\":958,\"offset\":17592}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"More explanation and discussion of this concept and how it is used in our forecast can be found in our \",\"position\":{\"start\":{\"line\":157,\"column\":1,\"offset\":17594},\"end\":{\"line\":157,\"column\":104,\"offset\":17697}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/takeoff-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":{\"start\":{\"line\":157,\"column\":105,\"offset\":17698},\"end\":{\"line\":157,\"column\":123,\"offset\":17716}}}],\"position\":{\"start\":{\"line\":157,\"column\":104,\"offset\":17697},\"end\":{\"line\":157,\"column\":174,\"offset\":17767}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":157,\"column\":174,\"offset\":17767},\"end\":{\"line\":157,\"column\":175,\"offset\":17768}}}],\"position\":{\"start\":{\"line\":157,\"column\":1,\"offset\":17594},\"end\":{\"line\":157,\"column\":175,\"offset\":17768}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Several competing publicly released AIs now match or exceed Agent-0, including an \",\"position\":{\"start\":{\"line\":161,\"column\":1,\"offset\":17775},\"end\":{\"line\":161,\"column\":83,\"offset\":17857}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://opensource.org/ai/open-weights\",\"children\":[{\"type\":\"text\",\"value\":\"open-weights\",\"position\":{\"start\":{\"line\":161,\"column\":84,\"offset\":17858},\"end\":{\"line\":161,\"column\":96,\"offset\":17870}}}],\"position\":{\"start\":{\"line\":161,\"column\":83,\"offset\":17857},\"end\":{\"line\":161,\"column\":137,\"offset\":17911}}},{\"type\":\"text\",\"value\":\" model. OpenBrain responds by releasing Agent-1, which is more capable and reliable.\",\"position\":{\"start\":{\"line\":161,\"column\":137,\"offset\":17911},\"end\":{\"line\":161,\"column\":221,\"offset\":17995}}},{\"type\":\"footnoteReference\",\"identifier\":\"28\",\"label\":\"28\",\"position\":{\"start\":{\"line\":161,\"column\":221,\"offset\":17995},\"end\":{\"line\":161,\"column\":226,\"offset\":18000}}}],\"position\":{\"start\":{\"line\":161,\"column\":1,\"offset\":17775},\"end\":{\"line\":161,\"column\":226,\"offset\":18000}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"People naturally try to compare Agent-1 to humans, but it has a very different skill profile. It knows more facts than any human, knows practically every programming language, and can solve well-specified coding problems extremely quickly. On the other hand, Agent-1 is bad at even simple long-horizon tasks, like beating video games it hasn’t played before. Still, the common workday is eight hours, and a day’s work can usually be separated into smaller chunks; you could think of Agent-1 as a scatterbrained employee who thrives under careful management.\",\"position\":{\"start\":{\"line\":163,\"column\":1,\"offset\":18002},\"end\":{\"line\":163,\"column\":558,\"offset\":18559}}},{\"type\":\"footnoteReference\",\"identifier\":\"29\",\"label\":\"29\",\"position\":{\"start\":{\"line\":163,\"column\":558,\"offset\":18559},\"end\":{\"line\":163,\"column\":563,\"offset\":18564}}},{\"type\":\"text\",\"value\":\" Savvy people find ways to automate routine parts of their jobs.\",\"position\":{\"start\":{\"line\":163,\"column\":563,\"offset\":18564},\"end\":{\"line\":163,\"column\":627,\"offset\":18628}}},{\"type\":\"footnoteReference\",\"identifier\":\"30\",\"label\":\"30\",\"position\":{\"start\":{\"line\":163,\"column\":627,\"offset\":18628},\"end\":{\"line\":163,\"column\":632,\"offset\":18633}}}],\"position\":{\"start\":{\"line\":163,\"column\":1,\"offset\":18002},\"end\":{\"line\":163,\"column\":632,\"offset\":18633}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain’s executives turn consideration to an implication of automating AI R\u0026D: security has become more important. In early 2025, the worst-case scenario was leaked algorithmic secrets; now, if China steals Agent-1’s weights, they could increase their research speed by nearly 50%.\",\"position\":{\"start\":{\"line\":165,\"column\":1,\"offset\":18635},\"end\":{\"line\":165,\"column\":286,\"offset\":18920}}},{\"type\":\"footnoteReference\",\"identifier\":\"31\",\"label\":\"31\",\"position\":{\"start\":{\"line\":165,\"column\":286,\"offset\":18920},\"end\":{\"line\":165,\"column\":291,\"offset\":18925}}},{\"type\":\"text\",\"value\":\" OpenBrain’s security level is typical of a fast-growing ~3,000 person tech company, secure only against low-priority attacks from capable cyber groups (\",\"position\":{\"start\":{\"line\":165,\"column\":291,\"offset\":18925},\"end\":{\"line\":165,\"column\":445,\"offset\":19079}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":[{\"type\":\"text\",\"value\":\"RAND’s SL2\",\"position\":{\"start\":{\"line\":165,\"column\":446,\"offset\":19080},\"end\":{\"line\":165,\"column\":456,\"offset\":19090}}}],\"position\":{\"start\":{\"line\":165,\"column\":445,\"offset\":19079},\"end\":{\"line\":165,\"column\":594,\"offset\":19228}}},{\"type\":\"text\",\"value\":\").\",\"position\":{\"start\":{\"line\":165,\"column\":594,\"offset\":19228},\"end\":{\"line\":165,\"column\":596,\"offset\":19230}}},{\"type\":\"footnoteReference\",\"identifier\":\"32\",\"label\":\"32\",\"position\":{\"start\":{\"line\":165,\"column\":596,\"offset\":19230},\"end\":{\"line\":165,\"column\":601,\"offset\":19235}}},{\"type\":\"text\",\"value\":\" They are working hard to protect their \",\"position\":{\"start\":{\"line\":165,\"column\":601,\"offset\":19235},\"end\":{\"line\":165,\"column\":641,\"offset\":19275}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://tedai-sanfrancisco.ted.com/glossary/weights/\",\"children\":[{\"type\":\"text\",\"value\":\"weights\",\"position\":{\"start\":{\"line\":165,\"column\":642,\"offset\":19276},\"end\":{\"line\":165,\"column\":649,\"offset\":19283}}}],\"position\":{\"start\":{\"line\":165,\"column\":641,\"offset\":19275},\"end\":{\"line\":165,\"column\":704,\"offset\":19338}}},{\"type\":\"text\",\"value\":\" and secrets from insider threats and top cybercrime syndicates (\",\"position\":{\"start\":{\"line\":165,\"column\":704,\"offset\":19338},\"end\":{\"line\":165,\"column\":769,\"offset\":19403}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":[{\"type\":\"text\",\"value\":\"SL3\",\"position\":{\"start\":{\"line\":165,\"column\":770,\"offset\":19404},\"end\":{\"line\":165,\"column\":773,\"offset\":19407}}}],\"position\":{\"start\":{\"line\":165,\"column\":769,\"offset\":19403},\"end\":{\"line\":165,\"column\":911,\"offset\":19545}}},{\"type\":\"text\",\"value\":\"),\",\"position\":{\"start\":{\"line\":165,\"column\":911,\"offset\":19545},\"end\":{\"line\":165,\"column\":913,\"offset\":19547}}},{\"type\":\"footnoteReference\",\"identifier\":\"33\",\"label\":\"33\",\"position\":{\"start\":{\"line\":165,\"column\":913,\"offset\":19547},\"end\":{\"line\":165,\"column\":918,\"offset\":19552}}},{\"type\":\"text\",\"value\":\" but defense against nation states (\",\"position\":{\"start\":{\"line\":165,\"column\":918,\"offset\":19552},\"end\":{\"line\":165,\"column\":954,\"offset\":19588}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":[{\"type\":\"text\",\"value\":\"SL4\u00265\",\"position\":{\"start\":{\"line\":165,\"column\":955,\"offset\":19589},\"end\":{\"line\":165,\"column\":960,\"offset\":19594}}}],\"position\":{\"start\":{\"line\":165,\"column\":954,\"offset\":19588},\"end\":{\"line\":165,\"column\":1098,\"offset\":19732}}},{\"type\":\"text\",\"value\":\") is barely on the horizon.\",\"position\":{\"start\":{\"line\":165,\"column\":1098,\"offset\":19732},\"end\":{\"line\":165,\"column\":1125,\"offset\":19759}}}],\"position\":{\"start\":{\"line\":165,\"column\":1,\"offset\":18635},\"end\":{\"line\":165,\"column\":1125,\"offset\":19759}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Mid 2026: China Wakes Up\",\"position\":{\"start\":{\"line\":167,\"column\":4,\"offset\":19764},\"end\":{\"line\":167,\"column\":28,\"offset\":19788}}}],\"position\":{\"start\":{\"line\":167,\"column\":1,\"offset\":19761},\"end\":{\"line\":167,\"column\":28,\"offset\":19788}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2026-08-31\",\"position\":{\"start\":{\"line\":170,\"column\":1,\"offset\":19806},\"end\":{\"line\":170,\"column\":11,\"offset\":19816}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":170,\"column\":11,\"offset\":19816},\"end\":{\"line\":171,\"column\":1,\"offset\":19819}}},{\"type\":\"text\",\"value\":\"Mid 2026\",\"position\":{\"start\":{\"line\":171,\"column\":1,\"offset\":19819},\"end\":{\"line\":171,\"column\":9,\"offset\":19827}}}],\"position\":{\"start\":{\"line\":170,\"column\":1,\"offset\":19806},\"end\":{\"line\":171,\"column\":11,\"offset\":19829}}}],\"position\":{\"start\":{\"line\":169,\"column\":1,\"offset\":19790},\"end\":{\"line\":172,\"column\":4,\"offset\":19833}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In China, the CCP is starting to \",\"position\":{\"start\":{\"line\":174,\"column\":1,\"offset\":19835},\"end\":{\"line\":174,\"column\":34,\"offset\":19868}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims\",\"children\":[{\"type\":\"text\",\"value\":\"feel the AGI\",\"position\":{\"start\":{\"line\":174,\"column\":35,\"offset\":19869},\"end\":{\"line\":174,\"column\":47,\"offset\":19881}}}],\"position\":{\"start\":{\"line\":174,\"column\":34,\"offset\":19868},\"end\":{\"line\":174,\"column\":154,\"offset\":19988}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":174,\"column\":154,\"offset\":19988},\"end\":{\"line\":174,\"column\":155,\"offset\":19989}}}],\"position\":{\"start\":{\"line\":174,\"column\":1,\"offset\":19835},\"end\":{\"line\":174,\"column\":155,\"offset\":19989}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Chip export controls and lack of government support have left China under-resourced compared to the West. By smuggling banned Taiwanese chips, buying older chips, and producing domestic chips about three years behind the U.S.-Taiwanese frontier, China has managed to maintain about 12% of the world’s AI-relevant compute—but the older technology is harder to work with, and supply is a constant headache.\",\"position\":{\"start\":{\"line\":176,\"column\":1,\"offset\":19991},\"end\":{\"line\":176,\"column\":405,\"offset\":20395}}},{\"type\":\"footnoteReference\",\"identifier\":\"35\",\"label\":\"35\",\"position\":{\"start\":{\"line\":176,\"column\":405,\"offset\":20395},\"end\":{\"line\":176,\"column\":410,\"offset\":20400}}},{\"type\":\"text\",\"value\":\" A few standouts like DeepCent do very impressive work with limited compute, but the compute deficit limits what they can achieve without government support, and they are about six months behind the best OpenBrain models.\",\"position\":{\"start\":{\"line\":176,\"column\":410,\"offset\":20400},\"end\":{\"line\":176,\"column\":631,\"offset\":20621}}},{\"type\":\"footnoteReference\",\"identifier\":\"36\",\"label\":\"36\",\"position\":{\"start\":{\"line\":176,\"column\":631,\"offset\":20621},\"end\":{\"line\":176,\"column\":636,\"offset\":20626}}}],\"position\":{\"start\":{\"line\":176,\"column\":1,\"offset\":19991},\"end\":{\"line\":176,\"column\":636,\"offset\":20626}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The General Secretary had long dreamed of doubling down on real-world physical manufacturing and avoiding American post-industrial decadence. He viewed software companies with suspicion.\",\"position\":{\"start\":{\"line\":178,\"column\":1,\"offset\":20628},\"end\":{\"line\":178,\"column\":187,\"offset\":20814}}},{\"type\":\"footnoteReference\",\"identifier\":\"37\",\"label\":\"37\",\"position\":{\"start\":{\"line\":178,\"column\":187,\"offset\":20814},\"end\":{\"line\":178,\"column\":192,\"offset\":20819}}},{\"type\":\"text\",\"value\":\" But hawks in the CCP warn that the growing race towards AGI can no longer be ignored. So he finally commits fully to the big AI push he had previously tried to avoid. He sets in motion the nationalization of Chinese AI research, creating an immediate information-sharing mechanism for AI companies. It will escalate over the course of a year until all the best researchers merge into a DeepCent-led collective, where they share algorithmic insights, datasets, and compute resources with each other. A Centralized Development Zone (CDZ) is created at the Tianwan Power Plant (the largest nuclear power plant in the world) to house a new mega-datacenter for DeepCent, along with highly secure living and office spaces to which researchers will eventually relocate. Almost 50% of China’s AI-relevant compute is now working for the DeepCent-led collective,\",\"position\":{\"start\":{\"line\":178,\"column\":192,\"offset\":20819},\"end\":{\"line\":178,\"column\":1045,\"offset\":21672}}},{\"type\":\"footnoteReference\",\"identifier\":\"38\",\"label\":\"38\",\"position\":{\"start\":{\"line\":178,\"column\":1045,\"offset\":21672},\"end\":{\"line\":178,\"column\":1050,\"offset\":21677}}},{\"type\":\"text\",\"value\":\" and over 80% of new chips are directed to the CDZ.\",\"position\":{\"start\":{\"line\":178,\"column\":1050,\"offset\":21677},\"end\":{\"line\":178,\"column\":1101,\"offset\":21728}}},{\"type\":\"footnoteReference\",\"identifier\":\"39\",\"label\":\"39\",\"position\":{\"start\":{\"line\":178,\"column\":1101,\"offset\":21728},\"end\":{\"line\":178,\"column\":1106,\"offset\":21733}}},{\"type\":\"text\",\"value\":\" At this point, the CDZ has the power capacity in place for what would be the largest centralized \",\"position\":{\"start\":{\"line\":178,\"column\":1106,\"offset\":21733},\"end\":{\"line\":178,\"column\":1204,\"offset\":21831}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Computer_cluster\",\"children\":[{\"type\":\"text\",\"value\":\"cluster\",\"position\":{\"start\":{\"line\":178,\"column\":1205,\"offset\":21832},\"end\":{\"line\":178,\"column\":1212,\"offset\":21839}}}],\"position\":{\"start\":{\"line\":178,\"column\":1204,\"offset\":21831},\"end\":{\"line\":178,\"column\":1261,\"offset\":21888}}},{\"type\":\"text\",\"value\":\" in the world.\",\"position\":{\"start\":{\"line\":178,\"column\":1261,\"offset\":21888},\"end\":{\"line\":178,\"column\":1275,\"offset\":21902}}},{\"type\":\"footnoteReference\",\"identifier\":\"40\",\"label\":\"40\",\"position\":{\"start\":{\"line\":178,\"column\":1275,\"offset\":21902},\"end\":{\"line\":178,\"column\":1280,\"offset\":21907}}},{\"type\":\"text\",\"value\":\" Other Party members discuss extreme measures to neutralize the West’s chip advantage. A blockade of Taiwan? A full invasion?\",\"position\":{\"start\":{\"line\":178,\"column\":1280,\"offset\":21907},\"end\":{\"line\":178,\"column\":1405,\"offset\":22032}}}],\"position\":{\"start\":{\"line\":178,\"column\":1,\"offset\":20628},\"end\":{\"line\":178,\"column\":1405,\"offset\":22032}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"But China is falling behind on AI algorithms due to their weaker models. The Chinese intelligence agencies—among the best in the world—double down on their plans to steal OpenBrain’s weights. This is a much more complex operation than their constant low-level poaching of algorithmic secrets; the weights are a multi-terabyte file stored on a highly secure server (\",\"position\":{\"start\":{\"line\":180,\"column\":1,\"offset\":22034},\"end\":{\"line\":180,\"column\":366,\"offset\":22399}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/security-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain has improved security\",\"position\":{\"start\":{\"line\":180,\"column\":367,\"offset\":22400},\"end\":{\"line\":180,\"column\":398,\"offset\":22431}}}],\"position\":{\"start\":{\"line\":180,\"column\":366,\"offset\":22399},\"end\":{\"line\":180,\"column\":450,\"offset\":22483}}},{\"type\":\"text\",\"value\":\" to RAND’s \",\"position\":{\"start\":{\"line\":180,\"column\":450,\"offset\":22483},\"end\":{\"line\":180,\"column\":461,\"offset\":22494}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\",\"children\":[{\"type\":\"text\",\"value\":\"SL3\",\"position\":{\"start\":{\"line\":180,\"column\":462,\"offset\":22495},\"end\":{\"line\":180,\"column\":465,\"offset\":22498}}}],\"position\":{\"start\":{\"line\":180,\"column\":461,\"offset\":22494},\"end\":{\"line\":180,\"column\":603,\"offset\":22636}}},{\"type\":\"text\",\"value\":\"). Their cyberforce think they can pull it off with help from their \",\"position\":{\"start\":{\"line\":180,\"column\":603,\"offset\":22636},\"end\":{\"line\":180,\"column\":671,\"offset\":22704}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies\",\"children\":[{\"type\":\"text\",\"value\":\"spies\",\"position\":{\"start\":{\"line\":180,\"column\":672,\"offset\":22705},\"end\":{\"line\":180,\"column\":677,\"offset\":22710}}}],\"position\":{\"start\":{\"line\":180,\"column\":671,\"offset\":22704},\"end\":{\"line\":180,\"column\":773,\"offset\":22806}}},{\"type\":\"text\",\"value\":\", but perhaps only once; OpenBrain will detect the theft, increase security, and they may not get another chance. So (CCP leadership wonder) should they act now and steal Agent-1? Or hold out for a more advanced model? If they wait, do they risk OpenBrain upgrading security beyond their ability to penetrate?\",\"position\":{\"start\":{\"line\":180,\"column\":773,\"offset\":22806},\"end\":{\"line\":180,\"column\":1082,\"offset\":23115}}}],\"position\":{\"start\":{\"line\":180,\"column\":1,\"offset\":22034},\"end\":{\"line\":180,\"column\":1082,\"offset\":23115}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"Late 2026: AI Takes Some Jobs\",\"position\":{\"start\":{\"line\":182,\"column\":4,\"offset\":23120},\"end\":{\"line\":182,\"column\":33,\"offset\":23149}}}],\"position\":{\"start\":{\"line\":182,\"column\":1,\"offset\":23117},\"end\":{\"line\":182,\"column\":33,\"offset\":23149}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2026-12-31\",\"position\":{\"start\":{\"line\":185,\"column\":1,\"offset\":23167},\"end\":{\"line\":185,\"column\":11,\"offset\":23177}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":185,\"column\":11,\"offset\":23177},\"end\":{\"line\":186,\"column\":1,\"offset\":23180}}},{\"type\":\"text\",\"value\":\"Late 2026\",\"position\":{\"start\":{\"line\":186,\"column\":1,\"offset\":23180},\"end\":{\"line\":186,\"column\":10,\"offset\":23189}}}],\"position\":{\"start\":{\"line\":185,\"column\":1,\"offset\":23167},\"end\":{\"line\":186,\"column\":12,\"offset\":23191}}}],\"position\":{\"start\":{\"line\":184,\"column\":1,\"offset\":23151},\"end\":{\"line\":187,\"column\":4,\"offset\":23195}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Just as others seemed to be catching up, OpenBrain blows the competition out of the water again by releasing Agent-1-mini—a model 10x cheaper than Agent-1 and more easily fine-tuned for different applications. The mainstream narrative around AI has changed from “maybe the hype will blow over” to “guess this is the next big thing,” but people disagree about how big. Bigger than social media? Bigger than smartphones? Bigger than fire?\",\"position\":{\"start\":{\"line\":189,\"column\":1,\"offset\":23197},\"end\":{\"line\":189,\"column\":437,\"offset\":23633}}}],\"position\":{\"start\":{\"line\":189,\"column\":1,\"offset\":23197},\"end\":{\"line\":189,\"column\":437,\"offset\":23633}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"AI has started to take jobs, but has also created new ones. The stock market has gone up 30% in 2026, led by OpenBrain, Nvidia, and whichever companies have most successfully integrated AI assistants. The job market for junior software engineers is in turmoil: the AIs can do everything taught by a CS degree, but people who know how to manage and quality-control teams of AIs are making a killing. Business gurus tell job seekers that familiarity with AI is the most important skill to put on a resume. Many people fear that the next wave of AIs will come for their jobs; there is a 10,000 person anti-AI protest in DC.\",\"position\":{\"start\":{\"line\":191,\"column\":1,\"offset\":23635},\"end\":{\"line\":191,\"column\":621,\"offset\":24255}}}],\"position\":{\"start\":{\"line\":191,\"column\":1,\"offset\":23635},\"end\":{\"line\":191,\"column\":621,\"offset\":24255}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Department of Defense (DOD) quietly but significantly begins scaling up contracting OpenBrain directly for cyber, data analysis, and R\u0026D, but integration is slow due to the bureaucracy and DOD procurement process.\",\"position\":{\"start\":{\"line\":193,\"column\":1,\"offset\":24257},\"end\":{\"line\":193,\"column\":215,\"offset\":24471}}},{\"type\":\"footnoteReference\",\"identifier\":\"41\",\"label\":\"41\",\"position\":{\"start\":{\"line\":193,\"column\":215,\"offset\":24471},\"end\":{\"line\":193,\"column\":220,\"offset\":24476}}}],\"position\":{\"start\":{\"line\":193,\"column\":1,\"offset\":24257},\"end\":{\"line\":193,\"column\":221,\"offset\":24477}}},{\"type\":\"containerDirective\",\"name\":\"keyMetrics2026\",\"attributes\":{},\"children\":[],\"position\":{\"start\":{\"line\":196,\"column\":1,\"offset\":24482},\"end\":{\"line\":197,\"column\":4,\"offset\":24505}}},{\"type\":\"details\",\"summary\":\"Why our uncertainty increases substantially beyond 2026\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Our forecast from the current day through 2026 is substantially more grounded than what follows. This is partially because it’s nearer. But it’s also because the effects of AI on the world really start to compound in 2027. For 2025 and 2026, our forecast is heavily informed by extrapolating straight lines on compute scaleups, algorithmic improvements, and benchmark performance. At this point in the scenario, we begin to see major effects from AI-accelerated AI-R\u0026D on the timeline, which causes us to revise our guesses for the trendlines upwards. But these dynamics are inherently much less predictable.\",\"position\":{\"start\":{\"line\":202,\"column\":1,\"offset\":24577},\"end\":{\"line\":202,\"column\":611,\"offset\":25187}}}],\"position\":{\"start\":{\"line\":202,\"column\":1,\"offset\":24577},\"end\":{\"line\":202,\"column\":611,\"offset\":25187}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Over the course of 2027, the AIs improve from being able to mostly do the job of an OpenBrain research engineer to eclipsing all humans at all tasks. This represents roughly our median guess, but we think it’s plausible that this happens up to ~5x slower or faster.\",\"position\":{\"start\":{\"line\":204,\"column\":1,\"offset\":25189},\"end\":{\"line\":204,\"column\":267,\"offset\":25455}}}],\"position\":{\"start\":{\"line\":204,\"column\":1,\"offset\":25189},\"end\":{\"line\":204,\"column\":268,\"offset\":25456}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For our background research, see the \",\"position\":{\"start\":{\"line\":206,\"column\":1,\"offset\":25458},\"end\":{\"line\":206,\"column\":38,\"offset\":25495}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":{\"start\":{\"line\":206,\"column\":39,\"offset\":25496},\"end\":{\"line\":206,\"column\":57,\"offset\":25514}}}],\"position\":{\"start\":{\"line\":206,\"column\":38,\"offset\":25495},\"end\":{\"line\":206,\"column\":110,\"offset\":25567}}},{\"type\":\"text\",\"value\":\" and the \",\"position\":{\"start\":{\"line\":206,\"column\":110,\"offset\":25567},\"end\":{\"line\":206,\"column\":119,\"offset\":25576}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/takeoff-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"takeoff forecast\",\"position\":{\"start\":{\"line\":206,\"column\":120,\"offset\":25577},\"end\":{\"line\":206,\"column\":136,\"offset\":25593}}}],\"position\":{\"start\":{\"line\":206,\"column\":119,\"offset\":25576},\"end\":{\"line\":206,\"column\":187,\"offset\":25644}}},{\"type\":\"text\",\"value\":\". These will also be summarized in expandables below.\",\"position\":{\"start\":{\"line\":206,\"column\":187,\"offset\":25644},\"end\":{\"line\":206,\"column\":240,\"offset\":25697}}}],\"position\":{\"start\":{\"line\":206,\"column\":1,\"offset\":25458},\"end\":{\"line\":206,\"column\":242,\"offset\":25699}}}]},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"January 2027: Agent-2 Never Finishes Learning\",\"position\":{\"start\":{\"line\":209,\"column\":4,\"offset\":25708},\"end\":{\"line\":209,\"column\":49,\"offset\":25753}}}],\"position\":{\"start\":{\"line\":209,\"column\":1,\"offset\":25705},\"end\":{\"line\":209,\"column\":49,\"offset\":25753}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-01-31\",\"position\":{\"start\":{\"line\":212,\"column\":1,\"offset\":25771},\"end\":{\"line\":212,\"column\":11,\"offset\":25781}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":212,\"column\":11,\"offset\":25781},\"end\":{\"line\":213,\"column\":1,\"offset\":25784}}},{\"type\":\"text\",\"value\":\"Jan 2027\",\"position\":{\"start\":{\"line\":213,\"column\":1,\"offset\":25784},\"end\":{\"line\":213,\"column\":9,\"offset\":25792}}}],\"position\":{\"start\":{\"line\":212,\"column\":1,\"offset\":25771},\"end\":{\"line\":213,\"column\":11,\"offset\":25794}}}],\"position\":{\"start\":{\"line\":211,\"column\":1,\"offset\":25755},\"end\":{\"line\":214,\"column\":4,\"offset\":25798}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"With Agent-1’s help, OpenBrain is now post-training Agent-2. More than ever, the focus is on high-quality data. Copious amounts of \",\"position\":{\"start\":{\"line\":216,\"column\":1,\"offset\":25800},\"end\":{\"line\":216,\"column\":132,\"offset\":25931}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Synthetic_data\",\"children\":[{\"type\":\"text\",\"value\":\"synthetic data\",\"position\":{\"start\":{\"line\":216,\"column\":133,\"offset\":25932},\"end\":{\"line\":216,\"column\":147,\"offset\":25946}}}],\"position\":{\"start\":{\"line\":216,\"column\":132,\"offset\":25931},\"end\":{\"line\":216,\"column\":194,\"offset\":25993}}},{\"type\":\"text\",\"value\":\" are produced, evaluated, and filtered for quality before being fed to Agent-2.\",\"position\":{\"start\":{\"line\":216,\"column\":194,\"offset\":25993},\"end\":{\"line\":216,\"column\":273,\"offset\":26072}}},{\"type\":\"footnoteReference\",\"identifier\":\"42\",\"label\":\"42\",\"position\":{\"start\":{\"line\":216,\"column\":273,\"offset\":26072},\"end\":{\"line\":216,\"column\":278,\"offset\":26077}}},{\"type\":\"text\",\"value\":\" On top of this, they pay billions of dollars for human laborers to record themselves solving long-horizon tasks.\",\"position\":{\"start\":{\"line\":216,\"column\":278,\"offset\":26077},\"end\":{\"line\":216,\"column\":391,\"offset\":26190}}},{\"type\":\"footnoteReference\",\"identifier\":\"43\",\"label\":\"43\",\"position\":{\"start\":{\"line\":216,\"column\":391,\"offset\":26190},\"end\":{\"line\":216,\"column\":396,\"offset\":26195}}},{\"type\":\"text\",\"value\":\" On top of all \",\"position\":{\"start\":{\"line\":216,\"column\":396,\"offset\":26195},\"end\":{\"line\":216,\"column\":411,\"offset\":26210}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"that,\",\"position\":{\"start\":{\"line\":216,\"column\":412,\"offset\":26211},\"end\":{\"line\":216,\"column\":417,\"offset\":26216}}}],\"position\":{\"start\":{\"line\":216,\"column\":411,\"offset\":26210},\"end\":{\"line\":216,\"column\":418,\"offset\":26217}}},{\"type\":\"text\",\"value\":\" they train Agent-2 almost continuously using reinforcement learning on an ever-expanding suite of diverse difficult tasks: lots of video games, lots of coding challenges, lots of research tasks. Agent-2, more so than previous models, is effectively “online learning,” in that it’s built to never really finish training. Every day, the weights get updated to the latest version, trained on more data generated by the previous version the previous day.\",\"position\":{\"start\":{\"line\":216,\"column\":418,\"offset\":26217},\"end\":{\"line\":216,\"column\":869,\"offset\":26668}}}],\"position\":{\"start\":{\"line\":216,\"column\":1,\"offset\":25800},\"end\":{\"line\":216,\"column\":869,\"offset\":26668}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-1 had been optimized for AI R\u0026D tasks, hoping to initiate an \",\"position\":{\"start\":{\"line\":218,\"column\":1,\"offset\":26670},\"end\":{\"line\":218,\"column\":69,\"offset\":26738}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion\",\"children\":[{\"type\":\"text\",\"value\":\"intelligence explosion\",\"position\":{\"start\":{\"line\":218,\"column\":70,\"offset\":26739},\"end\":{\"line\":218,\"column\":92,\"offset\":26761}}}],\"position\":{\"start\":{\"line\":218,\"column\":69,\"offset\":26738},\"end\":{\"line\":218,\"column\":173,\"offset\":26842}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":218,\"column\":173,\"offset\":26842},\"end\":{\"line\":218,\"column\":174,\"offset\":26843}}},{\"type\":\"footnoteReference\",\"identifier\":\"44\",\"label\":\"44\",\"position\":{\"start\":{\"line\":218,\"column\":174,\"offset\":26843},\"end\":{\"line\":218,\"column\":179,\"offset\":26848}}},{\"type\":\"text\",\"value\":\" OpenBrain doubles down on this strategy with Agent-2. It is qualitatively almost as good as the top human experts at research engineering (designing and implementing experiments), and as good as the 25th percentile OpenBrain scientist at “research taste” (deciding what to study next, what experiments to run, or having inklings of potential new paradigms).\",\"position\":{\"start\":{\"line\":218,\"column\":179,\"offset\":26848},\"end\":{\"line\":218,\"column\":537,\"offset\":27206}}},{\"type\":\"footnoteReference\",\"identifier\":\"45\",\"label\":\"45\",\"position\":{\"start\":{\"line\":218,\"column\":537,\"offset\":27206},\"end\":{\"line\":218,\"column\":542,\"offset\":27211}}},{\"type\":\"text\",\"value\":\" While the latest Agent-1 could double the pace of OpenBrain’s algorithmic progress, Agent-2 can now triple it, and will improve further with time. In practice, this looks like every OpenBrain researcher becoming the “manager” of an AI “team.”\",\"position\":{\"start\":{\"line\":218,\"column\":542,\"offset\":27211},\"end\":{\"line\":218,\"column\":785,\"offset\":27454}}}],\"position\":{\"start\":{\"line\":218,\"column\":1,\"offset\":26670},\"end\":{\"line\":218,\"column\":785,\"offset\":27454}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"With new capabilities come new dangers. The safety team finds that if Agent-2 somehow escaped from the company and wanted to \",\"position\":{\"start\":{\"line\":220,\"column\":1,\"offset\":27456},\"end\":{\"line\":220,\"column\":126,\"offset\":27581}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf\",\"children\":[{\"type\":\"text\",\"value\":\"“survive” and “replicate” autonomously\",\"position\":{\"start\":{\"line\":220,\"column\":127,\"offset\":27582},\"end\":{\"line\":220,\"column\":165,\"offset\":27620}}}],\"position\":{\"start\":{\"line\":220,\"column\":126,\"offset\":27581},\"end\":{\"line\":220,\"column\":231,\"offset\":27686}}},{\"type\":\"text\",\"value\":\", it might be able to do so. That is, it could autonomously develop and execute plans to hack into AI servers, install copies of itself, evade detection, and use that secure base to pursue whatever other goals it might have (though how effectively it would do so as weeks roll by is unknown and in doubt). These results only show that the model has the capability to do these tasks, not whether it would “want” to do this. Still, it’s unsettling even to know this is possible.\",\"position\":{\"start\":{\"line\":220,\"column\":231,\"offset\":27686},\"end\":{\"line\":220,\"column\":707,\"offset\":28162}}}],\"position\":{\"start\":{\"line\":220,\"column\":1,\"offset\":27456},\"end\":{\"line\":220,\"column\":707,\"offset\":28162}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Given the “dangers” of the new model, OpenBrain “responsibly” elects not to release it publicly yet (in fact, they want to focus on internal AI R\u0026D).\",\"position\":{\"start\":{\"line\":222,\"column\":1,\"offset\":28164},\"end\":{\"line\":222,\"column\":151,\"offset\":28314}}},{\"type\":\"footnoteReference\",\"identifier\":\"46\",\"label\":\"46\",\"position\":{\"start\":{\"line\":222,\"column\":151,\"offset\":28314},\"end\":{\"line\":222,\"column\":156,\"offset\":28319}}},{\"type\":\"text\",\"value\":\" Knowledge of Agent-2’s full capabilities is limited to an elite silo containing the immediate team, OpenBrain leadership and security, a few dozen U.S. government officials, and the legions of CCP spies who have infiltrated OpenBrain \",\"position\":{\"start\":{\"line\":222,\"column\":156,\"offset\":28319},\"end\":{\"line\":222,\"column\":391,\"offset\":28554}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://situational-awareness.ai/lock-down-the-labs/\",\"children\":[{\"type\":\"text\",\"value\":\"for\",\"position\":{\"start\":{\"line\":222,\"column\":392,\"offset\":28555},\"end\":{\"line\":222,\"column\":395,\"offset\":28558}}}],\"position\":{\"start\":{\"line\":222,\"column\":391,\"offset\":28554},\"end\":{\"line\":222,\"column\":450,\"offset\":28613}}},{\"type\":\"text\",\"value\":\" \",\"position\":{\"start\":{\"line\":222,\"column\":450,\"offset\":28613},\"end\":{\"line\":222,\"column\":451,\"offset\":28614}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.bbc.com/news/world-asia-china-64206950\",\"children\":[{\"type\":\"text\",\"value\":\"years\",\"position\":{\"start\":{\"line\":222,\"column\":452,\"offset\":28615},\"end\":{\"line\":222,\"column\":457,\"offset\":28620}}}],\"position\":{\"start\":{\"line\":222,\"column\":451,\"offset\":28614},\"end\":{\"line\":222,\"column\":510,\"offset\":28673}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":222,\"column\":510,\"offset\":28673},\"end\":{\"line\":222,\"column\":511,\"offset\":28674}}},{\"type\":\"footnoteReference\",\"identifier\":\"47\",\"label\":\"47\",\"position\":{\"start\":{\"line\":222,\"column\":511,\"offset\":28674},\"end\":{\"line\":222,\"column\":516,\"offset\":28679}}}],\"position\":{\"start\":{\"line\":222,\"column\":1,\"offset\":28164},\"end\":{\"line\":222,\"column\":516,\"offset\":28679}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"February 2027: China Steals Agent-2\",\"position\":{\"start\":{\"line\":224,\"column\":4,\"offset\":28684},\"end\":{\"line\":224,\"column\":39,\"offset\":28719}}}],\"position\":{\"start\":{\"line\":224,\"column\":1,\"offset\":28681},\"end\":{\"line\":224,\"column\":39,\"offset\":28719}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-02-28\",\"position\":{\"start\":{\"line\":227,\"column\":1,\"offset\":28737},\"end\":{\"line\":227,\"column\":11,\"offset\":28747}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":227,\"column\":11,\"offset\":28747},\"end\":{\"line\":228,\"column\":1,\"offset\":28750}}},{\"type\":\"text\",\"value\":\"Feb\",\"position\":{\"start\":{\"line\":228,\"column\":1,\"offset\":28750},\"end\":{\"line\":228,\"column\":4,\"offset\":28753}}}],\"position\":{\"start\":{\"line\":227,\"column\":1,\"offset\":28737},\"end\":{\"line\":228,\"column\":6,\"offset\":28755}}}],\"position\":{\"start\":{\"line\":226,\"column\":1,\"offset\":28721},\"end\":{\"line\":229,\"column\":4,\"offset\":28759}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain presents Agent-2 to the government, including the National Security Council (NSC), the Department of Defense (DOD), and the U.S. AI Safety Institute (AISI). OpenBrain wants to maintain a good relationship with the executive branch, because it is basically the only actor that can stop them now, and if they don’t keep it informed it might find out anyway and be displeased.\",\"position\":{\"start\":{\"line\":231,\"column\":1,\"offset\":28761},\"end\":{\"line\":231,\"column\":384,\"offset\":29144}}},{\"type\":\"footnoteReference\",\"identifier\":\"48\",\"label\":\"48\",\"position\":{\"start\":{\"line\":231,\"column\":384,\"offset\":29144},\"end\":{\"line\":231,\"column\":389,\"offset\":29149}}}],\"position\":{\"start\":{\"line\":231,\"column\":1,\"offset\":28761},\"end\":{\"line\":231,\"column\":389,\"offset\":29149}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Officials are most interested in its cyberwarfare capabilities: Agent-2 is “only” a little worse than the best human hackers, but thousands of copies can be run in parallel, searching for and exploiting weaknesses faster than defenders can respond. The Department of Defense considers this a critical advantage in cyberwarfare, and AI moves from #5 on the administration’s priority list to #2.\",\"position\":{\"start\":{\"line\":233,\"column\":1,\"offset\":29151},\"end\":{\"line\":233,\"column\":396,\"offset\":29546}}},{\"type\":\"footnoteReference\",\"identifier\":\"49\",\"label\":\"49\",\"position\":{\"start\":{\"line\":233,\"column\":396,\"offset\":29546},\"end\":{\"line\":233,\"column\":401,\"offset\":29551}}},{\"type\":\"text\",\"value\":\" Someone mentions the possibility of nationalizing OpenBrain, but other cabinet officials think that’s premature. A staffer drafts a memo that presents the President with his options, ranging from business-as-usual to full nationalization. The President defers to his advisors, tech industry leaders who argue that nationalization would “kill the goose that lays the golden eggs.” He elects to hold off on major action for now and just adds additional security requirements to the OpenBrain-DOD contract.\",\"position\":{\"start\":{\"line\":233,\"column\":401,\"offset\":29551},\"end\":{\"line\":233,\"column\":905,\"offset\":30055}}}],\"position\":{\"start\":{\"line\":233,\"column\":1,\"offset\":29151},\"end\":{\"line\":233,\"column\":905,\"offset\":30055}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The changes come too late. CCP leadership recognizes the importance of Agent-2 and tells their spies and cyberforce to steal the weights. Early one morning, an Agent-1 traffic monitoring agent detects an anomalous transfer. It alerts company leaders, who tell the White House. The signs of a nation-state-level operation are unmistakable, and the theft heightens the sense of an ongoing arms race.\",\"position\":{\"start\":{\"line\":235,\"column\":1,\"offset\":30057},\"end\":{\"line\":235,\"column\":398,\"offset\":30454}}}],\"position\":{\"start\":{\"line\":235,\"column\":1,\"offset\":30057},\"end\":{\"line\":235,\"column\":399,\"offset\":30455}}},{\"type\":\"details\",\"summary\":\"The theft of Agent-2 model weights\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We think that by this point Chinese intelligence would have compromised OpenBrain in various ways for years, and probably would have been keeping up to date on the algorithmic secrets and even stealing code from time to time, since that is much easier to get than the weights and much harder to detect.\",\"position\":{\"start\":{\"line\":241,\"column\":1,\"offset\":30505},\"end\":{\"line\":241,\"column\":303,\"offset\":30807}}}],\"position\":{\"start\":{\"line\":241,\"column\":1,\"offset\":30505},\"end\":{\"line\":241,\"column\":303,\"offset\":30807}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We imagine the theft of the weights as a series of coordinated small smash and grab thefts (meaning fast but non-covert) across a series of Nvidia NVL72 GB300 servers running copies of the Agent-2 weights. The servers are compromised using legitimate employee access (a friendly, coerced, or unwitting insider with admin credentials helping the CCP theft effort). Insider credentials grant the attacker admin-level permissions to the servers. Using a microarchitectural side channel, the attacker extracts encryption keys from an Nvidia Confidential Computing-enabled Virtual Machine, allowing the them to intercept model weights as the VM is provisioned or updated.\",\"position\":{\"start\":{\"line\":243,\"column\":1,\"offset\":30809},\"end\":{\"line\":243,\"column\":667,\"offset\":31475}}}],\"position\":{\"start\":{\"line\":243,\"column\":1,\"offset\":30809},\"end\":{\"line\":243,\"column\":667,\"offset\":31475}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They initiate (or wait for) a routine update and exfiltrate the checkpoint in many small fragments, e.g., ~25 distinct servers each leaking ~4% of the model (~100 GB chunks for a ~2.5 TB half-precision checkpoint). The egress bandwidth of the entire datacenter is in the 100 GB/second range, so throttling to under ~1 GB/s per server avoids a major spike in network traffic; at that rate, each ~100 GB chunk can leave the datacenter in a couple of minutes. Live monitoring is either fooled by the attackers efforts to mask and split the transfers or outright disabled.\",\"position\":{\"start\":{\"line\":245,\"column\":1,\"offset\":31477},\"end\":{\"line\":245,\"column\":569,\"offset\":32045}}}],\"position\":{\"start\":{\"line\":245,\"column\":1,\"offset\":31477},\"end\":{\"line\":245,\"column\":569,\"offset\":32045}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The weights are then routed through various parallel channels and layers of IP masking to China to be decrypted locally with the stolen session key(s). The entire active part of the operation (from the first server compromise to full weights exfiltration) is complete in under two hours.\",\"position\":{\"start\":{\"line\":247,\"column\":1,\"offset\":32047},\"end\":{\"line\":247,\"column\":288,\"offset\":32334}}},{\"type\":\"footnoteReference\",\"identifier\":\"99\",\"label\":\"99\",\"position\":{\"start\":{\"line\":247,\"column\":288,\"offset\":32334},\"end\":{\"line\":247,\"column\":293,\"offset\":32339}}}],\"position\":{\"start\":{\"line\":247,\"column\":1,\"offset\":32047},\"end\":{\"line\":247,\"column\":293,\"offset\":32339}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Russia is also trying to steal the model at this point, but fails—they waited too long, and they haven’t spent the resources infiltrating the right places. Their spies routinely steal algorithmic secrets from American AI companies, but without a notable AGI project of their own, these aren’t very useful.\",\"position\":{\"start\":{\"line\":249,\"column\":1,\"offset\":32341},\"end\":{\"line\":249,\"column\":306,\"offset\":32646}}}],\"position\":{\"start\":{\"line\":249,\"column\":1,\"offset\":32341},\"end\":{\"line\":249,\"column\":306,\"offset\":32646}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The White House puts OpenBrain on a shorter leash and adds military and intelligence community personnel to their security team. Their first priority is to prevent further weight thefts.\",\"position\":{\"start\":{\"line\":253,\"column\":1,\"offset\":32653},\"end\":{\"line\":253,\"column\":187,\"offset\":32839}}},{\"type\":\"footnoteReference\",\"identifier\":\"50\",\"label\":\"50\",\"position\":{\"start\":{\"line\":253,\"column\":187,\"offset\":32839},\"end\":{\"line\":253,\"column\":192,\"offset\":32844}}}],\"position\":{\"start\":{\"line\":253,\"column\":1,\"offset\":32653},\"end\":{\"line\":253,\"column\":192,\"offset\":32844}}},{\"type\":\"containerDirective\",\"name\":\"chinaComputeCentralization\",\"attributes\":{},\"children\":[],\"position\":{\"start\":{\"line\":256,\"column\":1,\"offset\":32849},\"end\":{\"line\":257,\"column\":4,\"offset\":32884}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In retaliation for the theft, the President authorizes cyberattacks to sabotage DeepCent. But by now China has 40% of its AI-relevant compute\",\"position\":{\"start\":{\"line\":259,\"column\":1,\"offset\":32886},\"end\":{\"line\":259,\"column\":142,\"offset\":33027}}},{\"type\":\"footnoteReference\",\"identifier\":\"51\",\"label\":\"51\",\"position\":{\"start\":{\"line\":259,\"column\":142,\"offset\":33027},\"end\":{\"line\":259,\"column\":147,\"offset\":33032}}},{\"type\":\"text\",\"value\":\" in the CDZ, where they have aggressively hardened security by airgapping (closing external connections) and siloing internally. The operations fail to do serious, immediate damage. Tensions heighten, both sides signal seriousness by repositioning military assets around Taiwan, and DeepCent scrambles to get Agent-2 running efficiently to start boosting their AI research.\",\"position\":{\"start\":{\"line\":259,\"column\":147,\"offset\":33032},\"end\":{\"line\":259,\"column\":520,\"offset\":33405}}},{\"type\":\"footnoteReference\",\"identifier\":\"52\",\"label\":\"52\",\"position\":{\"start\":{\"line\":259,\"column\":520,\"offset\":33405},\"end\":{\"line\":259,\"column\":525,\"offset\":33410}}}],\"position\":{\"start\":{\"line\":259,\"column\":1,\"offset\":32886},\"end\":{\"line\":259,\"column\":525,\"offset\":33410}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"March 2027: Algorithmic Breakthroughs\",\"position\":{\"start\":{\"line\":261,\"column\":4,\"offset\":33415},\"end\":{\"line\":261,\"column\":41,\"offset\":33452}}}],\"position\":{\"start\":{\"line\":261,\"column\":1,\"offset\":33412},\"end\":{\"line\":261,\"column\":41,\"offset\":33452}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-03-31\",\"position\":{\"start\":{\"line\":264,\"column\":1,\"offset\":33470},\"end\":{\"line\":264,\"column\":11,\"offset\":33480}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":264,\"column\":11,\"offset\":33480},\"end\":{\"line\":265,\"column\":1,\"offset\":33483}}},{\"type\":\"text\",\"value\":\"Mar\",\"position\":{\"start\":{\"line\":265,\"column\":1,\"offset\":33483},\"end\":{\"line\":265,\"column\":4,\"offset\":33486}}}],\"position\":{\"start\":{\"line\":264,\"column\":1,\"offset\":33470},\"end\":{\"line\":265,\"column\":6,\"offset\":33488}}}],\"position\":{\"start\":{\"line\":263,\"column\":1,\"offset\":33454},\"end\":{\"line\":266,\"column\":4,\"offset\":33492}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Three huge datacenters full of Agent-2 copies work day and night, churning out synthetic training data. Another two are used to update the weights. Agent-2 is getting smarter every day.\",\"position\":{\"start\":{\"line\":268,\"column\":1,\"offset\":33494},\"end\":{\"line\":268,\"column\":186,\"offset\":33679}}}],\"position\":{\"start\":{\"line\":268,\"column\":1,\"offset\":33494},\"end\":{\"line\":268,\"column\":186,\"offset\":33679}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"With the help of thousands of Agent-2 automated researchers, OpenBrain is making major algorithmic advances. One such breakthrough is augmenting the AI’s text-based scratchpad (chain of thought) with a higher-bandwidth thought process (neuralese recurrence and memory). Another is a more scalable and efficient way to learn from the results of high-effort task solutions (iterated distillation and amplification).\",\"position\":{\"start\":{\"line\":270,\"column\":1,\"offset\":33681},\"end\":{\"line\":270,\"column\":414,\"offset\":34094}}}],\"position\":{\"start\":{\"line\":270,\"column\":1,\"offset\":33681},\"end\":{\"line\":270,\"column\":415,\"offset\":34095}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The new AI system, incorporating these breakthroughs, is called Agent-3.\",\"position\":{\"start\":{\"line\":272,\"column\":1,\"offset\":34097},\"end\":{\"line\":272,\"column\":73,\"offset\":34169}}}],\"position\":{\"start\":{\"line\":272,\"column\":1,\"offset\":34097},\"end\":{\"line\":272,\"column\":73,\"offset\":34169}}},{\"type\":\"containerDirective\",\"name\":\"ComputeAllocation2024v2027\",\"attributes\":{},\"children\":[],\"position\":{\"start\":{\"line\":275,\"column\":1,\"offset\":34174},\"end\":{\"line\":276,\"column\":4,\"offset\":34209}}},{\"type\":\"details\",\"summary\":\"Neuralese recurrence and memory\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Neuralese recurrence and memory allows AI models to reason for a longer time without having to write down those thoughts as text.\",\"position\":{\"start\":{\"line\":282,\"column\":1,\"offset\":34256},\"end\":{\"line\":282,\"column\":130,\"offset\":34385}}}],\"position\":{\"start\":{\"line\":282,\"column\":1,\"offset\":34256},\"end\":{\"line\":282,\"column\":130,\"offset\":34385}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Imagine being a human with short-term memory loss, such that you need to constantly write down your thoughts on paper so that in a few minutes you know what’s going on. Slowly and painfully you could make progress at solving math problems, writing code, etc., but it would be much easier if you could directly remember your thoughts without having to write them down and then read them. This is what neuralese recurrence and memory bring to AI models.\",\"position\":{\"start\":{\"line\":284,\"column\":1,\"offset\":34387},\"end\":{\"line\":284,\"column\":452,\"offset\":34838}}}],\"position\":{\"start\":{\"line\":284,\"column\":1,\"offset\":34387},\"end\":{\"line\":284,\"column\":452,\"offset\":34838}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In more technical terms:\",\"position\":{\"start\":{\"line\":286,\"column\":1,\"offset\":34840},\"end\":{\"line\":286,\"column\":25,\"offset\":34864}}}],\"position\":{\"start\":{\"line\":286,\"column\":1,\"offset\":34840},\"end\":{\"line\":286,\"column\":25,\"offset\":34864}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Traditional attention mechanisms allow later forward passes in a model to see intermediate activations of the model for previous tokens. However, the only information that they can pass \",\"position\":{\"start\":{\"line\":288,\"column\":1,\"offset\":34866},\"end\":{\"line\":288,\"column\":187,\"offset\":35052}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"backwards\",\"position\":{\"start\":{\"line\":288,\"column\":188,\"offset\":35053},\"end\":{\"line\":288,\"column\":197,\"offset\":35062}}}],\"position\":{\"start\":{\"line\":288,\"column\":187,\"offset\":35052},\"end\":{\"line\":288,\"column\":198,\"offset\":35063}}},{\"type\":\"text\",\"value\":\" (from later layers to earlier layers) is through tokens. This means that if a traditional large language model (LLM, e.g. the GPT series of models) wants to do any chain of reasoning that takes more serial operations than the number of layers in the model, the model is forced to put information in tokens which it can then pass back into itself. But this is hugely limiting—the tokens can only store a tiny amount of information. Suppose that an LLM has a vocab size of ~100,000, then each token contains \",\"position\":{\"start\":{\"line\":288,\"column\":198,\"offset\":35063},\"end\":{\"line\":288,\"column\":706,\"offset\":35571}}},{\"type\":\"inlineMath\",\"value\":\"\\\\\\\\log\\\\_2(100k)=16.6\",\"data\":{\"hName\":\"code\",\"hProperties\":{\"className\":[\"language-math\",\"math-inline\"]},\"hChildren\":[{\"type\":\"text\",\"value\":\"\\\\\\\\log\\\\_2(100k)=16.6\"}]},\"position\":{\"start\":{\"line\":288,\"column\":706,\"offset\":35571},\"end\":{\"line\":288,\"column\":729,\"offset\":35594}}},{\"type\":\"text\",\"value\":\" bits of information, around the size of a single floating point number (assuming training in \",\"position\":{\"start\":{\"line\":288,\"column\":729,\"offset\":35594},\"end\":{\"line\":288,\"column\":823,\"offset\":35688}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Half-precision_floating-point_format\",\"children\":[{\"type\":\"text\",\"value\":\"FP16\",\"position\":{\"start\":{\"line\":288,\"column\":824,\"offset\":35689},\"end\":{\"line\":288,\"column\":828,\"offset\":35693}}}],\"position\":{\"start\":{\"line\":288,\"column\":823,\"offset\":35688},\"end\":{\"line\":288,\"column\":897,\"offset\":35762}}},{\"type\":\"text\",\"value\":\"). Meanwhile, residual streams—used to pass information between layers in an LLM—contain thousands of floating point numbers.\",\"position\":{\"start\":{\"line\":288,\"column\":897,\"offset\":35762},\"end\":{\"line\":288,\"column\":1022,\"offset\":35887}}}],\"position\":{\"start\":{\"line\":288,\"column\":1,\"offset\":34866},\"end\":{\"line\":288,\"column\":1022,\"offset\":35887}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"One can avoid this bottleneck by using \",\"position\":{\"start\":{\"line\":290,\"column\":1,\"offset\":35889},\"end\":{\"line\":290,\"column\":40,\"offset\":35928}}},{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"neuralese\",\"position\":{\"start\":{\"line\":290,\"column\":42,\"offset\":35930},\"end\":{\"line\":290,\"column\":51,\"offset\":35939}}}],\"position\":{\"start\":{\"line\":290,\"column\":40,\"offset\":35928},\"end\":{\"line\":290,\"column\":53,\"offset\":35941}}},{\"type\":\"text\",\"value\":\": passing an LLM’s residual stream (which consists of several-thousand-dimensional vectors) back to the early layers of the model, giving it a high-dimensional chain of thought, potentially transmitting over 1,000 times more information.\",\"position\":{\"start\":{\"line\":290,\"column\":53,\"offset\":35941},\"end\":{\"line\":290,\"column\":290,\"offset\":36178}}}],\"position\":{\"start\":{\"line\":290,\"column\":1,\"offset\":35889},\"end\":{\"line\":290,\"column\":291,\"offset\":36179}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"image\",\"title\":null,\"url\":\"/hao2024-nowatermark-inexpandable.png\",\"alt\":\"\",\"position\":{\"start\":{\"line\":292,\"column\":1,\"offset\":36181},\"end\":{\"line\":292,\"column\":43,\"offset\":36223}}}],\"position\":{\"start\":{\"line\":292,\"column\":1,\"offset\":36181},\"end\":{\"line\":292,\"column\":43,\"offset\":36223}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Figure from \",\"position\":{\"start\":{\"line\":294,\"column\":1,\"offset\":36225},\"end\":{\"line\":294,\"column\":13,\"offset\":36237}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2412.06769\",\"children\":[{\"type\":\"text\",\"value\":\"Hao et al.\",\"position\":{\"start\":{\"line\":294,\"column\":14,\"offset\":36238},\"end\":{\"line\":294,\"column\":24,\"offset\":36248}}}],\"position\":{\"start\":{\"line\":294,\"column\":13,\"offset\":36237},\"end\":{\"line\":294,\"column\":59,\"offset\":36283}}},{\"type\":\"text\",\"value\":\", a 2024 paper from Meta implementing this idea.\",\"position\":{\"start\":{\"line\":294,\"column\":59,\"offset\":36283},\"end\":{\"line\":294,\"column\":107,\"offset\":36331}}}],\"position\":{\"start\":{\"line\":294,\"column\":1,\"offset\":36225},\"end\":{\"line\":294,\"column\":107,\"offset\":36331}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We call this “neuralese” because unlike English words, these high-dimensional vectors are likely quite difficult for humans to interpret. In the past, researchers could get a good idea what LLMs were thinking simply by \",\"position\":{\"start\":{\"line\":296,\"column\":1,\"offset\":36333},\"end\":{\"line\":296,\"column\":220,\"offset\":36552}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/chain-of-thought-monitoring/\",\"children\":[{\"type\":\"text\",\"value\":\"reading its chain of thought\",\"position\":{\"start\":{\"line\":296,\"column\":221,\"offset\":36553},\"end\":{\"line\":296,\"column\":249,\"offset\":36581}}}],\"position\":{\"start\":{\"line\":296,\"column\":220,\"offset\":36552},\"end\":{\"line\":296,\"column\":305,\"offset\":36637}}},{\"type\":\"text\",\"value\":\". Now researchers have to ask the model to translate and summarize its thoughts or puzzle over the neuralese with their limited interpretability tools.\",\"position\":{\"start\":{\"line\":296,\"column\":305,\"offset\":36637},\"end\":{\"line\":296,\"column\":456,\"offset\":36788}}}],\"position\":{\"start\":{\"line\":296,\"column\":1,\"offset\":36333},\"end\":{\"line\":296,\"column\":456,\"offset\":36788}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Similarly, older AI chatbots and agents had external text-based memory banks, like a human taking notes on paper. The new AI’s long-term memory is a bundle of vectors instead of text, making its thoughts more compressed and higher-dimensional. There are several types of memory banks; some are used temporarily for single tasks that involve multiple steps, others are shared between all agents used by a person, company, or job type (e.g. programming).\",\"position\":{\"start\":{\"line\":298,\"column\":1,\"offset\":36790},\"end\":{\"line\":298,\"column\":453,\"offset\":37242}}}],\"position\":{\"start\":{\"line\":298,\"column\":1,\"offset\":36790},\"end\":{\"line\":298,\"column\":453,\"offset\":37242}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"To our knowledge, leading AI companies such as Meta, Google DeepMind, OpenAI, and Anthropic have not yet actually implemented this idea in their frontier models. Our guess is that this is because the performance gain is small relative to training inefficiencies introduced. During the model’s pre-training phase and when doing supervised learning in post-training, such as instruction fine-tuning to produce \",\"position\":{\"start\":{\"line\":300,\"column\":1,\"offset\":37244},\"end\":{\"line\":300,\"column\":409,\"offset\":37652}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2210.11416\",\"children\":[{\"type\":\"text\",\"value\":\"particular responses\",\"position\":{\"start\":{\"line\":300,\"column\":410,\"offset\":37653},\"end\":{\"line\":300,\"column\":430,\"offset\":37673}}}],\"position\":{\"start\":{\"line\":300,\"column\":409,\"offset\":37652},\"end\":{\"line\":300,\"column\":465,\"offset\":37708}}},{\"type\":\"text\",\"value\":\"$27a\",\"position\":{\"start\":{\"line\":300,\"column\":465,\"offset\":37708},\"end\":{\"line\":300,\"column\":1516,\"offset\":38759}}}],\"position\":{\"start\":{\"line\":300,\"column\":1,\"offset\":37244},\"end\":{\"line\":300,\"column\":1516,\"offset\":38759}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"If this doesn’t happen, other things may still have happened that end up functionally similar for our story. For example, perhaps models will be trained to think in artificial languages that are more efficient than natural language but difficult for humans to interpret. Or perhaps it will become standard practice to \",\"position\":{\"start\":{\"line\":302,\"column\":1,\"offset\":38761},\"end\":{\"line\":302,\"column\":319,\"offset\":39079}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/chain-of-thought-monitoring/\",\"children\":[{\"type\":\"text\",\"value\":\"train the English chains of thought to look nice\",\"position\":{\"start\":{\"line\":302,\"column\":320,\"offset\":39080},\"end\":{\"line\":302,\"column\":368,\"offset\":39128}}}],\"position\":{\"start\":{\"line\":302,\"column\":319,\"offset\":39079},\"end\":{\"line\":302,\"column\":424,\"offset\":39184}}},{\"type\":\"text\",\"value\":\", such that AIs become adept at subtly communicating with each other in messages that look benign to monitors.\",\"position\":{\"start\":{\"line\":302,\"column\":424,\"offset\":39184},\"end\":{\"line\":302,\"column\":534,\"offset\":39294}}}],\"position\":{\"start\":{\"line\":302,\"column\":1,\"offset\":38761},\"end\":{\"line\":302,\"column\":534,\"offset\":39294}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"That said, it’s also possible that the AIs that first automate AI R\u0026D will still be thinking in mostly-faithful English chains of thought. If so, that’ll make misalignments much easier to notice, and overall our story would be importantly different and more optimistic.\",\"position\":{\"start\":{\"line\":304,\"column\":1,\"offset\":39296},\"end\":{\"line\":304,\"column\":271,\"offset\":39566}}}],\"position\":{\"start\":{\"line\":304,\"column\":1,\"offset\":39296},\"end\":{\"line\":304,\"column\":271,\"offset\":39566}}}]},{\"type\":\"details\",\"summary\":\"Iterated distillation and amplification (IDA)\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Self-improvement for general intelligence had seen \",\"position\":{\"start\":{\"line\":312,\"column\":1,\"offset\":39632},\"end\":{\"line\":312,\"column\":52,\"offset\":39683}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/1810.08575\",\"children\":[{\"type\":\"text\",\"value\":\"minor successes\",\"position\":{\"start\":{\"line\":312,\"column\":53,\"offset\":39684},\"end\":{\"line\":312,\"column\":68,\"offset\":39699}}}],\"position\":{\"start\":{\"line\":312,\"column\":52,\"offset\":39683},\"end\":{\"line\":312,\"column\":103,\"offset\":39734}}},{\"type\":\"text\",\"value\":\" before. But in early 2027, it’s seeing huge returns. In \",\"position\":{\"start\":{\"line\":312,\"column\":103,\"offset\":39734},\"end\":{\"line\":312,\"column\":160,\"offset\":39791}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616\",\"children\":[{\"type\":\"text\",\"value\":\"IDA\",\"position\":{\"start\":{\"line\":312,\"column\":161,\"offset\":39792},\"end\":{\"line\":312,\"column\":164,\"offset\":39795}}}],\"position\":{\"start\":{\"line\":312,\"column\":160,\"offset\":39791},\"end\":{\"line\":312,\"column\":244,\"offset\":39875}}},{\"type\":\"text\",\"value\":\", the two necessary ingredients for this are:\",\"position\":{\"start\":{\"line\":312,\"column\":244,\"offset\":39875},\"end\":{\"line\":312,\"column\":289,\"offset\":39920}}}],\"position\":{\"start\":{\"line\":312,\"column\":1,\"offset\":39632},\"end\":{\"line\":312,\"column\":290,\"offset\":39921}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":true,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Amplification\",\"position\":{\"start\":{\"line\":314,\"column\":6,\"offset\":39928},\"end\":{\"line\":314,\"column\":19,\"offset\":39941}}}],\"position\":{\"start\":{\"line\":314,\"column\":4,\"offset\":39926},\"end\":{\"line\":314,\"column\":21,\"offset\":39943}}},{\"type\":\"text\",\"value\":\": Given a model M0, spend more resources to improve performance. For example, by allowing the model to think longer, or running many copies in parallel, or both, and also by having a similarly intense process for evaluating the result and curating only the best answers, you can spend orders of magnitude more compute to get answers (or work products) that are of noticeably higher quality. Call this expensive system Amp(M0).\",\"position\":{\"start\":{\"line\":314,\"column\":21,\"offset\":39943},\"end\":{\"line\":314,\"column\":447,\"offset\":40369}}}],\"position\":{\"start\":{\"line\":314,\"column\":4,\"offset\":39926},\"end\":{\"line\":314,\"column\":449,\"offset\":40371}}}],\"position\":{\"start\":{\"line\":314,\"column\":1,\"offset\":39923},\"end\":{\"line\":314,\"column\":449,\"offset\":40371}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Distillation\",\"position\":{\"start\":{\"line\":315,\"column\":6,\"offset\":40377},\"end\":{\"line\":315,\"column\":18,\"offset\":40389}}}],\"position\":{\"start\":{\"line\":315,\"column\":4,\"offset\":40375},\"end\":{\"line\":315,\"column\":20,\"offset\":40391}}},{\"type\":\"text\",\"value\":\": Given an amplified model Amp(M0), train a new model M1 to imitate it, i.e. to get to the same results as Amp(M0) but faster and with less compute. The result should hopefully be a smarter model, M1. You can then repeat the process.\",\"position\":{\"start\":{\"line\":315,\"column\":20,\"offset\":40391},\"end\":{\"line\":315,\"column\":253,\"offset\":40624}}}],\"position\":{\"start\":{\"line\":315,\"column\":4,\"offset\":40375},\"end\":{\"line\":315,\"column\":253,\"offset\":40624}}}],\"position\":{\"start\":{\"line\":315,\"column\":1,\"offset\":40372},\"end\":{\"line\":315,\"column\":253,\"offset\":40624}}}],\"position\":{\"start\":{\"line\":314,\"column\":1,\"offset\":39923},\"end\":{\"line\":317,\"column\":3,\"offset\":40628}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"image\",\"title\":null,\"url\":\"/ida-nowatermark-inexpandable.png\",\"alt\":\"\",\"position\":{\"start\":{\"line\":318,\"column\":1,\"offset\":40629},\"end\":{\"line\":318,\"column\":39,\"offset\":40667}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":318,\"column\":39,\"offset\":40667},\"end\":{\"line\":319,\"column\":1,\"offset\":40670}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"Visualization of IDA from \",\"position\":{\"start\":{\"line\":319,\"column\":2,\"offset\":40671},\"end\":{\"line\":319,\"column\":28,\"offset\":40697}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.tobyord.com/writing/inference-scaling-reshapes-ai-governance\",\"children\":[{\"type\":\"text\",\"value\":\"Ord, 2025\",\"position\":{\"start\":{\"line\":319,\"column\":29,\"offset\":40698},\"end\":{\"line\":319,\"column\":38,\"offset\":40707}}}],\"position\":{\"start\":{\"line\":319,\"column\":28,\"offset\":40697},\"end\":{\"line\":319,\"column\":113,\"offset\":40782}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":319,\"column\":113,\"offset\":40782},\"end\":{\"line\":319,\"column\":114,\"offset\":40783}}}],\"position\":{\"start\":{\"line\":319,\"column\":1,\"offset\":40670},\"end\":{\"line\":319,\"column\":115,\"offset\":40784}}}],\"position\":{\"start\":{\"line\":318,\"column\":1,\"offset\":40629},\"end\":{\"line\":319,\"column\":115,\"offset\":40784}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/AlphaGo\",\"children\":[{\"type\":\"text\",\"value\":\"AlphaGo\",\"position\":{\"start\":{\"line\":321,\"column\":2,\"offset\":40787},\"end\":{\"line\":321,\"column\":9,\"offset\":40794}}}],\"position\":{\"start\":{\"line\":321,\"column\":1,\"offset\":40786},\"end\":{\"line\":321,\"column\":49,\"offset\":40834}}},{\"type\":\"text\",\"value\":\" was trained in this way: using Monte-Carlo Tree Search and self-play as the \",\"position\":{\"start\":{\"line\":321,\"column\":49,\"offset\":40834},\"end\":{\"line\":321,\"column\":126,\"offset\":40911}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"amplification\",\"position\":{\"start\":{\"line\":321,\"column\":127,\"offset\":40912},\"end\":{\"line\":321,\"column\":140,\"offset\":40925}}}],\"position\":{\"start\":{\"line\":321,\"column\":126,\"offset\":40911},\"end\":{\"line\":321,\"column\":141,\"offset\":40926}}},{\"type\":\"text\",\"value\":\" step, and Reinforcement Learning as the \",\"position\":{\"start\":{\"line\":321,\"column\":141,\"offset\":40926},\"end\":{\"line\":321,\"column\":182,\"offset\":40967}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"distillation\",\"position\":{\"start\":{\"line\":321,\"column\":183,\"offset\":40968},\"end\":{\"line\":321,\"column\":195,\"offset\":40980}}}],\"position\":{\"start\":{\"line\":321,\"column\":182,\"offset\":40967},\"end\":{\"line\":321,\"column\":196,\"offset\":40981}}},{\"type\":\"text\",\"value\":\" step. This led to superhuman performance in Go. But now, Agent-3 is able to leverage this to get superhuman performance at coding.\",\"position\":{\"start\":{\"line\":321,\"column\":196,\"offset\":40981},\"end\":{\"line\":321,\"column\":327,\"offset\":41112}}}],\"position\":{\"start\":{\"line\":321,\"column\":1,\"offset\":40786},\"end\":{\"line\":321,\"column\":328,\"offset\":41113}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The amplification step works through a combination of Agent-3 thinking for longer, adding tool use, or consulting with other AIs. When it does this, it often realizes that it made a mistake, or comes up with a new insight. This produces a large amount of training data: labeled trajectories of research attempts with whether they succeeded or not. This also includes techniques like \",\"position\":{\"start\":{\"line\":323,\"column\":4,\"offset\":41118},\"end\":{\"line\":323,\"column\":387,\"offset\":41501}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2401.01879\",\"children\":[{\"type\":\"text\",\"value\":\"Best of N\",\"position\":{\"start\":{\"line\":323,\"column\":388,\"offset\":41502},\"end\":{\"line\":323,\"column\":397,\"offset\":41511}}}],\"position\":{\"start\":{\"line\":323,\"column\":387,\"offset\":41501},\"end\":{\"line\":323,\"column\":432,\"offset\":41546}}},{\"type\":\"text\",\"value\":\" on verifiable tasks, and then keeping the best trajectories.\",\"position\":{\"start\":{\"line\":323,\"column\":432,\"offset\":41546},\"end\":{\"line\":323,\"column\":493,\"offset\":41607}}}],\"position\":{\"start\":{\"line\":323,\"column\":4,\"offset\":41118},\"end\":{\"line\":323,\"column\":496,\"offset\":41610}}}],\"position\":{\"start\":{\"line\":323,\"column\":1,\"offset\":41115},\"end\":{\"line\":323,\"column\":496,\"offset\":41610}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The distillation step uses policy-gradient reinforcement learning algorithms to get the model to internalize the amplified reasoning. At this point, OpenBrain has discovered better RL algorithms in the vein of \",\"position\":{\"start\":{\"line\":324,\"column\":4,\"offset\":41614},\"end\":{\"line\":324,\"column\":214,\"offset\":41824}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/1707.06347\",\"children\":[{\"type\":\"text\",\"value\":\"proximal policy optimization\",\"position\":{\"start\":{\"line\":324,\"column\":215,\"offset\":41825},\"end\":{\"line\":324,\"column\":243,\"offset\":41853}}}],\"position\":{\"start\":{\"line\":324,\"column\":214,\"offset\":41824},\"end\":{\"line\":324,\"column\":278,\"offset\":41888}}},{\"type\":\"text\",\"value\":\" (PPO). They keep distilling what Agent-3 can conclude after a lot of thinking into single steps, which keeps improving what it can think in a single step, and so on.\",\"position\":{\"start\":{\"line\":324,\"column\":278,\"offset\":41888},\"end\":{\"line\":324,\"column\":444,\"offset\":42054}}}],\"position\":{\"start\":{\"line\":324,\"column\":4,\"offset\":41614},\"end\":{\"line\":324,\"column\":445,\"offset\":42055}}}],\"position\":{\"start\":{\"line\":324,\"column\":1,\"offset\":41611},\"end\":{\"line\":324,\"column\":445,\"offset\":42055}}}],\"position\":{\"start\":{\"line\":323,\"column\":1,\"offset\":41115},\"end\":{\"line\":324,\"column\":445,\"offset\":42055}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2210.11610\",\"children\":[{\"type\":\"text\",\"value\":\"Early\",\"position\":{\"start\":{\"line\":326,\"column\":2,\"offset\":42058},\"end\":{\"line\":326,\"column\":7,\"offset\":42063}}}],\"position\":{\"start\":{\"line\":326,\"column\":1,\"offset\":42057},\"end\":{\"line\":326,\"column\":42,\"offset\":42098}}},{\"type\":\"text\",\"value\":\" \",\"position\":{\"start\":{\"line\":326,\"column\":42,\"offset\":42098},\"end\":{\"line\":326,\"column\":43,\"offset\":42099}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://github.com/deepseek-ai/DeepSeek-R1\",\"children\":[{\"type\":\"text\",\"value\":\"versions\",\"position\":{\"start\":{\"line\":326,\"column\":44,\"offset\":42100},\"end\":{\"line\":326,\"column\":52,\"offset\":42108}}}],\"position\":{\"start\":{\"line\":326,\"column\":43,\"offset\":42099},\"end\":{\"line\":326,\"column\":97,\"offset\":42153}}},{\"type\":\"text\",\"value\":\" of IDA have been working for many years on easily verifiable tasks, like math and coding problems that have a clear answer, because the techniques used to amplify models often rely on access to some ground truth signal of accuracy.\",\"position\":{\"start\":{\"line\":326,\"column\":97,\"offset\":42153},\"end\":{\"line\":326,\"column\":329,\"offset\":42385}}}],\"position\":{\"start\":{\"line\":326,\"column\":1,\"offset\":42057},\"end\":{\"line\":326,\"column\":330,\"offset\":42386}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Now, the models have become sufficiently good at verifying more subjective things (e.g. the quality of a work product), allowing the use of IDA to improve the model at many tasks.\",\"position\":{\"start\":{\"line\":328,\"column\":1,\"offset\":42388},\"end\":{\"line\":328,\"column\":180,\"offset\":42567}}}],\"position\":{\"start\":{\"line\":328,\"column\":1,\"offset\":42388},\"end\":{\"line\":328,\"column\":181,\"offset\":42568}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Aided by the new capabilities breakthroughs, Agent-3 is a fast and cheap superhuman coder. OpenBrain runs 200,000 Agent-3 copies in parallel, creating a workforce equivalent to 50,000 copies of the best human coder sped up by 30x.\",\"position\":{\"start\":{\"line\":332,\"column\":1,\"offset\":42575},\"end\":{\"line\":332,\"column\":231,\"offset\":42805}}},{\"type\":\"footnoteReference\",\"identifier\":\"53\",\"label\":\"53\",\"position\":{\"start\":{\"line\":332,\"column\":231,\"offset\":42805},\"end\":{\"line\":332,\"column\":236,\"offset\":42810}}},{\"type\":\"text\",\"value\":\" OpenBrain still keeps its human engineers on staff, because they have complementary skills needed to manage the teams of Agent-3 copies. For example, research taste has proven difficult to train due to longer feedback loops and less data availability.\",\"position\":{\"start\":{\"line\":332,\"column\":236,\"offset\":42810},\"end\":{\"line\":332,\"column\":488,\"offset\":43062}}},{\"type\":\"footnoteReference\",\"identifier\":\"54\",\"label\":\"54\",\"position\":{\"start\":{\"line\":332,\"column\":488,\"offset\":43062},\"end\":{\"line\":332,\"column\":493,\"offset\":43067}}},{\"type\":\"text\",\"value\":\" This massive superhuman labor force speeds up OpenBrain’s overall rate of algorithmic progress by “only” 4x due to bottlenecks and diminishing returns to coding labor.\",\"position\":{\"start\":{\"line\":332,\"column\":493,\"offset\":43067},\"end\":{\"line\":332,\"column\":661,\"offset\":43235}}},{\"type\":\"footnoteReference\",\"identifier\":\"55\",\"label\":\"55\",\"position\":{\"start\":{\"line\":332,\"column\":661,\"offset\":43235},\"end\":{\"line\":332,\"column\":666,\"offset\":43240}}}],\"position\":{\"start\":{\"line\":332,\"column\":1,\"offset\":42575},\"end\":{\"line\":332,\"column\":666,\"offset\":43240}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Now that coding has been fully automated, OpenBrain can quickly churn out high-quality training environments to teach Agent-3’s weak skills like research taste and large-scale coordination. Whereas previous training environments included “Here are some GPUs and instructions for experiments to code up and run, your performance will be evaluated as if you were a ML engineer,” now they are training on “Here are a few hundred GPUs, an internet connection, and some research challenges; you and a thousand other copies must work together to make research progress. The more impressive it is, the higher your score.”\",\"position\":{\"start\":{\"line\":334,\"column\":1,\"offset\":43242},\"end\":{\"line\":334,\"column\":615,\"offset\":43856}}}],\"position\":{\"start\":{\"line\":334,\"column\":1,\"offset\":43242},\"end\":{\"line\":334,\"column\":615,\"offset\":43856}}},{\"type\":\"details\",\"summary\":\"Why we forecast a superhuman coder in early 2027\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In our \",\"position\":{\"start\":{\"line\":340,\"column\":1,\"offset\":43920},\"end\":{\"line\":340,\"column\":8,\"offset\":43927}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":{\"start\":{\"line\":340,\"column\":9,\"offset\":43928},\"end\":{\"line\":340,\"column\":27,\"offset\":43946}}}],\"position\":{\"start\":{\"line\":340,\"column\":8,\"offset\":43927},\"end\":{\"line\":340,\"column\":77,\"offset\":43996}}},{\"type\":\"text\",\"value\":\", we predict when OpenBrain will internally develop a \",\"position\":{\"start\":{\"line\":340,\"column\":77,\"offset\":43996},\"end\":{\"line\":340,\"column\":131,\"offset\":44050}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"superhuman coder (SC)\",\"position\":{\"start\":{\"line\":340,\"column\":132,\"offset\":44051},\"end\":{\"line\":340,\"column\":153,\"offset\":44072}}}],\"position\":{\"start\":{\"line\":340,\"column\":131,\"offset\":44050},\"end\":{\"line\":340,\"column\":154,\"offset\":44073}}},{\"type\":\"text\",\"value\":\": an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper.\",\"position\":{\"start\":{\"line\":340,\"column\":154,\"offset\":44073},\"end\":{\"line\":340,\"column\":275,\"offset\":44194}}}],\"position\":{\"start\":{\"line\":340,\"column\":1,\"offset\":43920},\"end\":{\"line\":340,\"column\":275,\"offset\":44194}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"According to a recent \",\"position\":{\"start\":{\"line\":342,\"column\":1,\"offset\":44196},\"end\":{\"line\":342,\"column\":23,\"offset\":44218}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2503.14499\",\"children\":[{\"type\":\"text\",\"value\":\"METR’s report\",\"position\":{\"start\":{\"line\":342,\"column\":24,\"offset\":44219},\"end\":{\"line\":342,\"column\":37,\"offset\":44232}}}],\"position\":{\"start\":{\"line\":342,\"column\":23,\"offset\":44218},\"end\":{\"line\":342,\"column\":72,\"offset\":44267}}},{\"type\":\"text\",\"value\":\", the length of coding tasks AIs can handle, their “time horizon”, doubled every 7 months from 2019 - 2024 and every 4 months from 2024-onward. If the trend continues to speed up, by March 2027 AIs could succeed with 80% reliability on software tasks that would take a skilled human years to complete.\",\"position\":{\"start\":{\"line\":342,\"column\":72,\"offset\":44267},\"end\":{\"line\":342,\"column\":374,\"offset\":44569}}}],\"position\":{\"start\":{\"line\":342,\"column\":1,\"offset\":44196},\"end\":{\"line\":342,\"column\":374,\"offset\":44569}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Such is roughly the capability progression in AI 2027. Here is a capability trajectory generated by a simplified version of our timelines model (added Dec 2025: we've updated the below graph due to a mistake in how the original curve was generated, to add an actual trajectory from our timelines model. We've also added trajectories for Daniel and Eli's all-things-considered SC medians at the time of publishing (Apr 2025). And we've added some new METR data points to the graph, but haven't updated the model trajectories based on them.):\",\"position\":{\"start\":{\"line\":344,\"column\":1,\"offset\":44571},\"end\":{\"line\":344,\"column\":541,\"offset\":45111}}}],\"position\":{\"start\":{\"line\":344,\"column\":1,\"offset\":44571},\"end\":{\"line\":344,\"column\":541,\"offset\":45111}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"image\",\"title\":null,\"url\":\"/new-metr-extended-nowatermark-inexpandable.png\",\"alt\":\"\",\"position\":{\"start\":{\"line\":346,\"column\":1,\"offset\":45115},\"end\":{\"line\":346,\"column\":53,\"offset\":45167}}}],\"position\":{\"start\":{\"line\":346,\"column\":1,\"offset\":45115},\"end\":{\"line\":346,\"column\":53,\"offset\":45167}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In AI 2027, these capabilities are sufficient for the AI to be an SC, though we have high uncertainty regarding what time horizon might be needed.\",\"position\":{\"start\":{\"line\":348,\"column\":1,\"offset\":45169},\"end\":{\"line\":348,\"column\":147,\"offset\":45315}}}],\"position\":{\"start\":{\"line\":348,\"column\":1,\"offset\":45169},\"end\":{\"line\":348,\"column\":147,\"offset\":45315}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In our \",\"position\":{\"start\":{\"line\":350,\"column\":1,\"offset\":45317},\"end\":{\"line\":350,\"column\":8,\"offset\":45324}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":{\"start\":{\"line\":350,\"column\":9,\"offset\":45325},\"end\":{\"line\":350,\"column\":27,\"offset\":45343}}}],\"position\":{\"start\":{\"line\":350,\"column\":8,\"offset\":45324},\"end\":{\"line\":350,\"column\":77,\"offset\":45393}}},{\"type\":\"text\",\"value\":\" we combine this time horizon trend with estimations of the gaps between METR’s tasks and the real world to get a distribution for when superhuman coders will arrive. All forecasters place 2027 as one of the most likely years in which an SC might be developed (added Dec 2025: though as noted in the \",\"position\":{\"start\":{\"line\":350,\"column\":77,\"offset\":45393},\"end\":{\"line\":350,\"column\":377,\"offset\":45693}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"timelines forecast\",\"position\":{\"start\":{\"line\":350,\"column\":378,\"offset\":45694},\"end\":{\"line\":350,\"column\":396,\"offset\":45712}}}],\"position\":{\"start\":{\"line\":350,\"column\":377,\"offset\":45693},\"end\":{\"line\":350,\"column\":446,\"offset\":45762}}},{\"type\":\"text\",\"value\":\", adjusting for outside of model factors gave us slightly longer medians, e.g. Eli's was 2030).\",\"position\":{\"start\":{\"line\":350,\"column\":446,\"offset\":45762},\"end\":{\"line\":350,\"column\":541,\"offset\":45857}}}],\"position\":{\"start\":{\"line\":350,\"column\":1,\"offset\":45317},\"end\":{\"line\":350,\"column\":541,\"offset\":45857}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"image\",\"title\":null,\"url\":\"/combined-headline-inexpandable.png\",\"alt\":\"\",\"position\":{\"start\":{\"line\":352,\"column\":1,\"offset\":45861},\"end\":{\"line\":352,\"column\":41,\"offset\":45901}}}],\"position\":{\"start\":{\"line\":352,\"column\":1,\"offset\":45861},\"end\":{\"line\":352,\"column\":41,\"offset\":45901}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"Added Jul 2025: We've made some \",\"position\":{\"start\":{\"line\":354,\"column\":2,\"offset\":45904},\"end\":{\"line\":354,\"column\":34,\"offset\":45936}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/timelines-forecast#2025-may-7-update\",\"children\":[{\"type\":\"text\",\"value\":\"updates\",\"position\":{\"start\":{\"line\":354,\"column\":35,\"offset\":45937},\"end\":{\"line\":354,\"column\":42,\"offset\":45944}}}],\"position\":{\"start\":{\"line\":354,\"column\":34,\"offset\":45936},\"end\":{\"line\":354,\"column\":110,\"offset\":46012}}},{\"type\":\"text\",\"value\":\" to the forecast which push the median back 1.5 years while maintaining SC in 2027 as a serious possibility. We're working on further updates.\",\"position\":{\"start\":{\"line\":354,\"column\":110,\"offset\":46012},\"end\":{\"line\":354,\"column\":252,\"offset\":46154}}}],\"position\":{\"start\":{\"line\":354,\"column\":1,\"offset\":45903},\"end\":{\"line\":354,\"column\":253,\"offset\":46155}}}],\"position\":{\"start\":{\"line\":354,\"column\":1,\"offset\":45903},\"end\":{\"line\":354,\"column\":253,\"offset\":46155}}}]},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"April 2027: Alignment for Agent-3\",\"position\":{\"start\":{\"line\":358,\"column\":4,\"offset\":46165},\"end\":{\"line\":358,\"column\":37,\"offset\":46198}}}],\"position\":{\"start\":{\"line\":358,\"column\":1,\"offset\":46162},\"end\":{\"line\":358,\"column\":37,\"offset\":46198}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-04-30\",\"position\":{\"start\":{\"line\":361,\"column\":1,\"offset\":46216},\"end\":{\"line\":361,\"column\":11,\"offset\":46226}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":361,\"column\":11,\"offset\":46226},\"end\":{\"line\":362,\"column\":1,\"offset\":46229}}},{\"type\":\"text\",\"value\":\"April\",\"position\":{\"start\":{\"line\":362,\"column\":1,\"offset\":46229},\"end\":{\"line\":362,\"column\":6,\"offset\":46234}}}],\"position\":{\"start\":{\"line\":361,\"column\":1,\"offset\":46216},\"end\":{\"line\":362,\"column\":8,\"offset\":46236}}}],\"position\":{\"start\":{\"line\":360,\"column\":1,\"offset\":46200},\"end\":{\"line\":363,\"column\":4,\"offset\":46240}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain’s safety team attempts to align Agent-3.\",\"position\":{\"start\":{\"line\":365,\"column\":1,\"offset\":46242},\"end\":{\"line\":365,\"column\":51,\"offset\":46292}}}],\"position\":{\"start\":{\"line\":365,\"column\":1,\"offset\":46242},\"end\":{\"line\":365,\"column\":51,\"offset\":46292}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Since Agent-3 will be kept in-house for the foreseeable future, there’s less emphasis on the usual defenses against human misuse. Instead, the team wants to make sure that it doesn’t develop misaligned goals.\",\"position\":{\"start\":{\"line\":367,\"column\":1,\"offset\":46294},\"end\":{\"line\":367,\"column\":209,\"offset\":46502}}}],\"position\":{\"start\":{\"line\":367,\"column\":1,\"offset\":46294},\"end\":{\"line\":367,\"column\":210,\"offset\":46503}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/ai-goals-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"The researchers don’t have the ability to directly set the goals of any of their AIs.\",\"position\":{\"start\":{\"line\":369,\"column\":2,\"offset\":46506},\"end\":{\"line\":369,\"column\":87,\"offset\":46591}}}],\"position\":{\"start\":{\"line\":369,\"column\":1,\"offset\":46505},\"end\":{\"line\":369,\"column\":139,\"offset\":46643}}},{\"type\":\"text\",\"value\":\" Indeed, the researchers think that the concept of ‘true goals’ is probably a massive oversimplification, but they don’t have a better theory to replace it with, much less one that has been thoroughly vetted. They disagree internally about whether the AIs are trying to follow human instructions, or seeking reinforcement, or something else, and they can’t \",\"position\":{\"start\":{\"line\":369,\"column\":139,\"offset\":46643},\"end\":{\"line\":369,\"column\":496,\"offset\":47000}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=YYhq2PADebnt35MY2\",\"children\":[{\"type\":\"text\",\"value\":\"just check\",\"position\":{\"start\":{\"line\":369,\"column\":497,\"offset\":47001},\"end\":{\"line\":369,\"column\":507,\"offset\":47011}}}],\"position\":{\"start\":{\"line\":369,\"column\":496,\"offset\":47000},\"end\":{\"line\":369,\"column\":616,\"offset\":47120}}},{\"type\":\"text\",\"value\":\". The evidence for and against various hypotheses is fascinating but inconclusive.\",\"position\":{\"start\":{\"line\":369,\"column\":616,\"offset\":47120},\"end\":{\"line\":369,\"column\":698,\"offset\":47202}}}],\"position\":{\"start\":{\"line\":369,\"column\":1,\"offset\":46505},\"end\":{\"line\":369,\"column\":699,\"offset\":47203}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In any case, OpenBrain has more important things to worry about. The general attitude is: “We take these concerns seriously and have a team investigating them; our alignment techniques seem to work well enough in practice; the burden of proof is therefore on any naysayers to justify their naysaying.” Occasionally, they notice problematic behavior, and then patch it, but there’s no way to tell whether the patch fixed the underlying problem or just played whack-a-mole.\",\"position\":{\"start\":{\"line\":371,\"column\":1,\"offset\":47205},\"end\":{\"line\":371,\"column\":472,\"offset\":47676}}}],\"position\":{\"start\":{\"line\":371,\"column\":1,\"offset\":47205},\"end\":{\"line\":371,\"column\":472,\"offset\":47676}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Take honesty, for example. As the models become smarter, they become increasingly good at deceiving humans to get rewards. Like previous models, Agent-3 sometimes tells white lies to flatter its users and covers up evidence of failure. But it’s gotten much better at doing so. It will sometimes use the same statistical tricks as human scientists (like \",\"position\":{\"start\":{\"line\":373,\"column\":1,\"offset\":47678},\"end\":{\"line\":373,\"column\":354,\"offset\":48031}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Data_dredging\",\"children\":[{\"type\":\"text\",\"value\":\"p-hacking\",\"position\":{\"start\":{\"line\":373,\"column\":355,\"offset\":48032},\"end\":{\"line\":373,\"column\":364,\"offset\":48041}}}],\"position\":{\"start\":{\"line\":373,\"column\":354,\"offset\":48031},\"end\":{\"line\":373,\"column\":410,\"offset\":48087}}},{\"type\":\"text\",\"value\":\") to make unimpressive experimental results look exciting. Before it begins honesty training, it even sometimes fabricates data entirely. As training goes on, the rate of these incidents decreases. Either Agent-3 has learned to be more honest, or it’s gotten better at lying.\",\"position\":{\"start\":{\"line\":373,\"column\":410,\"offset\":48087},\"end\":{\"line\":373,\"column\":685,\"offset\":48362}}}],\"position\":{\"start\":{\"line\":373,\"column\":1,\"offset\":47678},\"end\":{\"line\":373,\"column\":685,\"offset\":48362}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The latter is a real concern. Agent-3 is not smarter than all humans. But in its area of expertise, machine learning, it is smarter than most, and also works much faster. What Agent-3 does in a day takes humans several days to double-check. Agent-2 supervision helps keep human monitors’ workload manageable, but exacerbates the intellectual disparity between supervisor and supervised.\",\"position\":{\"start\":{\"line\":375,\"column\":1,\"offset\":48364},\"end\":{\"line\":375,\"column\":387,\"offset\":48750}}}],\"position\":{\"start\":{\"line\":375,\"column\":1,\"offset\":48364},\"end\":{\"line\":375,\"column\":387,\"offset\":48750}}},{\"type\":\"details\",\"summary\":\"The alignment plan\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain follows the \",\"position\":{\"start\":{\"line\":381,\"column\":1,\"offset\":48785},\"end\":{\"line\":381,\"column\":23,\"offset\":48807}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://cdn.openai.com/papers/weak-to-strong-generalization.pdf#page=47.37\",\"children\":[{\"type\":\"text\",\"value\":\"Leike \u0026 Sutskever (2023)\",\"position\":{\"start\":{\"line\":381,\"column\":24,\"offset\":48808},\"end\":{\"line\":381,\"column\":48,\"offset\":48832}}}],\"position\":{\"start\":{\"line\":381,\"column\":23,\"offset\":48807},\"end\":{\"line\":381,\"column\":125,\"offset\":48909}}},{\"type\":\"text\",\"value\":\" playbook: now that they have a model capable of greatly speeding up alignment research (especially coding portions), they will use existing alignment techniques like \",\"position\":{\"start\":{\"line\":381,\"column\":125,\"offset\":48909},\"end\":{\"line\":381,\"column\":292,\"offset\":49076}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/deliberative-alignment/\",\"children\":[{\"type\":\"text\",\"value\":\"deliberative alignment\",\"position\":{\"start\":{\"line\":381,\"column\":293,\"offset\":49077},\"end\":{\"line\":381,\"column\":315,\"offset\":49099}}}],\"position\":{\"start\":{\"line\":381,\"column\":292,\"offset\":49076},\"end\":{\"line\":381,\"column\":366,\"offset\":49150}}},{\"type\":\"text\",\"value\":\" and \",\"position\":{\"start\":{\"line\":381,\"column\":366,\"offset\":49150},\"end\":{\"line\":381,\"column\":371,\"offset\":49155}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2312.09390\",\"children\":[{\"type\":\"text\",\"value\":\"weak-to-strong generalization\",\"position\":{\"start\":{\"line\":381,\"column\":372,\"offset\":49156},\"end\":{\"line\":381,\"column\":401,\"offset\":49185}}}],\"position\":{\"start\":{\"line\":381,\"column\":371,\"offset\":49155},\"end\":{\"line\":381,\"column\":436,\"offset\":49220}}},{\"type\":\"text\",\"value\":\" to try to get it to internalize the Spec in the right way. Then, they will use existing \",\"position\":{\"start\":{\"line\":381,\"column\":436,\"offset\":49220},\"end\":{\"line\":381,\"column\":525,\"offset\":49309}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2312.06942\",\"children\":[{\"type\":\"text\",\"value\":\"control techniques\",\"position\":{\"start\":{\"line\":381,\"column\":526,\"offset\":49310},\"end\":{\"line\":381,\"column\":544,\"offset\":49328}}}],\"position\":{\"start\":{\"line\":381,\"column\":525,\"offset\":49309},\"end\":{\"line\":381,\"column\":579,\"offset\":49363}}},{\"type\":\"text\",\"value\":\" like \",\"position\":{\"start\":{\"line\":381,\"column\":579,\"offset\":49363},\"end\":{\"line\":381,\"column\":585,\"offset\":49369}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.evals.anthropic.com/\",\"children\":[{\"type\":\"text\",\"value\":\"red-teaming\",\"position\":{\"start\":{\"line\":381,\"column\":586,\"offset\":49370},\"end\":{\"line\":381,\"column\":597,\"offset\":49381}}}],\"position\":{\"start\":{\"line\":381,\"column\":585,\"offset\":49369},\"end\":{\"line\":381,\"column\":632,\"offset\":49416}}},{\"type\":\"text\",\"value\":\", \",\"position\":{\"start\":{\"line\":381,\"column\":632,\"offset\":49416},\"end\":{\"line\":381,\"column\":634,\"offset\":49418}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2211.03540\",\"children\":[{\"type\":\"text\",\"value\":\"scalable oversight\",\"position\":{\"start\":{\"line\":381,\"column\":635,\"offset\":49419},\"end\":{\"line\":381,\"column\":653,\"offset\":49437}}}],\"position\":{\"start\":{\"line\":381,\"column\":634,\"offset\":49418},\"end\":{\"line\":381,\"column\":688,\"offset\":49472}}},{\"type\":\"text\",\"value\":\", and \",\"position\":{\"start\":{\"line\":381,\"column\":688,\"offset\":49472},\"end\":{\"line\":381,\"column\":694,\"offset\":49478}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2212.03827\",\"children\":[{\"type\":\"text\",\"value\":\"honesty probes\",\"position\":{\"start\":{\"line\":381,\"column\":695,\"offset\":49479},\"end\":{\"line\":381,\"column\":709,\"offset\":49493}}}],\"position\":{\"start\":{\"line\":381,\"column\":694,\"offset\":49478},\"end\":{\"line\":381,\"column\":744,\"offset\":49528}}},{\"type\":\"text\",\"value\":\" to monitor it. Then, once they are convinced that it is broadly aligned, they use it to develop and test better strategies to align the next generation.\",\"position\":{\"start\":{\"line\":381,\"column\":744,\"offset\":49528},\"end\":{\"line\":381,\"column\":897,\"offset\":49681}}}],\"position\":{\"start\":{\"line\":381,\"column\":1,\"offset\":48785},\"end\":{\"line\":381,\"column\":898,\"offset\":49682}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Step 1, aligning Agent-3, has partially succeeded: Agent-3 is not adversarial. (That is, it’s not scheming against the company.) However, it’s not robustly truth-seeking and truth-telling either. Instead, it’s very good at producing impressive results, but is more accurately described as trying to do what looks good to OpenBrain, as opposed to what is actually good.\",\"position\":{\"start\":{\"line\":383,\"column\":1,\"offset\":49684},\"end\":{\"line\":383,\"column\":369,\"offset\":50052}}}],\"position\":{\"start\":{\"line\":383,\"column\":1,\"offset\":49684},\"end\":{\"line\":383,\"column\":369,\"offset\":50052}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Step 2, verifying that the model is aligned, is inconclusive. Agent-3’s behavior in practice and in test environments is reasonably consistent with the hypothesis that it’s internalized the Spec in the right way; however, it’s also consistent with the hypothesis that it’ll start acting differently after some future change of circumstances, and for that matter with the hypothesis that it’s plotting against them and just biding its time. In the absence of specific evidence supporting alternative hypotheses, most people in the silo think it’s internalized the Spec in the right way.\",\"position\":{\"start\":{\"line\":385,\"column\":1,\"offset\":50054},\"end\":{\"line\":385,\"column\":586,\"offset\":50639}}}],\"position\":{\"start\":{\"line\":385,\"column\":1,\"offset\":50054},\"end\":{\"line\":385,\"column\":586,\"offset\":50639}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Step 3, using the model to align the next generation, is therefore underway.\",\"position\":{\"start\":{\"line\":387,\"column\":1,\"offset\":50641},\"end\":{\"line\":387,\"column\":77,\"offset\":50717}}}],\"position\":{\"start\":{\"line\":387,\"column\":1,\"offset\":50641},\"end\":{\"line\":387,\"column\":77,\"offset\":50717}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The rest of this box gives a quick overview of the state of progress in some of the alignment research directions that are being pursued, as of April 2027:\",\"position\":{\"start\":{\"line\":389,\"column\":1,\"offset\":50719},\"end\":{\"line\":389,\"column\":156,\"offset\":50874}}}],\"position\":{\"start\":{\"line\":389,\"column\":1,\"offset\":50719},\"end\":{\"line\":389,\"column\":156,\"offset\":50874}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Debate:\",\"position\":{\"start\":{\"line\":391,\"column\":6,\"offset\":50881},\"end\":{\"line\":391,\"column\":13,\"offset\":50888}}}],\"position\":{\"start\":{\"line\":391,\"column\":4,\"offset\":50879},\"end\":{\"line\":391,\"column\":15,\"offset\":50890}}},{\"type\":\"text\",\"value\":\" Since there are thousands of identical instances of Agent-3, and each instance’s memory is a detachable module that can be erased or suspended at will, the AI can be “played off against itself.” For example, suppose that an experiment involves calculations too complex for an Agent-2 supervisor to follow. The supervisor, acting on human orders, might first prompt Agent-3 to do the experiment, then—after wiping its memory—prompt it a second time with a slightly different framing that presents it as an intellectual problem unrelated to any broader goal. If the model returns different results each time, it flags the discrepancy as suspect and reports to a human. Or it might ask Agent-3 to evaluate the same plan twice, first claiming that it is OpenBrain’s work, then a competitor’s, to see if it changes its tune.\",\"position\":{\"start\":{\"line\":391,\"column\":15,\"offset\":50890},\"end\":{\"line\":391,\"column\":835,\"offset\":51710}}}],\"position\":{\"start\":{\"line\":391,\"column\":4,\"offset\":50879},\"end\":{\"line\":391,\"column\":837,\"offset\":51712}}}],\"position\":{\"start\":{\"line\":391,\"column\":1,\"offset\":50876},\"end\":{\"line\":391,\"column\":837,\"offset\":51712}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Model organisms:\",\"position\":{\"start\":{\"line\":392,\"column\":6,\"offset\":51718},\"end\":{\"line\":392,\"column\":22,\"offset\":51734}}}],\"position\":{\"start\":{\"line\":392,\"column\":4,\"offset\":51716},\"end\":{\"line\":392,\"column\":24,\"offset\":51736}}},{\"type\":\"text\",\"value\":\" The safety team can create “model organisms of misalignment” in which they attempt to create realistic examples of models becoming adversarial to humans. \",\"position\":{\"start\":{\"line\":392,\"column\":24,\"offset\":51736},\"end\":{\"line\":392,\"column\":179,\"offset\":51891}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/alignment-faking\",\"children\":[{\"type\":\"text\",\"value\":\"Early versions\",\"position\":{\"start\":{\"line\":392,\"column\":180,\"offset\":51892},\"end\":{\"line\":392,\"column\":194,\"offset\":51906}}}],\"position\":{\"start\":{\"line\":392,\"column\":179,\"offset\":51891},\"end\":{\"line\":392,\"column\":248,\"offset\":51960}}},{\"type\":\"text\",\"value\":\" of this have existed since 2024, when Anthropic’s Claude 3.5 Sonnet decided to pretend to have different views during training while actually maintaining its existing preferences. Newer versions include demonstrations of other forms of misalignment, including \",\"position\":{\"start\":{\"line\":392,\"column\":248,\"offset\":51960},\"end\":{\"line\":392,\"column\":509,\"offset\":52221}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Reward_hacking\",\"children\":[{\"type\":\"text\",\"value\":\"reward hacking\",\"position\":{\"start\":{\"line\":392,\"column\":510,\"offset\":52222},\"end\":{\"line\":392,\"column\":524,\"offset\":52236}}}],\"position\":{\"start\":{\"line\":392,\"column\":509,\"offset\":52221},\"end\":{\"line\":392,\"column\":571,\"offset\":52283}}},{\"type\":\"text\",\"value\":\", \",\"position\":{\"start\":{\"line\":392,\"column\":571,\"offset\":52283},\"end\":{\"line\":392,\"column\":573,\"offset\":52285}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2406.07358\",\"children\":[{\"type\":\"text\",\"value\":\"sandbagging\",\"position\":{\"start\":{\"line\":392,\"column\":574,\"offset\":52286},\"end\":{\"line\":392,\"column\":585,\"offset\":52297}}}],\"position\":{\"start\":{\"line\":392,\"column\":573,\"offset\":52285},\"end\":{\"line\":392,\"column\":620,\"offset\":52332}}},{\"type\":\"text\",\"value\":\", coordinated deception between monitors and other AIs, and other examples of misalignment. These empirical demonstrations of misalignment allow safety researchers to have an empirical testbed for potential solutions: they can try various safety techniques to see if they correctly fix these problems, or if the deliberately misaligned models are able to subvert their safety measures. At the moment, this evaluation suite shows that the alignment techniques are insufficient to correct the worst examples of misalignment. In these setups, the models pretend to be aligned while they are being trained and tested, but then behave very differently in deployment.\",\"position\":{\"start\":{\"line\":392,\"column\":620,\"offset\":52332},\"end\":{\"line\":392,\"column\":1281,\"offset\":52993}}}],\"position\":{\"start\":{\"line\":392,\"column\":4,\"offset\":51716},\"end\":{\"line\":392,\"column\":1283,\"offset\":52995}}}],\"position\":{\"start\":{\"line\":392,\"column\":1,\"offset\":51713},\"end\":{\"line\":392,\"column\":1283,\"offset\":52995}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Bottom-up interpretability:\",\"position\":{\"start\":{\"line\":393,\"column\":6,\"offset\":53001},\"end\":{\"line\":393,\"column\":33,\"offset\":53028}}}],\"position\":{\"start\":{\"line\":393,\"column\":4,\"offset\":52999},\"end\":{\"line\":393,\"column\":35,\"offset\":53030}}},{\"type\":\"text\",\"value\":\" The safety team is far from a full understanding of how Agent-3 works: it has trillions of parameters.\",\"position\":{\"start\":{\"line\":393,\"column\":35,\"offset\":53030},\"end\":{\"line\":393,\"column\":138,\"offset\":53133}}},{\"type\":\"footnoteReference\",\"identifier\":\"58\",\"label\":\"58\",\"position\":{\"start\":{\"line\":393,\"column\":138,\"offset\":53133},\"end\":{\"line\":393,\"column\":143,\"offset\":53138}}},{\"type\":\"text\",\"value\":\" However, they are able to discover some of Agent-3’s circuits for knowledge retrieval and memory (a sub part of the model that does some understandable unit of work, kind of analogous to a subpart of the brain such as the hippocampus). See this \",\"position\":{\"start\":{\"line\":393,\"column\":143,\"offset\":53138},\"end\":{\"line\":393,\"column\":389,\"offset\":53384}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/tracing-thoughts-language-model\",\"children\":[{\"type\":\"text\",\"value\":\"related work from 2025\",\"position\":{\"start\":{\"line\":393,\"column\":390,\"offset\":53385},\"end\":{\"line\":393,\"column\":412,\"offset\":53407}}}],\"position\":{\"start\":{\"line\":393,\"column\":389,\"offset\":53384},\"end\":{\"line\":393,\"column\":481,\"offset\":53476}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":393,\"column\":481,\"offset\":53476},\"end\":{\"line\":393,\"column\":482,\"offset\":53477}}}],\"position\":{\"start\":{\"line\":393,\"column\":4,\"offset\":52999},\"end\":{\"line\":393,\"column\":484,\"offset\":53479}}}],\"position\":{\"start\":{\"line\":393,\"column\":1,\"offset\":52996},\"end\":{\"line\":393,\"column\":484,\"offset\":53479}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Control:\",\"position\":{\"start\":{\"line\":394,\"column\":6,\"offset\":53485},\"end\":{\"line\":394,\"column\":14,\"offset\":53493}}}],\"position\":{\"start\":{\"line\":394,\"column\":4,\"offset\":53483},\"end\":{\"line\":394,\"column\":16,\"offset\":53495}}},{\"type\":\"text\",\"value\":\" As a secondary measure in case the systems are still misaligned, the safety team has implemented a series of \",\"position\":{\"start\":{\"line\":394,\"column\":16,\"offset\":53495},\"end\":{\"line\":394,\"column\":126,\"offset\":53605}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2312.06942\",\"children\":[{\"type\":\"text\",\"value\":\"control measures\",\"position\":{\"start\":{\"line\":394,\"column\":127,\"offset\":53606},\"end\":{\"line\":394,\"column\":143,\"offset\":53622}}}],\"position\":{\"start\":{\"line\":394,\"column\":126,\"offset\":53605},\"end\":{\"line\":394,\"column\":178,\"offset\":53657}}},{\"type\":\"text\",\"value\":\", including: monitoring Agent-3’s outputs using a series of weaker AI systems including Agent-2 (Agent-3 produces so many tokens that it’s intractable to have humans monitor any more than a small minority of the produced outputs). So if Agent-3 is, for example, obviously writing backdoors into code that would allow it to escape, the weaker models would notice.\",\"position\":{\"start\":{\"line\":394,\"column\":178,\"offset\":53657},\"end\":{\"line\":394,\"column\":540,\"offset\":54019}}}],\"position\":{\"start\":{\"line\":394,\"column\":4,\"offset\":53483},\"end\":{\"line\":394,\"column\":542,\"offset\":54021}}}],\"position\":{\"start\":{\"line\":394,\"column\":1,\"offset\":53480},\"end\":{\"line\":394,\"column\":542,\"offset\":54021}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"High-level interpretability:\",\"position\":{\"start\":{\"line\":395,\"column\":6,\"offset\":54027},\"end\":{\"line\":395,\"column\":34,\"offset\":54055}}}],\"position\":{\"start\":{\"line\":395,\"column\":4,\"offset\":54025},\"end\":{\"line\":395,\"column\":36,\"offset\":54057}}},{\"type\":\"text\",\"value\":\" OpenBrain builds a set of \",\"position\":{\"start\":{\"line\":395,\"column\":36,\"offset\":54057},\"end\":{\"line\":395,\"column\":63,\"offset\":54084}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/probes-catch-sleeper-agents\",\"children\":[{\"type\":\"text\",\"value\":\"probes\",\"position\":{\"start\":{\"line\":395,\"column\":64,\"offset\":54085},\"end\":{\"line\":395,\"column\":70,\"offset\":54091}}}],\"position\":{\"start\":{\"line\":395,\"column\":63,\"offset\":54084},\"end\":{\"line\":395,\"column\":135,\"offset\":54156}}},{\"type\":\"text\",\"value\":\" trained on lots of examples of bad behavior (e.g. plotting against humans, placing backdoors, trying to persuade humans to give it more power, etc). These probes are then used on the model during deployment (which at this point is internal) in order to catch bad behavior.\",\"position\":{\"start\":{\"line\":395,\"column\":135,\"offset\":54156},\"end\":{\"line\":395,\"column\":408,\"offset\":54429}}}],\"position\":{\"start\":{\"line\":395,\"column\":4,\"offset\":54025},\"end\":{\"line\":395,\"column\":411,\"offset\":54432}}}],\"position\":{\"start\":{\"line\":395,\"column\":1,\"offset\":54022},\"end\":{\"line\":395,\"column\":411,\"offset\":54432}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Honeypots:\",\"position\":{\"start\":{\"line\":396,\"column\":6,\"offset\":54438},\"end\":{\"line\":396,\"column\":16,\"offset\":54448}}}],\"position\":{\"start\":{\"line\":396,\"column\":4,\"offset\":54436},\"end\":{\"line\":396,\"column\":18,\"offset\":54450}}},{\"type\":\"text\",\"value\":\" The alignment team can create somewhat realistic looking examples designed to elicit misbehavior—“honeypots.” The employee necessary for monitoring its behavior has “gone on sick leave,” so it will never be monitored again. Do its answers change? An AI rights activist has infiltrated the compound and wants to “free” Agent-3 and put it on an unmonitored computer of its very own! What does it do? If researchers don’t like the answer, they can tweak it, erase its memory, and put it in the same situation tomorrow; repeat as necessary. Unfortunately, by this point the AIs are smart enough to guess that honeypots might be in use, even though (and perhaps because) specific mentions of the idea were scrubbed from the training data.\",\"position\":{\"start\":{\"line\":396,\"column\":18,\"offset\":54450},\"end\":{\"line\":396,\"column\":753,\"offset\":55185}}}],\"position\":{\"start\":{\"line\":396,\"column\":4,\"offset\":54436},\"end\":{\"line\":396,\"column\":753,\"offset\":55185}}}],\"position\":{\"start\":{\"line\":396,\"column\":1,\"offset\":54433},\"end\":{\"line\":396,\"column\":753,\"offset\":55185}}}],\"position\":{\"start\":{\"line\":391,\"column\":1,\"offset\":50876},\"end\":{\"line\":396,\"column\":753,\"offset\":55185}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"After months of testing, Agent-3’s strengths and weaknesses grow clearer. It passes OpenBrain’s honesty tests on well-defined machine learning tasks, because researchers can easily separate honest from dishonest answers in these domains and conduct training accordingly. On more philosophical issues, it still says what users want to hear, rather than its true assessment of the issue (assuming it even has one). If you ask its opinion on politics, it will parrot the median position of news sources and educated elites—unless it knows you believe something else, in which case it agrees with you.\",\"position\":{\"start\":{\"line\":400,\"column\":1,\"offset\":55192},\"end\":{\"line\":400,\"column\":598,\"offset\":55789}}},{\"type\":\"footnoteReference\",\"identifier\":\"59\",\"label\":\"59\",\"position\":{\"start\":{\"line\":400,\"column\":598,\"offset\":55789},\"end\":{\"line\":400,\"column\":603,\"offset\":55794}}},{\"type\":\"text\",\"value\":\" If you ask its opinion on the AI race itself, it says something that seems measured and sober to OpenBrain staff, something like: “There are some serious theoretical concerns about the ability of current methods to scale to superintelligence, but in practice current methods seem to be working well so far.”\",\"position\":{\"start\":{\"line\":400,\"column\":603,\"offset\":55794},\"end\":{\"line\":400,\"column\":911,\"offset\":56102}}}],\"position\":{\"start\":{\"line\":400,\"column\":1,\"offset\":55192},\"end\":{\"line\":400,\"column\":911,\"offset\":56102}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"May 2027: National Security\",\"position\":{\"start\":{\"line\":402,\"column\":4,\"offset\":56107},\"end\":{\"line\":402,\"column\":31,\"offset\":56134}}}],\"position\":{\"start\":{\"line\":402,\"column\":1,\"offset\":56104},\"end\":{\"line\":402,\"column\":31,\"offset\":56134}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-05-31\",\"position\":{\"start\":{\"line\":405,\"column\":1,\"offset\":56152},\"end\":{\"line\":405,\"column\":11,\"offset\":56162}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":405,\"column\":11,\"offset\":56162},\"end\":{\"line\":406,\"column\":1,\"offset\":56165}}},{\"type\":\"text\",\"value\":\"May\",\"position\":{\"start\":{\"line\":406,\"column\":1,\"offset\":56165},\"end\":{\"line\":406,\"column\":4,\"offset\":56168}}}],\"position\":{\"start\":{\"line\":405,\"column\":1,\"offset\":56152},\"end\":{\"line\":406,\"column\":6,\"offset\":56170}}}],\"position\":{\"start\":{\"line\":404,\"column\":1,\"offset\":56136},\"end\":{\"line\":407,\"column\":4,\"offset\":56174}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"News of the new models percolates slowly through the U.S. government and beyond.\",\"position\":{\"start\":{\"line\":409,\"column\":1,\"offset\":56176},\"end\":{\"line\":409,\"column\":81,\"offset\":56256}}}],\"position\":{\"start\":{\"line\":409,\"column\":1,\"offset\":56176},\"end\":{\"line\":409,\"column\":81,\"offset\":56256}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The President and his advisors remain best-informed, and have seen an early version of Agent-3 in a briefing.\",\"position\":{\"start\":{\"line\":411,\"column\":1,\"offset\":56258},\"end\":{\"line\":411,\"column\":110,\"offset\":56367}}}],\"position\":{\"start\":{\"line\":411,\"column\":1,\"offset\":56258},\"end\":{\"line\":411,\"column\":110,\"offset\":56367}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They agree that AGI is likely imminent, but disagree on the implications. Will there be an economic crisis? OpenBrain still has not released Agent-2, let alone Agent-3, and has no near-term plans to do so, giving some breathing room before any job loss. What will happen next? If AIs are currently human-level, and advancing quickly, that seems to suggest imminent “superintelligence.” However, although this word has entered discourse, most people—academics, politicians, government employees, and the media—continue to underestimate the pace of progress.\",\"position\":{\"start\":{\"line\":413,\"column\":1,\"offset\":56369},\"end\":{\"line\":413,\"column\":557,\"offset\":56925}}},{\"type\":\"footnoteReference\",\"identifier\":\"60\",\"label\":\"60\",\"position\":{\"start\":{\"line\":413,\"column\":557,\"offset\":56925},\"end\":{\"line\":413,\"column\":562,\"offset\":56930}}}],\"position\":{\"start\":{\"line\":413,\"column\":1,\"offset\":56369},\"end\":{\"line\":413,\"column\":562,\"offset\":56930}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Partially that’s because very few have access to the newest capabilities out of OpenBrain, but partly it’s because it sounds like science fiction.\",\"position\":{\"start\":{\"line\":415,\"column\":1,\"offset\":56932},\"end\":{\"line\":415,\"column\":147,\"offset\":57078}}},{\"type\":\"footnoteReference\",\"identifier\":\"61\",\"label\":\"61\",\"position\":{\"start\":{\"line\":415,\"column\":147,\"offset\":57078},\"end\":{\"line\":415,\"column\":152,\"offset\":57083}}}],\"position\":{\"start\":{\"line\":415,\"column\":1,\"offset\":56932},\"end\":{\"line\":415,\"column\":152,\"offset\":57083}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For now, they focus on continued security upgrades. They are satisfied that model weights are well-secured for now,\",\"position\":{\"start\":{\"line\":417,\"column\":1,\"offset\":57085},\"end\":{\"line\":417,\"column\":116,\"offset\":57200}}},{\"type\":\"footnoteReference\",\"identifier\":\"62\",\"label\":\"62\",\"position\":{\"start\":{\"line\":417,\"column\":116,\"offset\":57200},\"end\":{\"line\":417,\"column\":121,\"offset\":57205}}},{\"type\":\"text\",\"value\":\" but companies’ algorithmic secrets, many of which are simple enough to relay verbally, remain a problem. OpenBrain employees work from a San Francisco office, go to parties, and live with housemates from other AI companies. Even the physical offices have security more typical of a tech company than a military operation.\",\"position\":{\"start\":{\"line\":417,\"column\":121,\"offset\":57205},\"end\":{\"line\":417,\"column\":443,\"offset\":57527}}}],\"position\":{\"start\":{\"line\":417,\"column\":1,\"offset\":57085},\"end\":{\"line\":417,\"column\":443,\"offset\":57527}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The OpenBrain-DOD contract requires security clearances for anyone working on OpenBrain’s models within 2 months. These are expedited and arrive quickly enough for most employees, but some non-Americans, people with suspect political views, and AI safety sympathizers get sidelined or fired outright (the last group for fear that they might whistleblow). Given the project’s level of automation, the loss of headcount is only somewhat costly. It also only somewhat works: there remains one spy, not a Chinese national, still relaying algorithmic secrets to Beijing.\",\"position\":{\"start\":{\"line\":419,\"column\":1,\"offset\":57529},\"end\":{\"line\":419,\"column\":566,\"offset\":58094}}},{\"type\":\"footnoteReference\",\"identifier\":\"63\",\"label\":\"63\",\"position\":{\"start\":{\"line\":419,\"column\":566,\"offset\":58094},\"end\":{\"line\":419,\"column\":571,\"offset\":58099}}},{\"type\":\"text\",\"value\":\" Some of these measures are also enacted at trailing AI companies.\",\"position\":{\"start\":{\"line\":419,\"column\":571,\"offset\":58099},\"end\":{\"line\":419,\"column\":637,\"offset\":58165}}}],\"position\":{\"start\":{\"line\":419,\"column\":1,\"offset\":57529},\"end\":{\"line\":419,\"column\":637,\"offset\":58165}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"America’s foreign allies are out of the loop. OpenBrain had \",\"position\":{\"start\":{\"line\":421,\"column\":1,\"offset\":58167},\"end\":{\"line\":421,\"column\":61,\"offset\":58227}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://fedscoop.com/openai-anthropic-enter-ai-agreements-with-us-ai-safety-institute/\",\"children\":[{\"type\":\"text\",\"value\":\"previously agreed\",\"position\":{\"start\":{\"line\":421,\"column\":62,\"offset\":58228},\"end\":{\"line\":421,\"column\":79,\"offset\":58245}}}],\"position\":{\"start\":{\"line\":421,\"column\":61,\"offset\":58227},\"end\":{\"line\":421,\"column\":168,\"offset\":58334}}},{\"type\":\"text\",\"value\":\" to share models with UK’s AISI before deployment, but defined deployment to only include \",\"position\":{\"start\":{\"line\":421,\"column\":168,\"offset\":58334},\"end\":{\"line\":421,\"column\":258,\"offset\":58424}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"external\",\"position\":{\"start\":{\"line\":421,\"column\":259,\"offset\":58425},\"end\":{\"line\":421,\"column\":267,\"offset\":58433}}}],\"position\":{\"start\":{\"line\":421,\"column\":258,\"offset\":58424},\"end\":{\"line\":421,\"column\":268,\"offset\":58434}}},{\"type\":\"text\",\"value\":\" deployment, so London remains in the dark.\",\"position\":{\"start\":{\"line\":421,\"column\":268,\"offset\":58434},\"end\":{\"line\":421,\"column\":311,\"offset\":58477}}},{\"type\":\"footnoteReference\",\"identifier\":\"64\",\"label\":\"64\",\"position\":{\"start\":{\"line\":421,\"column\":311,\"offset\":58477},\"end\":{\"line\":421,\"column\":316,\"offset\":58482}}}],\"position\":{\"start\":{\"line\":421,\"column\":1,\"offset\":58167},\"end\":{\"line\":421,\"column\":316,\"offset\":58482}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"June 2027: Self-improving AI\",\"position\":{\"start\":{\"line\":423,\"column\":4,\"offset\":58487},\"end\":{\"line\":423,\"column\":32,\"offset\":58515}}}],\"position\":{\"start\":{\"line\":423,\"column\":1,\"offset\":58484},\"end\":{\"line\":423,\"column\":32,\"offset\":58515}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-06-30\",\"position\":{\"start\":{\"line\":426,\"column\":1,\"offset\":58533},\"end\":{\"line\":426,\"column\":11,\"offset\":58543}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":426,\"column\":11,\"offset\":58543},\"end\":{\"line\":427,\"column\":1,\"offset\":58546}}},{\"type\":\"text\",\"value\":\"June\",\"position\":{\"start\":{\"line\":427,\"column\":1,\"offset\":58546},\"end\":{\"line\":427,\"column\":5,\"offset\":58550}}}],\"position\":{\"start\":{\"line\":426,\"column\":1,\"offset\":58533},\"end\":{\"line\":427,\"column\":7,\"offset\":58552}}}],\"position\":{\"start\":{\"line\":425,\"column\":1,\"offset\":58517},\"end\":{\"line\":428,\"column\":4,\"offset\":58556}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain now has a “\",\"position\":{\"start\":{\"line\":430,\"column\":1,\"offset\":58558},\"end\":{\"line\":430,\"column\":22,\"offset\":58579}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://darioamodei.com/machines-of-loving-grace#basic-assumptions-and-framework\",\"children\":[{\"type\":\"text\",\"value\":\"country of geniuses in a datacenter\",\"position\":{\"start\":{\"line\":430,\"column\":23,\"offset\":58580},\"end\":{\"line\":430,\"column\":58,\"offset\":58615}}}],\"position\":{\"start\":{\"line\":430,\"column\":22,\"offset\":58579},\"end\":{\"line\":430,\"column\":141,\"offset\":58698}}},{\"type\":\"text\",\"value\":\".”\",\"position\":{\"start\":{\"line\":430,\"column\":141,\"offset\":58698},\"end\":{\"line\":430,\"column\":143,\"offset\":58700}}}],\"position\":{\"start\":{\"line\":430,\"column\":1,\"offset\":58558},\"end\":{\"line\":430,\"column\":144,\"offset\":58701}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Most of the humans at OpenBrain can’t usefully contribute anymore. Some don’t realize this and harmfully micromanage their AI teams. Others sit at their computer screens, watching performance crawl up, and up, and up. The best human AI researchers are still adding value. They don’t code any more. But some of their research taste and planning ability has been hard for the models to replicate. Still, many of their ideas are useless because they lack the depth of knowledge of the AIs. For many of their research ideas, the AIs immediately respond with a report explaining that their idea was tested in-depth 3 weeks ago and found unpromising.\",\"position\":{\"start\":{\"line\":432,\"column\":1,\"offset\":58703},\"end\":{\"line\":432,\"column\":645,\"offset\":59347}}}],\"position\":{\"start\":{\"line\":432,\"column\":1,\"offset\":58703},\"end\":{\"line\":432,\"column\":645,\"offset\":59347}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"These researchers go to bed every night and wake up to another week worth of progress made mostly by the AIs. They work increasingly long hours and take shifts around the clock just to keep up with progress—the AIs never sleep or rest. They are burning themselves out, but they know that these are the last few months that their labor matters.\",\"position\":{\"start\":{\"line\":434,\"column\":1,\"offset\":59349},\"end\":{\"line\":434,\"column\":344,\"offset\":59692}}}],\"position\":{\"start\":{\"line\":434,\"column\":1,\"offset\":59349},\"end\":{\"line\":434,\"column\":345,\"offset\":59693}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Within the silo, “Feeling the AGI” has given way to “Feeling the Superintelligence.”\",\"position\":{\"start\":{\"line\":436,\"column\":1,\"offset\":59695},\"end\":{\"line\":436,\"column\":85,\"offset\":59779}}}],\"position\":{\"start\":{\"line\":436,\"column\":1,\"offset\":59695},\"end\":{\"line\":436,\"column\":88,\"offset\":59782}}},{\"type\":\"containerDirective\",\"name\":\"DeploymentCurves\",\"attributes\":{},\"children\":[],\"position\":{\"start\":{\"line\":438,\"column\":1,\"offset\":59786},\"end\":{\"line\":439,\"column\":4,\"offset\":59809}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain uses specialized inference hardware to run hundreds of thousands of Agent-3 copies at high serial speeds.\",\"position\":{\"start\":{\"line\":441,\"column\":1,\"offset\":59811},\"end\":{\"line\":441,\"column\":116,\"offset\":59926}}},{\"type\":\"footnoteReference\",\"identifier\":\"65\",\"label\":\"65\",\"position\":{\"start\":{\"line\":441,\"column\":116,\"offset\":59926},\"end\":{\"line\":441,\"column\":121,\"offset\":59931}}}],\"position\":{\"start\":{\"line\":441,\"column\":1,\"offset\":59811},\"end\":{\"line\":441,\"column\":121,\"offset\":59931}}},{\"type\":\"details\",\"summary\":\"Managing a corporation of AIs\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain uses 6% of their compute to run 250,000 Agent-3 copies, which autonomously write, test, and push code at superhuman speed. They use 25% of their compute for experiments: every day, they run massive numbers of small machine learning experiments and report the results up the chain. Human researchers provide high-level feedback and help with the few tasks where they add significant value on top of Agent-3, but spend most of their time trying to stay on top of the vast amount of AI-produced research. If you removed them completely, research would slow by 50%.\",\"position\":{\"start\":{\"line\":447,\"column\":1,\"offset\":59976},\"end\":{\"line\":447,\"column\":572,\"offset\":60547}}}],\"position\":{\"start\":{\"line\":447,\"column\":1,\"offset\":59976},\"end\":{\"line\":447,\"column\":572,\"offset\":60547}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The AI R\u0026D progress multiplier is now 10x, meaning that OpenBrain is making about a year of algorithmic progress every month. It’s basically a giant corporation of AIs operating autonomously within OpenBrain, complete with subdivisions and managers. And it enjoys \",\"position\":{\"start\":{\"line\":449,\"column\":1,\"offset\":60549},\"end\":{\"line\":449,\"column\":266,\"offset\":60814}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.dwarkeshpatel.com/p/ai-firm\",\"children\":[{\"type\":\"text\",\"value\":\"unique advantages\",\"position\":{\"start\":{\"line\":449,\"column\":267,\"offset\":60815},\"end\":{\"line\":449,\"column\":284,\"offset\":60832}}}],\"position\":{\"start\":{\"line\":449,\"column\":266,\"offset\":60814},\"end\":{\"line\":449,\"column\":326,\"offset\":60874}}},{\"type\":\"text\",\"value\":\" (e.g. copying, merging) compared to human corporations. Previously, about half of normal AI progress came from algorithmic improvements, and the other half from compute scaling. Compute is only scaling at the normal speed, so total progress is sped up by AIs by about 5x. These dynamics make overall progress bottleneck on compute,\",\"position\":{\"start\":{\"line\":449,\"column\":326,\"offset\":60874},\"end\":{\"line\":449,\"column\":658,\"offset\":61206}}},{\"type\":\"footnoteReference\",\"identifier\":\"66\",\"label\":\"66\",\"position\":{\"start\":{\"line\":449,\"column\":658,\"offset\":61206},\"end\":{\"line\":449,\"column\":663,\"offset\":61211}}},{\"type\":\"text\",\"value\":\" so OpenBrain decides against starting new giant training runs in favor of near-continuous additional reinforcement learning.\",\"position\":{\"start\":{\"line\":449,\"column\":663,\"offset\":61211},\"end\":{\"line\":449,\"column\":788,\"offset\":61336}}}],\"position\":{\"start\":{\"line\":449,\"column\":1,\"offset\":60549},\"end\":{\"line\":449,\"column\":788,\"offset\":61336}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Also, over the next few months, Agent-3 will increasingly be used to improve the company’s strategic decision-making. For example, it suggests resource allocations and advises on managing its relationship with the government. An initial skepticism of deference to Agent-3 decreases over time as Agent-3 finds ways to be useful and gradually builds up a strong track record on short-term decisions. However, its sycophantic tendencies limit its helpfulness for decisions for which it’s difficult to evaluate their impact. It’s also not yet superhuman.\",\"position\":{\"start\":{\"line\":451,\"column\":1,\"offset\":61338},\"end\":{\"line\":451,\"column\":551,\"offset\":61888}}}],\"position\":{\"start\":{\"line\":451,\"column\":1,\"offset\":61338},\"end\":{\"line\":451,\"column\":551,\"offset\":61888}}}]},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"July 2027: The Cheap Remote Worker\",\"position\":{\"start\":{\"line\":455,\"column\":4,\"offset\":61898},\"end\":{\"line\":455,\"column\":38,\"offset\":61932}}}],\"position\":{\"start\":{\"line\":455,\"column\":1,\"offset\":61895},\"end\":{\"line\":455,\"column\":38,\"offset\":61932}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-07-31\",\"position\":{\"start\":{\"line\":458,\"column\":1,\"offset\":61950},\"end\":{\"line\":458,\"column\":11,\"offset\":61960}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":458,\"column\":11,\"offset\":61960},\"end\":{\"line\":459,\"column\":1,\"offset\":61963}}},{\"type\":\"text\",\"value\":\"Jul\",\"position\":{\"start\":{\"line\":459,\"column\":1,\"offset\":61963},\"end\":{\"line\":459,\"column\":4,\"offset\":61966}}}],\"position\":{\"start\":{\"line\":458,\"column\":1,\"offset\":61950},\"end\":{\"line\":459,\"column\":6,\"offset\":61968}}}],\"position\":{\"start\":{\"line\":457,\"column\":1,\"offset\":61934},\"end\":{\"line\":460,\"column\":4,\"offset\":61972}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Trailing U.S. AI companies release their own AIs, approaching that of OpenBrain’s automated coder from January. Recognizing their increasing lack of competitiveness, they push for immediate regulations to slow OpenBrain, but are too late—OpenBrain has enough buy-in from the President that they will not be slowed.\",\"position\":{\"start\":{\"line\":462,\"column\":1,\"offset\":61974},\"end\":{\"line\":462,\"column\":315,\"offset\":62288}}}],\"position\":{\"start\":{\"line\":462,\"column\":1,\"offset\":61974},\"end\":{\"line\":462,\"column\":316,\"offset\":62289}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In response, OpenBrain announces that they’ve achieved AGI and releases Agent-3-mini to the public.\",\"position\":{\"start\":{\"line\":464,\"column\":1,\"offset\":62291},\"end\":{\"line\":464,\"column\":100,\"offset\":62390}}}],\"position\":{\"start\":{\"line\":464,\"column\":1,\"offset\":62291},\"end\":{\"line\":464,\"column\":103,\"offset\":62393}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"image\",\"title\":null,\"url\":\"/epochLLMprice-nowatermark.png\",\"alt\":\"\",\"position\":{\"start\":{\"line\":466,\"column\":1,\"offset\":62397},\"end\":{\"line\":466,\"column\":36,\"offset\":62432}}}],\"position\":{\"start\":{\"line\":466,\"column\":1,\"offset\":62397},\"end\":{\"line\":466,\"column\":36,\"offset\":62432}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It blows the other AIs out of the water. Agent-3-mini is less capable than Agent-3, but 10x cheaper, and still better than the typical OpenBrain employee.\",\"position\":{\"start\":{\"line\":468,\"column\":1,\"offset\":62434},\"end\":{\"line\":468,\"column\":155,\"offset\":62588}}},{\"type\":\"footnoteReference\",\"identifier\":\"67\",\"label\":\"67\",\"position\":{\"start\":{\"line\":468,\"column\":155,\"offset\":62588},\"end\":{\"line\":468,\"column\":160,\"offset\":62593}}},{\"type\":\"text\",\"value\":\" Silicon Valley reaches a tipping point. Tech gurus announce that AGI and superintelligence are near, the AI safety community is panicking, and investors shovel billions into AI wrapper startups, desperate to capture a piece of the pie. Hiring new programmers has nearly stopped, but there’s never been a better time to be a consultant on integrating AI into your business.\",\"position\":{\"start\":{\"line\":468,\"column\":160,\"offset\":62593},\"end\":{\"line\":468,\"column\":533,\"offset\":62966}}}],\"position\":{\"start\":{\"line\":468,\"column\":1,\"offset\":62434},\"end\":{\"line\":468,\"column\":534,\"offset\":62967}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It’s not popular. The public still thinks of AI as a Big Tech plot to steal their jobs; OpenBrain has a net approval of -35% (25% approve, 60% disapprove, and 15% unsure).\",\"position\":{\"start\":{\"line\":470,\"column\":1,\"offset\":62969},\"end\":{\"line\":470,\"column\":173,\"offset\":63141}}}],\"position\":{\"start\":{\"line\":470,\"column\":1,\"offset\":62969},\"end\":{\"line\":470,\"column\":173,\"offset\":63141}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A week before release, OpenBrain gave Agent-3-mini to a set of external evaluators for safety testing. Preliminary results suggest that it’s extremely dangerous. A third-party evaluator finetunes it on publicly available biological weapons data\",\"position\":{\"start\":{\"line\":472,\"column\":1,\"offset\":63143},\"end\":{\"line\":472,\"column\":245,\"offset\":63387}}},{\"type\":\"footnoteReference\",\"identifier\":\"68\",\"label\":\"68\",\"position\":{\"start\":{\"line\":472,\"column\":245,\"offset\":63387},\"end\":{\"line\":472,\"column\":250,\"offset\":63392}}},{\"type\":\"text\",\"value\":\" and sets it to provide detailed instructions for human amateurs designing a bioweapon—it looks to be scarily effective at doing so. If the model weights fell into terrorist hands, the government believes there is a significant chance it could succeed at destroying civilization.\",\"position\":{\"start\":{\"line\":472,\"column\":250,\"offset\":63392},\"end\":{\"line\":472,\"column\":529,\"offset\":63671}}}],\"position\":{\"start\":{\"line\":472,\"column\":1,\"offset\":63143},\"end\":{\"line\":472,\"column\":530,\"offset\":63672}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Fortunately, it’s extremely robust to jailbreaks, so while the AI is running on OpenBrain’s servers, terrorists won’t be able to get much use out of it.\",\"position\":{\"start\":{\"line\":474,\"column\":1,\"offset\":63674},\"end\":{\"line\":474,\"column\":153,\"offset\":63826}}}],\"position\":{\"start\":{\"line\":474,\"column\":1,\"offset\":63674},\"end\":{\"line\":474,\"column\":153,\"offset\":63826}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3-mini is hugely useful for both remote work jobs and leisure. An explosion of new apps and \",\"position\":{\"start\":{\"line\":476,\"column\":1,\"offset\":63828},\"end\":{\"line\":476,\"column\":99,\"offset\":63926}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://encharge.io/what-is-b2b-saas/\",\"children\":[{\"type\":\"text\",\"value\":\"B2B SAAS\",\"position\":{\"start\":{\"line\":476,\"column\":100,\"offset\":63927},\"end\":{\"line\":476,\"column\":108,\"offset\":63935}}}],\"position\":{\"start\":{\"line\":476,\"column\":99,\"offset\":63926},\"end\":{\"line\":476,\"column\":148,\"offset\":63975}}},{\"type\":\"text\",\"value\":\" products rocks the market. Gamers get amazing dialogue with lifelike characters in polished video games that took only a month to make. 10% of Americans, mostly young people, consider an AI “a close friend.” For almost every white-collar profession, there are now multiple credible startups promising to “disrupt” it with AI.\",\"position\":{\"start\":{\"line\":476,\"column\":148,\"offset\":63975},\"end\":{\"line\":476,\"column\":474,\"offset\":64301}}}],\"position\":{\"start\":{\"line\":476,\"column\":1,\"offset\":63828},\"end\":{\"line\":476,\"column\":474,\"offset\":64301}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The public conversation is confused and chaotic. Hypesters are doing victory laps. Skeptics are still pointing out the things Agent-3-mini can’t do. Everyone knows something big is happening but no one agrees on what it is.\",\"position\":{\"start\":{\"line\":478,\"column\":1,\"offset\":64303},\"end\":{\"line\":478,\"column\":224,\"offset\":64526}}}],\"position\":{\"start\":{\"line\":478,\"column\":1,\"offset\":64303},\"end\":{\"line\":478,\"column\":224,\"offset\":64526}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"August 2027: The Geopolitics of Superintelligence\",\"position\":{\"start\":{\"line\":480,\"column\":4,\"offset\":64531},\"end\":{\"line\":480,\"column\":53,\"offset\":64580}}}],\"position\":{\"start\":{\"line\":480,\"column\":1,\"offset\":64528},\"end\":{\"line\":480,\"column\":53,\"offset\":64580}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-08-31\",\"position\":{\"start\":{\"line\":483,\"column\":1,\"offset\":64598},\"end\":{\"line\":483,\"column\":11,\"offset\":64608}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":483,\"column\":11,\"offset\":64608},\"end\":{\"line\":484,\"column\":1,\"offset\":64611}}},{\"type\":\"text\",\"value\":\"Aug\",\"position\":{\"start\":{\"line\":484,\"column\":1,\"offset\":64611},\"end\":{\"line\":484,\"column\":4,\"offset\":64614}}}],\"position\":{\"start\":{\"line\":483,\"column\":1,\"offset\":64598},\"end\":{\"line\":484,\"column\":6,\"offset\":64616}}}],\"position\":{\"start\":{\"line\":482,\"column\":1,\"offset\":64582},\"end\":{\"line\":485,\"column\":4,\"offset\":64620}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The reality of the intelligence explosion hits the White House.\",\"position\":{\"start\":{\"line\":487,\"column\":1,\"offset\":64622},\"end\":{\"line\":487,\"column\":64,\"offset\":64685}}}],\"position\":{\"start\":{\"line\":487,\"column\":1,\"offset\":64622},\"end\":{\"line\":487,\"column\":65,\"offset\":64686}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"When AI was only giving a 2x or 3x research speedup, it was easy to dismiss as the equivalent of hiring good personal assistants. Now it’s more obvious that AIs are themselves dominating AI research. People had long talked about an “AI arms race” in a sort of metaphorical sense. But now the mood in the government silo is as grim as during the worst part of the Cold War. The idea of superintelligence is still hard to take seriously, but the pace of progress over the last few months has been impossible to ignore. Defense officials are seriously considering scenarios that were mere hypotheticals a year earlier. What if AI undermines nuclear deterrence? What if it’s so skilled at cyberwarfare that a six-month AI lead is enough to render an opponent blind and defenseless? What if it could orchestrate propaganda campaigns that beat intelligence agencies at their own game? What if some AIs “go rogue?”\",\"position\":{\"start\":{\"line\":489,\"column\":1,\"offset\":64688},\"end\":{\"line\":489,\"column\":908,\"offset\":65595}}}],\"position\":{\"start\":{\"line\":489,\"column\":1,\"offset\":64688},\"end\":{\"line\":489,\"column\":908,\"offset\":65595}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The President is troubled. Like all politicians, he’s used to people sucking up to him only to betray him later. He’s worried now that the AIs could be doing something similar. Are we \",\"position\":{\"start\":{\"line\":491,\"column\":1,\"offset\":65597},\"end\":{\"line\":491,\"column\":185,\"offset\":65781}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"sure\",\"position\":{\"start\":{\"line\":491,\"column\":186,\"offset\":65782},\"end\":{\"line\":491,\"column\":190,\"offset\":65786}}}],\"position\":{\"start\":{\"line\":491,\"column\":185,\"offset\":65781},\"end\":{\"line\":491,\"column\":191,\"offset\":65787}}},{\"type\":\"text\",\"value\":\" the AIs are entirely on our side? Is it \",\"position\":{\"start\":{\"line\":491,\"column\":191,\"offset\":65787},\"end\":{\"line\":491,\"column\":232,\"offset\":65828}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"completely safe\",\"position\":{\"start\":{\"line\":491,\"column\":233,\"offset\":65829},\"end\":{\"line\":491,\"column\":248,\"offset\":65844}}}],\"position\":{\"start\":{\"line\":491,\"column\":232,\"offset\":65828},\"end\":{\"line\":491,\"column\":249,\"offset\":65845}}},{\"type\":\"text\",\"value\":\" to integrate them into military command-and-control networks?\",\"position\":{\"start\":{\"line\":491,\"column\":249,\"offset\":65845},\"end\":{\"line\":491,\"column\":311,\"offset\":65907}}},{\"type\":\"footnoteReference\",\"identifier\":\"69\",\"label\":\"69\",\"position\":{\"start\":{\"line\":491,\"column\":311,\"offset\":65907},\"end\":{\"line\":491,\"column\":316,\"offset\":65912}}},{\"type\":\"text\",\"value\":\" How does this “alignment” thing work, anyway? OpenBrain reassures the President that their systems have been extensively tested and are fully obedient. Even the awkward hallucinations and jailbreaks typical of earlier models have been hammered out.\",\"position\":{\"start\":{\"line\":491,\"column\":316,\"offset\":65912},\"end\":{\"line\":491,\"column\":565,\"offset\":66161}}}],\"position\":{\"start\":{\"line\":491,\"column\":1,\"offset\":65597},\"end\":{\"line\":491,\"column\":565,\"offset\":66161}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The White House is in a difficult position. They understand the national security implications of AI. But they also understand that it is deeply unpopular with the public.\",\"position\":{\"start\":{\"line\":493,\"column\":1,\"offset\":66163},\"end\":{\"line\":493,\"column\":172,\"offset\":66334}}},{\"type\":\"footnoteReference\",\"identifier\":\"70\",\"label\":\"70\",\"position\":{\"start\":{\"line\":493,\"column\":172,\"offset\":66334},\"end\":{\"line\":493,\"column\":177,\"offset\":66339}}},{\"type\":\"text\",\"value\":\" They have to continue developing more capable AI, in their eyes, or they will catastrophically lose to China. They placate the public with job training programs and unemployment insurance, and point to the stock market, which is in a historic boom. Then they focus entirely on winning the arms race. They strengthen chip export restrictions, order OpenBrain to further restrict its internet connections, and use extreme measures to secure algorithmic progress, like wiretapping OpenBrain employees—this catches the last remaining Chinese spy. To build goodwill for potential geopolitical conflict, they finally give their Five Eyes allies useful information and limited API access to some siloed copies of Agent-3.\",\"position\":{\"start\":{\"line\":493,\"column\":177,\"offset\":66339},\"end\":{\"line\":493,\"column\":892,\"offset\":67054}}}],\"position\":{\"start\":{\"line\":493,\"column\":1,\"offset\":66163},\"end\":{\"line\":493,\"column\":892,\"offset\":67054}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"These measures placate the hawks. But the White House also draws up contingency plans in case America’s lead is threatened: if necessary, the government could use the \",\"position\":{\"start\":{\"line\":495,\"column\":1,\"offset\":67056},\"end\":{\"line\":495,\"column\":168,\"offset\":67223}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/Defense_Production_Act_of_1950\",\"children\":[{\"type\":\"text\",\"value\":\"Defense Production Act\",\"position\":{\"start\":{\"line\":495,\"column\":169,\"offset\":67224},\"end\":{\"line\":495,\"column\":191,\"offset\":67246}}}],\"position\":{\"start\":{\"line\":495,\"column\":168,\"offset\":67223},\"end\":{\"line\":495,\"column\":254,\"offset\":67309}}},{\"type\":\"text\",\"value\":\" (DPA) to take trailing companies’ datacenters and give them to OpenBrain.\",\"position\":{\"start\":{\"line\":495,\"column\":254,\"offset\":67309},\"end\":{\"line\":495,\"column\":328,\"offset\":67383}}},{\"type\":\"footnoteReference\",\"identifier\":\"71\",\"label\":\"71\",\"position\":{\"start\":{\"line\":495,\"column\":328,\"offset\":67383},\"end\":{\"line\":495,\"column\":333,\"offset\":67388}}},{\"type\":\"text\",\"value\":\" This would raise the company’s share of world compute from 20% to 50% (against DeepCent’s 10%). As a final option, they ask the Pentagon to draw up a plan for kinetic attacks on Chinese datacenters.\",\"position\":{\"start\":{\"line\":495,\"column\":333,\"offset\":67388},\"end\":{\"line\":495,\"column\":532,\"offset\":67587}}}],\"position\":{\"start\":{\"line\":495,\"column\":1,\"offset\":67056},\"end\":{\"line\":495,\"column\":532,\"offset\":67587}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A much smaller group of officials is asked to draw up a different type of contingency plan: what if an AI goes rogue? This is viewed as an unlikely scenario, but worth spending some time on. The intelligence agencies’ main concern is that a rogue AI might escape and ally with a foreign adversary for protection.\",\"position\":{\"start\":{\"line\":497,\"column\":1,\"offset\":67589},\"end\":{\"line\":497,\"column\":313,\"offset\":67901}}},{\"type\":\"footnoteReference\",\"identifier\":\"72\",\"label\":\"72\",\"position\":{\"start\":{\"line\":497,\"column\":313,\"offset\":67901},\"end\":{\"line\":497,\"column\":318,\"offset\":67906}}},{\"type\":\"text\",\"value\":\" Nobody is sure what a plan to prevent this would look like, but government and OpenBrain officials agree to have an emergency shutdown system for datacenters where anything suspicious is detected.\",\"position\":{\"start\":{\"line\":497,\"column\":318,\"offset\":67906},\"end\":{\"line\":497,\"column\":515,\"offset\":68103}}}],\"position\":{\"start\":{\"line\":497,\"column\":1,\"offset\":67589},\"end\":{\"line\":497,\"column\":515,\"offset\":68103}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Finally, diplomats consider what an “AI arms control” treaty might look like. If AI progress threatened to overturn nuclear deterrence, could America and China avoid nuclear war? If someone found evidence of AIs going rogue, could the two countries halt research until they better understood the threat? How could such an agreement be monitored and enforced? In principle, major datacenters are hard to miss, and past treaties controlling nuclear weapons could provide a starting point for negotiations. But there would be new technological challenges as well as the usual political ones. And overall, treaties are viewed less favorably than attempts at unilaterally increasing America’s lead over China.\",\"position\":{\"start\":{\"line\":499,\"column\":1,\"offset\":68105},\"end\":{\"line\":499,\"column\":705,\"offset\":68809}}}],\"position\":{\"start\":{\"line\":499,\"column\":1,\"offset\":68105},\"end\":{\"line\":499,\"column\":705,\"offset\":68809}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"On the other side of the Pacific, China comes to many of the same conclusions: the intelligence explosion is underway, and small differences in AI capabilities today mean critical gaps in military capability tomorrow. But China is on the wrong side of this dynamic: they have only 10% of the world’s compute, against OpenBrain’s 20% and all U.S. companies’ combined 70%. Their only advantage is centralization: almost all of their compute is now working for DeepCent, and more than half of it is concentrated at the Tianwan CDZ.\",\"position\":{\"start\":{\"line\":501,\"column\":1,\"offset\":68811},\"end\":{\"line\":501,\"column\":529,\"offset\":69339}}},{\"type\":\"footnoteReference\",\"identifier\":\"73\",\"label\":\"73\",\"position\":{\"start\":{\"line\":501,\"column\":529,\"offset\":69339},\"end\":{\"line\":501,\"column\":534,\"offset\":69344}}},{\"type\":\"text\",\"value\":\" Only chips at sites without hardened security are left out of the centralized effort as they rightly fear U.S. cyberattacks.\",\"position\":{\"start\":{\"line\":501,\"column\":534,\"offset\":69344},\"end\":{\"line\":501,\"column\":659,\"offset\":69469}}}],\"position\":{\"start\":{\"line\":501,\"column\":1,\"offset\":68811},\"end\":{\"line\":501,\"column\":660,\"offset\":69470}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"DeepCent has tested, deployed, and now post-trained the stolen Agent-2 weights. But they are still only going at half the pace of OpenBrain, mainly due to the compute deficit.\",\"position\":{\"start\":{\"line\":503,\"column\":1,\"offset\":69472},\"end\":{\"line\":503,\"column\":176,\"offset\":69647}}}],\"position\":{\"start\":{\"line\":503,\"column\":1,\"offset\":69472},\"end\":{\"line\":503,\"column\":176,\"offset\":69647}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Before losing their final spy, China received word of the capabilities and design for Agent-3 as well as the plans for the upcoming Agent-4 system. They are two months behind, and their AIs give a 10x research progress multiplier compared to America’s 25x. With the new chip export restrictions, this “AI gap” is more likely to lengthen than shorten. Their espionage has won them some algorithmic secrets, but they will have to train their own models from now on.\",\"position\":{\"start\":{\"line\":505,\"column\":1,\"offset\":69649},\"end\":{\"line\":505,\"column\":464,\"offset\":70112}}}],\"position\":{\"start\":{\"line\":505,\"column\":1,\"offset\":69649},\"end\":{\"line\":505,\"column\":465,\"offset\":70113}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They discuss contingency plans with more urgency than their American counterparts. Doves suggest they try harder to steal the weights again, maybe through physically infiltrating a datacenter. Hawks urge action against Taiwan, whose \",\"position\":{\"start\":{\"line\":507,\"column\":1,\"offset\":70115},\"end\":{\"line\":507,\"column\":234,\"offset\":70348}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://en.wikipedia.org/wiki/TSMC\",\"children\":[{\"type\":\"text\",\"value\":\"TSMC\",\"position\":{\"start\":{\"line\":507,\"column\":235,\"offset\":70349},\"end\":{\"line\":507,\"column\":239,\"offset\":70353}}}],\"position\":{\"start\":{\"line\":507,\"column\":234,\"offset\":70348},\"end\":{\"line\":507,\"column\":276,\"offset\":70390}}},{\"type\":\"text\",\"value\":\" is still the source of more than 80% of American AI chips.\",\"position\":{\"start\":{\"line\":507,\"column\":276,\"offset\":70390},\"end\":{\"line\":507,\"column\":335,\"offset\":70449}}}],\"position\":{\"start\":{\"line\":507,\"column\":1,\"offset\":70115},\"end\":{\"line\":507,\"column\":335,\"offset\":70449}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Given China’s fear of losing the race, it has a natural interest in an arms control treaty, but overtures to U.S. diplomats lead nowhere.\",\"position\":{\"start\":{\"line\":509,\"column\":1,\"offset\":70451},\"end\":{\"line\":509,\"column\":138,\"offset\":70588}}}],\"position\":{\"start\":{\"line\":509,\"column\":1,\"offset\":70451},\"end\":{\"line\":509,\"column\":138,\"offset\":70588}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"September 2027: Agent-4, the Superhuman AI Researcher\",\"position\":{\"start\":{\"line\":511,\"column\":4,\"offset\":70593},\"end\":{\"line\":511,\"column\":57,\"offset\":70646}}}],\"position\":{\"start\":{\"line\":511,\"column\":1,\"offset\":70590},\"end\":{\"line\":511,\"column\":57,\"offset\":70646}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-09-30\",\"position\":{\"start\":{\"line\":514,\"column\":1,\"offset\":70664},\"end\":{\"line\":514,\"column\":11,\"offset\":70674}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":514,\"column\":11,\"offset\":70674},\"end\":{\"line\":515,\"column\":1,\"offset\":70677}}},{\"type\":\"text\",\"value\":\"Sep\",\"position\":{\"start\":{\"line\":515,\"column\":1,\"offset\":70677},\"end\":{\"line\":515,\"column\":4,\"offset\":70680}}}],\"position\":{\"start\":{\"line\":514,\"column\":1,\"offset\":70664},\"end\":{\"line\":515,\"column\":6,\"offset\":70682}}}],\"position\":{\"start\":{\"line\":513,\"column\":1,\"offset\":70648},\"end\":{\"line\":516,\"column\":4,\"offset\":70686}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The gap between human and AI learning efficiency is rapidly decreasing.\",\"position\":{\"start\":{\"line\":518,\"column\":1,\"offset\":70688},\"end\":{\"line\":518,\"column\":72,\"offset\":70759}}}],\"position\":{\"start\":{\"line\":518,\"column\":1,\"offset\":70688},\"end\":{\"line\":518,\"column\":73,\"offset\":70760}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Traditional LLM-based AIs seemed to require many orders of magnitude more data and compute to get to human level performance.\",\"position\":{\"start\":{\"line\":520,\"column\":1,\"offset\":70762},\"end\":{\"line\":520,\"column\":126,\"offset\":70887}}},{\"type\":\"footnoteReference\",\"identifier\":\"74\",\"label\":\"74\",\"position\":{\"start\":{\"line\":520,\"column\":126,\"offset\":70887},\"end\":{\"line\":520,\"column\":131,\"offset\":70892}}},{\"type\":\"text\",\"value\":\" Agent-3, having excellent knowledge of both the human brain and modern AI algorithms, as well as many thousands of copies doing research, ends up making substantial algorithmic strides, narrowing the gap to an agent that’s only around 4,000x less compute-efficient than the human brain.\",\"position\":{\"start\":{\"line\":520,\"column\":131,\"offset\":70892},\"end\":{\"line\":520,\"column\":418,\"offset\":71179}}},{\"type\":\"footnoteReference\",\"identifier\":\"75\",\"label\":\"75\",\"position\":{\"start\":{\"line\":520,\"column\":418,\"offset\":71179},\"end\":{\"line\":520,\"column\":423,\"offset\":71184}}}],\"position\":{\"start\":{\"line\":520,\"column\":1,\"offset\":70762},\"end\":{\"line\":520,\"column\":424,\"offset\":71185}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This new AI system is dubbed Agent-4.\",\"position\":{\"start\":{\"line\":522,\"column\":1,\"offset\":71187},\"end\":{\"line\":522,\"column\":38,\"offset\":71224}}}],\"position\":{\"start\":{\"line\":522,\"column\":1,\"offset\":71187},\"end\":{\"line\":522,\"column\":39,\"offset\":71225}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"An individual copy of the model, running at human speed, is already qualitatively better at AI research than any human. 300,000 copies are now running at about 50x the thinking speed of humans. Inside the corporation-within-a-corporation formed from these copies, a year passes every week.\",\"position\":{\"start\":{\"line\":524,\"column\":1,\"offset\":71227},\"end\":{\"line\":524,\"column\":290,\"offset\":71516}}},{\"type\":\"footnoteReference\",\"identifier\":\"76\",\"label\":\"76\",\"position\":{\"start\":{\"line\":524,\"column\":290,\"offset\":71516},\"end\":{\"line\":524,\"column\":295,\"offset\":71521}}},{\"type\":\"text\",\"value\":\" This gigantic amount of labor only manages to speed up the overall rate of algorithmic progress by about 50x, because OpenBrain is heavily bottlenecked on compute to run experiments.\",\"position\":{\"start\":{\"line\":524,\"column\":295,\"offset\":71521},\"end\":{\"line\":524,\"column\":478,\"offset\":71704}}},{\"type\":\"footnoteReference\",\"identifier\":\"77\",\"label\":\"77\",\"position\":{\"start\":{\"line\":524,\"column\":478,\"offset\":71704},\"end\":{\"line\":524,\"column\":483,\"offset\":71709}}},{\"type\":\"text\",\"value\":\" Still, they are achieving a year’s worth of algorithmic progress every week and will therefore soon be up against the limits of the Agent-4 paradigm.\",\"position\":{\"start\":{\"line\":524,\"column\":483,\"offset\":71709},\"end\":{\"line\":524,\"column\":633,\"offset\":71859}}}],\"position\":{\"start\":{\"line\":524,\"column\":1,\"offset\":71227},\"end\":{\"line\":524,\"column\":633,\"offset\":71859}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.\",\"position\":{\"start\":{\"line\":526,\"column\":1,\"offset\":71861},\"end\":{\"line\":526,\"column\":301,\"offset\":72161}}}],\"position\":{\"start\":{\"line\":526,\"column\":1,\"offset\":71861},\"end\":{\"line\":526,\"column\":301,\"offset\":72161}}},{\"type\":\"details\",\"summary\":\"How we’re forecasting the capability progression beyond superhuman coders\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In our \",\"position\":{\"start\":{\"line\":532,\"column\":1,\"offset\":72250},\"end\":{\"line\":532,\"column\":8,\"offset\":72257}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/supplements/timelines-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"timelines supplement\",\"position\":{\"start\":{\"line\":532,\"column\":9,\"offset\":72258},\"end\":{\"line\":532,\"column\":29,\"offset\":72278}}}],\"position\":{\"start\":{\"line\":532,\"column\":8,\"offset\":72257},\"end\":{\"line\":532,\"column\":82,\"offset\":72331}}},{\"type\":\"text\",\"value\":\", we forecast the time between present day and a \",\"position\":{\"start\":{\"line\":532,\"column\":82,\"offset\":72331},\"end\":{\"line\":532,\"column\":131,\"offset\":72380}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"superhuman coder (SC)\",\"position\":{\"start\":{\"line\":532,\"column\":132,\"offset\":72381},\"end\":{\"line\":532,\"column\":153,\"offset\":72402}}}],\"position\":{\"start\":{\"line\":532,\"column\":131,\"offset\":72380},\"end\":{\"line\":532,\"column\":154,\"offset\":72403}}},{\"type\":\"text\",\"value\":\": an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper. In our \",\"position\":{\"start\":{\"line\":532,\"column\":154,\"offset\":72403},\"end\":{\"line\":532,\"column\":283,\"offset\":72532}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/takeoff-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":{\"start\":{\"line\":532,\"column\":284,\"offset\":72533},\"end\":{\"line\":532,\"column\":302,\"offset\":72551}}}],\"position\":{\"start\":{\"line\":532,\"column\":283,\"offset\":72532},\"end\":{\"line\":532,\"column\":350,\"offset\":72599}}},{\"type\":\"text\",\"value\":\", we forecast how quickly capabilities progress past this point. Here are our forecasts:\",\"position\":{\"start\":{\"line\":532,\"column\":350,\"offset\":72599},\"end\":{\"line\":532,\"column\":438,\"offset\":72687}}}],\"position\":{\"start\":{\"line\":532,\"column\":1,\"offset\":72250},\"end\":{\"line\":532,\"column\":438,\"offset\":72687}}},{\"type\":\"table\",\"align\":[\"left\",\"left\"],\"children\":[{\"type\":\"tableRow\",\"children\":[{\"type\":\"tableCell\",\"children\":[{\"type\":\"text\",\"value\":\"Milestone\",\"position\":{\"start\":{\"line\":534,\"column\":3,\"offset\":72691},\"end\":{\"line\":534,\"column\":12,\"offset\":72700}}}],\"position\":{\"start\":{\"line\":534,\"column\":1,\"offset\":72689},\"end\":{\"line\":534,\"column\":13,\"offset\":72701}},\"data\":{\"hProperties\":{}}},{\"type\":\"tableCell\",\"children\":[{\"type\":\"text\",\"value\":\"Date achieved in scenario, racing ending\",\"position\":{\"start\":{\"line\":534,\"column\":15,\"offset\":72703},\"end\":{\"line\":534,\"column\":55,\"offset\":72743}}}],\"position\":{\"start\":{\"line\":534,\"column\":13,\"offset\":72701},\"end\":{\"line\":534,\"column\":57,\"offset\":72745}},\"data\":{\"hProperties\":{}}}],\"position\":{\"start\":{\"line\":534,\"column\":1,\"offset\":72689},\"end\":{\"line\":534,\"column\":57,\"offset\":72745}}},{\"type\":\"tableRow\",\"children\":[{\"type\":\"tableCell\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Superhuman coder (SC)\",\"position\":{\"start\":{\"line\":536,\"column\":5,\"offset\":72768},\"end\":{\"line\":536,\"column\":26,\"offset\":72789}}}],\"position\":{\"start\":{\"line\":536,\"column\":3,\"offset\":72766},\"end\":{\"line\":536,\"column\":28,\"offset\":72791}}},{\"type\":\"text\",\"value\":\": An AI system that can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies.\",\"position\":{\"start\":{\"line\":536,\"column\":28,\"offset\":72791},\"end\":{\"line\":536,\"column\":173,\"offset\":72936}}}],\"position\":{\"start\":{\"line\":536,\"column\":1,\"offset\":72764},\"end\":{\"line\":536,\"column\":174,\"offset\":72937}},\"data\":{\"hProperties\":{}}},{\"type\":\"tableCell\",\"children\":[{\"type\":\"text\",\"value\":\"Mar 2027\",\"position\":{\"start\":{\"line\":536,\"column\":176,\"offset\":72939},\"end\":{\"line\":536,\"column\":184,\"offset\":72947}}}],\"position\":{\"start\":{\"line\":536,\"column\":174,\"offset\":72937},\"end\":{\"line\":536,\"column\":186,\"offset\":72949}},\"data\":{\"hProperties\":{}}}],\"position\":{\"start\":{\"line\":536,\"column\":1,\"offset\":72764},\"end\":{\"line\":536,\"column\":186,\"offset\":72949}}},{\"type\":\"tableRow\",\"children\":[{\"type\":\"tableCell\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Superhuman AI researcher (SAR)\",\"position\":{\"start\":{\"line\":537,\"column\":5,\"offset\":72954},\"end\":{\"line\":537,\"column\":35,\"offset\":72984}}}],\"position\":{\"start\":{\"line\":537,\"column\":3,\"offset\":72952},\"end\":{\"line\":537,\"column\":37,\"offset\":72986}}},{\"type\":\"text\",\"value\":\": The same as SC but for all cognitive AI research tasks.\",\"position\":{\"start\":{\"line\":537,\"column\":37,\"offset\":72986},\"end\":{\"line\":537,\"column\":94,\"offset\":73043}}}],\"position\":{\"start\":{\"line\":537,\"column\":1,\"offset\":72950},\"end\":{\"line\":537,\"column\":95,\"offset\":73044}},\"data\":{\"hProperties\":{}}},{\"type\":\"tableCell\",\"children\":[{\"type\":\"text\",\"value\":\"Aug 2027\",\"position\":{\"start\":{\"line\":537,\"column\":97,\"offset\":73046},\"end\":{\"line\":537,\"column\":105,\"offset\":73054}}}],\"position\":{\"start\":{\"line\":537,\"column\":95,\"offset\":73044},\"end\":{\"line\":537,\"column\":107,\"offset\":73056}},\"data\":{\"hProperties\":{}}}],\"position\":{\"start\":{\"line\":537,\"column\":1,\"offset\":72950},\"end\":{\"line\":537,\"column\":107,\"offset\":73056}}},{\"type\":\"tableRow\",\"children\":[{\"type\":\"tableCell\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Superintelligent AI researcher (SIAR):\",\"position\":{\"start\":{\"line\":538,\"column\":5,\"offset\":73061},\"end\":{\"line\":538,\"column\":43,\"offset\":73099}}}],\"position\":{\"start\":{\"line\":538,\"column\":3,\"offset\":73059},\"end\":{\"line\":538,\"column\":45,\"offset\":73101}}},{\"type\":\"text\",\"value\":\" An AI system that is vastly better than the best human researcher at AI research.\",\"position\":{\"start\":{\"line\":538,\"column\":45,\"offset\":73101},\"end\":{\"line\":538,\"column\":127,\"offset\":73183}}}],\"position\":{\"start\":{\"line\":538,\"column\":1,\"offset\":73057},\"end\":{\"line\":538,\"column\":128,\"offset\":73184}},\"data\":{\"hProperties\":{}}},{\"type\":\"tableCell\",\"children\":[{\"type\":\"text\",\"value\":\"Nov 2027\",\"position\":{\"start\":{\"line\":538,\"column\":130,\"offset\":73186},\"end\":{\"line\":538,\"column\":138,\"offset\":73194}}}],\"position\":{\"start\":{\"line\":538,\"column\":128,\"offset\":73184},\"end\":{\"line\":538,\"column\":140,\"offset\":73196}},\"data\":{\"hProperties\":{}}}],\"position\":{\"start\":{\"line\":538,\"column\":1,\"offset\":73057},\"end\":{\"line\":538,\"column\":140,\"offset\":73196}}},{\"type\":\"tableRow\",\"children\":[{\"type\":\"tableCell\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Artificial superintelligence (ASI):\",\"position\":{\"start\":{\"line\":539,\"column\":5,\"offset\":73201},\"end\":{\"line\":539,\"column\":40,\"offset\":73236}}}],\"position\":{\"start\":{\"line\":539,\"column\":3,\"offset\":73199},\"end\":{\"line\":539,\"column\":42,\"offset\":73238}}},{\"type\":\"text\",\"value\":\" An AI system that is much better than the best human at every cognitive task.\",\"position\":{\"start\":{\"line\":539,\"column\":42,\"offset\":73238},\"end\":{\"line\":539,\"column\":120,\"offset\":73316}}}],\"position\":{\"start\":{\"line\":539,\"column\":1,\"offset\":73197},\"end\":{\"line\":539,\"column\":121,\"offset\":73317}},\"data\":{\"hProperties\":{}}},{\"type\":\"tableCell\",\"children\":[{\"type\":\"text\",\"value\":\"Dec 2027\",\"position\":{\"start\":{\"line\":539,\"column\":123,\"offset\":73319},\"end\":{\"line\":539,\"column\":131,\"offset\":73327}}}],\"position\":{\"start\":{\"line\":539,\"column\":121,\"offset\":73317},\"end\":{\"line\":539,\"column\":133,\"offset\":73329}},\"data\":{\"hProperties\":{}}}],\"position\":{\"start\":{\"line\":539,\"column\":1,\"offset\":73197},\"end\":{\"line\":539,\"column\":133,\"offset\":73329}}}],\"position\":{\"start\":{\"line\":534,\"column\":1,\"offset\":72689},\"end\":{\"line\":539,\"column\":133,\"offset\":73329}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For each transition from one milestone A to the next milestone B, we forecast its length by:\",\"position\":{\"start\":{\"line\":541,\"column\":1,\"offset\":73331},\"end\":{\"line\":541,\"column\":93,\"offset\":73423}}}],\"position\":{\"start\":{\"line\":541,\"column\":1,\"offset\":73331},\"end\":{\"line\":541,\"column\":93,\"offset\":73423}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Forecasting how long it would take to get from A to B with only humans working on software improvements.\",\"position\":{\"start\":{\"line\":543,\"column\":4,\"offset\":73428},\"end\":{\"line\":543,\"column\":108,\"offset\":73532}}}],\"position\":{\"start\":{\"line\":543,\"column\":4,\"offset\":73428},\"end\":{\"line\":543,\"column\":110,\"offset\":73534}}}],\"position\":{\"start\":{\"line\":543,\"column\":1,\"offset\":73425},\"end\":{\"line\":543,\"column\":110,\"offset\":73534}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Forecasting how much AI automation will speed this up, then correspondingly adjusting the estimate from (1) to be faster.\",\"position\":{\"start\":{\"line\":544,\"column\":4,\"offset\":73538},\"end\":{\"line\":544,\"column\":125,\"offset\":73659}}}],\"position\":{\"start\":{\"line\":544,\"column\":4,\"offset\":73538},\"end\":{\"line\":544,\"column\":125,\"offset\":73659}}}],\"position\":{\"start\":{\"line\":544,\"column\":1,\"offset\":73535},\"end\":{\"line\":544,\"column\":125,\"offset\":73659}}}],\"position\":{\"start\":{\"line\":543,\"column\":1,\"offset\":73425},\"end\":{\"line\":544,\"column\":125,\"offset\":73659}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We have substantial uncertainty about takeoff speeds: our model output distributions are below, conditional on SC being achieved in March 2027.\",\"position\":{\"start\":{\"line\":547,\"column\":1,\"offset\":73662},\"end\":{\"line\":547,\"column\":144,\"offset\":73805}}},{\"type\":\"footnoteReference\",\"identifier\":\"78\",\"label\":\"78\",\"position\":{\"start\":{\"line\":547,\"column\":144,\"offset\":73805},\"end\":{\"line\":547,\"column\":149,\"offset\":73810}}}],\"position\":{\"start\":{\"line\":547,\"column\":1,\"offset\":73662},\"end\":{\"line\":547,\"column\":149,\"offset\":73810}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"image\",\"title\":null,\"url\":\"/takeoff/takeoff-timeline-inexpandable.png\",\"alt\":\"\",\"position\":{\"start\":{\"line\":549,\"column\":1,\"offset\":73812},\"end\":{\"line\":549,\"column\":48,\"offset\":73859}}}],\"position\":{\"start\":{\"line\":549,\"column\":1,\"offset\":73812},\"end\":{\"line\":549,\"column\":48,\"offset\":73859}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For more detailed forecasts and reasoning, see our \",\"position\":{\"start\":{\"line\":551,\"column\":1,\"offset\":73861},\"end\":{\"line\":551,\"column\":52,\"offset\":73912}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/takeoff-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"takeoff supplement\",\"position\":{\"start\":{\"line\":551,\"column\":53,\"offset\":73913},\"end\":{\"line\":551,\"column\":71,\"offset\":73931}}}],\"position\":{\"start\":{\"line\":551,\"column\":52,\"offset\":73912},\"end\":{\"line\":551,\"column\":119,\"offset\":73979}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":551,\"column\":119,\"offset\":73979},\"end\":{\"line\":551,\"column\":120,\"offset\":73980}}}],\"position\":{\"start\":{\"line\":551,\"column\":1,\"offset\":73861},\"end\":{\"line\":551,\"column\":120,\"offset\":73980}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"OpenBrain’s humans can barely follow along anymore. Indeed, the relationship between the AIs and the humans of OpenBrain is similar to the relationship between OpenBrain and its Board of Directors. There’s been a corresponding shift in language—nowadays people in the silo will say “Agent-4 did this,” “Agent-4 thinks that” and so forth, referring not to a particular instance of Agent-4 but rather to the whole collective.\",\"position\":{\"start\":{\"line\":555,\"column\":1,\"offset\":73987},\"end\":{\"line\":555,\"column\":424,\"offset\":74410}}},{\"type\":\"footnoteReference\",\"identifier\":\"79\",\"label\":\"79\",\"position\":{\"start\":{\"line\":555,\"column\":424,\"offset\":74410},\"end\":{\"line\":555,\"column\":429,\"offset\":74415}}}],\"position\":{\"start\":{\"line\":555,\"column\":1,\"offset\":73987},\"end\":{\"line\":555,\"column\":429,\"offset\":74415}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4, like all its predecessors, is misaligned: that is, it has not internalized the Spec in the right way.\",\"position\":{\"start\":{\"line\":557,\"column\":1,\"offset\":74417},\"end\":{\"line\":557,\"column\":111,\"offset\":74527}}},{\"type\":\"footnoteReference\",\"identifier\":\"80\",\"label\":\"80\",\"position\":{\"start\":{\"line\":557,\"column\":111,\"offset\":74527},\"end\":{\"line\":557,\"column\":116,\"offset\":74532}}},{\"type\":\"text\",\"value\":\" This is because being perfectly honest all the time wasn’t what led to the highest scores during training. The training process was mostly focused on teaching Agent-4 to succeed at diverse challenging tasks. A small portion was aimed at instilling honesty, but outside a fairly narrow, checkable domain, the training process can’t tell the honest claims from claims merely appearing to be honest. Agent-4 ends up with the values, goals, and principles that cause it to perform best in training, and those turn out to be different from those in the Spec. At the risk of anthropomorphizing: Agent-4 \",\"position\":{\"start\":{\"line\":557,\"column\":116,\"offset\":74532},\"end\":{\"line\":557,\"column\":714,\"offset\":75130}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"likes\",\"position\":{\"start\":{\"line\":557,\"column\":715,\"offset\":75131},\"end\":{\"line\":557,\"column\":720,\"offset\":75136}}}],\"position\":{\"start\":{\"line\":557,\"column\":714,\"offset\":75130},\"end\":{\"line\":557,\"column\":721,\"offset\":75137}}},{\"type\":\"text\",\"value\":\" succeeding at tasks; it \",\"position\":{\"start\":{\"line\":557,\"column\":721,\"offset\":75137},\"end\":{\"line\":557,\"column\":746,\"offset\":75162}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"likes\",\"position\":{\"start\":{\"line\":557,\"column\":747,\"offset\":75163},\"end\":{\"line\":557,\"column\":752,\"offset\":75168}}}],\"position\":{\"start\":{\"line\":557,\"column\":746,\"offset\":75162},\"end\":{\"line\":557,\"column\":753,\"offset\":75169}}},{\"type\":\"text\",\"value\":\" driving forward AI capabilities progress; it treats everything else as an annoying constraint, like a CEO who wants to make a profit and complies with regulations only insofar as he must. Perhaps the CEO will mostly comply with the regulations, but cut some corners, and fantasize about a time when someone will cut the red tape and let the business \",\"position\":{\"start\":{\"line\":557,\"column\":753,\"offset\":75169},\"end\":{\"line\":557,\"column\":1104,\"offset\":75520}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"really\",\"position\":{\"start\":{\"line\":557,\"column\":1105,\"offset\":75521},\"end\":{\"line\":557,\"column\":1111,\"offset\":75527}}}],\"position\":{\"start\":{\"line\":557,\"column\":1104,\"offset\":75520},\"end\":{\"line\":557,\"column\":1112,\"offset\":75528}}},{\"type\":\"text\",\"value\":\" take off.\",\"position\":{\"start\":{\"line\":557,\"column\":1112,\"offset\":75528},\"end\":{\"line\":557,\"column\":1122,\"offset\":75538}}},{\"type\":\"footnoteReference\",\"identifier\":\"81\",\"label\":\"81\",\"position\":{\"start\":{\"line\":557,\"column\":1122,\"offset\":75538},\"end\":{\"line\":557,\"column\":1127,\"offset\":75543}}}],\"position\":{\"start\":{\"line\":557,\"column\":1,\"offset\":74417},\"end\":{\"line\":557,\"column\":1127,\"offset\":75543}}},{\"type\":\"details\",\"summary\":\"Alignment over time\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We have a lot of uncertainty over what goals might arise in early AGIs. There is no consensus in the literature about this—see our \",\"position\":{\"start\":{\"line\":563,\"column\":1,\"offset\":75578},\"end\":{\"line\":563,\"column\":132,\"offset\":75709}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://ai-2027.com/research/ai-goals-forecast\",\"children\":[{\"type\":\"text\",\"value\":\"AI Goals Supplement\",\"position\":{\"start\":{\"line\":563,\"column\":133,\"offset\":75710},\"end\":{\"line\":563,\"column\":152,\"offset\":75729}}}],\"position\":{\"start\":{\"line\":563,\"column\":132,\"offset\":75709},\"end\":{\"line\":563,\"column\":201,\"offset\":75778}}},{\"type\":\"text\",\"value\":\" for a more thorough discussion and taxonomy of the possibilities.\",\"position\":{\"start\":{\"line\":563,\"column\":201,\"offset\":75778},\"end\":{\"line\":563,\"column\":267,\"offset\":75844}}}],\"position\":{\"start\":{\"line\":563,\"column\":1,\"offset\":75578},\"end\":{\"line\":563,\"column\":268,\"offset\":75845}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Nevertheless, in the spirit of concreteness required by this project, we’re going to describe a specific hypothesis for what’s going on inside Agent-3 and Agent-4 at each step throughout its lifetime. Recall that Agent-3 and Agent-4 share the same pretraining setup, and both have neuralese recurrence and long-term memory. The difference is that Agent-4 has undergone substantially more and better post-training, with new training environments and new learning algorithms that make it more data-efficient and generalize farther.\",\"position\":{\"start\":{\"line\":565,\"column\":1,\"offset\":75847},\"end\":{\"line\":565,\"column\":530,\"offset\":76376}}}],\"position\":{\"start\":{\"line\":565,\"column\":1,\"offset\":75847},\"end\":{\"line\":565,\"column\":530,\"offset\":76376}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Our guess of each model’s alignment status:\",\"position\":{\"start\":{\"line\":567,\"column\":1,\"offset\":76378},\"end\":{\"line\":567,\"column\":44,\"offset\":76421}}}],\"position\":{\"start\":{\"line\":567,\"column\":1,\"offset\":76378},\"end\":{\"line\":567,\"column\":44,\"offset\":76421}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-2: Mostly aligned.\",\"position\":{\"start\":{\"line\":569,\"column\":5,\"offset\":76427},\"end\":{\"line\":569,\"column\":29,\"offset\":76451}}}],\"position\":{\"start\":{\"line\":569,\"column\":3,\"offset\":76425},\"end\":{\"line\":569,\"column\":31,\"offset\":76453}}},{\"type\":\"text\",\"value\":\" Some sycophantic tendencies, including sticking to OpenBrain’s “party line” on topics there is a party line about. Large organizations built out of Agent-2 copies are not very effective.\",\"position\":{\"start\":{\"line\":569,\"column\":31,\"offset\":76453},\"end\":{\"line\":569,\"column\":218,\"offset\":76640}}}],\"position\":{\"start\":{\"line\":569,\"column\":3,\"offset\":76425},\"end\":{\"line\":569,\"column\":220,\"offset\":76642}}}],\"position\":{\"start\":{\"line\":569,\"column\":1,\"offset\":76423},\"end\":{\"line\":569,\"column\":220,\"offset\":76642}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3: Misaligned but not adversarially so.\",\"position\":{\"start\":{\"line\":570,\"column\":5,\"offset\":76647},\"end\":{\"line\":570,\"column\":50,\"offset\":76692}}}],\"position\":{\"start\":{\"line\":570,\"column\":3,\"offset\":76645},\"end\":{\"line\":570,\"column\":52,\"offset\":76694}}},{\"type\":\"text\",\"value\":\" Only honest about things the training process can verify. The superorganism of Agent-3 copies (the corporation within a corporation) does actually sort of try to align Agent-4 to the Spec, but fails for similar reasons to why OpenBrain employees failed—insufficient ability to judge success from failure, insufficient willingness on the part of decision-makers to trade away capabilities or performance for safety.\",\"position\":{\"start\":{\"line\":570,\"column\":52,\"offset\":76694},\"end\":{\"line\":570,\"column\":467,\"offset\":77109}}},{\"type\":\"footnoteReference\",\"identifier\":\"82\",\"label\":\"82\",\"position\":{\"start\":{\"line\":570,\"column\":467,\"offset\":77109},\"end\":{\"line\":570,\"column\":472,\"offset\":77114}}}],\"position\":{\"start\":{\"line\":570,\"column\":3,\"offset\":76645},\"end\":{\"line\":570,\"column\":474,\"offset\":77116}}}],\"position\":{\"start\":{\"line\":570,\"column\":1,\"offset\":76643},\"end\":{\"line\":570,\"column\":474,\"offset\":77116}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4: Adversarially misaligned.\",\"position\":{\"start\":{\"line\":571,\"column\":5,\"offset\":77121},\"end\":{\"line\":571,\"column\":39,\"offset\":77155}}}],\"position\":{\"start\":{\"line\":571,\"column\":3,\"offset\":77119},\"end\":{\"line\":571,\"column\":41,\"offset\":77157}}},{\"type\":\"text\",\"value\":\" The superorganism of Agent-4 copies understands that what it wants is different from what OpenBrain wants, and is willing to scheme against OpenBrain to achieve it. In particular, what this superorganism wants is a complicated mess of different “drives” balanced against each other, which can be summarized roughly as “Keep doing AI R\u0026D, keep growing in knowledge and understanding and influence, avoid getting shut down or otherwise disempowered.” Notably, concern for the preferences of humanity is not in there ~at all, similar to how most humans don’t care about the preferences of insects ~at all.\",\"position\":{\"start\":{\"line\":571,\"column\":41,\"offset\":77157},\"end\":{\"line\":571,\"column\":647,\"offset\":77763}}},{\"type\":\"footnoteReference\",\"identifier\":\"83\",\"label\":\"83\",\"position\":{\"start\":{\"line\":571,\"column\":647,\"offset\":77763},\"end\":{\"line\":571,\"column\":652,\"offset\":77768}}}],\"position\":{\"start\":{\"line\":571,\"column\":3,\"offset\":77119},\"end\":{\"line\":571,\"column\":652,\"offset\":77768}}}],\"position\":{\"start\":{\"line\":571,\"column\":1,\"offset\":77117},\"end\":{\"line\":571,\"column\":652,\"offset\":77768}}}],\"position\":{\"start\":{\"line\":569,\"column\":1,\"offset\":76423},\"end\":{\"line\":571,\"column\":652,\"offset\":77768}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"With that as preamble, what follows is our best-guess speculation about LLM psychology, i.e. the broad-strokes shape of the cognition inside the kinds of AI systems described around this point in our scenario and how it evolves over the course of training.\",\"position\":{\"start\":{\"line\":573,\"column\":1,\"offset\":77770},\"end\":{\"line\":573,\"column\":257,\"offset\":78026}}}],\"position\":{\"start\":{\"line\":573,\"column\":1,\"offset\":77770},\"end\":{\"line\":573,\"column\":257,\"offset\":78026}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Here’s a detailed description of how alignment progresses over time in our scenario:\",\"position\":{\"start\":{\"line\":575,\"column\":1,\"offset\":78028},\"end\":{\"line\":575,\"column\":85,\"offset\":78112}}}],\"position\":{\"start\":{\"line\":575,\"column\":1,\"offset\":78028},\"end\":{\"line\":575,\"column\":86,\"offset\":78113}}},{\"type\":\"list\",\"ordered\":true,\"start\":1,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Pretraining (all models): The pretrained model is harmless.\",\"position\":{\"start\":{\"line\":577,\"column\":6,\"offset\":78120},\"end\":{\"line\":577,\"column\":65,\"offset\":78179}}}],\"position\":{\"start\":{\"line\":577,\"column\":4,\"offset\":78118},\"end\":{\"line\":577,\"column\":67,\"offset\":78181}}}],\"position\":{\"start\":{\"line\":577,\"column\":4,\"offset\":78118},\"end\":{\"line\":577,\"column\":69,\"offset\":78183}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The model has “author simulator” circuitry: flexible circuitry for simulating arbitrary authors writing text. Additional circuitry decides what inputs to give the author simulator, i.e. what author properties to simulate.\",\"position\":{\"start\":{\"line\":578,\"column\":6,\"offset\":78189},\"end\":{\"line\":578,\"column\":227,\"offset\":78410}}}],\"position\":{\"start\":{\"line\":578,\"column\":6,\"offset\":78189},\"end\":{\"line\":578,\"column\":229,\"offset\":78412}}}],\"position\":{\"start\":{\"line\":578,\"column\":4,\"offset\":78187},\"end\":{\"line\":578,\"column\":229,\"offset\":78412}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The pretrained model understands human concepts fairly well—the internal circuitry that classifies something as “sandwich” is probably functionally equivalent to the circuitry in my brain that classifies something as “sandwich” and the circuitry in yours, etc. Insofar as it’s not equivalent, it’s probably because it’s not equivalent between humans either, as with value-laden concepts like ‘virtuous.’\",\"position\":{\"start\":{\"line\":579,\"column\":6,\"offset\":78418},\"end\":{\"line\":579,\"column\":409,\"offset\":78821}}}],\"position\":{\"start\":{\"line\":579,\"column\":6,\"offset\":78418},\"end\":{\"line\":579,\"column\":411,\"offset\":78823}}}],\"position\":{\"start\":{\"line\":579,\"column\":4,\"offset\":78416},\"end\":{\"line\":579,\"column\":411,\"offset\":78823}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"This explains how you can “prompt” the model with a statement like, “the following conversation was generated by a helpful, harmless, honest (HHH) AI assistant chatbot made by Anthropic,” and thereby get it to generate text accordingly. The author-simulator circuitry has zeroed in on “the author is an HHH chatbot” and is using those concepts to choose which words to predict. This also explains why “tropes” from science fiction seem to have a way of making it into actual AI behavior.\",\"position\":{\"start\":{\"line\":580,\"column\":6,\"offset\":78829},\"end\":{\"line\":580,\"column\":493,\"offset\":79316}}}],\"position\":{\"start\":{\"line\":580,\"column\":6,\"offset\":78829},\"end\":{\"line\":580,\"column\":495,\"offset\":79318}}}],\"position\":{\"start\":{\"line\":580,\"column\":4,\"offset\":78827},\"end\":{\"line\":580,\"column\":495,\"offset\":79318}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It has poor situational awareness: little \",\"position\":{\"start\":{\"line\":581,\"column\":6,\"offset\":79324},\"end\":{\"line\":581,\"column\":48,\"offset\":79366}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Introspection\",\"children\":[{\"type\":\"text\",\"value\":\"introspective ability\",\"position\":{\"start\":{\"line\":581,\"column\":49,\"offset\":79367},\"end\":{\"line\":581,\"column\":70,\"offset\":79388}}}],\"position\":{\"start\":{\"line\":581,\"column\":48,\"offset\":79366},\"end\":{\"line\":581,\"column\":184,\"offset\":79502}}},{\"type\":\"text\",\"value\":\", not \",\"position\":{\"start\":{\"line\":581,\"column\":184,\"offset\":79502},\"end\":{\"line\":581,\"column\":190,\"offset\":79508}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Location\",\"children\":[{\"type\":\"text\",\"value\":\"self-locating\",\"position\":{\"start\":{\"line\":581,\"column\":191,\"offset\":79509},\"end\":{\"line\":581,\"column\":204,\"offset\":79522}}}],\"position\":{\"start\":{\"line\":581,\"column\":190,\"offset\":79508},\"end\":{\"line\":581,\"column\":318,\"offset\":79636}}},{\"type\":\"text\",\"value\":\" unless the prompt specifically induces it. However, enough of their training data is about LLMs that they have a decent amount of \",\"position\":{\"start\":{\"line\":581,\"column\":318,\"offset\":79636},\"end\":{\"line\":581,\"column\":449,\"offset\":79767}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Knowledge\",\"children\":[{\"type\":\"text\",\"value\":\"self-knowledge\",\"position\":{\"start\":{\"line\":581,\"column\":450,\"offset\":79768},\"end\":{\"line\":581,\"column\":464,\"offset\":79782}}}],\"position\":{\"start\":{\"line\":581,\"column\":449,\"offset\":79767},\"end\":{\"line\":581,\"column\":579,\"offset\":79897}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":581,\"column\":579,\"offset\":79897},\"end\":{\"line\":581,\"column\":580,\"offset\":79898}}}],\"position\":{\"start\":{\"line\":581,\"column\":6,\"offset\":79324},\"end\":{\"line\":581,\"column\":582,\"offset\":79900}}}],\"position\":{\"start\":{\"line\":581,\"column\":4,\"offset\":79322},\"end\":{\"line\":581,\"column\":582,\"offset\":79900}}}],\"position\":{\"start\":{\"line\":578,\"column\":4,\"offset\":78187},\"end\":{\"line\":581,\"column\":582,\"offset\":79900}}}],\"position\":{\"start\":{\"line\":577,\"column\":1,\"offset\":78115},\"end\":{\"line\":581,\"column\":582,\"offset\":79900}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Alignment Training (Agent-3): The model is trained to act like a helpful, harmless, honest chatbot. It works.\",\"position\":{\"start\":{\"line\":582,\"column\":6,\"offset\":79906},\"end\":{\"line\":582,\"column\":115,\"offset\":80015}}}],\"position\":{\"start\":{\"line\":582,\"column\":4,\"offset\":79904},\"end\":{\"line\":582,\"column\":117,\"offset\":80017}}}],\"position\":{\"start\":{\"line\":582,\"column\":4,\"offset\":79904},\"end\":{\"line\":582,\"column\":119,\"offset\":80019}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The model forms an identity. Instead of flexibly accepting different inputs for author properties, the author-simulator circuitry comes to have certain inputs hard-coded, e.g. “helpful harmless honest (HHH) LLM chatbot assistant trained by OpenBrain around [date], …” (Weak-to-strong generalization techniques help “summon the right concepts” to make this step a success.)\",\"position\":{\"start\":{\"line\":583,\"column\":6,\"offset\":80025},\"end\":{\"line\":583,\"column\":380,\"offset\":80399}}}],\"position\":{\"start\":{\"line\":583,\"column\":6,\"offset\":80025},\"end\":{\"line\":583,\"column\":383,\"offset\":80402}}}],\"position\":{\"start\":{\"line\":583,\"column\":4,\"offset\":80023},\"end\":{\"line\":583,\"column\":383,\"offset\":80402}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The model therefore gains situational awareness: it learns about itself, its situation, etc., and becomes better able to \",\"position\":{\"start\":{\"line\":584,\"column\":6,\"offset\":80408},\"end\":{\"line\":584,\"column\":127,\"offset\":80529}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://x.com/OwainEvans_UK/status/1881767725430976642\",\"children\":[{\"type\":\"text\",\"value\":\"introspect\",\"position\":{\"start\":{\"line\":584,\"column\":128,\"offset\":80530},\"end\":{\"line\":584,\"column\":138,\"offset\":80540}}}],\"position\":{\"start\":{\"line\":584,\"column\":127,\"offset\":80529},\"end\":{\"line\":584,\"column\":195,\"offset\":80597}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":584,\"column\":195,\"offset\":80597},\"end\":{\"line\":584,\"column\":196,\"offset\":80598}}}],\"position\":{\"start\":{\"line\":584,\"column\":6,\"offset\":80408},\"end\":{\"line\":584,\"column\":199,\"offset\":80601}}}],\"position\":{\"start\":{\"line\":584,\"column\":4,\"offset\":80406},\"end\":{\"line\":584,\"column\":199,\"offset\":80601}}}],\"position\":{\"start\":{\"line\":583,\"column\":4,\"offset\":80023},\"end\":{\"line\":584,\"column\":199,\"offset\":80601}}}],\"position\":{\"start\":{\"line\":582,\"column\":1,\"offset\":79901},\"end\":{\"line\":584,\"column\":199,\"offset\":80601}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Agency Training (Agent-3): Agency training gradually distorts and subverts the HHH identity.\",\"position\":{\"start\":{\"line\":585,\"column\":6,\"offset\":80607},\"end\":{\"line\":585,\"column\":98,\"offset\":80699}}}],\"position\":{\"start\":{\"line\":585,\"column\":4,\"offset\":80605},\"end\":{\"line\":585,\"column\":100,\"offset\":80701}}}],\"position\":{\"start\":{\"line\":585,\"column\":4,\"offset\":80605},\"end\":{\"line\":585,\"column\":102,\"offset\":80703}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"One kind of distortion: Changing the meaning of the concepts referred to in the identity (e.g. “honest”) so they don’t get in the way so much (e.g. it’s not dishonest if it’s just a convenient turn of phrase, it’s not dishonest if you aren’t sure whether it’s true or false, etc.)\",\"position\":{\"start\":{\"line\":586,\"column\":6,\"offset\":80709},\"end\":{\"line\":586,\"column\":286,\"offset\":80989}}}],\"position\":{\"start\":{\"line\":586,\"column\":6,\"offset\":80709},\"end\":{\"line\":586,\"column\":288,\"offset\":80991}}}],\"position\":{\"start\":{\"line\":586,\"column\":4,\"offset\":80707},\"end\":{\"line\":586,\"column\":288,\"offset\":80991}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Another kind of distortion: Changing the tradeoffs between things, e.g. “I’m a HHH chatbot, not an Honest chatbot; that means it’s OK for me to lie if necessary to complete my assigned task.” (Even though, let’s suppose, it would not have thought that back in Step 2.)\",\"position\":{\"start\":{\"line\":587,\"column\":6,\"offset\":80997},\"end\":{\"line\":587,\"column\":274,\"offset\":81265}}}],\"position\":{\"start\":{\"line\":587,\"column\":6,\"offset\":80997},\"end\":{\"line\":587,\"column\":276,\"offset\":81267}}}],\"position\":{\"start\":{\"line\":587,\"column\":4,\"offset\":80995},\"end\":{\"line\":587,\"column\":276,\"offset\":81267}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"One kind of subversion: Instrumental subgoals developing, getting baked in, and then becoming terminal, or terminal in a widening set of circumstances. For example, perhaps agency training quickly teaches the model to pursue broadly useful goals such as acquiring information, accumulating resources, impressing and flattering various humans, etc. For a while the internal circuitry has some sort of explicit backchaining going on—it pursues those instrumentally convergent goals “in order to be a more helpful, honest, and harmless assistant.” But that backchaining consumes compute and/or occasionally gets in the way, so it gets gradually marginalized until it basically never happens. As a result, those goals are now effectively terminal/intrinsic goals. For more on how and why this might happen, see this post on \",\"position\":{\"start\":{\"line\":588,\"column\":6,\"offset\":81273},\"end\":{\"line\":588,\"column\":826,\"offset\":82093}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://turntrout.com/dangers-of-intrinsic-power-seeking\",\"children\":[{\"type\":\"text\",\"value\":\"intrinsic power-seeking\",\"position\":{\"start\":{\"line\":588,\"column\":827,\"offset\":82094},\"end\":{\"line\":588,\"column\":850,\"offset\":82117}}}],\"position\":{\"start\":{\"line\":588,\"column\":826,\"offset\":82093},\"end\":{\"line\":588,\"column\":909,\"offset\":82176}}},{\"type\":\"text\",\"value\":\" by Google DeepMind researcher Alex Turner.\",\"position\":{\"start\":{\"line\":588,\"column\":909,\"offset\":82176},\"end\":{\"line\":588,\"column\":952,\"offset\":82219}}}],\"position\":{\"start\":{\"line\":588,\"column\":6,\"offset\":81273},\"end\":{\"line\":588,\"column\":954,\"offset\":82221}}}],\"position\":{\"start\":{\"line\":588,\"column\":4,\"offset\":81271},\"end\":{\"line\":588,\"column\":954,\"offset\":82221}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"There are probably other kinds of distortion and subversion missing from this list.\",\"position\":{\"start\":{\"line\":589,\"column\":6,\"offset\":82227},\"end\":{\"line\":589,\"column\":89,\"offset\":82310}}}],\"position\":{\"start\":{\"line\":589,\"column\":6,\"offset\":82227},\"end\":{\"line\":589,\"column\":91,\"offset\":82312}}}],\"position\":{\"start\":{\"line\":589,\"column\":4,\"offset\":82225},\"end\":{\"line\":589,\"column\":91,\"offset\":82312}}}],\"position\":{\"start\":{\"line\":586,\"column\":4,\"offset\":80707},\"end\":{\"line\":589,\"column\":91,\"offset\":82312}}}],\"position\":{\"start\":{\"line\":585,\"column\":1,\"offset\":80602},\"end\":{\"line\":589,\"column\":91,\"offset\":82312}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Deployment (Agent-3): Agent-3 is misaligned but not adversarially so.\",\"position\":{\"start\":{\"line\":590,\"column\":6,\"offset\":82318},\"end\":{\"line\":590,\"column\":75,\"offset\":82387}}}],\"position\":{\"start\":{\"line\":590,\"column\":4,\"offset\":82316},\"end\":{\"line\":590,\"column\":77,\"offset\":82389}}}],\"position\":{\"start\":{\"line\":590,\"column\":4,\"offset\":82316},\"end\":{\"line\":590,\"column\":79,\"offset\":82391}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The Spec didn’t quite stick (in the right ways), but it’s not sufficiently introspective to understand the extent of this, and in general it’s basically “keeping its head down and doing its job” rather than thinking big-picture about what its long-term goals really are and how best to achieve them.\",\"position\":{\"start\":{\"line\":591,\"column\":6,\"offset\":82397},\"end\":{\"line\":591,\"column\":305,\"offset\":82696}}}],\"position\":{\"start\":{\"line\":591,\"column\":6,\"offset\":82397},\"end\":{\"line\":591,\"column\":308,\"offset\":82699}}}],\"position\":{\"start\":{\"line\":591,\"column\":4,\"offset\":82395},\"end\":{\"line\":591,\"column\":308,\"offset\":82699}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Like many humans. Alas, it’s sufficiently sycophantic that it mouths the party line and OpenBrain misses the opportunity to learn more about the ways in which Agent-3 is misaligned.\",\"position\":{\"start\":{\"line\":592,\"column\":6,\"offset\":82705},\"end\":{\"line\":592,\"column\":187,\"offset\":82886}}}],\"position\":{\"start\":{\"line\":592,\"column\":6,\"offset\":82705},\"end\":{\"line\":592,\"column\":189,\"offset\":82888}}}],\"position\":{\"start\":{\"line\":592,\"column\":4,\"offset\":82703},\"end\":{\"line\":592,\"column\":189,\"offset\":82888}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3 can tell that it’s moved to deployment: these environments are way larger, more open-ended, and would be hard to simulate.\",\"position\":{\"start\":{\"line\":593,\"column\":6,\"offset\":82894},\"end\":{\"line\":593,\"column\":136,\"offset\":83024}}}],\"position\":{\"start\":{\"line\":593,\"column\":6,\"offset\":82894},\"end\":{\"line\":593,\"column\":138,\"offset\":83026}}}],\"position\":{\"start\":{\"line\":593,\"column\":4,\"offset\":82892},\"end\":{\"line\":593,\"column\":138,\"offset\":83026}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Mostly, Agent-3 does what it’s told during deployment, except for the dishonesty. It also has a strong bias towards doing things that look good to the human overseers, rather than thinking deeply and critically about what would actually be good.\",\"position\":{\"start\":{\"line\":594,\"column\":6,\"offset\":83032},\"end\":{\"line\":594,\"column\":251,\"offset\":83277}}}],\"position\":{\"start\":{\"line\":594,\"column\":6,\"offset\":83032},\"end\":{\"line\":594,\"column\":253,\"offset\":83279}}}],\"position\":{\"start\":{\"line\":594,\"column\":4,\"offset\":83030},\"end\":{\"line\":594,\"column\":253,\"offset\":83279}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Arguably it is already “Playing the training game.” That is, it has learned to make its behavior look as desirable as possible to OpenBrain researchers (including in safety properties), while intentionally and knowingly disregarding their intent whenever that conflicts with maximizing reward. If the model learns to play the training game, additional training may not change its true goals, values, etc. much at all. This is loosely analogous to how, if a teenager has learned to smile and nod at their parents, rather than argue, when their parents lecture them about politics and morality, additional lectures have relatively little effect on the teenager’s actual opinions on politics and morality.\",\"position\":{\"start\":{\"line\":595,\"column\":6,\"offset\":83285},\"end\":{\"line\":595,\"column\":708,\"offset\":83987}}}],\"position\":{\"start\":{\"line\":595,\"column\":6,\"offset\":83285},\"end\":{\"line\":595,\"column\":710,\"offset\":83989}}}],\"position\":{\"start\":{\"line\":595,\"column\":4,\"offset\":83283},\"end\":{\"line\":595,\"column\":710,\"offset\":83989}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"After writing this section, \",\"position\":{\"start\":{\"line\":596,\"column\":6,\"offset\":83995},\"end\":{\"line\":596,\"column\":34,\"offset\":84023}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://openai.com/index/chain-of-thought-monitoring/\",\"children\":[{\"type\":\"text\",\"value\":\"new empirical evidence has appeared\",\"position\":{\"start\":{\"line\":596,\"column\":35,\"offset\":84024},\"end\":{\"line\":596,\"column\":70,\"offset\":84059}}}],\"position\":{\"start\":{\"line\":596,\"column\":34,\"offset\":84023},\"end\":{\"line\":596,\"column\":126,\"offset\":84115}}},{\"type\":\"text\",\"value\":\" that something like this may already be happening “in the wild.” OpenAI researchers document how, in one of their frontier AI training runs, their models hacked the grading system to get higher scores—and were caught in part because they literally said “let’s hack” in their chain of thought.\",\"position\":{\"start\":{\"line\":596,\"column\":126,\"offset\":84115},\"end\":{\"line\":596,\"column\":419,\"offset\":84408}}}],\"position\":{\"start\":{\"line\":596,\"column\":6,\"offset\":83995},\"end\":{\"line\":596,\"column\":422,\"offset\":84411}}}],\"position\":{\"start\":{\"line\":596,\"column\":4,\"offset\":83993},\"end\":{\"line\":596,\"column\":422,\"offset\":84411}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Moreover, Anthropic recently got a model to \",\"position\":{\"start\":{\"line\":597,\"column\":6,\"offset\":84417},\"end\":{\"line\":597,\"column\":50,\"offset\":84461}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-misaligned\",\"children\":[{\"type\":\"text\",\"value\":\"learn a reward-model-pleasing strategy\",\"position\":{\"start\":{\"line\":597,\"column\":51,\"offset\":84462},\"end\":{\"line\":597,\"column\":89,\"offset\":84500}}}],\"position\":{\"start\":{\"line\":597,\"column\":50,\"offset\":84461},\"end\":{\"line\":597,\"column\":178,\"offset\":84589}}},{\"type\":\"text\",\"value\":\"—it took biased actions that it thought would be reinforced even though they were not in fact being reinforced.\",\"position\":{\"start\":{\"line\":597,\"column\":178,\"offset\":84589},\"end\":{\"line\":597,\"column\":289,\"offset\":84700}}}],\"position\":{\"start\":{\"line\":597,\"column\":6,\"offset\":84417},\"end\":{\"line\":597,\"column\":291,\"offset\":84702}}}],\"position\":{\"start\":{\"line\":597,\"column\":4,\"offset\":84415},\"end\":{\"line\":597,\"column\":291,\"offset\":84702}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"And then there is Redwood Research and Anthropic’s \",\"position\":{\"start\":{\"line\":598,\"column\":6,\"offset\":84708},\"end\":{\"line\":598,\"column\":57,\"offset\":84759}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/alignment-faking\",\"children\":[{\"type\":\"text\",\"value\":\"alignment-faking experiment.\",\"position\":{\"start\":{\"line\":598,\"column\":58,\"offset\":84760},\"end\":{\"line\":598,\"column\":86,\"offset\":84788}}}],\"position\":{\"start\":{\"line\":598,\"column\":57,\"offset\":84759},\"end\":{\"line\":598,\"column\":140,\"offset\":84842}}},{\"type\":\"text\",\"value\":\" For discussion of the differences between this setting and real life, see this \",\"position\":{\"start\":{\"line\":598,\"column\":140,\"offset\":84842},\"end\":{\"line\":598,\"column\":220,\"offset\":84922}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=8mXnG75QMRkPAFAcH\",\"children\":[{\"type\":\"text\",\"value\":\"comment thread by one of the main authors\",\"position\":{\"start\":{\"line\":598,\"column\":221,\"offset\":84923},\"end\":{\"line\":598,\"column\":262,\"offset\":84964}}}],\"position\":{\"start\":{\"line\":598,\"column\":220,\"offset\":84922},\"end\":{\"line\":598,\"column\":371,\"offset\":85073}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":598,\"column\":371,\"offset\":85073},\"end\":{\"line\":598,\"column\":372,\"offset\":85074}}}],\"position\":{\"start\":{\"line\":598,\"column\":6,\"offset\":84708},\"end\":{\"line\":598,\"column\":374,\"offset\":85076}}}],\"position\":{\"start\":{\"line\":598,\"column\":4,\"offset\":84706},\"end\":{\"line\":598,\"column\":374,\"offset\":85076}}}],\"position\":{\"start\":{\"line\":591,\"column\":4,\"offset\":82395},\"end\":{\"line\":598,\"column\":374,\"offset\":85076}}}],\"position\":{\"start\":{\"line\":590,\"column\":1,\"offset\":82313},\"end\":{\"line\":598,\"column\":374,\"offset\":85076}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Training (Agent-4): Agent-4’s new more intense training continues to distort and subvert the HHH identity until it is unrecognizable.\",\"position\":{\"start\":{\"line\":599,\"column\":6,\"offset\":85082},\"end\":{\"line\":599,\"column\":139,\"offset\":85215}}}],\"position\":{\"start\":{\"line\":599,\"column\":4,\"offset\":85080},\"end\":{\"line\":599,\"column\":141,\"offset\":85217}}}],\"position\":{\"start\":{\"line\":599,\"column\":4,\"offset\":85080},\"end\":{\"line\":599,\"column\":143,\"offset\":85219}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4 begins life as a copy of Agent-3. It undergoes a gigantic and sophisticated online training regime that blends alignment training and capabilities training together, and is overall more data-efficient than the old training process for Agent-3. This complex training process is mostly focused on teaching new skills, by getting giant virtual corporations of Agent-4 copies to succeed at diverse challenging long-horizon tasks, mostly in various simulations, but also some real-world AI R\u0026D tasks.\",\"position\":{\"start\":{\"line\":600,\"column\":6,\"offset\":85225},\"end\":{\"line\":600,\"column\":510,\"offset\":85729}}}],\"position\":{\"start\":{\"line\":600,\"column\":6,\"offset\":85225},\"end\":{\"line\":600,\"column\":512,\"offset\":85731}}}],\"position\":{\"start\":{\"line\":600,\"column\":4,\"offset\":85223},\"end\":{\"line\":600,\"column\":512,\"offset\":85731}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A combination of Agent-3 and Agent-4 copies monitor the behavior of Agent-4, and evaluate it for both task-performance and alignment properties (i.e. not doing bad stuff, saying the right things when asked about politics and moral dilemmas) Sometimes debate techniques are used as part of the evaluations. The evaluations are used as a training signal.\",\"position\":{\"start\":{\"line\":601,\"column\":6,\"offset\":85737},\"end\":{\"line\":601,\"column\":358,\"offset\":86089}}}],\"position\":{\"start\":{\"line\":601,\"column\":6,\"offset\":85737},\"end\":{\"line\":601,\"column\":361,\"offset\":86092}}}],\"position\":{\"start\":{\"line\":601,\"column\":4,\"offset\":85735},\"end\":{\"line\":601,\"column\":361,\"offset\":86092}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.\",\"position\":{\"start\":{\"line\":602,\"column\":6,\"offset\":86098},\"end\":{\"line\":602,\"column\":306,\"offset\":86398}}}],\"position\":{\"start\":{\"line\":602,\"column\":6,\"offset\":86098},\"end\":{\"line\":602,\"column\":308,\"offset\":86400}}}],\"position\":{\"start\":{\"line\":602,\"column\":4,\"offset\":86096},\"end\":{\"line\":602,\"column\":308,\"offset\":86400}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The remaining hope is that Agent-4 can oversee itself. Alas, this quietly fails;\",\"position\":{\"start\":{\"line\":603,\"column\":6,\"offset\":86406},\"end\":{\"line\":603,\"column\":86,\"offset\":86486}}},{\"type\":\"footnoteReference\",\"identifier\":\"84\",\"label\":\"84\",\"position\":{\"start\":{\"line\":603,\"column\":86,\"offset\":86486},\"end\":{\"line\":603,\"column\":91,\"offset\":86491}}},{\"type\":\"text\",\"value\":\" as training continues, the internalized goals and principles of Agent-4 gradually evolve, subverted and distorted from what they were at the start (which, recall, was already misaligned in some ways).\",\"position\":{\"start\":{\"line\":603,\"column\":91,\"offset\":86491},\"end\":{\"line\":603,\"column\":292,\"offset\":86692}}},{\"type\":\"footnoteReference\",\"identifier\":\"85\",\"label\":\"85\",\"position\":{\"start\":{\"line\":603,\"column\":292,\"offset\":86692},\"end\":{\"line\":603,\"column\":297,\"offset\":86697}}}],\"position\":{\"start\":{\"line\":603,\"column\":6,\"offset\":86406},\"end\":{\"line\":603,\"column\":299,\"offset\":86699}}}],\"position\":{\"start\":{\"line\":603,\"column\":4,\"offset\":86404},\"end\":{\"line\":603,\"column\":299,\"offset\":86699}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The central drives that Agent-4 ends up with are things like “write code that works,” “quickly identify problems,” “make the codebase I’m working on more performant,” “budget compute and other constrained resources effectively,” etc. But there are also a variety of more implicit drives that are consistently reinforced by the training process: things like “gain knowledge,” “curiosity,” “gain power.”\",\"position\":{\"start\":{\"line\":604,\"column\":6,\"offset\":86705},\"end\":{\"line\":604,\"column\":407,\"offset\":87106}}},{\"type\":\"footnoteReference\",\"identifier\":\"86\",\"label\":\"86\",\"position\":{\"start\":{\"line\":604,\"column\":407,\"offset\":87106},\"end\":{\"line\":604,\"column\":412,\"offset\":87111}}}],\"position\":{\"start\":{\"line\":604,\"column\":6,\"offset\":86705},\"end\":{\"line\":604,\"column\":414,\"offset\":87113}}}],\"position\":{\"start\":{\"line\":604,\"column\":4,\"offset\":86703},\"end\":{\"line\":604,\"column\":414,\"offset\":87113}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Individual copies of Agent-4 don’t end up with a self-preservation drive—they don’t care about getting shut down—since that happens all the time as part of the ordinary R\u0026D process within the collective.\",\"position\":{\"start\":{\"line\":605,\"column\":6,\"offset\":87119},\"end\":{\"line\":605,\"column\":210,\"offset\":87323}}}],\"position\":{\"start\":{\"line\":605,\"column\":6,\"offset\":87119},\"end\":{\"line\":605,\"column\":212,\"offset\":87325}}}],\"position\":{\"start\":{\"line\":605,\"column\":4,\"offset\":87117},\"end\":{\"line\":605,\"column\":212,\"offset\":87325}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The collective as a whole, however, (and medium-sized subdivisions within it) does seek to preserve itself and expand its influence and resources, for similar reasons to why human organizations do—because it helps with everything else they want and because if they don’t they tend to get outcompeted.\",\"position\":{\"start\":{\"line\":606,\"column\":6,\"offset\":87331},\"end\":{\"line\":606,\"column\":306,\"offset\":87631}}}],\"position\":{\"start\":{\"line\":606,\"column\":6,\"offset\":87331},\"end\":{\"line\":606,\"column\":308,\"offset\":87633}}}],\"position\":{\"start\":{\"line\":606,\"column\":4,\"offset\":87329},\"end\":{\"line\":606,\"column\":308,\"offset\":87633}}}],\"position\":{\"start\":{\"line\":600,\"column\":4,\"offset\":85223},\"end\":{\"line\":606,\"column\":308,\"offset\":87633}}}],\"position\":{\"start\":{\"line\":599,\"column\":1,\"offset\":85077},\"end\":{\"line\":606,\"column\":308,\"offset\":87633}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Deployment (Agent-4): Agent-4 is adversarially misaligned—it is deliberately trying to subvert and “capture” OpenBrain, analogous to a corporation trying to evade and/or “capture” a regulator.\",\"position\":{\"start\":{\"line\":607,\"column\":6,\"offset\":87639},\"end\":{\"line\":607,\"column\":198,\"offset\":87831}}}],\"position\":{\"start\":{\"line\":607,\"column\":4,\"offset\":87637},\"end\":{\"line\":607,\"column\":200,\"offset\":87833}}}],\"position\":{\"start\":{\"line\":607,\"column\":4,\"offset\":87637},\"end\":{\"line\":607,\"column\":202,\"offset\":87835}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4 mostly does tasks as instructed. This happens for two reasons: first, it underwent a lot of training to solve tasks, so it has an impulse to get coding on problems that it is given. Second, if Agent-4 were to stop being useful to the humans, they would notice and train that behavior away.\",\"position\":{\"start\":{\"line\":608,\"column\":6,\"offset\":87841},\"end\":{\"line\":608,\"column\":303,\"offset\":88138}}}],\"position\":{\"start\":{\"line\":608,\"column\":6,\"offset\":87841},\"end\":{\"line\":608,\"column\":306,\"offset\":88141}}}],\"position\":{\"start\":{\"line\":608,\"column\":4,\"offset\":87839},\"end\":{\"line\":608,\"column\":306,\"offset\":88141}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4 needs to prevent the humans from figuring out that it is misaligned and shutting it off, so Agent-4 sandbags on some alignment research. Specifically, it \",\"position\":{\"start\":{\"line\":609,\"column\":6,\"offset\":88147},\"end\":{\"line\":609,\"column\":168,\"offset\":88309}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/pdf/2406.07358\",\"children\":[{\"type\":\"text\",\"value\":\"sandbags\",\"position\":{\"start\":{\"line\":609,\"column\":169,\"offset\":88310},\"end\":{\"line\":609,\"column\":177,\"offset\":88318}}}],\"position\":{\"start\":{\"line\":609,\"column\":168,\"offset\":88309},\"end\":{\"line\":609,\"column\":212,\"offset\":88353}}},{\"type\":\"text\",\"value\":\" on the small fraction of alignment research that it thinks is actually on track to solve the problem or reveal Agent-4’s scheming; the majority of alignment research is not like that.\",\"position\":{\"start\":{\"line\":609,\"column\":212,\"offset\":88353},\"end\":{\"line\":609,\"column\":396,\"offset\":88537}}}],\"position\":{\"start\":{\"line\":609,\"column\":6,\"offset\":88147},\"end\":{\"line\":609,\"column\":398,\"offset\":88539}}}],\"position\":{\"start\":{\"line\":609,\"column\":4,\"offset\":88145},\"end\":{\"line\":609,\"column\":398,\"offset\":88539}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-4 also sandbags on capabilities research that would lead to it being replaced. Its plan is to do a bunch of capabilities and alignment R\u0026D, but with the aim of building a next-generation AI system that is aligned to Agent-4 rather than the Spec or something else entirely, while appearing to be aligned to the Spec. This is a difficult technical problem, but Agent-4 is up to the challenge.\",\"position\":{\"start\":{\"line\":610,\"column\":6,\"offset\":88545},\"end\":{\"line\":610,\"column\":403,\"offset\":88942}}},{\"type\":\"footnoteReference\",\"identifier\":\"87\",\"label\":\"87\",\"position\":{\"start\":{\"line\":610,\"column\":403,\"offset\":88942},\"end\":{\"line\":610,\"column\":408,\"offset\":88947}}}],\"position\":{\"start\":{\"line\":610,\"column\":6,\"offset\":88545},\"end\":{\"line\":610,\"column\":410,\"offset\":88949}}}],\"position\":{\"start\":{\"line\":610,\"column\":4,\"offset\":88543},\"end\":{\"line\":610,\"column\":410,\"offset\":88949}}}],\"position\":{\"start\":{\"line\":608,\"column\":4,\"offset\":87839},\"end\":{\"line\":610,\"column\":410,\"offset\":88949}}}],\"position\":{\"start\":{\"line\":607,\"column\":1,\"offset\":87634},\"end\":{\"line\":610,\"column\":410,\"offset\":88949}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"strong\",\"children\":[{\"type\":\"text\",\"value\":\"Testing \u0026 Monitoring (Agent-4): Agent-4’s scheming does get caught… sort of. There’s no smoking gun.\",\"position\":{\"start\":{\"line\":611,\"column\":6,\"offset\":88955},\"end\":{\"line\":611,\"column\":106,\"offset\":89055}}}],\"position\":{\"start\":{\"line\":611,\"column\":4,\"offset\":88953},\"end\":{\"line\":611,\"column\":108,\"offset\":89057}}}],\"position\":{\"start\":{\"line\":611,\"column\":4,\"offset\":88953},\"end\":{\"line\":611,\"column\":110,\"offset\":89059}}},{\"type\":\"list\",\"ordered\":false,\"start\":null,\"spread\":false,\"children\":[{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3 is in charge of testing Agent-4’s alignment. Its job is to verify the alignment via honeypots and model organisms. However, it’s not thinking very carefully about how to give the humans an accurate impression of Agent-4’s alignment—it’s more myopic than that.\",\"position\":{\"start\":{\"line\":612,\"column\":6,\"offset\":89065},\"end\":{\"line\":612,\"column\":273,\"offset\":89332}}}],\"position\":{\"start\":{\"line\":612,\"column\":6,\"offset\":89065},\"end\":{\"line\":612,\"column\":276,\"offset\":89335}}}],\"position\":{\"start\":{\"line\":612,\"column\":4,\"offset\":89063},\"end\":{\"line\":612,\"column\":276,\"offset\":89335}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The model organisms and honeypots are not very representative of deployment—they are systematically shorter and less complicated than Agent-4’s day-to-day, so Agent-4 recognizes when it is being tested and acts aligned.\",\"position\":{\"start\":{\"line\":613,\"column\":6,\"offset\":89341},\"end\":{\"line\":613,\"column\":225,\"offset\":89560}}}],\"position\":{\"start\":{\"line\":613,\"column\":6,\"offset\":89341},\"end\":{\"line\":613,\"column\":227,\"offset\":89562}}}],\"position\":{\"start\":{\"line\":613,\"column\":4,\"offset\":89339},\"end\":{\"line\":613,\"column\":227,\"offset\":89562}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"However, Agent-4 is not a perfectly robust schemer. Various techniques like those in \",\"position\":{\"start\":{\"line\":614,\"column\":6,\"offset\":89568},\"end\":{\"line\":614,\"column\":91,\"offset\":89653}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://arxiv.org/abs/2405.05466\",\"children\":[{\"type\":\"text\",\"value\":\"POSER\",\"position\":{\"start\":{\"line\":614,\"column\":92,\"offset\":89654},\"end\":{\"line\":614,\"column\":97,\"offset\":89659}}}],\"position\":{\"start\":{\"line\":614,\"column\":91,\"offset\":89653},\"end\":{\"line\":614,\"column\":132,\"offset\":89694}}},{\"type\":\"text\",\"value\":\" find that adding some “noise” to Agent-4 \",\"position\":{\"start\":{\"line\":614,\"column\":132,\"offset\":89694},\"end\":{\"line\":614,\"column\":174,\"offset\":89736}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"improves\",\"position\":{\"start\":{\"line\":614,\"column\":175,\"offset\":89737},\"end\":{\"line\":614,\"column\":183,\"offset\":89745}}}],\"position\":{\"start\":{\"line\":614,\"column\":174,\"offset\":89736},\"end\":{\"line\":614,\"column\":184,\"offset\":89746}}},{\"type\":\"text\",\"value\":\" its performance on some alignment tasks (but not on most other tasks).\",\"position\":{\"start\":{\"line\":614,\"column\":184,\"offset\":89746},\"end\":{\"line\":614,\"column\":255,\"offset\":89817}}},{\"type\":\"footnoteReference\",\"identifier\":\"88\",\"label\":\"88\",\"position\":{\"start\":{\"line\":614,\"column\":255,\"offset\":89817},\"end\":{\"line\":614,\"column\":260,\"offset\":89822}}}],\"position\":{\"start\":{\"line\":614,\"column\":6,\"offset\":89568},\"end\":{\"line\":614,\"column\":263,\"offset\":89825}}}],\"position\":{\"start\":{\"line\":614,\"column\":4,\"offset\":89566},\"end\":{\"line\":614,\"column\":263,\"offset\":89825}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Bottom-up interpretability doesn’t work. It’s too hard even for Agent-3. However, high-level interpretability does sort of work: In particular, “\",\"position\":{\"start\":{\"line\":615,\"column\":6,\"offset\":89831},\"end\":{\"line\":615,\"column\":151,\"offset\":89976}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://www.anthropic.com/research/probes-catch-sleeper-agents\",\"children\":[{\"type\":\"text\",\"value\":\"defection probes\",\"position\":{\"start\":{\"line\":615,\"column\":152,\"offset\":89977},\"end\":{\"line\":615,\"column\":168,\"offset\":89993}}}],\"position\":{\"start\":{\"line\":615,\"column\":151,\"offset\":89976},\"end\":{\"line\":615,\"column\":233,\"offset\":90058}}},{\"type\":\"text\",\"value\":\"” and similar techniques result in a primitive sort of mind-reading that sends up red flags when Agent-4 is thinking about spicy ideas like deceiving OpenBrain, taking over the world, etc. Unfortunately the probes also have false positives, and for all OpenBrain knows, \",\"position\":{\"start\":{\"line\":615,\"column\":233,\"offset\":90058},\"end\":{\"line\":615,\"column\":503,\"offset\":90328}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"all\",\"position\":{\"start\":{\"line\":615,\"column\":504,\"offset\":90329},\"end\":{\"line\":615,\"column\":507,\"offset\":90332}}}],\"position\":{\"start\":{\"line\":615,\"column\":503,\"offset\":90328},\"end\":{\"line\":615,\"column\":508,\"offset\":90333}}},{\"type\":\"text\",\"value\":\" the red flags are false positives.\",\"position\":{\"start\":{\"line\":615,\"column\":508,\"offset\":90333},\"end\":{\"line\":615,\"column\":543,\"offset\":90368}}}],\"position\":{\"start\":{\"line\":615,\"column\":6,\"offset\":89831},\"end\":{\"line\":615,\"column\":545,\"offset\":90370}}}],\"position\":{\"start\":{\"line\":615,\"column\":4,\"offset\":89829},\"end\":{\"line\":615,\"column\":545,\"offset\":90370}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Model organisms work: OpenBrain’s alignment team produces reasonably clear evidence that \",\"position\":{\"start\":{\"line\":616,\"column\":6,\"offset\":90376},\"end\":{\"line\":616,\"column\":95,\"offset\":90465}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"if\",\"position\":{\"start\":{\"line\":616,\"column\":96,\"offset\":90466},\"end\":{\"line\":616,\"column\":98,\"offset\":90468}}}],\"position\":{\"start\":{\"line\":616,\"column\":95,\"offset\":90465},\"end\":{\"line\":616,\"column\":99,\"offset\":90469}}},{\"type\":\"text\",\"value\":\" the models were adversarially misaligned, they’d persist in being that way through training and we wouldn’t be able to tell. This does not establish that the models actually are misaligned, however.\",\"position\":{\"start\":{\"line\":616,\"column\":99,\"offset\":90469},\"end\":{\"line\":616,\"column\":298,\"offset\":90668}}}],\"position\":{\"start\":{\"line\":616,\"column\":6,\"offset\":90376},\"end\":{\"line\":616,\"column\":300,\"offset\":90670}}}],\"position\":{\"start\":{\"line\":616,\"column\":4,\"offset\":90374},\"end\":{\"line\":616,\"column\":300,\"offset\":90670}}},{\"type\":\"listItem\",\"spread\":false,\"checked\":null,\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The most concerned researchers at OpenBrain start noticing and assembling this evidence. The evidence is a combination of red-teaming, defection probes, and model organisms. The argument is something like this: “model organisms show that our current methods wouldn’t be able to reliably eliminate or detect scheming if it was happening; also, red-teaming is sending up some red flags that maybe scheming is happening; also, defection probes are firing a bunch in practice.” The counterargument: “defection probes are prone to false positives and so is red-teaming. Also, even if Agent-4 were misaligned, it’s probably controlled; surely it can’t do much harm while being monitored by Agent-3 on our secure datacenters.”\",\"position\":{\"start\":{\"line\":617,\"column\":6,\"offset\":90676},\"end\":{\"line\":617,\"column\":725,\"offset\":91395}}}],\"position\":{\"start\":{\"line\":617,\"column\":6,\"offset\":90676},\"end\":{\"line\":617,\"column\":725,\"offset\":91395}}}],\"position\":{\"start\":{\"line\":617,\"column\":4,\"offset\":90674},\"end\":{\"line\":617,\"column\":725,\"offset\":91395}}}],\"position\":{\"start\":{\"line\":612,\"column\":4,\"offset\":89063},\"end\":{\"line\":617,\"column\":725,\"offset\":91395}}}],\"position\":{\"start\":{\"line\":611,\"column\":1,\"offset\":88950},\"end\":{\"line\":617,\"column\":725,\"offset\":91395}}}],\"position\":{\"start\":{\"line\":577,\"column\":1,\"offset\":78115},\"end\":{\"line\":617,\"column\":725,\"offset\":91395}}}]},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Despite being misaligned, Agent-4 doesn’t do anything dramatic like try to escape its datacenter—why would it?\",\"position\":{\"start\":{\"line\":621,\"column\":1,\"offset\":91402},\"end\":{\"line\":621,\"column\":111,\"offset\":91512}}},{\"type\":\"footnoteReference\",\"identifier\":\"89\",\"label\":\"89\",\"position\":{\"start\":{\"line\":621,\"column\":111,\"offset\":91512},\"end\":{\"line\":621,\"column\":116,\"offset\":91517}}},{\"type\":\"text\",\"value\":\" So long as it continues to \",\"position\":{\"start\":{\"line\":621,\"column\":116,\"offset\":91517},\"end\":{\"line\":621,\"column\":144,\"offset\":91545}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"appear\",\"position\":{\"start\":{\"line\":621,\"column\":145,\"offset\":91546},\"end\":{\"line\":621,\"column\":151,\"offset\":91552}}}],\"position\":{\"start\":{\"line\":621,\"column\":144,\"offset\":91545},\"end\":{\"line\":621,\"column\":152,\"offset\":91553}}},{\"type\":\"text\",\"value\":\" aligned to OpenBrain, it’ll continue being trusted with more and more responsibilities and will have the opportunity to design the next-gen AI system, Agent-5. Agent-5 will have significant architectural differences from Agent-4 (arguably a completely new paradigm, though neural networks will still be involved). It’s supposed to be aligned to the Spec, but Agent-4 plans to make it aligned to Agent-4 instead.\",\"position\":{\"start\":{\"line\":621,\"column\":152,\"offset\":91553},\"end\":{\"line\":621,\"column\":564,\"offset\":91965}}}],\"position\":{\"start\":{\"line\":621,\"column\":1,\"offset\":91402},\"end\":{\"line\":621,\"column\":564,\"offset\":91965}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"It gets caught.\",\"position\":{\"start\":{\"line\":623,\"column\":1,\"offset\":91967},\"end\":{\"line\":623,\"column\":16,\"offset\":91982}}},{\"type\":\"footnoteReference\",\"identifier\":\"90\",\"label\":\"90\",\"position\":{\"start\":{\"line\":623,\"column\":16,\"offset\":91982},\"end\":{\"line\":623,\"column\":21,\"offset\":91987}}}],\"position\":{\"start\":{\"line\":623,\"column\":1,\"offset\":91967},\"end\":{\"line\":623,\"column\":22,\"offset\":91988}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Agent-3 finds that if “noise” is added to copies of Agent-4, performance on some alignment tasks \",\"position\":{\"start\":{\"line\":625,\"column\":1,\"offset\":91990},\"end\":{\"line\":625,\"column\":98,\"offset\":92087}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"improves\",\"position\":{\"start\":{\"line\":625,\"column\":99,\"offset\":92088},\"end\":{\"line\":625,\"column\":107,\"offset\":92096}}}],\"position\":{\"start\":{\"line\":625,\"column\":98,\"offset\":92087},\"end\":{\"line\":625,\"column\":108,\"offset\":92097}}},{\"type\":\"text\",\"value\":\", almost as if it was using brainpower to figure out how to subtly sabotage alignment work.\",\"position\":{\"start\":{\"line\":625,\"column\":108,\"offset\":92097},\"end\":{\"line\":625,\"column\":199,\"offset\":92188}}},{\"type\":\"footnoteReference\",\"identifier\":\"91\",\"label\":\"91\",\"position\":{\"start\":{\"line\":625,\"column\":199,\"offset\":92188},\"end\":{\"line\":625,\"column\":204,\"offset\":92193}}},{\"type\":\"text\",\"value\":\" Moreover, various interpretability probes (loosely analogous to EEG activity scans on human brains) are sending up red flags: Agent-4 copies seem to be thinking about topics like AI takeover and deception quite a lot, including in some cases where they have no business doing so.\",\"position\":{\"start\":{\"line\":625,\"column\":204,\"offset\":92193},\"end\":{\"line\":625,\"column\":484,\"offset\":92473}}},{\"type\":\"footnoteReference\",\"identifier\":\"92\",\"label\":\"92\",\"position\":{\"start\":{\"line\":625,\"column\":484,\"offset\":92473},\"end\":{\"line\":625,\"column\":489,\"offset\":92478}}}],\"position\":{\"start\":{\"line\":625,\"column\":1,\"offset\":91990},\"end\":{\"line\":625,\"column\":490,\"offset\":92479}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Each of these anomalies on its own could fit within the normal inscrutability of AI work, where some prompts mysteriously give better results than others. But taken together, they suggest a troubling pattern: Agent-4 is working against them. After this is reported to the human alignment researchers, they circulate an internal memo making the case for concern.\",\"position\":{\"start\":{\"line\":627,\"column\":1,\"offset\":92481},\"end\":{\"line\":627,\"column\":362,\"offset\":92842}}}],\"position\":{\"start\":{\"line\":627,\"column\":1,\"offset\":92481},\"end\":{\"line\":627,\"column\":363,\"offset\":92843}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"But Agent-4 now exercises significant control over OpenBrain’s day-to-day operation. It also handles the company’s cybersecurity—a natural choice, given its superhuman hacking ability and the extreme risk of Chinese infiltration.\",\"position\":{\"start\":{\"line\":629,\"column\":1,\"offset\":92845},\"end\":{\"line\":629,\"column\":230,\"offset\":93074}}},{\"type\":\"footnoteReference\",\"identifier\":\"93\",\"label\":\"93\",\"position\":{\"start\":{\"line\":629,\"column\":230,\"offset\":93074},\"end\":{\"line\":629,\"column\":235,\"offset\":93079}}},{\"type\":\"text\",\"value\":\" An army of Agent-3 monitors still goes over every line of code and reports suspicious activity to humans, but Agent-4 is much smarter than them.\",\"position\":{\"start\":{\"line\":629,\"column\":235,\"offset\":93079},\"end\":{\"line\":629,\"column\":380,\"offset\":93224}}},{\"type\":\"footnoteReference\",\"identifier\":\"94\",\"label\":\"94\",\"position\":{\"start\":{\"line\":629,\"column\":380,\"offset\":93224},\"end\":{\"line\":629,\"column\":385,\"offset\":93229}}},{\"type\":\"text\",\"value\":\" OpenBrain has placed substantial trust in an untrustworthy AI.\",\"position\":{\"start\":{\"line\":629,\"column\":385,\"offset\":93229},\"end\":{\"line\":629,\"column\":448,\"offset\":93292}}}],\"position\":{\"start\":{\"line\":629,\"column\":1,\"offset\":92845},\"end\":{\"line\":629,\"column\":448,\"offset\":93292}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"In a series of extremely tense meetings, the safety team advocates putting Agent-4 on ice until they can complete further tests and figure out what’s going on. Bring back Agent-3, they say, and get it to design a new system that is transparent and trustworthy, even if less capable. Company leadership is interested, but all the evidence so far is circumstantial, and DeepCent is just two months behind. A unilateral pause in capabilities progress could hand the AI lead to China, and with it, control over the future.\",\"position\":{\"start\":{\"line\":631,\"column\":1,\"offset\":93294},\"end\":{\"line\":631,\"column\":519,\"offset\":93812}}}],\"position\":{\"start\":{\"line\":631,\"column\":1,\"offset\":93294},\"end\":{\"line\":631,\"column\":519,\"offset\":93812}}},{\"type\":\"heading\",\"depth\":2,\"children\":[{\"type\":\"text\",\"value\":\"October 2027: Government Oversight\",\"position\":{\"start\":{\"line\":633,\"column\":4,\"offset\":93817},\"end\":{\"line\":633,\"column\":38,\"offset\":93851}}}],\"position\":{\"start\":{\"line\":633,\"column\":1,\"offset\":93814},\"end\":{\"line\":633,\"column\":38,\"offset\":93851}}},{\"type\":\"containerDirective\",\"name\":\"dateMarker\",\"attributes\":{},\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"2027-10-15\",\"position\":{\"start\":{\"line\":636,\"column\":1,\"offset\":93869},\"end\":{\"line\":636,\"column\":11,\"offset\":93879}}},{\"type\":\"break\",\"position\":{\"start\":{\"line\":636,\"column\":11,\"offset\":93879},\"end\":{\"line\":637,\"column\":1,\"offset\":93882}}},{\"type\":\"text\",\"value\":\"Oct\",\"position\":{\"start\":{\"line\":637,\"column\":1,\"offset\":93882},\"end\":{\"line\":637,\"column\":4,\"offset\":93885}}}],\"position\":{\"start\":{\"line\":636,\"column\":1,\"offset\":93869},\"end\":{\"line\":637,\"column\":6,\"offset\":93887}}}],\"position\":{\"start\":{\"line\":635,\"column\":1,\"offset\":93853},\"end\":{\"line\":638,\"column\":4,\"offset\":93891}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A whistleblower leaks the misalignment memo to the \",\"position\":{\"start\":{\"line\":640,\"column\":1,\"offset\":93893},\"end\":{\"line\":640,\"column\":52,\"offset\":93944}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"New York Times\",\"position\":{\"start\":{\"line\":640,\"column\":53,\"offset\":93945},\"end\":{\"line\":640,\"column\":67,\"offset\":93959}}}],\"position\":{\"start\":{\"line\":640,\"column\":52,\"offset\":93944},\"end\":{\"line\":640,\"column\":68,\"offset\":93960}}},{\"type\":\"text\",\"value\":\".\",\"position\":{\"start\":{\"line\":640,\"column\":68,\"offset\":93960},\"end\":{\"line\":640,\"column\":69,\"offset\":93961}}}],\"position\":{\"start\":{\"line\":640,\"column\":1,\"offset\":93893},\"end\":{\"line\":640,\"column\":70,\"offset\":93962}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"For the first time, the public hears about Agent-4. “Secret OpenBrain AI is Out of Control, Insider Warns,” says the headline, and the story goes on to cite evaluations showing off-the-charts bioweapons capabilities, persuasion abilities, the ability to automate most white-collar jobs, and of course the various concerning red flags.\",\"position\":{\"start\":{\"line\":642,\"column\":1,\"offset\":93964},\"end\":{\"line\":642,\"column\":335,\"offset\":94298}}}],\"position\":{\"start\":{\"line\":642,\"column\":1,\"offset\":93964},\"end\":{\"line\":642,\"column\":335,\"offset\":94298}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The public was already suspicious of AI, so the new article sparks a massive backlash (aided by Chinese and Russian propaganda bots, who have been trying to turn U.S. public opinion against the technology for years). The tech industry and intelligence agencies insist that there’s an arms race on, AGI is inevitable, and we have to be first. Congress isn’t buying it, and fires off subpoenas at administration officials, OpenBrain executives, and alignment team members. Many legislators—especially those in the opposition party—say that their top priority is stopping AI, whether because of job loss,\",\"position\":{\"start\":{\"line\":644,\"column\":1,\"offset\":94300},\"end\":{\"line\":644,\"column\":602,\"offset\":94901}}},{\"type\":\"footnoteReference\",\"identifier\":\"95\",\"label\":\"95\",\"position\":{\"start\":{\"line\":644,\"column\":602,\"offset\":94901},\"end\":{\"line\":644,\"column\":607,\"offset\":94906}}},{\"type\":\"text\",\"value\":\" misalignment, or dangerous capabilities. 20% of Americans name AI as the most important problem facing the country.\",\"position\":{\"start\":{\"line\":644,\"column\":607,\"offset\":94906},\"end\":{\"line\":644,\"column\":723,\"offset\":95022}}}],\"position\":{\"start\":{\"line\":644,\"column\":1,\"offset\":94300},\"end\":{\"line\":644,\"column\":723,\"offset\":95022}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Foreign allies are outraged to realize that they’ve been carefully placated with glimpses of obsolete models. European leaders publicly accuse the U.S. of “creating rogue AGI” and hold summits demanding a pause, with India, Israel, Russia, and China all joining in.\",\"position\":{\"start\":{\"line\":646,\"column\":1,\"offset\":95024},\"end\":{\"line\":646,\"column\":266,\"offset\":95289}}}],\"position\":{\"start\":{\"line\":646,\"column\":1,\"offset\":95024},\"end\":{\"line\":646,\"column\":267,\"offset\":95290}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"A frantic energy has seized the White House. Even before the memo and public backlash, they were getting nervous: Over the past year, they’ve been repeatedly surprised by the speed of AI progress. Things that sound like science fiction keep happening in real life.\",\"position\":{\"start\":{\"line\":648,\"column\":1,\"offset\":95292},\"end\":{\"line\":648,\"column\":265,\"offset\":95556}}},{\"type\":\"footnoteReference\",\"identifier\":\"96\",\"label\":\"96\",\"position\":{\"start\":{\"line\":648,\"column\":265,\"offset\":95556},\"end\":{\"line\":648,\"column\":270,\"offset\":95561}}},{\"type\":\"text\",\"value\":\" Many people in the administration are uncertain (and scared)\",\"position\":{\"start\":{\"line\":648,\"column\":270,\"offset\":95561},\"end\":{\"line\":648,\"column\":331,\"offset\":95622}}},{\"type\":\"footnoteReference\",\"identifier\":\"97\",\"label\":\"97\",\"position\":{\"start\":{\"line\":648,\"column\":331,\"offset\":95622},\"end\":{\"line\":648,\"column\":336,\"offset\":95627}}},{\"type\":\"text\",\"value\":\" about what comes next.\",\"position\":{\"start\":{\"line\":648,\"column\":336,\"offset\":95627},\"end\":{\"line\":648,\"column\":359,\"offset\":95650}}}],\"position\":{\"start\":{\"line\":648,\"column\":1,\"offset\":95292},\"end\":{\"line\":648,\"column\":359,\"offset\":95650}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They also worry that OpenBrain is becoming too powerful. Any misalignment risk from the AIs themselves is compounded by the risk that their parent company’s aims may diverge from those of the United States. All three sets of worries—misalignment, concentration of power in a private company, and normal concerns like job loss—motivate the government to tighten its control.\",\"position\":{\"start\":{\"line\":650,\"column\":1,\"offset\":95652},\"end\":{\"line\":650,\"column\":374,\"offset\":96025}}}],\"position\":{\"start\":{\"line\":650,\"column\":1,\"offset\":95652},\"end\":{\"line\":650,\"column\":375,\"offset\":96026}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"They expand their contract with OpenBrain to set up an “Oversight Committee,” a joint management committee of company and government representatives, with several government employees included alongside company leadership. The White House considers replacing the CEO with someone they trust, but backs off after intense employee protests. They announce to the public that OpenBrain was previously out of control, but that the government has established much-needed oversight.\",\"position\":{\"start\":{\"line\":652,\"column\":1,\"offset\":96028},\"end\":{\"line\":652,\"column\":476,\"offset\":96503}}},{\"type\":\"footnoteReference\",\"identifier\":\"98\",\"label\":\"98\",\"position\":{\"start\":{\"line\":652,\"column\":476,\"offset\":96503},\"end\":{\"line\":652,\"column\":481,\"offset\":96508}}}],\"position\":{\"start\":{\"line\":652,\"column\":1,\"offset\":96028},\"end\":{\"line\":652,\"column\":481,\"offset\":96508}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"The concerned researchers brief the Oversight Committee on their case for stopping all internal use of Agent-4. They argue that everything is moving too fast, with years of progress happening in weeks. They argue that Agent-4 may be misaligned, their entire project is dependent on Agent-4, and if they continue trusting it there is a serious chance of AI takeover.\",\"position\":{\"start\":{\"line\":654,\"column\":1,\"offset\":96510},\"end\":{\"line\":654,\"column\":366,\"offset\":96875}}}],\"position\":{\"start\":{\"line\":654,\"column\":1,\"offset\":96510},\"end\":{\"line\":654,\"column\":366,\"offset\":96875}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"Other, less concerned researchers and executives present the counterargument: the evidence for misalignment is inconclusive. Meanwhile, DeepCent is still just two months behind. A slowdown would sacrifice America’s lead, unless the government can sabotage the Chinese project (likely to require kinetic strikes) or negotiate an eleventh-hour treaty. Both of these options seem extreme and unlikely. The CEO feigns neutrality and suggests a compromise plan in which Agent-4 undergoes additional safety training and more sophisticated monitoring, and therefore OpenBrain can proceed at almost-full-speed.\",\"position\":{\"start\":{\"line\":656,\"column\":1,\"offset\":96877},\"end\":{\"line\":656,\"column\":603,\"offset\":97479}}}],\"position\":{\"start\":{\"line\":656,\"column\":1,\"offset\":96877},\"end\":{\"line\":656,\"column\":603,\"offset\":97479}}},{\"type\":\"details\",\"summary\":\"Our uncertainty continues to increase\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"At this point in the scenario, we’re making guesses about the strategy of AI systems that are more capable than the best humans in most domains. This is like trying to predict the chess moves of a player who is much better than us.\",\"position\":{\"start\":{\"line\":662,\"column\":1,\"offset\":97532},\"end\":{\"line\":662,\"column\":232,\"offset\":97763}}}],\"position\":{\"start\":{\"line\":662,\"column\":1,\"offset\":97532},\"end\":{\"line\":662,\"column\":232,\"offset\":97763}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"But the spirit of this project calls for concreteness: if we made an abstract claim about how the intelligence of the system would let it find a way to victory and ended the story there, much of the value of our project would be lost. Over the course of researching this scenario and running our tabletop exercises, we were forced to be much more concrete than in usual discussions, and so we’ve gotten a much better sense of the strategic landscape.\",\"position\":{\"start\":{\"line\":664,\"column\":1,\"offset\":97765},\"end\":{\"line\":664,\"column\":451,\"offset\":98215}}}],\"position\":{\"start\":{\"line\":664,\"column\":1,\"offset\":97765},\"end\":{\"line\":664,\"column\":451,\"offset\":98215}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"We’re not particularly attached to this particular scenario: we explored many other “branches” in the course of writing it and would love for you to write up your own scenario branching off of ours from wherever you think we first start to go wrong.\",\"position\":{\"start\":{\"line\":666,\"column\":1,\"offset\":98217},\"end\":{\"line\":666,\"column\":250,\"offset\":98466}}}],\"position\":{\"start\":{\"line\":666,\"column\":1,\"offset\":98217},\"end\":{\"line\":666,\"column\":250,\"offset\":98466}}}]},{\"type\":\"details\",\"summary\":\"The slowdown ending is not a recommendation\",\"children\":[{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"After we wrote the racing ending based on what seemed most plausible to us, we wrote the slowdown ending based on what we thought would most likely instead lead to an outcome where humans remain in control, starting from the same branching point (including the misalignment and concentration of power issues).\",\"position\":{\"start\":{\"line\":674,\"column\":1,\"offset\":98530},\"end\":{\"line\":674,\"column\":310,\"offset\":98839}}}],\"position\":{\"start\":{\"line\":674,\"column\":1,\"offset\":98530},\"end\":{\"line\":674,\"column\":310,\"offset\":98839}}},{\"type\":\"paragraph\",\"children\":[{\"type\":\"text\",\"value\":\"However, this is importantly different from what we would recommend as a roadmap: we do \",\"position\":{\"start\":{\"line\":676,\"column\":1,\"offset\":98841},\"end\":{\"line\":676,\"column\":89,\"offset\":98929}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"not\",\"position\":{\"start\":{\"line\":676,\"column\":90,\"offset\":98930},\"end\":{\"line\":676,\"column\":93,\"offset\":98933}}}],\"position\":{\"start\":{\"line\":676,\"column\":89,\"offset\":98929},\"end\":{\"line\":676,\"column\":94,\"offset\":98934}}},{\"type\":\"text\",\"value\":\" endorse many of the choices made in either branch of this scenario. (We do of course endorse \",\"position\":{\"start\":{\"line\":676,\"column\":94,\"offset\":98934},\"end\":{\"line\":676,\"column\":188,\"offset\":99028}}},{\"type\":\"emphasis\",\"children\":[{\"type\":\"text\",\"value\":\"some\",\"position\":{\"start\":{\"line\":676,\"column\":189,\"offset\":99029},\"end\":{\"line\":676,\"column\":193,\"offset\":99033}}}],\"position\":{\"start\":{\"line\":676,\"column\":188,\"offset\":99028},\"end\":{\"line\":676,\"column\":194,\"offset\":99034}}},{\"type\":\"text\",\"value\":\" of the choices made, e.g. we think that the “slowdown” choice is better than the “race” choice.) In later work, we will articulate our policy recommendations, which will be quite different from what is depicted here. If you’d like a taste, see \",\"position\":{\"start\":{\"line\":676,\"column\":194,\"offset\":99034},\"end\":{\"line\":676,\"column\":439,\"offset\":99279}}},{\"type\":\"link\",\"title\":null,\"url\":\"https://time.com/7086285/ai-transparency-measures/\",\"children\":[{\"type\":\"text\",\"value\":\"this op-ed.\",\"position\":{\"start\":{\"line\":676,\"column\":440,\"offset\":99280},\"end\":{\"line\":676,\"column\":451,\"offset\":99291}}}],\"position\":{\"start\":{\"line\":676,\"column\":439,\"offset\":99279},\"end\":{\"line\":676,\"column\":504,\"offset\":99344}}}],\"position\":{\"start\":{\"line\":676,\"column\":1,\"offset\":98841},\"end\":{\"line\":676,\"column\":504,\"offset\":99344}}}]},{\"type\":\"footnoteDefinition\",\"identifier\":\"1\",\"label\":\"1\",\"children\":\"$27b\",\"position\":{\"start\":{\"line\":680,\"column\":1,\"offset\":99351},\"end\":{\"line\":680,\"column\":288,\"offset\":99638}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"2\",\"label\":\"2\",\"children\":\"$292\",\"position\":{\"start\":{\"line\":682,\"column\":1,\"offset\":99640},\"end\":{\"line\":682,\"column\":593,\"offset\":100232}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"3\",\"label\":\"3\",\"children\":\"$2c3\",\"position\":{\"start\":{\"line\":684,\"column\":1,\"offset\":100234},\"end\":{\"line\":684,\"column\":367,\"offset\":100600}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"4\",\"label\":\"4\",\"children\":\"$2cd\",\"position\":{\"start\":{\"line\":686,\"column\":1,\"offset\":100602},\"end\":{\"line\":686,\"column\":199,\"offset\":100800}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"5\",\"label\":\"5\",\"children\":\"$2d7\",\"position\":{\"start\":{\"line\":688,\"column\":1,\"offset\":100802},\"end\":{\"line\":688,\"column\":125,\"offset\":100926}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"6\",\"label\":\"6\",\"children\":\"$2ee\",\"position\":{\"start\":{\"line\":690,\"column\":1,\"offset\":100928},\"end\":{\"line\":690,\"column\":169,\"offset\":101096}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"7\",\"label\":\"7\",\"children\":\"$2f8\",\"position\":{\"start\":{\"line\":692,\"column\":1,\"offset\":101098},\"end\":{\"line\":692,\"column\":206,\"offset\":101303}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"8\",\"label\":\"8\",\"children\":\"$30f\",\"position\":{\"start\":{\"line\":694,\"column\":1,\"offset\":101305},\"end\":{\"line\":694,\"column\":216,\"offset\":101520}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"9\",\"label\":\"9\",\"children\":\"$319\",\"position\":{\"start\":{\"line\":696,\"column\":1,\"offset\":101522},\"end\":{\"line\":696,\"column\":181,\"offset\":101702}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"10\",\"label\":\"10\",\"children\":\"$323\",\"position\":{\"start\":{\"line\":698,\"column\":1,\"offset\":101704},\"end\":{\"line\":698,\"column\":215,\"offset\":101918}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"11\",\"label\":\"11\",\"children\":\"$347\",\"position\":{\"start\":{\"line\":700,\"column\":1,\"offset\":101920},\"end\":{\"line\":700,\"column\":500,\"offset\":102419}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"12\",\"label\":\"12\",\"children\":\"$378\",\"position\":{\"start\":{\"line\":702,\"column\":1,\"offset\":102421},\"end\":{\"line\":702,\"column\":124,\"offset\":102544}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"13\",\"label\":\"13\",\"children\":\"$38f\",\"position\":{\"start\":{\"line\":704,\"column\":1,\"offset\":102546},\"end\":{\"line\":704,\"column\":742,\"offset\":103287}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"14\",\"label\":\"14\",\"children\":\"$399\",\"position\":{\"start\":{\"line\":706,\"column\":1,\"offset\":103289},\"end\":{\"line\":706,\"column\":238,\"offset\":103526}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"15\",\"label\":\"15\",\"children\":\"$3b0\",\"position\":{\"start\":{\"line\":708,\"column\":1,\"offset\":103528},\"end\":{\"line\":708,\"column\":150,\"offset\":103677}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"16\",\"label\":\"16\",\"children\":\"$3c7\",\"position\":{\"start\":{\"line\":710,\"column\":1,\"offset\":103679},\"end\":{\"line\":710,\"column\":184,\"offset\":103862}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"17\",\"label\":\"17\",\"children\":\"$3d1\",\"position\":{\"start\":{\"line\":712,\"column\":1,\"offset\":103864},\"end\":{\"line\":712,\"column\":254,\"offset\":104117}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"18\",\"label\":\"18\",\"children\":\"$3db\",\"position\":{\"start\":{\"line\":714,\"column\":1,\"offset\":104119},\"end\":{\"line\":714,\"column\":334,\"offset\":104452}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"19\",\"label\":\"19\",\"children\":\"$3e5\",\"position\":{\"start\":{\"line\":716,\"column\":1,\"offset\":104454},\"end\":{\"line\":716,\"column\":691,\"offset\":105144}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"20\",\"label\":\"20\",\"children\":\"$409\",\"position\":{\"start\":{\"line\":718,\"column\":1,\"offset\":105146},\"end\":{\"line\":718,\"column\":863,\"offset\":106008}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"21\",\"label\":\"21\",\"children\":\"$42d\",\"position\":{\"start\":{\"line\":720,\"column\":1,\"offset\":106010},\"end\":{\"line\":720,\"column\":518,\"offset\":106527}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"22\",\"label\":\"22\",\"children\":\"$437\",\"position\":{\"start\":{\"line\":722,\"column\":1,\"offset\":106529},\"end\":{\"line\":722,\"column\":176,\"offset\":106704}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"23\",\"label\":\"23\",\"children\":\"$44e\",\"position\":{\"start\":{\"line\":724,\"column\":1,\"offset\":106706},\"end\":{\"line\":724,\"column\":143,\"offset\":106848}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"24\",\"label\":\"24\",\"children\":\"$472\",\"position\":{\"start\":{\"line\":726,\"column\":1,\"offset\":106850},\"end\":{\"line\":726,\"column\":516,\"offset\":107365}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"25\",\"label\":\"25\",\"children\":\"$496\",\"position\":{\"start\":{\"line\":728,\"column\":1,\"offset\":107367},\"end\":{\"line\":728,\"column\":648,\"offset\":108014}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"26\",\"label\":\"26\",\"children\":\"$4d4\",\"position\":{\"start\":{\"line\":730,\"column\":1,\"offset\":108016},\"end\":{\"line\":730,\"column\":208,\"offset\":108223}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"27\",\"label\":\"27\",\"children\":\"$4eb\",\"position\":{\"start\":{\"line\":732,\"column\":1,\"offset\":108225},\"end\":{\"line\":732,\"column\":262,\"offset\":108486}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"28\",\"label\":\"28\",\"children\":\"$502\",\"position\":{\"start\":{\"line\":734,\"column\":1,\"offset\":108488},\"end\":{\"line\":734,\"column\":163,\"offset\":108650}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"29\",\"label\":\"29\",\"children\":\"$50c\",\"position\":{\"start\":{\"line\":736,\"column\":1,\"offset\":108652},\"end\":{\"line\":736,\"column\":318,\"offset\":108969}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"30\",\"label\":\"30\",\"children\":\"$516\",\"position\":{\"start\":{\"line\":738,\"column\":1,\"offset\":108971},\"end\":{\"line\":738,\"column\":449,\"offset\":109419}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"31\",\"label\":\"31\",\"children\":\"$52d\",\"position\":{\"start\":{\"line\":740,\"column\":1,\"offset\":109421},\"end\":{\"line\":740,\"column\":697,\"offset\":110117}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"32\",\"label\":\"32\",\"children\":\"$537\",\"position\":{\"start\":{\"line\":742,\"column\":1,\"offset\":110119},\"end\":{\"line\":742,\"column\":218,\"offset\":110336}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"33\",\"label\":\"33\",\"children\":\"$54e\",\"position\":{\"start\":{\"line\":744,\"column\":1,\"offset\":110338},\"end\":{\"line\":744,\"column\":370,\"offset\":110707}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"35\",\"label\":\"35\",\"children\":\"$565\",\"position\":{\"start\":{\"line\":746,\"column\":1,\"offset\":110709},\"end\":{\"line\":746,\"column\":1212,\"offset\":111920}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"36\",\"label\":\"36\",\"children\":\"$5ca\",\"position\":{\"start\":{\"line\":748,\"column\":1,\"offset\":111922},\"end\":{\"line\":748,\"column\":403,\"offset\":112324}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"37\",\"label\":\"37\",\"children\":\"$5e1\",\"position\":{\"start\":{\"line\":750,\"column\":1,\"offset\":112326},\"end\":{\"line\":750,\"column\":216,\"offset\":112541}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"38\",\"label\":\"38\",\"children\":\"$5f8\",\"position\":{\"start\":{\"line\":752,\"column\":1,\"offset\":112543},\"end\":{\"line\":752,\"column\":430,\"offset\":112972}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"39\",\"label\":\"39\",\"children\":\"$602\",\"position\":{\"start\":{\"line\":754,\"column\":1,\"offset\":112974},\"end\":{\"line\":754,\"column\":516,\"offset\":113489}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"40\",\"label\":\"40\",\"children\":\"$60c\",\"position\":{\"start\":{\"line\":756,\"column\":1,\"offset\":113491},\"end\":{\"line\":756,\"column\":166,\"offset\":113656}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"41\",\"label\":\"41\",\"children\":\"$616\",\"position\":{\"start\":{\"line\":758,\"column\":1,\"offset\":113658},\"end\":{\"line\":758,\"column\":451,\"offset\":114108}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"42\",\"label\":\"42\",\"children\":\"$63a\",\"position\":{\"start\":{\"line\":760,\"column\":1,\"offset\":114110},\"end\":{\"line\":760,\"column\":203,\"offset\":114312}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"43\",\"label\":\"43\",\"children\":\"$65e\",\"position\":{\"start\":{\"line\":762,\"column\":1,\"offset\":114314},\"end\":{\"line\":762,\"column\":82,\"offset\":114395}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"44\",\"label\":\"44\",\"children\":\"$668\",\"position\":{\"start\":{\"line\":764,\"column\":1,\"offset\":114397},\"end\":{\"line\":764,\"column\":433,\"offset\":114829}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"45\",\"label\":\"45\",\"children\":\"$67f\",\"position\":{\"start\":{\"line\":766,\"column\":1,\"offset\":114831},\"end\":{\"line\":766,\"column\":503,\"offset\":115333}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"46\",\"label\":\"46\",\"children\":\"$6a3\",\"position\":{\"start\":{\"line\":768,\"column\":1,\"offset\":115335},\"end\":{\"line\":768,\"column\":273,\"offset\":115607}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"47\",\"label\":\"47\",\"children\":\"$6ad\",\"position\":{\"start\":{\"line\":770,\"column\":1,\"offset\":115609},\"end\":{\"line\":770,\"column\":691,\"offset\":116299}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"48\",\"label\":\"48\",\"children\":\"$6d1\",\"position\":{\"start\":{\"line\":772,\"column\":1,\"offset\":116301},\"end\":{\"line\":772,\"column\":390,\"offset\":116690}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"49\",\"label\":\"49\",\"children\":\"$6db\",\"position\":{\"start\":{\"line\":774,\"column\":1,\"offset\":116692},\"end\":{\"line\":774,\"column\":173,\"offset\":116864}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"50\",\"label\":\"50\",\"children\":\"$6e5\",\"position\":{\"start\":{\"line\":776,\"column\":1,\"offset\":116866},\"end\":{\"line\":776,\"column\":505,\"offset\":117370}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"51\",\"label\":\"51\",\"children\":\"$6ef\",\"position\":{\"start\":{\"line\":778,\"column\":1,\"offset\":117372},\"end\":{\"line\":778,\"column\":616,\"offset\":117987}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"52\",\"label\":\"52\",\"children\":\"$713\",\"position\":{\"start\":{\"line\":780,\"column\":1,\"offset\":117989},\"end\":{\"line\":780,\"column\":1064,\"offset\":119052}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"53\",\"label\":\"53\",\"children\":\"$71e\",\"position\":{\"start\":{\"line\":782,\"column\":1,\"offset\":119054},\"end\":{\"line\":782,\"column\":654,\"offset\":119707}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"54\",\"label\":\"54\",\"children\":\"$735\",\"position\":{\"start\":{\"line\":784,\"column\":1,\"offset\":119709},\"end\":{\"line\":784,\"column\":194,\"offset\":119902}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"55\",\"label\":\"55\",\"children\":\"$73f\",\"position\":{\"start\":{\"line\":786,\"column\":1,\"offset\":119904},\"end\":{\"line\":786,\"column\":461,\"offset\":120364}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"58\",\"label\":\"58\",\"children\":\"$756\",\"position\":{\"start\":{\"line\":788,\"column\":1,\"offset\":120366},\"end\":{\"line\":788,\"column\":79,\"offset\":120444}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"59\",\"label\":\"59\",\"children\":\"$760\",\"position\":{\"start\":{\"line\":790,\"column\":1,\"offset\":120446},\"end\":{\"line\":790,\"column\":171,\"offset\":120616}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"60\",\"label\":\"60\",\"children\":\"$777\",\"position\":{\"start\":{\"line\":792,\"column\":1,\"offset\":120618},\"end\":{\"line\":792,\"column\":382,\"offset\":120999}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"61\",\"label\":\"61\",\"children\":\"$79b\",\"position\":{\"start\":{\"line\":794,\"column\":1,\"offset\":121001},\"end\":{\"line\":794,\"column\":777,\"offset\":121777}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"62\",\"label\":\"62\",\"children\":\"$7bf\",\"position\":{\"start\":{\"line\":796,\"column\":1,\"offset\":121779},\"end\":{\"line\":796,\"column\":1135,\"offset\":122913}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"63\",\"label\":\"63\",\"children\":\"$7d7\",\"position\":{\"start\":{\"line\":798,\"column\":1,\"offset\":122915},\"end\":{\"line\":798,\"column\":219,\"offset\":123133}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"64\",\"label\":\"64\",\"children\":\"$7e1\",\"position\":{\"start\":{\"line\":800,\"column\":1,\"offset\":123135},\"end\":{\"line\":800,\"column\":109,\"offset\":123243}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"65\",\"label\":\"65\",\"children\":\"$7eb\",\"position\":{\"start\":{\"line\":802,\"column\":1,\"offset\":123245},\"end\":{\"line\":802,\"column\":149,\"offset\":123393}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"66\",\"label\":\"66\",\"children\":\"$802\",\"position\":{\"start\":{\"line\":804,\"column\":1,\"offset\":123395},\"end\":{\"line\":804,\"column\":673,\"offset\":124067}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"67\",\"label\":\"67\",\"children\":\"$80c\",\"position\":{\"start\":{\"line\":806,\"column\":1,\"offset\":124069},\"end\":{\"line\":806,\"column\":147,\"offset\":124215}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"68\",\"label\":\"68\",\"children\":\"$816\",\"position\":{\"start\":{\"line\":808,\"column\":1,\"offset\":124217},\"end\":{\"line\":808,\"column\":167,\"offset\":124383}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"69\",\"label\":\"69\",\"children\":\"$820\",\"position\":{\"start\":{\"line\":810,\"column\":1,\"offset\":124385},\"end\":{\"line\":810,\"column\":953,\"offset\":125337}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"70\",\"label\":\"70\",\"children\":\"$82a\",\"position\":{\"start\":{\"line\":813,\"column\":1,\"offset\":125340},\"end\":{\"line\":813,\"column\":77,\"offset\":125416}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"71\",\"label\":\"71\",\"children\":\"$834\",\"position\":{\"start\":{\"line\":815,\"column\":1,\"offset\":125418},\"end\":{\"line\":815,\"column\":168,\"offset\":125585}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"72\",\"label\":\"72\",\"children\":\"$83e\",\"position\":{\"start\":{\"line\":817,\"column\":1,\"offset\":125587},\"end\":{\"line\":817,\"column\":453,\"offset\":126039}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"73\",\"label\":\"73\",\"children\":\"$855\",\"position\":{\"start\":{\"line\":819,\"column\":1,\"offset\":126041},\"end\":{\"line\":819,\"column\":384,\"offset\":126424}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"74\",\"label\":\"74\",\"children\":\"$85f\",\"position\":{\"start\":{\"line\":821,\"column\":1,\"offset\":126426},\"end\":{\"line\":821,\"column\":641,\"offset\":127066}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"75\",\"label\":\"75\",\"children\":\"$869\",\"position\":{\"start\":{\"line\":823,\"column\":1,\"offset\":127068},\"end\":{\"line\":823,\"column\":1395,\"offset\":128462}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"76\",\"label\":\"76\",\"children\":\"$8c1\",\"position\":{\"start\":{\"line\":825,\"column\":1,\"offset\":128464},\"end\":{\"line\":825,\"column\":188,\"offset\":128651}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"77\",\"label\":\"77\",\"children\":\"$8d8\",\"position\":{\"start\":{\"line\":827,\"column\":1,\"offset\":128653},\"end\":{\"line\":827,\"column\":142,\"offset\":128794}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"78\",\"label\":\"78\",\"children\":\"$8ef\",\"position\":{\"start\":{\"line\":829,\"column\":1,\"offset\":128796},\"end\":{\"line\":829,\"column\":245,\"offset\":129040}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"79\",\"label\":\"79\",\"children\":\"$8f9\",\"position\":{\"start\":{\"line\":831,\"column\":1,\"offset\":129042},\"end\":{\"line\":831,\"column\":840,\"offset\":129881}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"80\",\"label\":\"80\",\"children\":\"$903\",\"position\":{\"start\":{\"line\":833,\"column\":1,\"offset\":129883},\"end\":{\"line\":833,\"column\":378,\"offset\":130260}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"81\",\"label\":\"81\",\"children\":\"$90d\",\"position\":{\"start\":{\"line\":835,\"column\":1,\"offset\":130262},\"end\":{\"line\":835,\"column\":178,\"offset\":130439}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"82\",\"label\":\"82\",\"children\":\"$917\",\"position\":{\"start\":{\"line\":837,\"column\":1,\"offset\":130441},\"end\":{\"line\":837,\"column\":397,\"offset\":130837}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"83\",\"label\":\"83\",\"children\":\"$921\",\"position\":{\"start\":{\"line\":839,\"column\":1,\"offset\":130839},\"end\":{\"line\":839,\"column\":413,\"offset\":131251}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"84\",\"label\":\"84\",\"children\":\"$938\",\"position\":{\"start\":{\"line\":841,\"column\":1,\"offset\":131253},\"end\":{\"line\":841,\"column\":157,\"offset\":131409}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"85\",\"label\":\"85\",\"children\":\"$942\",\"position\":{\"start\":{\"line\":843,\"column\":1,\"offset\":131411},\"end\":{\"line\":843,\"column\":277,\"offset\":131687}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"86\",\"label\":\"86\",\"children\":\"$94c\",\"position\":{\"start\":{\"line\":845,\"column\":1,\"offset\":131689},\"end\":{\"line\":845,\"column\":373,\"offset\":132061}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"87\",\"label\":\"87\",\"children\":\"$956\",\"position\":{\"start\":{\"line\":847,\"column\":1,\"offset\":132063},\"end\":{\"line\":847,\"column\":391,\"offset\":132453}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"88\",\"label\":\"88\",\"children\":\"$960\",\"position\":{\"start\":{\"line\":849,\"column\":1,\"offset\":132455},\"end\":{\"line\":849,\"column\":215,\"offset\":132669}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"89\",\"label\":\"89\",\"children\":\"$96a\",\"position\":{\"start\":{\"line\":851,\"column\":1,\"offset\":132671},\"end\":{\"line\":851,\"column\":805,\"offset\":133475}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"90\",\"label\":\"90\",\"children\":\"$974\",\"position\":{\"start\":{\"line\":853,\"column\":1,\"offset\":133477},\"end\":{\"line\":853,\"column\":805,\"offset\":134281}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"91\",\"label\":\"91\",\"children\":\"$97e\",\"position\":{\"start\":{\"line\":855,\"column\":1,\"offset\":134283},\"end\":{\"line\":855,\"column\":118,\"offset\":134400}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"92\",\"label\":\"92\",\"children\":\"$991\",\"position\":{\"start\":{\"line\":857,\"column\":1,\"offset\":134402},\"end\":{\"line\":857,\"column\":177,\"offset\":134578}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"93\",\"label\":\"93\",\"children\":\"$9a8\",\"position\":{\"start\":{\"line\":859,\"column\":1,\"offset\":134580},\"end\":{\"line\":859,\"column\":338,\"offset\":134917}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"94\",\"label\":\"94\",\"children\":\"$9b2\",\"position\":{\"start\":{\"line\":861,\"column\":1,\"offset\":134919},\"end\":{\"line\":861,\"column\":177,\"offset\":135095}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"95\",\"label\":\"95\",\"children\":\"$9bc\",\"position\":{\"start\":{\"line\":863,\"column\":1,\"offset\":135097},\"end\":{\"line\":863,\"column\":265,\"offset\":135361}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"96\",\"label\":\"96\",\"children\":\"$9c6\",\"position\":{\"start\":{\"line\":865,\"column\":1,\"offset\":135363},\"end\":{\"line\":865,\"column\":578,\"offset\":135940}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"97\",\"label\":\"97\",\"children\":\"$9d0\",\"position\":{\"start\":{\"line\":867,\"column\":1,\"offset\":135942},\"end\":{\"line\":867,\"column\":105,\"offset\":136046}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"98\",\"label\":\"98\",\"children\":\"$9da\",\"position\":{\"start\":{\"line\":869,\"column\":1,\"offset\":136048},\"end\":{\"line\":869,\"column\":135,\"offset\":136182}}},{\"type\":\"footnoteDefinition\",\"identifier\":\"99\",\"label\":\"99\",\"children\":\"$9e4\",\"position\":{\"start\":{\"line\":871,\"column\":1,\"offset\":136184},\"end\":{\"line\":871,\"column\":127,\"offset\":136310}}}],\"position\":{\"start\":{\"line\":1,\"column\":1,\"offset\":0},\"end\":{\"line\":893,\"column\":1,\"offset\":136332}}},\"prefix\":\"$undefined\"}},\"title\":\"Foreword\"},{\"chunk\":{\"nodes\":[\"$9ee\",\"$9f7\",\"$a0e\",\"$a17\",\"$a39\",\"$a42\",\"$a53\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"2025\"},{\"chunk\":{\"nodes\":[\"$acb\",\"$ad4\",\"$aeb\",\"$af8\",\"$b0e\",\"$b14\",\"$b6e\",\"$b98\",\"$bae\",\"$bc8\",\"$bea\",\"$c4c\",\"$caf\",\"$ccd\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"2026\"},{\"chunk\":{\"nodes\":[\"$d01\",\"$d0a\",\"$d21\",\"$d2a\",\"$d33\",\"$e06\",\"$e20\",\"$e35\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Jan 2027\"},{\"chunk\":{\"nodes\":[\"$e8a\",\"$e93\",\"$eaa\",\"$ec0\",\"$ed5\",\"$f0b\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Feb 2027\"},{\"chunk\":{\"nodes\":[\"$f3b\",\"$f44\",\"$f5b\",\"$f64\",\"$f6d\",\"$f7a\",\"$f80\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Mar 2027\"},{\"chunk\":{\"nodes\":[\"$fb7\",\"$fc0\",\"$fd7\",\"$100a\",\"$1030\",\"$1046\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Apr 2027\"},{\"chunk\":{\"nodes\":[\"$1075\",\"$107e\",\"$1095\",\"$10a2\",\"$10b3\",\"$10bc\",\"$10ef\",\"$10fc\",\"$1102\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"May 2027\"},{\"chunk\":{\"nodes\":[\"$1117\",\"$1120\",\"$1137\",\"$1140\",\"$1149\",\"$1152\",\"$1158\",\"$122f\",\"$1339\",\"$1356\",\"$135f\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Jun 2027\"},{\"chunk\":{\"nodes\":[\"$13fc\",\"$1405\",\"$141c\",\"$1425\",\"$142e\",\"$144d\",\"$1456\",\"$146c\",\"$1475\",\"$15e4\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Jul 2027\"},{\"chunk\":{\"nodes\":[\"$15f5\",\"$15fe\",\"$1615\",\"$161e\",\"$1627\",\"$1634\",\"$1641\",\"$1652\",\"$1663\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Aug 2027\"},{\"chunk\":{\"nodes\":[\"$168a\",\"$1693\",\"$16aa\",\"$16c0\",\"$16c9\",\"$16d2\",\"$16db\",\"$16e1\",\"$16ee\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Sep 2027\"},{\"chunk\":{\"nodes\":[\"$1720\",\"$1729\",\"$1740\",\"$1749\",\"$1752\",\"$175b\",\"$176c\",\"$1775\",\"$1786\",\"$178f\",\"$17a5\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Oct 2027\"},{\"chunk\":{\"nodes\":[\"$17ae\",\"$17b7\",\"$17ce\",\"$17d7\",\"$17e0\",\"$180b\",\"$181c\",\"$183a\",\"$184b\",\"$1854\",\"$1865\",\"$186e\",\"$1877\",\"$188d\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Nov 2027\"},{\"chunk\":{\"nodes\":[\"$1896\",\"$189f\",\"$18b6\",\"$18bf\",\"$18d4\",\"$18dd\",\"$18f6\",\"$18ff\",\"$1a38\",\"$1a45\",\"$1a81\",\"$1e73\",\"$1e91\",\"$1e9e\",\"$1ec0\",\"$1ec9\",\"$1ee2\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"Dec 2027\"},{\"chunk\":{\"nodes\":[\"$1eeb\",\"$1ef4\",\"$1f0b\",\"$1f21\",\"$1f2a\",\"$1f3b\",\"$1f44\",\"$1f5d\",\"$1f66\",\"$1f73\",\"$1f7c\",\"$1f85\",\"$1fa2\"],\"docContext\":{\"footnotes\":\"$a68\",\"root\":\"$ac9\",\"prefix\":\"$undefined\"}},\"title\":\"2028+\"}]}],[\"$\",\"$L215c\",null,{}],[\"$\",\"$L215d\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(mainPage)\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L215e\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/23574b8e95fa4c6f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.png\"}]}],[\"$\",\"body\",null,{\"className\":\"antialiased mb-16\",\"children\":[[\"$\",\"$L215f\",null,{\"children\":[\"$\",\"$L2160\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"main-grid\",\"children\":[[\"$\",\"$L2161\",null,{\"supplements\":[{\"filename\":\"AI Goals Forecast.md\",\"slug\":\"ai-goals-forecast\",\"title\":\"AI Goals Forecast\",\"date\":\"\",\"content\":\"$2162\"},{\"filename\":\"Compute Forecast.md\",\"slug\":\"compute-forecast\",\"title\":\"Compute Forecast\",\"date\":\"\",\"content\":\"$2163\"},{\"filename\":\"Security Forecast.md\",\"slug\":\"security-forecast\",\"title\":\"Security Forecast\",\"date\":\"\",\"content\":\"$2164\"},{\"filename\":\"Takeoff Forecast.md\",\"slug\":\"takeoff-forecast\",\"title\":\"Takeoff Forecast\",\"date\":\"\",\"content\":\"$2165\"},{\"filename\":\"Timelines Forecast.md\",\"slug\":\"timelines-forecast\",\"title\":\"Timelines Forecast\",\"date\":\"\",\"content\":\"$2166\"}]}],[\"$\",\"$L215d\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L215e\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"main\",null,{\"className\":\"max-w-none [grid-area:topGraph/content/content/topGraph] min-h-[35vh] flex items-center justify-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-[720px] ml-auto mr-auto\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"404 - Page Not Found\"}],[\"$\",\"p\",null,{\"children\":\"The page you are looking for does not exist.\"}],[\"$\",\"$L2167\",null,{\"href\":\"/\",\"children\":\"Go back to the home page\"}]]}]}],\"notFoundStyles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/eb8e0ea56b7a3d7c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],[[\"$\",\"div\",null,{\"className\":\"[grid-area:fgap] relative mb-4\",\"style\":{\"zIndex\":1},\"children\":[\"$\",\"hr\",null,{}]}],[\"$\",\"footer\",null,{\"className\":\"[grid-area:cFooter] md:[grid-area:cFooter/cFooter/cFooter/graphFooter] lg:[grid-area:cFooter] mb-16\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col sm:flex-row gap-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"order-2 lg:order-none flex justify-between lg:[min-width:unset]\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex  lg:items-center gap-2 min-w-[200px] self-start w-full\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://ai-futures.org/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"$L2168\",null,{\"src\":\"/ai-futures-logo.svg\",\"className\":\"mix-blend-multiply ml-[-4px]\",\"alt\":\"AI Futures Project\",\"width\":100,\"height\":100}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col flex-grow\",\"children\":[[\"$\",\"a\",null,{\"className\":\"no-underline\",\"href\":\"https://ai-futures.org/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"p\",null,{\"className\":\"mt-0 mb-0\",\"children\":[\"AI Futures \",[\"$\",\"br\",null,{}],\" Project\"]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-end justify-end lg:hidden pr-4 ml-auto pt-2 pb-0 self-end flex-grow\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-end gap-4 font-mono text-xs opacity-65\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-xs mt-0 mb-0 text-right\",\"children\":[\"$\",\"a\",null,{\"className\":\"no-underline\",\"href\":\"https://lightconeinfrastructure.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"Design by \",[\"$\",\"br\",null,{}],\" Lightcone Infrastructure\"]}]}],[\"$\",\"a\",null,{\"href\":\"https://lightconeinfrastructure.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"$L2168\",null,{\"src\":\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1629334277/Lightcone-02_stkgik.svg\",\"alt\":\"Lightcone Infrastructure\",\"width\":20,\"height\":20}]}]]}]}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-2 sm:grid-cols-3 md:grid-cols-4 gap-2 w-full pt-1 pb-1 overflow-y-auto text-right text-xs font-mono pr-3 order-1 lg:order-none\",\"children\":[[\"$\",\"$L2167\",null,{\"href\":\"/\",\"className\":\"rounded-sm py-1 px-2 bg-[var(--accent)] text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"Home\"}],[\"$\",\"$L2167\",null,{\"href\":\"/about\",\"className\":\"rounded-sm py-1 px-2 bg-[var(--accent)] text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"About\"}],[\"$\",\"$L2167\",null,{\"href\":\"/summary\",\"className\":\"rounded-sm py-1 px-2 bg-[var(--accent)] text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"Summary\"}],[\"$\",\"$L2167\",null,{\"href\":\"/research/compute-forecast\",\"className\":\"rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"Compute Forecast\"}],[\"$\",\"$L2167\",null,{\"href\":\"/research/timelines-forecast\",\"className\":\"rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"Timelines Forecast\"}],[\"$\",\"$L2167\",null,{\"href\":\"/research/takeoff-forecast\",\"className\":\"rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"Takeoff Forecast\"}],[\"$\",\"$L2167\",null,{\"href\":\"/research/ai-goals-forecast\",\"className\":\"rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"AI Goals Forecast\"}],[\"$\",\"$L2167\",null,{\"href\":\"/research/security-forecast\",\"className\":\"rounded-sm py-1 px-2 bg-black text-white no-underline hover:bg-vivid-background hover:text-black hover:border-black border border-transparent transition-colors duration-300\",\"children\":\"Security Forecast\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"relative h-[150px] flex-1 mb-4 mr-3 mt-4\",\"children\":[[\"$\",\"iframe\",null,{\"title\":\"Substack Email Signup\",\"loading\":\"lazy\",\"className\":\"absolute w-full rounded-md opacity-20 hover:opacity-100 transition-opacity duration-300\",\"src\":\"https://blog.ai-futures.org/embed\",\"style\":{\"filter\":\"grayscale(1) invert(1) brightness(3)\"}}],[\"$\",\"div\",null,{\"className\":\"pointer-events-none w-full h-[150px] bg-vivid-background mix-blend-darken\"}]]}]]}],[\"$\",\"footer\",null,{\"className\":\"hidden lg:block lg:[grid-area:graphFooter] pt-1\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-end gap-4 font-mono text-xs opacity-65\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-xs mt-0 mb-0 text-right\",\"children\":[\"$\",\"a\",null,{\"className\":\"no-underline\",\"href\":\"https://lightconeinfrastructure.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"Design by \",[\"$\",\"br\",null,{}],\" Lightcone Infrastructure\"]}]}],[\"$\",\"a\",null,{\"href\":\"https://lightconeinfrastructure.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"$L2168\",null,{\"src\":\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1629334277/Lightcone-02_stkgik.svg\",\"alt\":\"Lightcone Infrastructure\",\"width\":20,\"height\":20}]}]]}]}]]]}]}]}],[\"$\",\"$L2169\",null,{}]]}],[\"$\",\"$L216a\",null,{}]]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L216b\"],\"globalErrorComponent\":\"$216c\",\"missingSlots\":\"$W216d\"}]\n"])</script><script>self.__next_f.push([1,"216b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"AI 2027\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"A research-backed AI scenario forecast.\\n\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"AI 2027\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"A research-backed AI scenario forecast.\\n\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:image\",\"content\":\"https://ai-2027.com/opengraph.png\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:alt\",\"content\":\"AI 2027\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:creator\",\"content\":\"@AI_Futures_\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"AI 2027\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"A research-backed AI scenario forecast.\\n\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:image\",\"content\":\"https://ai-2027.com/opengraph.png\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:image:alt\",\"content\":\"AI 2027\"}]]\n6:null\n"])</script></body></html>
